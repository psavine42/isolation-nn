Epoch: 1/10, step: 19, training_loss: 3.85930
Epoch: 1/10, step: 39, training_loss: 3.84488
Epoch: 1/10, step: 59, training_loss: 3.92691
Epoch: 1/10, step: 79, training_loss: 3.89353
Epoch: 1/10, step: 99, training_loss: 3.93251
Epoch: 1/10, step: 119, training_loss: 3.88021
Epoch: 1/10, step: 139, training_loss: 3.89227
Epoch: 1/10, step: 159, training_loss: 3.85857
Epoch: 1/10, step: 179, training_loss: 3.89479
Epoch: 1/10, step: 199, training_loss: 3.91684
Epoch: 1/10, step: 219, training_loss: 3.81673
Epoch: 1/10, step: 239, training_loss: 3.84902
Epoch: 1/10, step: 259, training_loss: 3.89781
Epoch: 1/10, step: 279, training_loss: 3.88619
Epoch: 1/10, step: 299, training_loss: 3.86915
Epoch: 1/10, step: 319, training_loss: 3.86875
Epoch: 1/10, step: 339, training_loss: 3.87718
Epoch: 1/10, step: 359, training_loss: 3.87206
Epoch: 1/10, step: 379, training_loss: 3.87170
Epoch: 1/10, step: 399, training_loss: 3.88541
Epoch: 1/10, step: 419, training_loss: 3.86032
Epoch: 1/10, step: 439, training_loss: 3.86084
Epoch: 1/10, step: 459, training_loss: 3.89876
Epoch: 1/10, step: 479, training_loss: 3.85193
Epoch: 1/10, step: 499, training_loss: 3.91811
Epoch: 1/10, step: 519, training_loss: 3.80387
Epoch: 1/10, step: 539, training_loss: 3.87333
Epoch: 1/10, step: 559, training_loss: 3.82593
Epoch: 1/10, step: 579, training_loss: 3.88743
Epoch: 1/10, step: 599, training_loss: 3.86689
Epoch: 1/10, step: 619, training_loss: 3.86712
Epoch: 1/10, step: 639, training_loss: 3.87221
Epoch: 1/10, step: 659, training_loss: 3.82696
Epoch: 1/10, step: 679, training_loss: 3.90103
Epoch: 1/10, step: 699, training_loss: 3.81617
Epoch: 1/10, step: 719, training_loss: 3.84637
Epoch: 1/10, step: 739, training_loss: 3.87242
Epoch: 1/10, step: 759, training_loss: 3.76316
Epoch: 1/10, step: 779, training_loss: 3.79735
Epoch: 1/10, step: 799, training_loss: 3.92368
Epoch: 1/10, step: 819, training_loss: 3.86120
Epoch: 1/10, step: 839, training_loss: 3.74724
Epoch: 1/10, step: 859, training_loss: 3.85900
Epoch: 1/10, step: 879, training_loss: 3.92139
Epoch: 1/10, step: 899, training_loss: 3.76737
Epoch: 1/10, step: 919, training_loss: 3.89726
Epoch: 1/10, step: 939, training_loss: 3.93578
Epoch: 1/10, step: 959, training_loss: 3.79481
Epoch: 1/10, step: 979, training_loss: 3.82653
Epoch: 1/10, step: 999, training_loss: 3.89138
accuracy: 0.13, validation_loss: 3.789138078689575, num_samples: 100
Epoch: 1/10, step: 1019, training_loss: 3.85138
Epoch: 1/10, step: 1039, training_loss: 3.77181
Epoch: 1/10, step: 1059, training_loss: 3.87578
Epoch: 1/10, step: 1079, training_loss: 3.92527
Epoch: 1/10, step: 1099, training_loss: 3.71880
Epoch: 1/10, step: 1119, training_loss: 3.81445
Epoch: 1/10, step: 1139, training_loss: 3.65305
Epoch: 1/10, step: 1159, training_loss: 3.91520
Epoch: 1/10, step: 1179, training_loss: 3.79940
Epoch: 1/10, step: 1199, training_loss: 3.74686
Epoch: 1/10, step: 1219, training_loss: 3.88865
Epoch: 1/10, step: 1239, training_loss: 3.80987
Epoch: 1/10, step: 1259, training_loss: 3.69167
Epoch: 1/10, step: 1279, training_loss: 3.82704
Epoch: 1/10, step: 1299, training_loss: 3.87466
Epoch: 1/10, step: 1319, training_loss: 3.73845
Epoch: 1/10, step: 1339, training_loss: 3.66725
Epoch: 1/10, step: 1359, training_loss: 3.80310
Epoch: 1/10, step: 1379, training_loss: 3.53797
Epoch: 1/10, step: 1399, training_loss: 3.84087
Epoch: 1/10, step: 1419, training_loss: 3.59746
Epoch: 1/10, step: 1439, training_loss: 3.73969
Epoch: 1/10, step: 1459, training_loss: 3.92548
Epoch: 1/10, step: 1479, training_loss: 3.61187
Epoch: 1/10, step: 1499, training_loss: 3.62075
Epoch: 1/10, step: 1519, training_loss: 3.56887
Epoch: 1/10, step: 1539, training_loss: 3.62602
Epoch: 1/10, step: 1559, training_loss: 3.33642
Epoch: 1/10, step: 1579, training_loss: 3.52947
Epoch: 1/10, step: 1599, training_loss: 3.53414
Epoch: 1/10, step: 1619, training_loss: 3.54895
Epoch: 1/10, step: 1639, training_loss: 3.63086
Epoch: 1/10, step: 1659, training_loss: 3.39057
Epoch: 1/10, step: 1679, training_loss: 3.80894
Epoch: 1/10, step: 1699, training_loss: 3.62969
Epoch: 1/10, step: 1719, training_loss: 3.65396
Epoch: 1/10, step: 1739, training_loss: 3.18429
Epoch: 1/10, step: 1759, training_loss: 3.34783
Epoch: 1/10, step: 1779, training_loss: 3.63988
Epoch: 1/10, step: 1799, training_loss: 3.09448
Epoch: 1/10, step: 1819, training_loss: 3.61391
Epoch: 1/10, step: 1839, training_loss: 3.46589
Epoch: 1/10, step: 1859, training_loss: 2.97150
Epoch: 1/10, step: 1879, training_loss: 3.36202
Epoch: 1/10, step: 1899, training_loss: 3.10637
Epoch: 1/10, step: 1919, training_loss: 3.18042
Epoch: 1/10, step: 1939, training_loss: 2.97079
Epoch: 1/10, step: 1959, training_loss: 3.30500
Epoch: 1/10, step: 1979, training_loss: 2.81765
Epoch: 1/10, step: 1999, training_loss: 3.42398
accuracy: 0.32, validation_loss: 3.107907772064209, num_samples: 100
Epoch: 1/10, step: 2019, training_loss: 2.91666
Epoch: 1/10, step: 2039, training_loss: 2.44025
Epoch: 1/10, step: 2059, training_loss: 2.88289
Epoch: 1/10, step: 2079, training_loss: 2.10460
Epoch: 1/10, step: 2099, training_loss: 3.07590
Epoch: 1/10, step: 2119, training_loss: 3.25262
Epoch: 1/10, step: 2139, training_loss: 3.18024
Epoch: 1/10, step: 2159, training_loss: 3.05827
Epoch: 1/10, step: 2179, training_loss: 2.66367
Epoch: 1/10, step: 2199, training_loss: 2.86913
Epoch: 1/10, step: 2219, training_loss: 2.35403
Epoch: 1/10, step: 2239, training_loss: 2.64089
Epoch: 1/10, step: 2259, training_loss: 2.98348
Epoch: 1/10, step: 2279, training_loss: 2.29670
Epoch: 1/10, step: 2299, training_loss: 2.37425
Epoch: 1/10, step: 2319, training_loss: 2.06715
Epoch: 1/10, step: 2339, training_loss: 3.63359
Epoch: 1/10, step: 2359, training_loss: 2.51669
Epoch: 1/10, step: 2379, training_loss: 2.87768
Epoch: 1/10, step: 2399, training_loss: 1.61733
Epoch: 1/10, step: 2419, training_loss: 2.36048
Epoch: 1/10, step: 2439, training_loss: 1.61475
Epoch: 1/10, step: 2459, training_loss: 2.73598
Epoch: 1/10, step: 2479, training_loss: 3.41854
Epoch: 1/10, step: 2499, training_loss: 2.85484
Epoch: 1/10, step: 2519, training_loss: 3.67608
Epoch: 1/10, step: 2539, training_loss: 2.14095
Epoch: 1/10, step: 2559, training_loss: 3.03183
Epoch: 1/10, step: 2579, training_loss: 2.04154
Epoch: 1/10, step: 2599, training_loss: 3.18356
Epoch: 1/10, step: 2619, training_loss: 2.97190
Epoch: 1/10, step: 2639, training_loss: 1.86194
Epoch: 1/10, step: 2659, training_loss: 2.12465
Epoch: 1/10, step: 2679, training_loss: 2.82042
Epoch: 1/10, step: 2699, training_loss: 2.74141
Epoch: 1/10, step: 2719, training_loss: 1.90112
Epoch: 1/10, step: 2739, training_loss: 2.81479
Epoch: 1/10, step: 2759, training_loss: 2.72689
Epoch: 1/10, step: 2779, training_loss: 2.38917
Epoch: 1/10, step: 2799, training_loss: 2.79025
Epoch: 1/10, step: 2819, training_loss: 2.93975
Epoch: 1/10, step: 2839, training_loss: 2.65414
Epoch: 1/10, step: 2859, training_loss: 1.80530
Epoch: 1/10, step: 2879, training_loss: 2.33433
Epoch: 1/10, step: 2899, training_loss: 3.04962
Epoch: 1/10, step: 2919, training_loss: 1.72390
Epoch: 1/10, step: 2939, training_loss: 2.76391
Epoch: 1/10, step: 2959, training_loss: 2.45700
Epoch: 1/10, step: 2979, training_loss: 1.95414
Epoch: 1/10, step: 2999, training_loss: 2.51881
accuracy: 0.49, validation_loss: 1.8612500429153442, num_samples: 100
Epoch: 1/10, step: 3019, training_loss: 2.61100
Epoch: 1/10, step: 3039, training_loss: 2.18298
Epoch: 1/10, step: 3059, training_loss: 2.62639
Epoch: 1/10, step: 3079, training_loss: 2.13211
Epoch: 1/10, step: 3099, training_loss: 2.17042
Epoch: 1/10, step: 3119, training_loss: 2.25956
Epoch: 1/10, step: 3139, training_loss: 2.10205
Epoch: 1/10, step: 3159, training_loss: 2.95013
Epoch: 1/10, step: 3179, training_loss: 1.73695
Epoch: 1/10, step: 3199, training_loss: 2.26248
Epoch: 1/10, step: 3219, training_loss: 2.67488
Epoch: 1/10, step: 3239, training_loss: 2.21013
Epoch: 1/10, step: 3259, training_loss: 3.42867
Epoch: 1/10, step: 3279, training_loss: 2.09370
Epoch: 1/10, step: 3299, training_loss: 1.73755
Epoch: 1/10, step: 3319, training_loss: 2.19481
Epoch: 1/10, step: 3339, training_loss: 1.97147
Epoch: 1/10, step: 3359, training_loss: 1.53700
Epoch: 1/10, step: 3379, training_loss: 1.96759
Epoch: 1/10, step: 3399, training_loss: 1.64973
Epoch: 1/10, step: 3419, training_loss: 1.88418
Epoch: 1/10, step: 3439, training_loss: 2.17376
Epoch: 1/10, step: 3459, training_loss: 2.29581
Epoch: 1/10, step: 3479, training_loss: 2.19174
Epoch: 1/10, step: 3499, training_loss: 1.99422
Epoch: 1/10, step: 3519, training_loss: 1.60444
Epoch: 1/10, step: 3539, training_loss: 1.75271
Epoch: 1/10, step: 3559, training_loss: 1.90252
Epoch: 1/10, step: 3579, training_loss: 2.18295
Epoch: 1/10, step: 3599, training_loss: 2.23219
Epoch: 1/10, step: 3619, training_loss: 2.26940
Epoch: 1/10, step: 3639, training_loss: 1.34280
Epoch: 1/10, step: 3659, training_loss: 2.40055
Epoch: 1/10, step: 3679, training_loss: 2.34700
Epoch: 1/10, step: 3699, training_loss: 2.15967
Epoch: 1/10, step: 3719, training_loss: 2.87296
Epoch: 1/10, step: 3739, training_loss: 2.22637
Epoch: 1/10, step: 3759, training_loss: 2.33436
Epoch: 1/10, step: 3779, training_loss: 2.83732
Epoch: 1/10, step: 3799, training_loss: 2.23539
Epoch: 1/10, step: 3819, training_loss: 1.59633
Epoch: 1/10, step: 3839, training_loss: 2.42408
Epoch: 1/10, step: 3859, training_loss: 2.68893
Epoch: 1/10, step: 3879, training_loss: 2.08544
Epoch: 1/10, step: 3899, training_loss: 1.80964
Epoch: 1/10, step: 3919, training_loss: 1.78664
Epoch: 1/10, step: 3939, training_loss: 1.89042
Epoch: 1/10, step: 3959, training_loss: 1.86333
Epoch: 1/10, step: 3979, training_loss: 1.93852
Epoch: 1/10, step: 3999, training_loss: 1.19523
accuracy: 0.52, validation_loss: 1.7056063413619995, num_samples: 100
Epoch: 1/10, step: 4019, training_loss: 0.92245
Epoch: 1/10, step: 4039, training_loss: 1.26270
Epoch: 1/10, step: 4059, training_loss: 1.85234
Epoch: 1/10, step: 4079, training_loss: 1.98453
Epoch: 1/10, step: 4099, training_loss: 2.03990
Epoch: 1/10, step: 4119, training_loss: 1.45486
Epoch: 1/10, step: 4139, training_loss: 2.18593
Epoch: 1/10, step: 4159, training_loss: 1.38213
Epoch: 1/10, step: 4179, training_loss: 2.25427
Epoch: 1/10, step: 4199, training_loss: 2.12945
Epoch: 1/10, step: 4219, training_loss: 2.34213
Epoch: 1/10, step: 4239, training_loss: 1.76902
Epoch: 1/10, step: 4259, training_loss: 2.08316
Epoch: 1/10, step: 4279, training_loss: 1.57102
Epoch: 1/10, step: 4299, training_loss: 2.59471
Epoch: 1/10, step: 4319, training_loss: 1.66409
Epoch: 1/10, step: 4339, training_loss: 1.54522
Epoch: 1/10, step: 4359, training_loss: 1.46534
Epoch: 1/10, step: 4379, training_loss: 1.65457
Epoch: 1/10, step: 4399, training_loss: 2.07527
Epoch: 1/10, step: 4419, training_loss: 1.63958
Epoch: 1/10, step: 4439, training_loss: 2.45050
Epoch: 1/10, step: 4459, training_loss: 1.80160
Epoch: 1/10, step: 4479, training_loss: 1.93463
Epoch: 1/10, step: 4499, training_loss: 1.61013
Epoch: 1/10, step: 4519, training_loss: 1.69866
Epoch: 1/10, step: 4539, training_loss: 2.37459
Epoch: 1/10, step: 4559, training_loss: 2.11838
Epoch: 1/10, step: 4579, training_loss: 2.00484
Epoch: 1/10, step: 4599, training_loss: 1.38457
Epoch: 1/10, step: 4619, training_loss: 1.47979
Epoch: 1/10, step: 4639, training_loss: 1.75276
Epoch: 1/10, step: 4659, training_loss: 2.43098
Epoch: 1/10, step: 4679, training_loss: 1.35764
Epoch: 1/10, step: 4699, training_loss: 1.60504
Epoch: 1/10, step: 4719, training_loss: 1.71238
Epoch: 1/10, step: 4739, training_loss: 1.85276
Epoch: 1/10, step: 4759, training_loss: 1.63535
Epoch: 1/10, step: 4779, training_loss: 1.89678
Epoch: 1/10, step: 4799, training_loss: 1.88532
Epoch: 1/10, step: 4819, training_loss: 1.15924
Epoch: 1/10, step: 4839, training_loss: 1.43920
Epoch: 1/10, step: 4859, training_loss: 1.57137
Epoch: 1/10, step: 4879, training_loss: 1.65375
Epoch: 1/10, step: 4899, training_loss: 2.88313
Epoch: 1/10, step: 4919, training_loss: 2.56804
Epoch: 1/10, step: 4939, training_loss: 1.98568
Epoch: 1/10, step: 4959, training_loss: 1.63850
Epoch: 1/10, step: 4979, training_loss: 0.97835
Epoch: 1/10, step: 4999, training_loss: 2.50572
accuracy: 0.36, validation_loss: 2.020317792892456, num_samples: 100
Epoch: 1/10, step: 5019, training_loss: 2.09846
Epoch: 1/10, step: 5039, training_loss: 1.41946
Epoch: 1/10, step: 5059, training_loss: 2.50485
Epoch: 1/10, step: 5079, training_loss: 2.23057
Epoch: 1/10, step: 5099, training_loss: 1.72103
Epoch: 1/10, step: 5119, training_loss: 1.68792
Epoch: 1/10, step: 5139, training_loss: 2.31799
Epoch: 1/10, step: 5159, training_loss: 1.23793
Epoch: 1/10, step: 5179, training_loss: 1.13663
Epoch: 1/10, step: 5199, training_loss: 1.26931
Epoch: 1/10, step: 5219, training_loss: 1.97068
Epoch: 1/10, step: 5239, training_loss: 1.64832
Epoch: 1/10, step: 5259, training_loss: 1.86080
Epoch: 1/10, step: 5279, training_loss: 2.01351
Epoch: 1/10, step: 5299, training_loss: 2.51560
Epoch: 1/10, step: 5319, training_loss: 2.27428
Epoch: 1/10, step: 5339, training_loss: 2.24581
Epoch: 1/10, step: 5359, training_loss: 1.82146
Epoch: 1/10, step: 5379, training_loss: 1.63045
Epoch: 1/10, step: 5399, training_loss: 2.24413
Epoch: 1/10, step: 5419, training_loss: 2.05456
Epoch: 1/10, step: 5439, training_loss: 2.54115
Epoch: 1/10, step: 5459, training_loss: 2.03320
Epoch: 1/10, step: 5479, training_loss: 1.95623
Epoch: 1/10, step: 5499, training_loss: 2.04913
Epoch: 1/10, step: 5519, training_loss: 1.73481
Epoch: 1/10, step: 5539, training_loss: 2.50403
Epoch: 1/10, step: 5559, training_loss: 1.90168
Epoch: 1/10, step: 5579, training_loss: 1.55971
Epoch: 1/10, step: 5599, training_loss: 1.34165
Epoch: 1/10, step: 5619, training_loss: 1.49686
Epoch: 1/10, step: 5639, training_loss: 0.70717
Epoch: 1/10, step: 5659, training_loss: 2.32022
Epoch: 1/10, step: 5679, training_loss: 2.17026
Epoch: 1/10, step: 5699, training_loss: 1.93400
Epoch: 1/10, step: 5719, training_loss: 2.65350
Epoch: 1/10, step: 5739, training_loss: 1.79894
Epoch: 1/10, step: 5759, training_loss: 2.13838
Epoch: 1/10, step: 5779, training_loss: 2.42957
Epoch: 1/10, step: 5799, training_loss: 1.84076
Epoch: 1/10, step: 5819, training_loss: 1.81644
Epoch: 1/10, step: 5839, training_loss: 2.13335
Epoch: 1/10, step: 5859, training_loss: 2.53676
Epoch: 1/10, step: 5879, training_loss: 1.84344
Epoch: 1/10, step: 5899, training_loss: 1.85543
Epoch: 1/10, step: 5919, training_loss: 1.61832
Epoch: 1/10, step: 5939, training_loss: 1.98155
Epoch: 1/10, step: 5959, training_loss: 1.64633
Epoch: 1/10, step: 5979, training_loss: 2.27172
Epoch: 1/10, step: 5999, training_loss: 1.47990
accuracy: 0.41, validation_loss: 1.9232707023620605, num_samples: 100
Epoch: 1/10, step: 6019, training_loss: 2.32798
Epoch: 1/10, step: 6039, training_loss: 1.73032
Epoch: 1/10, step: 6059, training_loss: 1.62704
Epoch: 1/10, step: 6079, training_loss: 1.70631
Epoch: 1/10, step: 6099, training_loss: 1.22012
Epoch: 1/10, step: 6119, training_loss: 1.52351
Epoch: 1/10, step: 6139, training_loss: 1.45361
Epoch: 1/10, step: 6159, training_loss: 2.03052
Epoch: 1/10, step: 6179, training_loss: 1.75974
Epoch: 1/10, step: 6199, training_loss: 1.98190
Epoch: 1/10, step: 6219, training_loss: 1.61343
Epoch: 1/10, step: 6239, training_loss: 1.14629
Epoch: 1/10, step: 6259, training_loss: 1.61969
Epoch: 1/10, step: 6279, training_loss: 1.58645
Epoch: 1/10, step: 6299, training_loss: 1.72197
Epoch: 1/10, step: 6319, training_loss: 2.21311
Epoch: 1/10, step: 6339, training_loss: 1.82981
Epoch: 1/10, step: 6359, training_loss: 2.10651
Epoch: 1/10, step: 6379, training_loss: 1.97243
Epoch: 1/10, step: 6399, training_loss: 1.46889
Epoch: 1/10, step: 6419, training_loss: 1.41462
Epoch: 1/10, step: 6439, training_loss: 1.82471
Epoch: 1/10, step: 6459, training_loss: 2.23358
Epoch: 1/10, step: 6479, training_loss: 1.46698
Epoch: 1/10, step: 6499, training_loss: 1.47226
Epoch: 1/10, step: 6519, training_loss: 2.24837
Epoch: 1/10, step: 6539, training_loss: 1.16174
Epoch: 1/10, step: 6559, training_loss: 1.77672
Epoch: 1/10, step: 6579, training_loss: 1.49799
Epoch: 1/10, step: 6599, training_loss: 1.62300
Epoch: 1/10, step: 6619, training_loss: 1.97929
Epoch: 1/10, step: 6639, training_loss: 2.35266
Epoch: 1/10, step: 6659, training_loss: 0.91218
Epoch: 1/10, step: 6679, training_loss: 1.45394
Epoch: 1/10, step: 6699, training_loss: 1.75234
Epoch: 1/10, step: 6719, training_loss: 1.16007
Epoch: 1/10, step: 6739, training_loss: 1.68826
Epoch: 1/10, step: 6759, training_loss: 1.22251
Epoch: 1/10, step: 6779, training_loss: 1.50391
Epoch: 1/10, step: 6799, training_loss: 1.50228
Epoch: 1/10, step: 6819, training_loss: 1.68780
Epoch: 1/10, step: 6839, training_loss: 1.50960
Epoch: 1/10, step: 6859, training_loss: 1.44790
Epoch: 1/10, step: 6879, training_loss: 1.90675
Epoch: 1/10, step: 6899, training_loss: 1.66511
Epoch: 1/10, step: 6919, training_loss: 2.19181
Epoch: 1/10, step: 6939, training_loss: 1.67825
Epoch: 1/10, step: 6959, training_loss: 2.10086
Epoch: 1/10, step: 6979, training_loss: 1.52266
Epoch: 1/10, step: 6999, training_loss: 1.46063
accuracy: 0.36, validation_loss: 1.7827229499816895, num_samples: 100
Epoch: 1/10, step: 7019, training_loss: 2.04078
Epoch: 1/10, step: 7039, training_loss: 1.98347
Epoch: 1/10, step: 7059, training_loss: 2.16979
Epoch: 1/10, step: 7079, training_loss: 1.93789
Epoch: 1/10, step: 7099, training_loss: 1.53673
Epoch: 1/10, step: 7119, training_loss: 1.29560
Epoch: 1/10, step: 7139, training_loss: 1.61684
Epoch: 1/10, step: 7159, training_loss: 1.48299
Epoch: 1/10, step: 7179, training_loss: 1.85586
Epoch: 1/10, step: 7199, training_loss: 1.60965
Epoch: 1/10, step: 7219, training_loss: 1.54674
Epoch: 1/10, step: 7239, training_loss: 2.38750
Epoch: 1/10, step: 7259, training_loss: 2.34791
Epoch: 1/10, step: 7279, training_loss: 2.14524
Epoch: 1/10, step: 7299, training_loss: 2.43062
Epoch: 1/10, step: 7319, training_loss: 1.56987
Epoch: 1/10, step: 7339, training_loss: 2.06969
Epoch: 1/10, step: 7359, training_loss: 2.46502
Epoch: 1/10, step: 7379, training_loss: 1.81988
Epoch: 1/10, step: 7399, training_loss: 1.29966
Epoch: 1/10, step: 7419, training_loss: 1.69706
Epoch: 1/10, step: 7439, training_loss: 2.42854
Epoch: 1/10, step: 7459, training_loss: 1.70632
Epoch: 1/10, step: 7479, training_loss: 1.73253
Epoch: 1/10, step: 7499, training_loss: 1.37269
Epoch: 1/10, step: 7519, training_loss: 2.12982
Epoch: 1/10, step: 7539, training_loss: 1.38759
Epoch: 1/10, step: 7559, training_loss: 1.91071
Epoch: 1/10, step: 7579, training_loss: 1.44337
Epoch: 1/10, step: 7599, training_loss: 2.04217
Epoch: 1/10, step: 7619, training_loss: 2.09510
Epoch: 1/10, step: 7639, training_loss: 2.00891
Epoch: 1/10, step: 7659, training_loss: 0.72819
Epoch: 1/10, step: 7679, training_loss: 1.75493
Epoch: 1/10, step: 7699, training_loss: 2.28553
Epoch: 1/10, step: 7719, training_loss: 2.17430
Epoch: 1/10, step: 7739, training_loss: 2.03290
Epoch: 1/10, step: 7759, training_loss: 1.73502
Epoch: 1/10, step: 7779, training_loss: 1.82981
Epoch: 1/10, step: 7799, training_loss: 1.84132
Epoch: 1/10, step: 7819, training_loss: 1.47971
Epoch: 1/10, step: 7839, training_loss: 2.22848
Epoch: 1/10, step: 7859, training_loss: 2.59259
Epoch: 1/10, step: 7879, training_loss: 1.32779
Epoch: 1/10, step: 7899, training_loss: 1.34725
Epoch: 1/10, step: 7919, training_loss: 1.81427
Epoch: 1/10, step: 7939, training_loss: 1.84048
Epoch: 1/10, step: 7959, training_loss: 2.68089
Epoch: 1/10, step: 7979, training_loss: 1.59958
Epoch: 1/10, step: 7999, training_loss: 2.07891
accuracy: 0.43, validation_loss: 1.8699400424957275, num_samples: 100
Epoch: 1/10, step: 8019, training_loss: 2.22880
Epoch: 1/10, step: 8039, training_loss: 1.61021
Epoch: 1/10, step: 8059, training_loss: 1.75941
Epoch: 1/10, step: 8079, training_loss: 1.34897
Epoch: 1/10, step: 8099, training_loss: 2.30859
Epoch: 1/10, step: 8119, training_loss: 2.01935
Epoch: 1/10, step: 8139, training_loss: 2.43273
Epoch: 1/10, step: 8159, training_loss: 2.12446
Epoch: 1/10, step: 8179, training_loss: 2.03887
Epoch: 1/10, step: 8199, training_loss: 1.27924
Epoch: 1/10, step: 8219, training_loss: 1.87175
Epoch: 1/10, step: 8239, training_loss: 2.58826
Epoch: 1/10, step: 8259, training_loss: 2.50039
Epoch: 1/10, step: 8279, training_loss: 1.70922
Epoch: 1/10, step: 8299, training_loss: 1.98951
Epoch: 1/10, step: 8319, training_loss: 1.68690
Epoch: 1/10, step: 8339, training_loss: 1.88413
Epoch: 1/10, step: 8359, training_loss: 2.47526
Epoch: 1/10, step: 8379, training_loss: 2.01214
Epoch: 1/10, step: 8399, training_loss: 1.20439
Epoch: 1/10, step: 8419, training_loss: 1.67274
Epoch: 1/10, step: 8439, training_loss: 2.08165
Epoch: 1/10, step: 8459, training_loss: 0.88388
Epoch: 1/10, step: 8479, training_loss: 1.70151
Epoch: 1/10, step: 8499, training_loss: 2.10377
Epoch: 1/10, step: 8519, training_loss: 1.61785
Epoch: 1/10, step: 8539, training_loss: 1.39570
Epoch: 1/10, step: 8559, training_loss: 1.63263
Epoch: 1/10, step: 8579, training_loss: 1.38939
Epoch: 1/10, step: 8599, training_loss: 1.52586
Epoch: 1/10, step: 8619, training_loss: 1.69096
Epoch: 1/10, step: 8639, training_loss: 1.95973
Epoch: 1/10, step: 8659, training_loss: 0.91440
Epoch: 1/10, step: 8679, training_loss: 1.44677
Epoch: 1/10, step: 8699, training_loss: 2.04015
Epoch: 1/10, step: 8719, training_loss: 1.63219
Epoch: 1/10, step: 8739, training_loss: 2.02494
Epoch: 1/10, step: 8759, training_loss: 1.74037
Epoch: 1/10, step: 8779, training_loss: 1.79657
Epoch: 1/10, step: 8799, training_loss: 1.73323
Epoch: 1/10, step: 8819, training_loss: 1.62350
Epoch: 1/10, step: 8839, training_loss: 1.98301
Epoch: 1/10, step: 8859, training_loss: 1.70037
Epoch: 1/10, step: 8879, training_loss: 1.86188
Epoch: 1/10, step: 8899, training_loss: 1.95148
Epoch: 1/10, step: 8919, training_loss: 1.43090
Epoch: 1/10, step: 8939, training_loss: 2.06439
Epoch: 1/10, step: 8959, training_loss: 1.72354
Epoch: 1/10, step: 8979, training_loss: 1.42984
Epoch: 1/10, step: 8999, training_loss: 1.49676
accuracy: 0.43, validation_loss: 1.651877999305725, num_samples: 100
Epoch: 1/10, step: 9019, training_loss: 1.32861
Epoch: 1/10, step: 9039, training_loss: 1.45160
Epoch: 1/10, step: 9059, training_loss: 2.30327
Epoch: 1/10, step: 9079, training_loss: 1.63108
Epoch: 1/10, step: 9099, training_loss: 1.89247
Epoch: 1/10, step: 9119, training_loss: 1.91797
Epoch: 1/10, step: 9139, training_loss: 1.43626
Epoch: 1/10, step: 9159, training_loss: 0.80439
Epoch: 1/10, step: 9179, training_loss: 2.05894
Epoch: 1/10, step: 9199, training_loss: 1.38386
Epoch: 1/10, step: 9219, training_loss: 1.79644
Epoch: 1/10, step: 9239, training_loss: 2.15823
Epoch: 1/10, step: 9259, training_loss: 1.70880
Epoch: 1/10, step: 9279, training_loss: 1.51039
Epoch: 1/10, step: 9299, training_loss: 1.76642
Epoch: 1/10, step: 9319, training_loss: 1.76568
Epoch: 1/10, step: 9339, training_loss: 2.04609
Epoch: 1/10, step: 9359, training_loss: 1.80216
Epoch: 1/10, step: 9379, training_loss: 2.34647
Epoch: 1/10, step: 9399, training_loss: 1.09168
Epoch: 1/10, step: 9419, training_loss: 1.98369
Epoch: 1/10, step: 9439, training_loss: 1.60571
Epoch: 1/10, step: 9459, training_loss: 1.89750
Epoch: 1/10, step: 9479, training_loss: 1.95280
Epoch: 1/10, step: 9499, training_loss: 1.95052
Epoch: 1/10, step: 9519, training_loss: 1.88271
Epoch: 1/10, step: 9539, training_loss: 1.97816
Epoch: 1/10, step: 9559, training_loss: 1.93760
Epoch: 1/10, step: 9579, training_loss: 1.73929
Epoch: 1/10, step: 9599, training_loss: 1.75538
Epoch: 1/10, step: 9619, training_loss: 1.90959
Epoch: 1/10, step: 9639, training_loss: 1.45179
Epoch: 1/10, step: 9659, training_loss: 1.40189
Epoch: 1/10, step: 9679, training_loss: 0.93763
Epoch: 1/10, step: 9699, training_loss: 1.31852
Epoch: 1/10, step: 9719, training_loss: 1.64764
Epoch: 1/10, step: 9739, training_loss: 1.77813
Epoch: 1/10, step: 9759, training_loss: 1.83045
Epoch: 1/10, step: 9779, training_loss: 1.72212
Epoch: 1/10, step: 9799, training_loss: 1.51194
Epoch: 1/10, step: 9819, training_loss: 2.45893
Epoch: 1/10, step: 9839, training_loss: 1.76663
Epoch: 1/10, step: 9859, training_loss: 1.65358
Epoch: 1/10, step: 9879, training_loss: 1.81358
Epoch: 1/10, step: 9899, training_loss: 1.66316
Epoch: 1/10, step: 9919, training_loss: 1.46248
Epoch: 1/10, step: 9939, training_loss: 1.59698
Epoch: 1/10, step: 9959, training_loss: 1.22013
Epoch: 1/10, step: 9979, training_loss: 1.26448
Epoch: 1/10, step: 9999, training_loss: 1.69433
accuracy: 0.4, validation_loss: 1.6339322328567505, num_samples: 100
Epoch: 1/10, step: 10019, training_loss: 0.90084
Epoch: 1/10, step: 10039, training_loss: 1.68117
Epoch: 1/10, step: 10059, training_loss: 1.56474
Epoch: 1/10, step: 10079, training_loss: 1.66009
Epoch: 1/10, step: 10099, training_loss: 1.66721
Epoch: 1/10, step: 10119, training_loss: 1.49652
Epoch: 1/10, step: 10139, training_loss: 2.00851
Epoch: 1/10, step: 10159, training_loss: 1.61839
Epoch: 1/10, step: 10179, training_loss: 2.21296
Epoch: 1/10, step: 10199, training_loss: 1.72767
Epoch: 1/10, step: 10219, training_loss: 1.41680
Epoch: 1/10, step: 10239, training_loss: 1.61317
Epoch: 1/10, step: 10259, training_loss: 1.75025
Epoch: 1/10, step: 10279, training_loss: 1.31153
Epoch: 1/10, step: 10299, training_loss: 1.71286
Epoch: 1/10, step: 10319, training_loss: 2.04755
Epoch: 1/10, step: 10339, training_loss: 1.58944
Epoch: 1/10, step: 10359, training_loss: 1.27833
Epoch: 1/10, step: 10379, training_loss: 1.34036
Epoch: 1/10, step: 10399, training_loss: 1.77548
Epoch: 1/10, step: 10419, training_loss: 1.13105
Epoch: 1/10, step: 10439, training_loss: 1.40667
Epoch: 1/10, step: 10459, training_loss: 2.46847
Epoch: 1/10, step: 10479, training_loss: 1.45774
Epoch: 1/10, step: 10499, training_loss: 1.51889
Epoch: 1/10, step: 10519, training_loss: 1.86340
Epoch: 1/10, step: 10539, training_loss: 1.32322
Epoch: 1/10, step: 10559, training_loss: 1.55951
Epoch: 1/10, step: 10579, training_loss: 1.18794
Epoch: 1/10, step: 10599, training_loss: 1.40361
Epoch: 1/10, step: 10619, training_loss: 1.56470
Epoch: 1/10, step: 10639, training_loss: 2.37895
Epoch: 1/10, step: 10659, training_loss: 1.38627
Epoch: 1/10, step: 10679, training_loss: 1.93201
Epoch: 1/10, step: 10699, training_loss: 1.73892
Epoch: 1/10, step: 10719, training_loss: 2.03038
Epoch: 1/10, step: 10739, training_loss: 1.63991
Epoch: 1/10, step: 10759, training_loss: 2.09794
Epoch: 1/10, step: 10779, training_loss: 1.99859
Epoch: 1/10, step: 10799, training_loss: 1.89831
Epoch: 1/10, step: 10819, training_loss: 1.95388
Epoch: 1/10, step: 10839, training_loss: 1.80281
Epoch: 1/10, step: 10859, training_loss: 1.34352
Epoch: 1/10, step: 10879, training_loss: 1.74505
Epoch: 1/10, step: 10899, training_loss: 1.70739
Epoch: 1/10, step: 10919, training_loss: 1.81285
Epoch: 1/10, step: 10939, training_loss: 2.06874
Epoch: 1/10, step: 10959, training_loss: 1.78785
Epoch: 1/10, step: 10979, training_loss: 1.62056
Epoch: 1/10, step: 10999, training_loss: 1.65069
accuracy: 0.36, validation_loss: 1.902092695236206, num_samples: 100
Epoch: 1/10, step: 11019, training_loss: 1.11599
Epoch: 1/10, step: 11039, training_loss: 1.79411
Epoch: 1/10, step: 11059, training_loss: 1.38910
Epoch: 1/10, step: 11079, training_loss: 2.17178
Epoch: 1/10, step: 11099, training_loss: 1.93743
Epoch: 1/10, step: 11119, training_loss: 1.47685
Epoch: 1/10, step: 11139, training_loss: 2.42076
Epoch: 1/10, step: 11159, training_loss: 1.30713
Epoch: 1/10, step: 11179, training_loss: 1.16409
Epoch: 1/10, step: 11199, training_loss: 1.71104
Epoch: 1/10, step: 11219, training_loss: 1.77492
Epoch: 1/10, step: 11239, training_loss: 1.90520
Epoch: 1/10, step: 11259, training_loss: 1.21779
Epoch: 1/10, step: 11279, training_loss: 2.03259
Epoch: 1/10, step: 11299, training_loss: 1.81956
Epoch: 1/10, step: 11319, training_loss: 2.17595
Epoch: 1/10, step: 11339, training_loss: 2.18159
Epoch: 1/10, step: 11359, training_loss: 1.54358
Epoch: 1/10, step: 11379, training_loss: 2.13129
Epoch: 1/10, step: 11399, training_loss: 0.85000
Epoch: 1/10, step: 11419, training_loss: 1.16071
Epoch: 1/10, step: 11439, training_loss: 1.65483
Epoch: 1/10, step: 11459, training_loss: 1.49894
Epoch: 1/10, step: 11479, training_loss: 1.64002
Epoch: 1/10, step: 11499, training_loss: 1.73846
Epoch: 1/10, step: 11519, training_loss: 1.34653
Epoch: 1/10, step: 11539, training_loss: 1.54066
Epoch: 1/10, step: 11559, training_loss: 1.36132
Epoch: 1/10, step: 11579, training_loss: 1.70942
Epoch: 1/10, step: 11599, training_loss: 2.23930
Epoch: 1/10, step: 11619, training_loss: 1.75517
Epoch: 1/10, step: 11639, training_loss: 2.97734
Epoch: 1/10, step: 11659, training_loss: 1.10338
Epoch: 1/10, step: 11679, training_loss: 1.32575
Epoch: 1/10, step: 11699, training_loss: 1.65363
Epoch: 1/10, step: 11719, training_loss: 1.71996
Epoch: 1/10, step: 11739, training_loss: 1.64624
Epoch: 1/10, step: 11759, training_loss: 1.44029
Epoch: 1/10, step: 11779, training_loss: 2.05677
Epoch: 1/10, step: 11799, training_loss: 1.37976
Epoch: 1/10, step: 11819, training_loss: 1.19526
Epoch: 1/10, step: 11839, training_loss: 1.34113
Epoch: 1/10, step: 11859, training_loss: 1.49608
Epoch: 1/10, step: 11879, training_loss: 2.17943
Epoch: 1/10, step: 11899, training_loss: 1.66362
Epoch: 1/10, step: 11919, training_loss: 1.08244
Epoch: 1/10, step: 11939, training_loss: 1.64291
Epoch: 1/10, step: 11959, training_loss: 1.48696
Epoch: 1/10, step: 11979, training_loss: 1.51370
Epoch: 1/10, step: 11999, training_loss: 1.10244
accuracy: 0.44, validation_loss: 1.5376482009887695, num_samples: 100
Epoch: 1/10, step: 12019, training_loss: 1.72183
Epoch: 1/10, step: 12039, training_loss: 1.22725
Epoch: 1/10, step: 12059, training_loss: 1.26726
Epoch: 1/10, step: 12079, training_loss: 1.20418
Epoch: 1/10, step: 12099, training_loss: 2.18993
Epoch: 1/10, step: 12119, training_loss: 2.12345
Epoch: 1/10, step: 12139, training_loss: 1.99114
Epoch: 1/10, step: 12159, training_loss: 1.35147
Epoch: 1/10, step: 12179, training_loss: 1.70037
Epoch: 1/10, step: 12199, training_loss: 1.87577
Epoch: 1/10, step: 12219, training_loss: 0.80572
Epoch: 1/10, step: 12239, training_loss: 1.59659
Epoch: 1/10, step: 12259, training_loss: 1.43249
Epoch: 1/10, step: 12279, training_loss: 1.39889
Epoch: 1/10, step: 12299, training_loss: 1.56899
Epoch: 1/10, step: 12319, training_loss: 1.95381
Epoch: 1/10, step: 12339, training_loss: 2.36774
Epoch: 1/10, step: 12359, training_loss: 1.50648
Epoch: 1/10, step: 12379, training_loss: 1.82840
Epoch: 1/10, step: 12399, training_loss: 2.10916
Epoch: 1/10, step: 12419, training_loss: 1.76591
Epoch: 1/10, step: 12439, training_loss: 1.89957
Epoch: 1/10, step: 12459, training_loss: 2.05829
Epoch: 1/10, step: 12479, training_loss: 2.11754
Epoch: 1/10, step: 12499, training_loss: 1.82166
Epoch: 1/10, step: 12519, training_loss: 1.16527
Epoch: 1/10, step: 12539, training_loss: 1.75363
Epoch: 1/10, step: 12559, training_loss: 1.77779
Epoch: 1/10, step: 12579, training_loss: 1.53877
Epoch: 1/10, step: 12599, training_loss: 1.41673
Epoch: 1/10, step: 12619, training_loss: 1.61313
Epoch: 1/10, step: 12639, training_loss: 1.33098
Epoch: 1/10, step: 12659, training_loss: 2.31051
Epoch: 1/10, step: 12679, training_loss: 1.23282
Epoch: 1/10, step: 12699, training_loss: 1.66040
Epoch: 1/10, step: 12719, training_loss: 0.83895
Epoch: 1/10, step: 12739, training_loss: 1.78739
Epoch: 1/10, step: 12759, training_loss: 2.23211
Epoch: 1/10, step: 12779, training_loss: 2.29657
Epoch: 1/10, step: 12799, training_loss: 1.48562
Epoch: 1/10, step: 12819, training_loss: 2.04912
Epoch: 1/10, step: 12839, training_loss: 2.13028
Epoch: 1/10, step: 12859, training_loss: 2.04666
Epoch: 1/10, step: 12879, training_loss: 1.72193
Epoch: 1/10, step: 12899, training_loss: 1.83633
Epoch: 1/10, step: 12919, training_loss: 1.72392
Epoch: 1/10, step: 12939, training_loss: 2.25178
Epoch: 1/10, step: 12959, training_loss: 2.59679
Epoch: 1/10, step: 12979, training_loss: 2.01868
Epoch: 1/10, step: 12999, training_loss: 1.52607
accuracy: 0.47, validation_loss: 1.7559047937393188, num_samples: 100
Epoch: 1/10, step: 13019, training_loss: 1.62186
Epoch: 1/10, step: 13039, training_loss: 1.83564
Epoch: 1/10, step: 13059, training_loss: 1.86865
Epoch: 1/10, step: 13079, training_loss: 1.51078
Epoch: 1/10, step: 13099, training_loss: 2.19591
Epoch: 1/10, step: 13119, training_loss: 1.46758
Epoch: 1/10, step: 13139, training_loss: 2.56789
Epoch: 1/10, step: 13159, training_loss: 2.24533
Epoch: 1/10, step: 13179, training_loss: 1.23253
Epoch: 1/10, step: 13199, training_loss: 1.41617
Epoch: 1/10, step: 13219, training_loss: 2.09604
Epoch: 1/10, step: 13239, training_loss: 1.12547
Epoch: 1/10, step: 13259, training_loss: 1.41608
Epoch: 1/10, step: 13279, training_loss: 1.86578
Epoch: 1/10, step: 13299, training_loss: 2.25946
Epoch: 1/10, step: 13319, training_loss: 1.61239
Epoch: 1/10, step: 13339, training_loss: 1.69830
Epoch: 1/10, step: 13359, training_loss: 1.53364
Epoch: 1/10, step: 13379, training_loss: 1.20798
Epoch: 1/10, step: 13399, training_loss: 2.16427
Epoch: 1/10, step: 13419, training_loss: 1.94749
Epoch: 1/10, step: 13439, training_loss: 1.58203
Epoch: 1/10, step: 13459, training_loss: 1.03062
Epoch: 1/10, step: 13479, training_loss: 2.18043
Epoch: 1/10, step: 13499, training_loss: 2.25006
Epoch: 1/10, step: 13519, training_loss: 1.78345
Epoch: 1/10, step: 13539, training_loss: 1.27603
Epoch: 1/10, step: 13559, training_loss: 2.03878
Epoch: 1/10, step: 13579, training_loss: 1.10998
Epoch: 1/10, step: 13599, training_loss: 1.79313
Epoch: 1/10, step: 13619, training_loss: 1.42504
Epoch: 1/10, step: 13639, training_loss: 1.31581
Epoch: 1/10, step: 13659, training_loss: 1.56811
Epoch: 1/10, step: 13679, training_loss: 2.36519
Epoch: 1/10, step: 13699, training_loss: 1.68764
Epoch: 1/10, step: 13719, training_loss: 1.14904
Epoch: 1/10, step: 13739, training_loss: 1.48312
Epoch: 1/10, step: 13759, training_loss: 1.34169
Epoch: 1/10, step: 13779, training_loss: 2.46169
Epoch: 1/10, step: 13799, training_loss: 2.16746
Epoch: 1/10, step: 13819, training_loss: 2.10519
Epoch: 1/10, step: 13839, training_loss: 1.49807
Epoch: 1/10, step: 13859, training_loss: 1.64287
Epoch: 1/10, step: 13879, training_loss: 1.68063
Epoch: 1/10, step: 13899, training_loss: 1.40511
Epoch: 1/10, step: 13919, training_loss: 1.58529
Epoch: 1/10, step: 13939, training_loss: 1.99740
Epoch: 1/10, step: 13959, training_loss: 1.19147
Epoch: 1/10, step: 13979, training_loss: 1.65993
Epoch: 1/10, step: 13999, training_loss: 1.42443
accuracy: 0.5, validation_loss: 1.5968469381332397, num_samples: 100
Epoch: 1/10, step: 14019, training_loss: 2.29662
Epoch: 1/10, step: 14039, training_loss: 1.84121
Epoch: 1/10, step: 14059, training_loss: 1.60134
Epoch: 1/10, step: 14079, training_loss: 2.45886
Epoch: 1/10, step: 14099, training_loss: 1.27072
Epoch: 1/10, step: 14119, training_loss: 1.40492
Epoch: 1/10, step: 14139, training_loss: 1.51428
Epoch: 1/10, step: 14159, training_loss: 1.84564
Epoch: 1/10, step: 14179, training_loss: 1.56453
Epoch: 1/10, step: 14199, training_loss: 1.37563
Epoch: 1/10, step: 14219, training_loss: 1.45130
Epoch: 1/10, step: 14239, training_loss: 1.87593
Epoch: 1/10, step: 14259, training_loss: 1.63199
Epoch: 1/10, step: 14279, training_loss: 1.56134
Epoch: 1/10, step: 14299, training_loss: 2.53459
Epoch: 1/10, step: 14319, training_loss: 1.60006
Epoch: 1/10, step: 14339, training_loss: 1.31604
Epoch: 1/10, step: 14359, training_loss: 2.01640
Epoch: 1/10, step: 14379, training_loss: 1.48664
Epoch: 1/10, step: 14399, training_loss: 1.77553
Epoch: 1/10, step: 14419, training_loss: 2.77104
Epoch: 1/10, step: 14439, training_loss: 2.11241
Epoch: 1/10, step: 14459, training_loss: 0.96275
Epoch: 1/10, step: 14479, training_loss: 1.72666
Epoch: 1/10, step: 14499, training_loss: 1.35913
Epoch: 1/10, step: 14519, training_loss: 2.01513
Epoch: 1/10, step: 14539, training_loss: 1.91677
Epoch: 1/10, step: 14559, training_loss: 1.37485
Epoch: 1/10, step: 14579, training_loss: 1.34072
Epoch: 1/10, step: 14599, training_loss: 1.99307
Epoch: 1/10, step: 14619, training_loss: 1.92365
Epoch: 1/10, step: 14639, training_loss: 1.37181
Epoch: 1/10, step: 14659, training_loss: 1.22345
Epoch: 1/10, step: 14679, training_loss: 1.65126
Epoch: 1/10, step: 14699, training_loss: 2.59363
Epoch: 1/10, step: 14719, training_loss: 1.27705
Epoch: 1/10, step: 14739, training_loss: 2.03125
Epoch: 1/10, step: 14759, training_loss: 1.51594
Epoch: 1/10, step: 14779, training_loss: 1.86103
Epoch: 1/10, step: 14799, training_loss: 1.98177
Epoch: 1/10, step: 14819, training_loss: 1.55197
Epoch: 1/10, step: 14839, training_loss: 2.05445
Epoch: 1/10, step: 14859, training_loss: 1.18076
Epoch: 1/10, step: 14879, training_loss: 2.09814
Epoch: 1/10, step: 14899, training_loss: 1.86763
Epoch: 1/10, step: 14919, training_loss: 1.27687
Epoch: 1/10, step: 14939, training_loss: 1.72869
Epoch: 1/10, step: 14959, training_loss: 1.25010
Epoch: 1/10, step: 14979, training_loss: 1.64892
Epoch: 1/10, step: 14999, training_loss: 0.91298
accuracy: 0.41, validation_loss: 1.6279151439666748, num_samples: 100
Epoch: 1/10, step: 15019, training_loss: 1.51796
Epoch: 1/10, step: 15039, training_loss: 1.30262
Epoch: 1/10, step: 15059, training_loss: 1.71453
Epoch: 1/10, step: 15079, training_loss: 1.56937
Epoch: 1/10, step: 15099, training_loss: 1.19484
Epoch: 1/10, step: 15119, training_loss: 1.46310
Epoch: 1/10, step: 15139, training_loss: 1.82707
Epoch: 1/10, step: 15159, training_loss: 2.00609
Epoch: 1/10, step: 15179, training_loss: 2.01815
Epoch: 1/10, step: 15199, training_loss: 0.85782
Epoch: 1/10, step: 15219, training_loss: 1.98805
Epoch: 1/10, step: 15239, training_loss: 1.27668
Epoch: 1/10, step: 15259, training_loss: 2.32214
Epoch: 1/10, step: 15279, training_loss: 1.10908
Epoch: 1/10, step: 15299, training_loss: 1.64849
Epoch: 1/10, step: 15319, training_loss: 1.50183
Epoch: 1/10, step: 15339, training_loss: 2.01881
Epoch: 1/10, step: 15359, training_loss: 0.94552
Epoch: 1/10, step: 15379, training_loss: 1.83191
Epoch: 1/10, step: 15399, training_loss: 1.35621
Epoch: 1/10, step: 15419, training_loss: 1.49412
Epoch: 1/10, step: 15439, training_loss: 2.17622
Epoch: 1/10, step: 15459, training_loss: 2.29197
Epoch: 1/10, step: 15479, training_loss: 1.10071
Epoch: 1/10, step: 15499, training_loss: 1.57636
Epoch: 1/10, step: 15519, training_loss: 1.80797
Epoch: 1/10, step: 15539, training_loss: 2.14823
Epoch: 1/10, step: 15559, training_loss: 0.85193
Epoch: 1/10, step: 15579, training_loss: 1.38646
Epoch: 1/10, step: 15599, training_loss: 1.40442
Epoch: 1/10, step: 15619, training_loss: 1.74830
Epoch: 1/10, step: 15639, training_loss: 2.36668
Epoch: 1/10, step: 15659, training_loss: 1.38797
Epoch: 1/10, step: 15679, training_loss: 1.94035
Epoch: 1/10, step: 15699, training_loss: 1.96375
Epoch: 1/10, step: 15719, training_loss: 2.10042
Epoch: 1/10, step: 15739, training_loss: 1.86036
Epoch: 1/10, step: 15759, training_loss: 1.97636
Epoch: 1/10, step: 15779, training_loss: 1.55176
Epoch: 1/10, step: 15799, training_loss: 1.61264
Epoch: 1/10, step: 15819, training_loss: 1.75033
Epoch: 1/10, step: 15839, training_loss: 1.18728
Epoch: 1/10, step: 15859, training_loss: 1.88899
Epoch: 1/10, step: 15879, training_loss: 0.62390
Epoch: 1/10, step: 15899, training_loss: 1.65619
Epoch: 1/10, step: 15919, training_loss: 1.34905
Epoch: 1/10, step: 15939, training_loss: 2.05556
Epoch: 1/10, step: 15959, training_loss: 0.81826
Epoch: 1/10, step: 15979, training_loss: 1.45923
Epoch: 1/10, step: 15999, training_loss: 1.89956
accuracy: 0.42, validation_loss: 1.5667028427124023, num_samples: 100
Epoch: 1/10, step: 16019, training_loss: 1.24393
Epoch: 1/10, step: 16039, training_loss: 0.74327
Epoch: 1/10, step: 16059, training_loss: 1.21853
Epoch: 1/10, step: 16079, training_loss: 1.54437
Epoch: 1/10, step: 16099, training_loss: 1.67522
Epoch: 1/10, step: 16119, training_loss: 2.16129
Epoch: 1/10, step: 16139, training_loss: 1.97674
Epoch: 1/10, step: 16159, training_loss: 1.50612
Epoch: 1/10, step: 16179, training_loss: 1.50039
Epoch: 1/10, step: 16199, training_loss: 1.01219
Epoch: 1/10, step: 16219, training_loss: 2.47393
Epoch: 1/10, step: 16239, training_loss: 1.58501
Epoch: 1/10, step: 16259, training_loss: 1.62431
Epoch: 1/10, step: 16279, training_loss: 1.44439
Epoch: 1/10, step: 16299, training_loss: 1.39245
Epoch: 1/10, step: 16319, training_loss: 1.53500
Epoch: 1/10, step: 16339, training_loss: 1.44886
Epoch: 1/10, step: 16359, training_loss: 2.22414
Epoch: 1/10, step: 16379, training_loss: 1.26387
Epoch: 1/10, step: 16399, training_loss: 1.85282
Epoch: 1/10, step: 16419, training_loss: 1.59328
Epoch: 1/10, step: 16439, training_loss: 1.04570
Epoch: 1/10, step: 16459, training_loss: 1.10573
Epoch: 1/10, step: 16479, training_loss: 2.37461
Epoch: 1/10, step: 16499, training_loss: 1.18842
Epoch: 1/10, step: 16519, training_loss: 1.28114
Epoch: 1/10, step: 16539, training_loss: 2.10260
Epoch: 1/10, step: 16559, training_loss: 1.08315
Epoch: 1/10, step: 16579, training_loss: 2.12235
Epoch: 1/10, step: 16599, training_loss: 1.88511
Epoch: 1/10, step: 16619, training_loss: 1.91476
Epoch: 1/10, step: 16639, training_loss: 1.75951
Epoch: 1/10, step: 16659, training_loss: 1.90319
Epoch: 1/10, step: 16679, training_loss: 1.38825
Epoch: 1/10, step: 16699, training_loss: 1.71711
Epoch: 1/10, step: 16719, training_loss: 1.27114
Epoch: 1/10, step: 16739, training_loss: 1.58744
Epoch: 1/10, step: 16759, training_loss: 1.55632
Epoch: 1/10, step: 16779, training_loss: 1.13412
Epoch: 1/10, step: 16799, training_loss: 1.95667
Epoch: 1/10, step: 16819, training_loss: 1.37327
Epoch: 1/10, step: 16839, training_loss: 1.50926
Epoch: 1/10, step: 16859, training_loss: 1.64330
Epoch: 1/10, step: 16879, training_loss: 1.48711
Epoch: 1/10, step: 16899, training_loss: 1.70469
Epoch: 1/10, step: 16919, training_loss: 1.38975
Epoch: 1/10, step: 16939, training_loss: 1.91538
Epoch: 1/10, step: 16959, training_loss: 1.57416
Epoch: 1/10, step: 16979, training_loss: 1.23162
Epoch: 1/10, step: 16999, training_loss: 2.04674
accuracy: 0.51, validation_loss: 1.6895710229873657, num_samples: 100
Epoch: 1/10, step: 17019, training_loss: 1.89915
Epoch: 1/10, step: 17039, training_loss: 1.40010
Epoch: 1/10, step: 17059, training_loss: 1.69212
Epoch: 1/10, step: 17079, training_loss: 1.73822
Epoch: 1/10, step: 17099, training_loss: 1.75926
Epoch: 1/10, step: 17119, training_loss: 1.05649
Epoch: 1/10, step: 17139, training_loss: 2.12732
Epoch: 1/10, step: 17159, training_loss: 1.55679
Epoch: 1/10, step: 17179, training_loss: 1.34235
Epoch: 1/10, step: 17199, training_loss: 1.49383
Epoch: 1/10, step: 17219, training_loss: 1.78759
Epoch: 1/10, step: 17239, training_loss: 1.93906
Epoch: 1/10, step: 17259, training_loss: 1.41006
Epoch: 1/10, step: 17279, training_loss: 1.36962
Epoch: 1/10, step: 17299, training_loss: 2.00148
Epoch: 1/10, step: 17319, training_loss: 1.80561
Epoch: 1/10, step: 17339, training_loss: 1.60444
Epoch: 1/10, step: 17359, training_loss: 1.99891
Epoch: 1/10, step: 17379, training_loss: 1.09055
Epoch: 1/10, step: 17399, training_loss: 1.25445
Epoch: 1/10, step: 17419, training_loss: 1.58606
Epoch: 1/10, step: 17439, training_loss: 2.63589
Epoch: 1/10, step: 17459, training_loss: 1.22970
Epoch: 1/10, step: 17479, training_loss: 2.19007
Epoch: 1/10, step: 17499, training_loss: 1.40150
Epoch: 1/10, step: 17519, training_loss: 1.54100
Epoch: 1/10, step: 17539, training_loss: 1.67572
Epoch: 1/10, step: 17559, training_loss: 1.55690
Epoch: 1/10, step: 17579, training_loss: 1.37679
Epoch: 1/10, step: 17599, training_loss: 2.00795
Epoch: 1/10, step: 17619, training_loss: 1.88945
Epoch: 1/10, step: 17639, training_loss: 1.76061
Epoch: 1/10, step: 17659, training_loss: 1.37331
Epoch: 1/10, step: 17679, training_loss: 1.09404
Epoch: 1/10, step: 17699, training_loss: 1.99621
Epoch: 1/10, step: 17719, training_loss: 1.36380
Epoch: 1/10, step: 17739, training_loss: 2.05938
Epoch: 1/10, step: 17759, training_loss: 1.11018
Epoch: 1/10, step: 17779, training_loss: 1.35188
Epoch: 1/10, step: 17799, training_loss: 1.96022
Epoch: 1/10, step: 17819, training_loss: 1.40586
Epoch: 1/10, step: 17839, training_loss: 0.77559
Epoch: 1/10, step: 17859, training_loss: 2.11968
Epoch: 1/10, step: 17879, training_loss: 2.02400
Epoch: 1/10, step: 17899, training_loss: 1.91632
Epoch: 1/10, step: 17919, training_loss: 0.76296
Epoch: 1/10, step: 17939, training_loss: 1.79374
Epoch: 1/10, step: 17959, training_loss: 2.55793
Epoch: 1/10, step: 17979, training_loss: 1.58851
Epoch: 1/10, step: 17999, training_loss: 1.78018
accuracy: 0.44, validation_loss: 1.2088652849197388, num_samples: 100
Epoch: 1/10, step: 18019, training_loss: 1.76745
Epoch: 1/10, step: 18039, training_loss: 2.08007
Epoch: 1/10, step: 18059, training_loss: 1.28754
Epoch: 1/10, step: 18079, training_loss: 1.63842
Epoch: 1/10, step: 18099, training_loss: 1.86583
Epoch: 1/10, step: 18119, training_loss: 1.86025
Epoch: 1/10, step: 18139, training_loss: 1.91560
Epoch: 1/10, step: 18159, training_loss: 2.03447
Epoch: 1/10, step: 18179, training_loss: 1.93680
Epoch: 1/10, step: 18199, training_loss: 1.13557
Epoch: 1/10, step: 18219, training_loss: 1.23231
Epoch: 1/10, step: 18239, training_loss: 2.38126
Epoch: 1/10, step: 18259, training_loss: 1.39176
Epoch: 1/10, step: 18279, training_loss: 2.16090
Epoch: 1/10, step: 18299, training_loss: 1.61765
Epoch: 1/10, step: 18319, training_loss: 0.74801
Epoch: 1/10, step: 18339, training_loss: 1.37336
Epoch: 1/10, step: 18359, training_loss: 1.50807
Epoch: 1/10, step: 18379, training_loss: 2.14484
Epoch: 1/10, step: 18399, training_loss: 1.32282
Epoch: 1/10, step: 18419, training_loss: 1.88098
Epoch: 1/10, step: 18439, training_loss: 1.17155
Epoch: 1/10, step: 18459, training_loss: 0.89747
Epoch: 1/10, step: 18479, training_loss: 1.51120
Epoch: 1/10, step: 18499, training_loss: 1.95408
Epoch: 1/10, step: 18519, training_loss: 1.23082
Epoch: 1/10, step: 18539, training_loss: 1.28706
Epoch: 1/10, step: 18559, training_loss: 1.36035
Epoch: 1/10, step: 18579, training_loss: 1.99831
Epoch: 1/10, step: 18599, training_loss: 0.99948
Epoch: 1/10, step: 18619, training_loss: 1.43593
Epoch: 1/10, step: 18639, training_loss: 1.36142
Epoch: 1/10, step: 18659, training_loss: 1.49140
Epoch: 1/10, step: 18679, training_loss: 1.03883
Epoch: 1/10, step: 18699, training_loss: 1.85419
Epoch: 1/10, step: 18719, training_loss: 1.63643
Epoch: 1/10, step: 18739, training_loss: 1.79319
Epoch: 1/10, step: 18759, training_loss: 1.23579
Epoch: 1/10, step: 18779, training_loss: 1.91375
Epoch: 1/10, step: 18799, training_loss: 1.61923
Epoch: 1/10, step: 18819, training_loss: 1.13410
Epoch: 1/10, step: 18839, training_loss: 1.52126
Epoch: 1/10, step: 18859, training_loss: 1.27668
Epoch: 1/10, step: 18879, training_loss: 1.60739
Epoch: 1/10, step: 18899, training_loss: 1.12265
Epoch: 1/10, step: 18919, training_loss: 1.65791
Epoch: 1/10, step: 18939, training_loss: 1.89380
Epoch: 1/10, step: 18959, training_loss: 2.16763
Epoch: 1/10, step: 18979, training_loss: 2.62104
Epoch: 1/10, step: 18999, training_loss: 1.92777
accuracy: 0.54, validation_loss: 1.4528145790100098, num_samples: 100
Epoch: 1/10, step: 19019, training_loss: 1.38308
Epoch: 1/10, step: 19039, training_loss: 1.39826
Epoch: 1/10, step: 19059, training_loss: 1.50872
Epoch: 1/10, step: 19079, training_loss: 1.14136
Epoch: 1/10, step: 19099, training_loss: 1.68007
Epoch: 1/10, step: 19119, training_loss: 1.40630
Epoch: 1/10, step: 19139, training_loss: 1.72762
Epoch: 1/10, step: 19159, training_loss: 1.27860
Epoch: 1/10, step: 19179, training_loss: 1.43281
Epoch: 1/10, step: 19199, training_loss: 1.73961
Epoch: 1/10, step: 19219, training_loss: 1.20519
Epoch: 1/10, step: 19239, training_loss: 2.17984
Epoch: 1/10, step: 19259, training_loss: 1.23225
Epoch: 1/10, step: 19279, training_loss: 1.42367
Epoch: 1/10, step: 19299, training_loss: 1.85978
Epoch: 1/10, step: 19319, training_loss: 1.25673
Epoch: 1/10, step: 19339, training_loss: 1.34323
Epoch: 1/10, step: 19359, training_loss: 1.90369
Epoch: 1/10, step: 19379, training_loss: 2.47678
Epoch: 1/10, step: 19399, training_loss: 1.74329
Epoch: 1/10, step: 19419, training_loss: 1.70872
Epoch: 1/10, step: 19439, training_loss: 1.93676
Epoch: 1/10, step: 19459, training_loss: 1.72354
Epoch: 1/10, step: 19479, training_loss: 0.87776
Epoch: 1/10, step: 19499, training_loss: 1.58835
Epoch: 1/10, step: 19519, training_loss: 1.73928
Epoch: 1/10, step: 19539, training_loss: 1.69398
Epoch: 1/10, step: 19559, training_loss: 1.42159
Epoch: 1/10, step: 19579, training_loss: 1.57434
Epoch: 1/10, step: 19599, training_loss: 1.65621
Epoch: 1/10, step: 19619, training_loss: 1.87307
Epoch: 1/10, step: 19639, training_loss: 1.47375
Epoch: 1/10, step: 19659, training_loss: 1.77117
Epoch: 1/10, step: 19679, training_loss: 2.18954
Epoch: 1/10, step: 19699, training_loss: 2.25515
Epoch: 1/10, step: 19719, training_loss: 1.80262
Epoch: 1/10, step: 19739, training_loss: 1.94814
Epoch: 1/10, step: 19759, training_loss: 1.66894
Epoch: 1/10, step: 19779, training_loss: 1.05925
Epoch: 1/10, step: 19799, training_loss: 2.46288
Epoch: 1/10, step: 19819, training_loss: 1.74666
Epoch: 1/10, step: 19839, training_loss: 1.39992
Epoch: 1/10, step: 19859, training_loss: 2.37231
Epoch: 1/10, step: 19879, training_loss: 1.30132
Epoch: 1/10, step: 19899, training_loss: 1.33408
Epoch: 1/10, step: 19919, training_loss: 1.40695
Epoch: 1/10, step: 19939, training_loss: 1.63357
Epoch: 1/10, step: 19959, training_loss: 1.76009
Epoch: 1/10, step: 19979, training_loss: 1.34999
Epoch: 1/10, step: 19999, training_loss: 1.21582
accuracy: 0.46, validation_loss: 1.8525974750518799, num_samples: 100
Epoch: 1/10, step: 20019, training_loss: 1.77708
Epoch: 1/10, step: 20039, training_loss: 1.18383
Epoch: 1/10, step: 20059, training_loss: 1.20009
Epoch: 1/10, step: 20079, training_loss: 2.07378
Epoch: 1/10, step: 20099, training_loss: 1.43242
Epoch: 1/10, step: 20119, training_loss: 1.58744
Epoch: 1/10, step: 20139, training_loss: 1.69916
Epoch: 1/10, step: 20159, training_loss: 1.99488
Epoch: 1/10, step: 20179, training_loss: 1.36015
Epoch: 1/10, step: 20199, training_loss: 1.39132
Epoch: 1/10, step: 20219, training_loss: 1.83768
Epoch: 1/10, step: 20239, training_loss: 1.21610
Epoch: 1/10, step: 20259, training_loss: 1.88461
Epoch: 1/10, step: 20279, training_loss: 1.85541
Epoch: 1/10, step: 20299, training_loss: 1.62016
Epoch: 1/10, step: 20319, training_loss: 2.05847
Epoch: 1/10, step: 20339, training_loss: 1.41174
Epoch: 1/10, step: 20359, training_loss: 1.67621
Epoch: 1/10, step: 20379, training_loss: 2.20717
Epoch: 1/10, step: 20399, training_loss: 2.09572
Epoch: 1/10, step: 20419, training_loss: 1.31916
Epoch: 1/10, step: 20439, training_loss: 1.43848
Epoch: 1/10, step: 20459, training_loss: 1.62556
Epoch: 1/10, step: 20479, training_loss: 2.46645
Epoch: 1/10, step: 20499, training_loss: 1.68966
Epoch: 1/10, step: 20519, training_loss: 1.92819
Epoch: 1/10, step: 20539, training_loss: 0.96564
Epoch: 1/10, step: 20559, training_loss: 1.43645
Epoch: 1/10, step: 20579, training_loss: 1.00361
Epoch: 1/10, step: 20599, training_loss: 1.44000
Epoch: 1/10, step: 20619, training_loss: 1.11757
Epoch: 1/10, step: 20639, training_loss: 1.56281
Epoch: 1/10, step: 20659, training_loss: 1.54514
Epoch: 1/10, step: 20679, training_loss: 1.37916
Epoch: 1/10, step: 20699, training_loss: 1.66580
Epoch: 1/10, step: 20719, training_loss: 1.45308
Epoch: 1/10, step: 20739, training_loss: 1.85840
Epoch: 1/10, step: 20759, training_loss: 1.67330
Epoch: 1/10, step: 20779, training_loss: 1.95053
Epoch: 1/10, step: 20799, training_loss: 1.95832
Epoch: 1/10, step: 20819, training_loss: 1.90773
Epoch: 1/10, step: 20839, training_loss: 1.48785
Epoch: 1/10, step: 20859, training_loss: 1.78622
Epoch: 1/10, step: 20879, training_loss: 1.91383
Epoch: 1/10, step: 20899, training_loss: 1.95205
Epoch: 1/10, step: 20919, training_loss: 1.42701
Epoch: 1/10, step: 20939, training_loss: 1.11135
Epoch: 1/10, step: 20959, training_loss: 1.61346
Epoch: 1/10, step: 20979, training_loss: 1.09774
Epoch: 1/10, step: 20999, training_loss: 1.52067
accuracy: 0.42, validation_loss: 1.739484429359436, num_samples: 100
Epoch: 1/10, step: 21019, training_loss: 1.69202
Epoch: 1/10, step: 21039, training_loss: 1.18084
Epoch: 1/10, step: 21059, training_loss: 1.02154
Epoch: 1/10, step: 21079, training_loss: 1.84690
Epoch: 1/10, step: 21099, training_loss: 1.77257
Epoch: 1/10, step: 21119, training_loss: 1.37538
Epoch: 1/10, step: 21139, training_loss: 2.17502
Epoch: 1/10, step: 21159, training_loss: 1.53671
Epoch: 1/10, step: 21179, training_loss: 1.17143
Epoch: 1/10, step: 21199, training_loss: 2.03077
Epoch: 1/10, step: 21219, training_loss: 1.42176
Epoch: 1/10, step: 21239, training_loss: 1.62870
Epoch: 1/10, step: 21259, training_loss: 2.56414
Epoch: 1/10, step: 21279, training_loss: 1.28212
Epoch: 1/10, step: 21299, training_loss: 1.26278
Epoch: 1/10, step: 21319, training_loss: 1.80653
Epoch: 1/10, step: 21339, training_loss: 1.63741
Epoch: 1/10, step: 21359, training_loss: 2.00887
Epoch: 1/10, step: 21379, training_loss: 1.78227
Epoch: 1/10, step: 21399, training_loss: 1.34391
Epoch: 1/10, step: 21419, training_loss: 1.18417
Epoch: 1/10, step: 21439, training_loss: 1.48491
Epoch: 1/10, step: 21459, training_loss: 1.46502
Epoch: 1/10, step: 21479, training_loss: 1.85736
Epoch: 1/10, step: 21499, training_loss: 1.53160
Epoch: 1/10, step: 21519, training_loss: 1.57314
Epoch: 1/10, step: 21539, training_loss: 2.16962
Epoch: 1/10, step: 21559, training_loss: 0.88436
Epoch: 1/10, step: 21579, training_loss: 1.55353
Epoch: 1/10, step: 21599, training_loss: 1.92366
Epoch: 1/10, step: 21619, training_loss: 1.94382
Epoch: 1/10, step: 21639, training_loss: 1.24823
Epoch: 1/10, step: 21659, training_loss: 1.50169
Epoch: 1/10, step: 21679, training_loss: 1.16401
Epoch: 1/10, step: 21699, training_loss: 1.78833
Epoch: 1/10, step: 21719, training_loss: 2.29355
Epoch: 1/10, step: 21739, training_loss: 1.86629
Epoch: 1/10, step: 21759, training_loss: 1.20252
Epoch: 1/10, step: 21779, training_loss: 2.02916
Epoch: 1/10, step: 21799, training_loss: 2.70845
Epoch: 1/10, step: 21819, training_loss: 1.16500
Epoch: 1/10, step: 21839, training_loss: 1.15892
Epoch: 1/10, step: 21859, training_loss: 1.87387
Epoch: 1/10, step: 21879, training_loss: 1.87172
Epoch: 1/10, step: 21899, training_loss: 1.03940
Epoch: 1/10, step: 21919, training_loss: 1.87060
Epoch: 1/10, step: 21939, training_loss: 1.62847
Epoch: 1/10, step: 21959, training_loss: 1.59565
Epoch: 1/10, step: 21979, training_loss: 1.66241
Epoch: 1/10, step: 21999, training_loss: 1.14448
accuracy: 0.51, validation_loss: 1.6927250623703003, num_samples: 100
Epoch: 1/10, step: 22019, training_loss: 0.97418
Epoch: 1/10, step: 22039, training_loss: 1.19538
Epoch: 1/10, step: 22059, training_loss: 1.32158
Epoch: 1/10, step: 22079, training_loss: 1.87763
Epoch: 1/10, step: 22099, training_loss: 1.91627
Epoch: 1/10, step: 22119, training_loss: 1.68858
Epoch: 1/10, step: 22139, training_loss: 1.75987
Epoch: 1/10, step: 22159, training_loss: 2.36489
Epoch: 1/10, step: 22179, training_loss: 1.27493
Epoch: 1/10, step: 22199, training_loss: 1.18726
Epoch: 1/10, step: 22219, training_loss: 1.86011
Epoch: 1/10, step: 22239, training_loss: 1.85501
Epoch: 1/10, step: 22259, training_loss: 1.63278
Epoch: 1/10, step: 22279, training_loss: 1.44812
Epoch: 1/10, step: 22299, training_loss: 1.76070
Epoch: 1/10, step: 22319, training_loss: 1.51490
Epoch: 1/10, step: 22339, training_loss: 1.19253
Epoch: 1/10, step: 22359, training_loss: 0.98258
Epoch: 1/10, step: 22379, training_loss: 1.93550
Epoch: 1/10, step: 22399, training_loss: 1.56155
Epoch: 1/10, step: 22419, training_loss: 0.80728
Epoch: 1/10, step: 22439, training_loss: 1.67008
Epoch: 1/10, step: 22459, training_loss: 1.40314
Epoch: 1/10, step: 22479, training_loss: 1.02402
Epoch: 1/10, step: 22499, training_loss: 1.33429
Epoch: 1/10, step: 22519, training_loss: 1.38845
Epoch: 1/10, step: 22539, training_loss: 1.91311
Epoch: 1/10, step: 22559, training_loss: 1.65285
Epoch: 1/10, step: 22579, training_loss: 1.74369
Epoch: 1/10, step: 22599, training_loss: 0.73254
Epoch: 1/10, step: 22619, training_loss: 2.00855
Epoch: 1/10, step: 22639, training_loss: 1.77795
Epoch: 1/10, step: 22659, training_loss: 1.38408
Epoch: 1/10, step: 22679, training_loss: 1.04224
Epoch: 1/10, step: 22699, training_loss: 1.90485
Epoch: 1/10, step: 22719, training_loss: 2.27821
Epoch: 1/10, step: 22739, training_loss: 1.48861
Epoch: 1/10, step: 22759, training_loss: 2.69016
Epoch: 1/10, step: 22779, training_loss: 1.11735
Epoch: 1/10, step: 22799, training_loss: 1.14193
Epoch: 1/10, step: 22819, training_loss: 2.05124
Epoch: 1/10, step: 22839, training_loss: 1.65207
Epoch: 1/10, step: 22859, training_loss: 1.38390
Epoch: 1/10, step: 22879, training_loss: 2.20121
Epoch: 1/10, step: 22899, training_loss: 1.69814
Epoch: 1/10, step: 22919, training_loss: 1.63706
Epoch: 1/10, step: 22939, training_loss: 2.25978
Epoch: 1/10, step: 22959, training_loss: 1.19085
Epoch: 1/10, step: 22979, training_loss: 1.53278
Epoch: 1/10, step: 22999, training_loss: 1.12402
accuracy: 0.36, validation_loss: 1.8119087219238281, num_samples: 100
Epoch: 1/10, step: 23019, training_loss: 2.63954
Epoch: 1/10, step: 23039, training_loss: 1.42296
Epoch: 1/10, step: 23059, training_loss: 1.71823
Epoch: 1/10, step: 23079, training_loss: 1.96350
Epoch: 1/10, step: 23099, training_loss: 1.55595
Epoch: 1/10, step: 23119, training_loss: 1.65903
Epoch: 1/10, step: 23139, training_loss: 1.71339
Epoch: 1/10, step: 23159, training_loss: 2.17190
Epoch: 1/10, step: 23179, training_loss: 1.51664
Epoch: 1/10, step: 23199, training_loss: 1.90169
Epoch: 1/10, step: 23219, training_loss: 1.60893
Epoch: 1/10, step: 23239, training_loss: 1.64760
Epoch: 1/10, step: 23259, training_loss: 1.85438
Epoch: 1/10, step: 23279, training_loss: 1.36364
Epoch: 1/10, step: 23299, training_loss: 1.70213
Epoch: 1/10, step: 23319, training_loss: 1.66447
Epoch: 1/10, step: 23339, training_loss: 1.72956
Epoch: 1/10, step: 23359, training_loss: 1.84750
Epoch: 1/10, step: 23379, training_loss: 1.24474
Epoch: 1/10, step: 23399, training_loss: 1.24394
Epoch: 1/10, step: 23419, training_loss: 1.37469
Epoch: 1/10, step: 23439, training_loss: 1.89593
Epoch: 1/10, step: 23459, training_loss: 1.42513
Epoch: 1/10, step: 23479, training_loss: 1.46763
Epoch: 1/10, step: 23499, training_loss: 2.38419
Epoch: 1/10, step: 23519, training_loss: 2.14667
Epoch: 1/10, step: 23539, training_loss: 2.37358
Epoch: 1/10, step: 23559, training_loss: 2.69102
Epoch: 1/10, step: 23579, training_loss: 1.35514
Epoch: 1/10, step: 23599, training_loss: 1.15477
Epoch: 1/10, step: 23619, training_loss: 0.87098
Epoch: 1/10, step: 23639, training_loss: 2.08346
Epoch: 1/10, step: 23659, training_loss: 1.96811
Epoch: 1/10, step: 23679, training_loss: 1.60743
Epoch: 1/10, step: 23699, training_loss: 1.09061
Epoch: 1/10, step: 23719, training_loss: 1.78569
Epoch: 1/10, step: 23739, training_loss: 0.93982
Epoch: 1/10, step: 23759, training_loss: 1.82274
Epoch: 1/10, step: 23779, training_loss: 0.84361
Epoch: 1/10, step: 23799, training_loss: 1.71433
Epoch: 1/10, step: 23819, training_loss: 1.68953
Epoch: 1/10, step: 23839, training_loss: 1.60040
Epoch: 1/10, step: 23859, training_loss: 1.67886
Epoch: 1/10, step: 23879, training_loss: 1.67961
Epoch: 1/10, step: 23899, training_loss: 1.44852
Epoch: 1/10, step: 23919, training_loss: 1.75683
Epoch: 1/10, step: 23939, training_loss: 1.79620
Epoch: 1/10, step: 23959, training_loss: 1.56324
Epoch: 1/10, step: 23979, training_loss: 1.50163
Epoch: 1/10, step: 23999, training_loss: 1.88568
accuracy: 0.46, validation_loss: 1.4708653688430786, num_samples: 100
Epoch: 1/10, step: 24019, training_loss: 1.69108
Epoch: 1/10, step: 24039, training_loss: 2.46988
Epoch: 1/10, step: 24059, training_loss: 2.72660
Epoch: 1/10, step: 24079, training_loss: 1.61292
Epoch: 1/10, step: 24099, training_loss: 1.55071
Epoch: 1/10, step: 24119, training_loss: 1.97912
Epoch: 1/10, step: 24139, training_loss: 1.83997
Epoch: 1/10, step: 24159, training_loss: 1.59213
Epoch: 1/10, step: 24179, training_loss: 1.15436
Epoch: 1/10, step: 24199, training_loss: 2.04523
Epoch: 1/10, step: 24219, training_loss: 1.41508
Epoch: 1/10, step: 24239, training_loss: 1.52280
Epoch: 1/10, step: 24259, training_loss: 1.75810
Epoch: 1/10, step: 24279, training_loss: 1.51632
Epoch: 1/10, step: 24299, training_loss: 1.46899
Epoch: 1/10, step: 24319, training_loss: 0.99592
Epoch: 1/10, step: 24339, training_loss: 1.88754
Epoch: 1/10, step: 24359, training_loss: 1.39767
Epoch: 1/10, step: 24379, training_loss: 1.29087
Epoch: 1/10, step: 24399, training_loss: 1.42261
Epoch: 1/10, step: 24419, training_loss: 1.41847
Epoch: 1/10, step: 24439, training_loss: 0.86192
Epoch: 1/10, step: 24459, training_loss: 1.14120
Epoch: 1/10, step: 24479, training_loss: 1.39897
Epoch: 1/10, step: 24499, training_loss: 1.72554
Epoch: 1/10, step: 24519, training_loss: 1.09068
Epoch: 1/10, step: 24539, training_loss: 1.91217
Epoch: 1/10, step: 24559, training_loss: 1.48524
Epoch: 1/10, step: 24579, training_loss: 2.19559
Epoch: 1/10, step: 24599, training_loss: 1.17907
Epoch: 1/10, step: 24619, training_loss: 2.05331
Epoch: 1/10, step: 24639, training_loss: 1.04798
Epoch: 1/10, step: 24659, training_loss: 1.33310
Epoch: 1/10, step: 24679, training_loss: 1.81615
Epoch: 1/10, step: 24699, training_loss: 1.45979
Epoch: 1/10, step: 24719, training_loss: 1.80882
Epoch: 1/10, step: 24739, training_loss: 1.49706
Epoch: 1/10, step: 24759, training_loss: 1.57977
Epoch: 1/10, step: 24779, training_loss: 1.50534
Epoch: 1/10, step: 24799, training_loss: 1.55892
Epoch: 1/10, step: 24819, training_loss: 1.55677
Epoch: 1/10, step: 24839, training_loss: 1.38740
Epoch: 1/10, step: 24859, training_loss: 1.65791
Epoch: 1/10, step: 24879, training_loss: 1.75018
Epoch: 1/10, step: 24899, training_loss: 2.45950
Epoch: 1/10, step: 24919, training_loss: 1.45159
Epoch: 1/10, step: 24939, training_loss: 1.44000
Epoch: 1/10, step: 24959, training_loss: 2.19727
Epoch: 1/10, step: 24979, training_loss: 1.80146
Epoch: 1/10, step: 24999, training_loss: 1.07899
accuracy: 0.51, validation_loss: 1.4576363563537598, num_samples: 100
Epoch: 1/10, step: 25019, training_loss: 1.36023
Epoch: 1/10, step: 25039, training_loss: 1.96000
Epoch: 1/10, step: 25059, training_loss: 1.53017
Epoch: 1/10, step: 25079, training_loss: 2.46372
Epoch: 1/10, step: 25099, training_loss: 2.10481
Epoch: 1/10, step: 25119, training_loss: 1.46142
Epoch: 1/10, step: 25139, training_loss: 1.41672
Epoch: 1/10, step: 25159, training_loss: 1.19085
Epoch: 1/10, step: 25179, training_loss: 1.27342
Epoch: 1/10, step: 25199, training_loss: 1.16166
Epoch: 1/10, step: 25219, training_loss: 1.83589
Epoch: 1/10, step: 25239, training_loss: 1.47198
Epoch: 1/10, step: 25259, training_loss: 0.97906
Epoch: 1/10, step: 25279, training_loss: 1.08763
Epoch: 1/10, step: 25299, training_loss: 0.86543
Epoch: 1/10, step: 25319, training_loss: 1.92842
Epoch: 1/10, step: 25339, training_loss: 1.45291
Epoch: 1/10, step: 25359, training_loss: 1.84541
Epoch: 1/10, step: 25379, training_loss: 1.81685
Epoch: 1/10, step: 25399, training_loss: 1.76323
Epoch: 1/10, step: 25419, training_loss: 1.82808
Epoch: 1/10, step: 25439, training_loss: 1.48477
Epoch: 1/10, step: 25459, training_loss: 2.59908
Epoch: 1/10, step: 25479, training_loss: 2.39257
Epoch: 1/10, step: 25499, training_loss: 1.66994
Epoch: 1/10, step: 25519, training_loss: 1.71871
Epoch: 1/10, step: 25539, training_loss: 1.67487
Epoch: 1/10, step: 25559, training_loss: 1.74574
Epoch: 1/10, step: 25579, training_loss: 1.73771
Epoch: 1/10, step: 25599, training_loss: 1.68211
Epoch: 1/10, step: 25619, training_loss: 1.11577
Epoch: 1/10, step: 25639, training_loss: 1.24667
Epoch: 1/10, step: 25659, training_loss: 1.64282
Epoch: 1/10, step: 25679, training_loss: 1.94748
Epoch: 1/10, step: 25699, training_loss: 1.56693
Epoch: 1/10, step: 25719, training_loss: 1.30765
Epoch: 1/10, step: 25739, training_loss: 1.32317
Epoch: 1/10, step: 25759, training_loss: 1.06259
Epoch: 1/10, step: 25779, training_loss: 1.46076
Epoch: 1/10, step: 25799, training_loss: 1.93708
Epoch: 1/10, step: 25819, training_loss: 1.39276
Epoch: 1/10, step: 25839, training_loss: 1.88997
Epoch: 1/10, step: 25859, training_loss: 1.93477
Epoch: 1/10, step: 25879, training_loss: 1.47637
Epoch: 1/10, step: 25899, training_loss: 2.22678
Epoch: 1/10, step: 25919, training_loss: 1.30534
Epoch: 1/10, step: 25939, training_loss: 2.16197
Epoch: 1/10, step: 25959, training_loss: 1.75318
Epoch: 1/10, step: 25979, training_loss: 1.67812
Epoch: 1/10, step: 25999, training_loss: 2.31257
accuracy: 0.45, validation_loss: 1.600732684135437, num_samples: 100
Epoch: 1/10, step: 26019, training_loss: 1.21438
Epoch: 1/10, step: 26039, training_loss: 1.47440
Epoch: 1/10, step: 26059, training_loss: 2.14361
Epoch: 1/10, step: 26079, training_loss: 0.84048
Epoch: 1/10, step: 26099, training_loss: 1.60758
Epoch: 1/10, step: 26119, training_loss: 2.06079
Epoch: 1/10, step: 26139, training_loss: 0.81218
Epoch: 1/10, step: 26159, training_loss: 1.98988
Epoch: 1/10, step: 26179, training_loss: 2.38360
Epoch: 1/10, step: 26199, training_loss: 1.63115
Epoch: 1/10, step: 26219, training_loss: 1.92803
Epoch: 1/10, step: 26239, training_loss: 1.79640
Epoch: 1/10, step: 26259, training_loss: 2.00338
Epoch: 1/10, step: 26279, training_loss: 1.40207
Epoch: 1/10, step: 26299, training_loss: 1.11676
Epoch: 1/10, step: 26319, training_loss: 1.66479
Epoch: 1/10, step: 26339, training_loss: 1.53080
Epoch: 1/10, step: 26359, training_loss: 1.39816
Epoch: 1/10, step: 26379, training_loss: 1.56988
Epoch: 1/10, step: 26399, training_loss: 1.13223
Epoch: 1/10, step: 26419, training_loss: 1.63283
Epoch: 1/10, step: 26439, training_loss: 1.87952
Epoch: 1/10, step: 26459, training_loss: 1.34196
Epoch: 1/10, step: 26479, training_loss: 2.16294
Epoch: 1/10, step: 26499, training_loss: 1.61446
Epoch: 1/10, step: 26519, training_loss: 1.50378
Epoch: 1/10, step: 26539, training_loss: 1.70382
Epoch: 1/10, step: 26559, training_loss: 1.71151
Epoch: 1/10, step: 26579, training_loss: 1.44009
Epoch: 1/10, step: 26599, training_loss: 1.16305
Epoch: 1/10, step: 26619, training_loss: 2.27262
Epoch: 1/10, step: 26639, training_loss: 1.51492
Epoch: 1/10, step: 26659, training_loss: 2.25836
Epoch: 1/10, step: 26679, training_loss: 2.00997
Epoch: 1/10, step: 26699, training_loss: 2.57638
Epoch: 1/10, step: 26719, training_loss: 1.39962
Epoch: 1/10, step: 26739, training_loss: 0.88236
Epoch: 1/10, step: 26759, training_loss: 1.69512
Epoch: 1/10, step: 26779, training_loss: 1.17426
Epoch: 1/10, step: 26799, training_loss: 1.79913
Epoch: 1/10, step: 26819, training_loss: 1.09627
Epoch: 1/10, step: 26839, training_loss: 2.20010
Epoch: 1/10, step: 26859, training_loss: 1.36073
Epoch: 1/10, step: 26879, training_loss: 2.15106
Epoch: 1/10, step: 26899, training_loss: 2.07406
Epoch: 1/10, step: 26919, training_loss: 1.59699
Epoch: 1/10, step: 26939, training_loss: 1.06793
Epoch: 1/10, step: 26959, training_loss: 1.69856
Epoch: 1/10, step: 26979, training_loss: 1.75175
Epoch: 1/10, step: 26999, training_loss: 1.84256
accuracy: 0.42, validation_loss: 1.6657847166061401, num_samples: 100
Epoch: 1/10, step: 27019, training_loss: 1.42627
Epoch: 1/10, step: 27039, training_loss: 1.75227
Epoch: 1/10, step: 27059, training_loss: 1.32762
Epoch: 1/10, step: 27079, training_loss: 2.12839
Epoch: 1/10, step: 27099, training_loss: 1.94305
Epoch: 1/10, step: 27119, training_loss: 1.44109
Epoch: 1/10, step: 27139, training_loss: 2.41617
Epoch: 1/10, step: 27159, training_loss: 1.83960
Epoch: 1/10, step: 27179, training_loss: 1.00208
Epoch: 1/10, step: 27199, training_loss: 1.81126
Epoch: 1/10, step: 27219, training_loss: 1.44156
Epoch: 1/10, step: 27239, training_loss: 2.86168
Epoch: 1/10, step: 27259, training_loss: 1.52943
Epoch: 1/10, step: 27279, training_loss: 2.53026
Epoch: 1/10, step: 27299, training_loss: 1.62309
Epoch: 1/10, step: 27319, training_loss: 2.32354
Epoch: 1/10, step: 27339, training_loss: 1.79325
Epoch: 1/10, step: 27359, training_loss: 1.28805
Epoch: 1/10, step: 27379, training_loss: 1.46342
Epoch: 1/10, step: 27399, training_loss: 2.55358
Epoch: 1/10, step: 27419, training_loss: 1.18816
Epoch: 1/10, step: 27439, training_loss: 1.86335
Epoch: 1/10, step: 27459, training_loss: 1.37673
Epoch: 1/10, step: 27479, training_loss: 2.26479
Epoch: 1/10, step: 27499, training_loss: 2.16121
Epoch: 1/10, step: 27519, training_loss: 1.52369
Epoch: 1/10, step: 27539, training_loss: 2.13588
Epoch: 1/10, step: 27559, training_loss: 1.84010
Epoch: 1/10, step: 27579, training_loss: 0.92879
Epoch: 1/10, step: 27599, training_loss: 0.83447
Epoch: 1/10, step: 27619, training_loss: 1.18563
Epoch: 1/10, step: 27639, training_loss: 1.81140
Epoch: 1/10, step: 27659, training_loss: 1.57585
Epoch: 1/10, step: 27679, training_loss: 1.43310
Epoch: 1/10, step: 27699, training_loss: 1.40002
Epoch: 1/10, step: 27719, training_loss: 1.17762
Epoch: 1/10, step: 27739, training_loss: 1.63665
Epoch: 1/10, step: 27759, training_loss: 1.35196
Epoch: 1/10, step: 27779, training_loss: 1.98723
Epoch: 1/10, step: 27799, training_loss: 2.09459
Epoch: 1/10, step: 27819, training_loss: 1.79597
Epoch: 1/10, step: 27839, training_loss: 1.40024
Epoch: 1/10, step: 27859, training_loss: 1.74369
Epoch: 1/10, step: 27879, training_loss: 2.22184
Epoch: 1/10, step: 27899, training_loss: 1.37803
Epoch: 1/10, step: 27919, training_loss: 1.28906
Epoch: 1/10, step: 27939, training_loss: 2.88821
Epoch: 1/10, step: 27959, training_loss: 1.79037
Epoch: 1/10, step: 27979, training_loss: 1.96200
Epoch: 1/10, step: 27999, training_loss: 2.23190
accuracy: 0.45, validation_loss: 1.581208348274231, num_samples: 100
Epoch: 1/10, step: 28019, training_loss: 1.57510
Epoch: 1/10, step: 28039, training_loss: 1.49354
Epoch: 1/10, step: 28059, training_loss: 2.54759
Epoch: 1/10, step: 28079, training_loss: 1.48581
Epoch: 1/10, step: 28099, training_loss: 1.59576
Epoch: 1/10, step: 28119, training_loss: 1.67784
Epoch: 1/10, step: 28139, training_loss: 1.00480
Epoch: 1/10, step: 28159, training_loss: 2.23718
Epoch: 1/10, step: 28179, training_loss: 1.28750
Epoch: 1/10, step: 28199, training_loss: 2.79932
Epoch: 1/10, step: 28219, training_loss: 2.11345
Epoch: 1/10, step: 28239, training_loss: 1.83171
Epoch: 1/10, step: 28259, training_loss: 1.23406
Epoch: 1/10, step: 28279, training_loss: 1.67589
Epoch: 1/10, step: 28299, training_loss: 1.46052
Epoch: 1/10, step: 28319, training_loss: 1.59134
Epoch: 1/10, step: 28339, training_loss: 1.19079
Epoch: 1/10, step: 28359, training_loss: 1.74418
Epoch: 1/10, step: 28379, training_loss: 1.61011
Epoch: 1/10, step: 28399, training_loss: 1.84882
Epoch: 1/10, step: 28419, training_loss: 1.29718
Epoch: 1/10, step: 28439, training_loss: 1.60404
Epoch: 1/10, step: 28459, training_loss: 1.56737
Epoch: 1/10, step: 28479, training_loss: 1.78712
Epoch: 1/10, step: 28499, training_loss: 1.81682
Epoch: 1/10, step: 28519, training_loss: 0.99996
Epoch: 1/10, step: 28539, training_loss: 1.76984
Epoch: 1/10, step: 28559, training_loss: 1.97375
Epoch: 1/10, step: 28579, training_loss: 2.13778
Epoch: 1/10, step: 28599, training_loss: 1.46135
Epoch: 1/10, step: 28619, training_loss: 1.53204
Epoch: 1/10, step: 28639, training_loss: 2.70167
Epoch: 1/10, step: 28659, training_loss: 2.20473
Epoch: 1/10, step: 28679, training_loss: 1.53743
Epoch: 1/10, step: 28699, training_loss: 1.40374
Epoch: 1/10, step: 28719, training_loss: 1.79648
Epoch: 1/10, step: 28739, training_loss: 1.26825
Epoch: 1/10, step: 28759, training_loss: 1.32409
Epoch: 1/10, step: 28779, training_loss: 1.24696
Epoch: 1/10, step: 28799, training_loss: 1.07112
Epoch: 1/10, step: 28819, training_loss: 1.49379
Epoch: 1/10, step: 28839, training_loss: 1.63397
Epoch: 1/10, step: 28859, training_loss: 1.85295
Epoch: 1/10, step: 28879, training_loss: 1.63284
Epoch: 1/10, step: 28899, training_loss: 1.85721
Epoch: 1/10, step: 28919, training_loss: 1.08227
Epoch: 1/10, step: 28939, training_loss: 1.04721
Epoch: 1/10, step: 28959, training_loss: 1.89923
Epoch: 1/10, step: 28979, training_loss: 1.65210
Epoch: 1/10, step: 28999, training_loss: 1.42144
accuracy: 0.44, validation_loss: 1.5520340204238892, num_samples: 100
Epoch: 1/10, step: 29019, training_loss: 1.20435
Epoch: 1/10, step: 29039, training_loss: 1.89733
Epoch: 1/10, step: 29059, training_loss: 1.74534
Epoch: 1/10, step: 29079, training_loss: 1.02140
Epoch: 1/10, step: 29099, training_loss: 1.61263
Epoch: 1/10, step: 29119, training_loss: 1.43153
Epoch: 1/10, step: 29139, training_loss: 1.13680
Epoch: 1/10, step: 29159, training_loss: 0.97133
Epoch: 1/10, step: 29179, training_loss: 1.72283
Epoch: 1/10, step: 29199, training_loss: 1.31672
Epoch: 1/10, step: 29219, training_loss: 1.66036
Epoch: 1/10, step: 29239, training_loss: 2.08782
Epoch: 1/10, step: 29259, training_loss: 1.60463
Epoch: 1/10, step: 29279, training_loss: 1.38620
Epoch: 1/10, step: 29299, training_loss: 2.23782
Epoch: 1/10, step: 29319, training_loss: 1.77618
Epoch: 1/10, step: 29339, training_loss: 1.79233
Epoch: 1/10, step: 29359, training_loss: 1.63519
Epoch: 1/10, step: 29379, training_loss: 2.04525
Epoch: 1/10, step: 29399, training_loss: 1.13701
Epoch: 1/10, step: 29419, training_loss: 1.93968
Epoch: 1/10, step: 29439, training_loss: 0.99158
Epoch: 1/10, step: 29459, training_loss: 1.57956
Epoch: 1/10, step: 29479, training_loss: 2.30191
Epoch: 1/10, step: 29499, training_loss: 1.40604
Epoch: 1/10, step: 29519, training_loss: 1.00974
Epoch: 1/10, step: 29539, training_loss: 0.67878
Epoch: 1/10, step: 29559, training_loss: 1.23892
Epoch: 1/10, step: 29579, training_loss: 2.19469
Epoch: 1/10, step: 29599, training_loss: 1.57606
Epoch: 1/10, step: 29619, training_loss: 1.46414
Epoch: 1/10, step: 29639, training_loss: 1.36090
Epoch: 1/10, step: 29659, training_loss: 1.70916
Epoch: 1/10, step: 29679, training_loss: 1.75304
Epoch: 1/10, step: 29699, training_loss: 1.25320
Epoch: 1/10, step: 29719, training_loss: 1.26469
Epoch: 1/10, step: 29739, training_loss: 1.76491
Epoch: 1/10, step: 29759, training_loss: 1.92706
Epoch: 1/10, step: 29779, training_loss: 1.44062
Epoch: 1/10, step: 29799, training_loss: 1.75532
Epoch: 1/10, step: 29819, training_loss: 1.23254
Epoch: 1/10, step: 29839, training_loss: 1.85333
Epoch: 1/10, step: 29859, training_loss: 1.45833
Epoch: 1/10, step: 29879, training_loss: 2.17557
Epoch: 1/10, step: 29899, training_loss: 1.41156
Epoch: 1/10, step: 29919, training_loss: 1.50002
Epoch: 1/10, step: 29939, training_loss: 1.62365
Epoch: 1/10, step: 29959, training_loss: 1.41875
Epoch: 1/10, step: 29979, training_loss: 2.02059
Epoch: 1/10, step: 29999, training_loss: 0.90780
accuracy: 0.49, validation_loss: 1.439195156097412, num_samples: 100
Epoch: 1/10, step: 30019, training_loss: 0.88133
Epoch: 1/10, step: 30039, training_loss: 1.52316
Epoch: 1/10, step: 30059, training_loss: 1.97200
Epoch: 1/10, step: 30079, training_loss: 1.89980
Epoch: 1/10, step: 30099, training_loss: 1.12740
Epoch: 1/10, step: 30119, training_loss: 1.34833
Epoch: 1/10, step: 30139, training_loss: 1.11626
Epoch: 1/10, step: 30159, training_loss: 1.65106
Epoch: 1/10, step: 30179, training_loss: 1.75518
Epoch: 1/10, step: 30199, training_loss: 1.40128
Epoch: 1/10, step: 30219, training_loss: 1.63701
Epoch: 1/10, step: 30239, training_loss: 0.81170
Epoch: 1/10, step: 30259, training_loss: 1.61872
Epoch: 1/10, step: 30279, training_loss: 1.74071
Epoch: 1/10, step: 30299, training_loss: 1.53787
Epoch: 1/10, step: 30319, training_loss: 1.32492
Epoch: 1/10, step: 30339, training_loss: 1.64486
Epoch: 1/10, step: 30359, training_loss: 1.39197
Epoch: 1/10, step: 30379, training_loss: 2.39238
Epoch: 1/10, step: 30399, training_loss: 2.04056
Epoch: 1/10, step: 30419, training_loss: 2.32002
Epoch: 1/10, step: 30439, training_loss: 1.82171
Epoch: 1/10, step: 30459, training_loss: 2.30061
Epoch: 1/10, step: 30479, training_loss: 2.06538
Epoch: 1/10, step: 30499, training_loss: 1.46166
Epoch: 1/10, step: 30519, training_loss: 1.14956
Epoch: 1/10, step: 30539, training_loss: 1.73559
Epoch: 1/10, step: 30559, training_loss: 1.70749
Epoch: 1/10, step: 30579, training_loss: 1.96549
Epoch: 1/10, step: 30599, training_loss: 1.07702
Epoch: 1/10, step: 30619, training_loss: 1.61148
Epoch: 1/10, step: 30639, training_loss: 1.57791
Epoch: 1/10, step: 30659, training_loss: 1.84202
Epoch: 1/10, step: 30679, training_loss: 1.48585
Epoch: 1/10, step: 30699, training_loss: 1.66237
Epoch: 1/10, step: 30719, training_loss: 1.50672
Epoch: 1/10, step: 30739, training_loss: 2.81884
Epoch: 1/10, step: 30759, training_loss: 1.73051
Epoch: 1/10, step: 30779, training_loss: 1.16386
Epoch: 1/10, step: 30799, training_loss: 1.04165
Epoch: 1/10, step: 30819, training_loss: 1.63426
Epoch: 1/10, step: 30839, training_loss: 1.45365
Epoch: 1/10, step: 30859, training_loss: 1.24671
Epoch: 1/10, step: 30879, training_loss: 1.14104
Epoch: 1/10, step: 30899, training_loss: 1.51084
Epoch: 1/10, step: 30919, training_loss: 1.41532
Epoch: 1/10, step: 30939, training_loss: 1.95382
Epoch: 1/10, step: 30959, training_loss: 1.20585
Epoch: 1/10, step: 30979, training_loss: 2.00970
Epoch: 1/10, step: 30999, training_loss: 1.42802
accuracy: 0.52, validation_loss: 1.4901546239852905, num_samples: 100
Epoch: 1/10, step: 31019, training_loss: 1.46462
Epoch: 1/10, step: 31039, training_loss: 0.99549
Epoch: 1/10, step: 31059, training_loss: 1.53349
Epoch: 1/10, step: 31079, training_loss: 1.84399
Epoch: 1/10, step: 31099, training_loss: 2.19785
Epoch: 1/10, step: 31119, training_loss: 2.53539
Epoch: 1/10, step: 31139, training_loss: 1.66797
Epoch: 1/10, step: 31159, training_loss: 1.98170
Epoch: 1/10, step: 31179, training_loss: 1.79074
Epoch: 1/10, step: 31199, training_loss: 1.57455
Epoch: 1/10, step: 31219, training_loss: 2.02054
Epoch: 1/10, step: 31239, training_loss: 2.12506
Epoch: 1/10, step: 31259, training_loss: 1.75891
Epoch: 1/10, step: 31279, training_loss: 1.43468
Epoch: 1/10, step: 31299, training_loss: 0.91674
Epoch: 1/10, step: 31319, training_loss: 1.53152
Epoch: 1/10, step: 31339, training_loss: 2.17210
Epoch: 1/10, step: 31359, training_loss: 2.22616
Epoch: 1/10, step: 31379, training_loss: 1.70602
Epoch: 1/10, step: 31399, training_loss: 1.66276
Epoch: 1/10, step: 31419, training_loss: 1.86054
Epoch: 1/10, step: 31439, training_loss: 0.87949
Epoch: 1/10, step: 31459, training_loss: 1.29515
Epoch: 1/10, step: 31479, training_loss: 1.75665
Epoch: 1/10, step: 31499, training_loss: 1.60927
Epoch: 1/10, step: 31519, training_loss: 1.12968
Epoch: 1/10, step: 31539, training_loss: 1.51632
Epoch: 1/10, step: 31559, training_loss: 1.50951
Epoch: 1/10, step: 31579, training_loss: 1.79636
Epoch: 1/10, step: 31599, training_loss: 1.77533
Epoch: 1/10, step: 31619, training_loss: 1.28338
Epoch: 1/10, step: 31639, training_loss: 1.70855
Epoch: 1/10, step: 31659, training_loss: 0.90005
Epoch: 1/10, step: 31679, training_loss: 2.14353
Epoch: 1/10, step: 31699, training_loss: 1.12343
Epoch: 1/10, step: 31719, training_loss: 1.22490
Epoch: 1/10, step: 31739, training_loss: 1.62379
Epoch: 1/10, step: 31759, training_loss: 1.15822
Epoch: 1/10, step: 31779, training_loss: 1.77337
Epoch: 1/10, step: 31799, training_loss: 1.47606
Epoch: 1/10, step: 31819, training_loss: 1.76382
Epoch: 1/10, step: 31839, training_loss: 1.32336
Epoch: 1/10, step: 31859, training_loss: 1.47514
Epoch: 1/10, step: 31879, training_loss: 1.23155
Epoch: 1/10, step: 31899, training_loss: 1.46080
Epoch: 1/10, step: 31919, training_loss: 1.63788
Epoch: 1/10, step: 31939, training_loss: 1.85284
Epoch: 1/10, step: 31959, training_loss: 1.88702
Epoch: 1/10, step: 31979, training_loss: 1.13411
Epoch: 1/10, step: 31999, training_loss: 2.09182
accuracy: 0.56, validation_loss: 1.5489999055862427, num_samples: 100
Epoch: 1/10, step: 32019, training_loss: 1.81568
Epoch: 1/10, step: 32039, training_loss: 1.37521
Epoch: 1/10, step: 32059, training_loss: 2.09123
Epoch: 1/10, step: 32079, training_loss: 1.84425
Epoch: 1/10, step: 32099, training_loss: 1.37374
Epoch: 1/10, step: 32119, training_loss: 1.61838
Epoch: 1/10, step: 32139, training_loss: 1.41358
Epoch: 1/10, step: 32159, training_loss: 1.80487
Epoch: 1/10, step: 32179, training_loss: 1.81295
Epoch: 1/10, step: 32199, training_loss: 1.80916
Epoch: 1/10, step: 32219, training_loss: 1.57510
Epoch: 1/10, step: 32239, training_loss: 2.32637
Epoch: 1/10, step: 32259, training_loss: 1.56201
Epoch: 1/10, step: 32279, training_loss: 2.12906
Epoch: 1/10, step: 32299, training_loss: 1.81433
Epoch: 1/10, step: 32319, training_loss: 2.14224
Epoch: 1/10, step: 32339, training_loss: 1.67995
Epoch: 1/10, step: 32359, training_loss: 1.31442
Epoch: 1/10, step: 32379, training_loss: 1.46949
Epoch: 1/10, step: 32399, training_loss: 1.22788
Epoch: 1/10, step: 32419, training_loss: 2.18847
Epoch: 1/10, step: 32439, training_loss: 1.51076
Epoch: 1/10, step: 32459, training_loss: 2.13600
Epoch: 1/10, step: 32479, training_loss: 1.38827
Epoch: 1/10, step: 32499, training_loss: 1.29549
Epoch: 1/10, step: 32519, training_loss: 1.21841
Epoch: 1/10, step: 32539, training_loss: 1.07499
Epoch: 1/10, step: 32559, training_loss: 1.71936
Epoch: 1/10, step: 32579, training_loss: 1.76678
Epoch: 1/10, step: 32599, training_loss: 1.34125
Epoch: 1/10, step: 32619, training_loss: 1.87376
Epoch: 1/10, step: 32639, training_loss: 1.28920
Epoch: 1/10, step: 32659, training_loss: 1.10010
Epoch: 1/10, step: 32679, training_loss: 1.36709
Epoch: 1/10, step: 32699, training_loss: 1.00319
Epoch: 1/10, step: 32719, training_loss: 1.59456
Epoch: 1/10, step: 32739, training_loss: 1.30776
Epoch: 1/10, step: 32759, training_loss: 2.15852
Epoch: 1/10, step: 32779, training_loss: 1.64647
Epoch: 1/10, step: 32799, training_loss: 1.17934
Epoch: 1/10, step: 32819, training_loss: 1.20464
Epoch: 1/10, step: 32839, training_loss: 1.73260
Epoch: 1/10, step: 32859, training_loss: 2.03077
Epoch: 1/10, step: 32879, training_loss: 1.22149
Epoch: 1/10, step: 32899, training_loss: 1.55992
Epoch: 1/10, step: 32919, training_loss: 2.24660
Epoch: 1/10, step: 32939, training_loss: 2.21341
Epoch: 1/10, step: 32959, training_loss: 1.62010
Epoch: 1/10, step: 32979, training_loss: 1.50523
Epoch: 1/10, step: 32999, training_loss: 1.79868
accuracy: 0.47, validation_loss: 1.6349554061889648, num_samples: 100
Epoch: 1/10, step: 33019, training_loss: 2.13563
Epoch: 1/10, step: 33039, training_loss: 1.19164
Epoch: 1/10, step: 33059, training_loss: 1.42551
Epoch: 1/10, step: 33079, training_loss: 1.20798
Epoch: 1/10, step: 33099, training_loss: 1.28254
Epoch: 1/10, step: 33119, training_loss: 1.75971
Epoch: 1/10, step: 33139, training_loss: 1.85666
Epoch: 1/10, step: 33159, training_loss: 1.57842
Epoch: 1/10, step: 33179, training_loss: 1.38611
Epoch: 1/10, step: 33199, training_loss: 0.91112
Epoch: 1/10, step: 33219, training_loss: 1.63636
Epoch: 1/10, step: 33239, training_loss: 1.20511
Epoch: 1/10, step: 33259, training_loss: 1.38354
Epoch: 1/10, step: 33279, training_loss: 1.18300
Epoch: 1/10, step: 33299, training_loss: 1.40680
Epoch: 1/10, step: 33319, training_loss: 2.37200
Epoch: 1/10, step: 33339, training_loss: 1.48405
Epoch: 1/10, step: 33359, training_loss: 1.63138
Epoch: 1/10, step: 33379, training_loss: 1.61343
Epoch: 1/10, step: 33399, training_loss: 1.23984
Epoch: 1/10, step: 33419, training_loss: 1.73834
Epoch: 1/10, step: 33439, training_loss: 2.05503
Epoch: 1/10, step: 33459, training_loss: 1.81516
Epoch: 1/10, step: 33479, training_loss: 1.80493
Epoch: 1/10, step: 33499, training_loss: 1.63204
Epoch: 1/10, step: 33519, training_loss: 1.59921
Epoch: 1/10, step: 33539, training_loss: 1.81871
Epoch: 1/10, step: 33559, training_loss: 1.71710
Epoch: 1/10, step: 33579, training_loss: 2.05253
Epoch: 1/10, step: 33599, training_loss: 1.71820
Epoch: 1/10, step: 33619, training_loss: 1.76458
Epoch: 1/10, step: 33639, training_loss: 1.55896
Epoch: 1/10, step: 33659, training_loss: 1.88491
Epoch: 1/10, step: 33679, training_loss: 1.55397
Epoch: 1/10, step: 33699, training_loss: 1.16304
Epoch: 1/10, step: 33719, training_loss: 1.71768
Epoch: 1/10, step: 33739, training_loss: 1.17701
Epoch: 1/10, step: 33759, training_loss: 2.66352
Epoch: 1/10, step: 33779, training_loss: 2.06472
Epoch: 1/10, step: 33799, training_loss: 1.06313
Epoch: 1/10, step: 33819, training_loss: 1.69346
Epoch: 1/10, step: 33839, training_loss: 1.72805
Epoch: 1/10, step: 33859, training_loss: 1.51325
Epoch: 1/10, step: 33879, training_loss: 2.19674
Epoch: 1/10, step: 33899, training_loss: 1.90264
Epoch: 1/10, step: 33919, training_loss: 1.90722
Epoch: 1/10, step: 33939, training_loss: 1.81919
Epoch: 1/10, step: 33959, training_loss: 1.65789
Epoch: 1/10, step: 33979, training_loss: 1.09433
Epoch: 1/10, step: 33999, training_loss: 1.83846
accuracy: 0.47, validation_loss: 1.503954291343689, num_samples: 100
Epoch: 1/10, step: 34019, training_loss: 1.36621
Epoch: 1/10, step: 34039, training_loss: 1.14698
Epoch: 1/10, step: 34059, training_loss: 2.42432
Epoch: 1/10, step: 34079, training_loss: 1.70593
Epoch: 1/10, step: 34099, training_loss: 2.13209
Epoch: 1/10, step: 34119, training_loss: 0.92703
Epoch: 1/10, step: 34139, training_loss: 1.96579
Epoch: 1/10, step: 34159, training_loss: 1.99318
Epoch: 1/10, step: 34179, training_loss: 1.04792
Epoch: 1/10, step: 34199, training_loss: 1.66249
Epoch: 1/10, step: 34219, training_loss: 1.38310
Epoch: 1/10, step: 34239, training_loss: 1.28166
Epoch: 1/10, step: 34259, training_loss: 1.62022
Epoch: 1/10, step: 34279, training_loss: 1.30302
Epoch: 1/10, step: 34299, training_loss: 1.75669
Epoch: 1/10, step: 34319, training_loss: 1.29775
Epoch: 1/10, step: 34339, training_loss: 1.69597
Epoch: 1/10, step: 34359, training_loss: 1.09339
Epoch: 1/10, step: 34379, training_loss: 1.99606
Epoch: 1/10, step: 34399, training_loss: 2.26695
Epoch: 1/10, step: 34419, training_loss: 1.11756
Epoch: 1/10, step: 34439, training_loss: 2.14419
Epoch: 1/10, step: 34459, training_loss: 1.74328
Epoch: 1/10, step: 34479, training_loss: 1.91857
Epoch: 1/10, step: 34499, training_loss: 1.82413
Epoch: 1/10, step: 34519, training_loss: 1.09991
Epoch: 1/10, step: 34539, training_loss: 1.87744
Epoch: 1/10, step: 34559, training_loss: 1.06426
Epoch: 1/10, step: 34579, training_loss: 1.01560
Epoch: 1/10, step: 34599, training_loss: 2.74041
Epoch: 1/10, step: 34619, training_loss: 1.52794
Epoch: 1/10, step: 34639, training_loss: 1.91609
Epoch: 1/10, step: 34659, training_loss: 1.56038
Epoch: 1/10, step: 34679, training_loss: 2.24459
Epoch: 1/10, step: 34699, training_loss: 1.75710
Epoch: 1/10, step: 34719, training_loss: 1.54435
Epoch: 1/10, step: 34739, training_loss: 1.75118
Epoch: 1/10, step: 34759, training_loss: 2.27327
Epoch: 1/10, step: 34779, training_loss: 1.56598
Epoch: 1/10, step: 34799, training_loss: 2.48935
Epoch: 1/10, step: 34819, training_loss: 1.06842
Epoch: 1/10, step: 34839, training_loss: 2.04326
Epoch: 1/10, step: 34859, training_loss: 1.62420
Epoch: 1/10, step: 34879, training_loss: 1.89578
Epoch: 1/10, step: 34899, training_loss: 1.74500
Epoch: 1/10, step: 34919, training_loss: 1.80309
Epoch: 1/10, step: 34939, training_loss: 1.95723
Epoch: 1/10, step: 34959, training_loss: 1.37387
Epoch: 1/10, step: 34979, training_loss: 1.45939
Epoch: 1/10, step: 34999, training_loss: 1.73640
accuracy: 0.44, validation_loss: 1.6842061281204224, num_samples: 100
Epoch: 1/10, step: 35019, training_loss: 1.68065
Epoch: 1/10, step: 35039, training_loss: 1.14672
Epoch: 1/10, step: 35059, training_loss: 1.83870
Epoch: 1/10, step: 35079, training_loss: 1.58740
Epoch: 1/10, step: 35099, training_loss: 1.51779
Epoch: 1/10, step: 35119, training_loss: 1.45080
Epoch: 1/10, step: 35139, training_loss: 1.85887
Epoch: 1/10, step: 35159, training_loss: 0.92595
Epoch: 1/10, step: 35179, training_loss: 1.28535
Epoch: 1/10, step: 35199, training_loss: 0.80411
Epoch: 1/10, step: 35219, training_loss: 2.08274
Epoch: 1/10, step: 35239, training_loss: 1.68141
Epoch: 1/10, step: 35259, training_loss: 0.94958
Epoch: 1/10, step: 35279, training_loss: 1.49869
Epoch: 1/10, step: 35299, training_loss: 1.85065
Epoch: 1/10, step: 35319, training_loss: 1.39195
Epoch: 1/10, step: 35339, training_loss: 1.69704
Epoch: 1/10, step: 35359, training_loss: 1.76351
Epoch: 1/10, step: 35379, training_loss: 1.34397
Epoch: 1/10, step: 35399, training_loss: 0.75341
Epoch: 1/10, step: 35419, training_loss: 1.14195
Epoch: 1/10, step: 35439, training_loss: 1.24788
Epoch: 1/10, step: 35459, training_loss: 2.00221
Epoch: 1/10, step: 35479, training_loss: 1.40105
Epoch: 1/10, step: 35499, training_loss: 2.16650
Epoch: 1/10, step: 35519, training_loss: 2.36909
Epoch: 1/10, step: 35539, training_loss: 1.80683
Epoch: 1/10, step: 35559, training_loss: 1.94369
Epoch: 1/10, step: 35579, training_loss: 2.14051
Epoch: 1/10, step: 35599, training_loss: 1.50710
Epoch: 1/10, step: 35619, training_loss: 1.07276
Epoch: 1/10, step: 35639, training_loss: 1.86645
Epoch: 1/10, step: 35659, training_loss: 1.47158
Epoch: 1/10, step: 35679, training_loss: 1.52920
Epoch: 1/10, step: 35699, training_loss: 1.71849
Epoch: 1/10, step: 35719, training_loss: 1.32345
Epoch: 1/10, step: 35739, training_loss: 1.60203
Epoch: 1/10, step: 35759, training_loss: 2.24380
Epoch: 1/10, step: 35779, training_loss: 1.58874
Epoch: 1/10, step: 35799, training_loss: 1.36808
Epoch: 1/10, step: 35819, training_loss: 2.19252
Epoch: 1/10, step: 35839, training_loss: 0.87032
Epoch: 1/10, step: 35859, training_loss: 1.35734
Epoch: 1/10, step: 35879, training_loss: 1.47784
Epoch: 1/10, step: 35899, training_loss: 1.98614
Epoch: 1/10, step: 35919, training_loss: 1.62322
Epoch: 1/10, step: 35939, training_loss: 2.84459
Epoch: 1/10, step: 35959, training_loss: 1.38144
Epoch: 1/10, step: 35979, training_loss: 1.64868
Epoch: 1/10, step: 35999, training_loss: 1.89173
accuracy: 0.46, validation_loss: 1.5976905822753906, num_samples: 100
Epoch: 1/10, step: 36019, training_loss: 1.53177
Epoch: 1/10, step: 36039, training_loss: 0.91082
Epoch: 1/10, step: 36059, training_loss: 1.83235
Epoch: 1/10, step: 36079, training_loss: 1.45380
Epoch: 1/10, step: 36099, training_loss: 1.79292
Epoch: 1/10, step: 36119, training_loss: 1.77161
Epoch: 1/10, step: 36139, training_loss: 2.03517
Epoch: 1/10, step: 36159, training_loss: 1.83189
Epoch: 1/10, step: 36179, training_loss: 1.74227
Epoch: 1/10, step: 36199, training_loss: 0.91995
Epoch: 1/10, step: 36219, training_loss: 1.05624
Epoch: 1/10, step: 36239, training_loss: 1.06421
Epoch: 1/10, step: 36259, training_loss: 2.19626
Epoch: 1/10, step: 36279, training_loss: 1.80181
Epoch: 1/10, step: 36299, training_loss: 1.05646
Epoch: 1/10, step: 36319, training_loss: 1.33695
Epoch: 1/10, step: 36339, training_loss: 1.46201
Epoch: 1/10, step: 36359, training_loss: 1.52821
Epoch: 1/10, step: 36379, training_loss: 1.70445
Epoch: 1/10, step: 36399, training_loss: 1.10571
Epoch: 1/10, step: 36419, training_loss: 1.78136
Epoch: 1/10, step: 36439, training_loss: 2.25327
Epoch: 1/10, step: 36459, training_loss: 1.20539
Epoch: 1/10, step: 36479, training_loss: 1.56535
Epoch: 1/10, step: 36499, training_loss: 1.70641
Epoch: 1/10, step: 36519, training_loss: 1.74044
Epoch: 1/10, step: 36539, training_loss: 2.44574
Epoch: 1/10, step: 36559, training_loss: 2.07010
Epoch: 1/10, step: 36579, training_loss: 1.99244
Epoch: 1/10, step: 36599, training_loss: 1.55374
Epoch: 1/10, step: 36619, training_loss: 1.97076
Epoch: 1/10, step: 36639, training_loss: 1.93185
Epoch: 1/10, step: 36659, training_loss: 1.79514
Epoch: 1/10, step: 36679, training_loss: 1.82672
Epoch: 1/10, step: 36699, training_loss: 1.17363
Epoch: 1/10, step: 36719, training_loss: 1.63601
Epoch: 1/10, step: 36739, training_loss: 1.67102
Epoch: 1/10, step: 36759, training_loss: 2.25108
Epoch: 1/10, step: 36779, training_loss: 2.37925
Epoch: 1/10, step: 36799, training_loss: 1.18645
Epoch: 1/10, step: 36819, training_loss: 1.21704
Epoch: 1/10, step: 36839, training_loss: 1.90521
Epoch: 1/10, step: 36859, training_loss: 2.24996
Epoch: 1/10, step: 36879, training_loss: 1.65555
Epoch: 1/10, step: 36899, training_loss: 1.64558
Epoch: 1/10, step: 36919, training_loss: 1.81937
Epoch: 1/10, step: 36939, training_loss: 1.60254
Epoch: 1/10, step: 36959, training_loss: 2.34355
Epoch: 1/10, step: 36979, training_loss: 1.71509
Epoch: 1/10, step: 36999, training_loss: 2.08024
accuracy: 0.43, validation_loss: 1.6627776622772217, num_samples: 100
Epoch: 1/10, step: 37019, training_loss: 2.06816
Epoch: 1/10, step: 37039, training_loss: 1.62289
Epoch: 1/10, step: 37059, training_loss: 1.26631
Epoch: 1/10, step: 37079, training_loss: 1.85747
Epoch: 1/10, step: 37099, training_loss: 1.03084
Epoch: 1/10, step: 37119, training_loss: 1.78941
Epoch: 1/10, step: 37139, training_loss: 1.89961
Epoch: 1/10, step: 37159, training_loss: 1.07774
Epoch: 1/10, step: 37179, training_loss: 0.95845
Epoch: 1/10, step: 37199, training_loss: 1.83563
Epoch: 1/10, step: 37219, training_loss: 2.02532
Epoch: 1/10, step: 37239, training_loss: 1.86831
Epoch: 1/10, step: 37259, training_loss: 1.62488
Epoch: 1/10, step: 37279, training_loss: 1.65867
Epoch: 1/10, step: 37299, training_loss: 1.67374
Epoch: 1/10, step: 37319, training_loss: 2.01129
Epoch: 1/10, step: 37339, training_loss: 1.79472
Epoch: 1/10, step: 37359, training_loss: 1.22294
Epoch: 1/10, step: 37379, training_loss: 2.13159
Epoch: 1/10, step: 37399, training_loss: 1.32141
Epoch: 1/10, step: 37419, training_loss: 2.19840
Epoch: 1/10, step: 37439, training_loss: 1.97077
Epoch: 1/10, step: 37459, training_loss: 2.16298
Epoch: 1/10, step: 37479, training_loss: 1.23514
Epoch: 1/10, step: 37499, training_loss: 1.11686
Epoch: 1/10, step: 37519, training_loss: 1.64765
Epoch: 1/10, step: 37539, training_loss: 2.30534
Epoch: 1/10, step: 37559, training_loss: 1.63854
Epoch: 1/10, step: 37579, training_loss: 1.51757
Epoch: 1/10, step: 37599, training_loss: 1.35286
Epoch: 1/10, step: 37619, training_loss: 1.51730
Epoch: 1/10, step: 37639, training_loss: 2.42256
Epoch: 1/10, step: 37659, training_loss: 1.68276
Epoch: 1/10, step: 37679, training_loss: 1.43326
Epoch: 1/10, step: 37699, training_loss: 1.48576
Epoch: 1/10, step: 37719, training_loss: 1.78505
Epoch: 1/10, step: 37739, training_loss: 1.56745
Epoch: 1/10, step: 37759, training_loss: 1.93131
Epoch: 1/10, step: 37779, training_loss: 1.04376
Epoch: 1/10, step: 37799, training_loss: 1.58769
Epoch: 1/10, step: 37819, training_loss: 2.14640
Epoch: 1/10, step: 37839, training_loss: 1.53960
Epoch: 1/10, step: 37859, training_loss: 1.58453
Epoch: 1/10, step: 37879, training_loss: 1.85719
Epoch: 1/10, step: 37899, training_loss: 1.81583
Epoch: 1/10, step: 37919, training_loss: 1.36246
Epoch: 1/10, step: 37939, training_loss: 1.60281
Epoch: 1/10, step: 37959, training_loss: 1.81097
Epoch: 1/10, step: 37979, training_loss: 1.12209
Epoch: 1/10, step: 37999, training_loss: 1.53498
accuracy: 0.47, validation_loss: 1.400886058807373, num_samples: 100
Epoch: 1/10, step: 38019, training_loss: 1.67737
Epoch: 1/10, step: 38039, training_loss: 1.63272
Epoch: 1/10, step: 38059, training_loss: 1.59698
Epoch: 1/10, step: 38079, training_loss: 1.32162
Epoch: 1/10, step: 38099, training_loss: 1.49088
Epoch: 1/10, step: 38119, training_loss: 1.29014
Epoch: 1/10, step: 38139, training_loss: 1.28963
Epoch: 1/10, step: 38159, training_loss: 1.41219
Epoch: 1/10, step: 38179, training_loss: 1.54104
Epoch: 1/10, step: 38199, training_loss: 1.69383
Epoch: 1/10, step: 38219, training_loss: 1.40142
Epoch: 1/10, step: 38239, training_loss: 1.01429
Epoch: 1/10, step: 38259, training_loss: 1.34042
Epoch: 1/10, step: 38279, training_loss: 2.15522
Epoch: 1/10, step: 38299, training_loss: 1.53738
Epoch: 1/10, step: 38319, training_loss: 2.53013
Epoch: 1/10, step: 38339, training_loss: 1.70262
Epoch: 1/10, step: 38359, training_loss: 1.83806
Epoch: 1/10, step: 38379, training_loss: 1.76785
Epoch: 1/10, step: 38399, training_loss: 1.94685
Epoch: 1/10, step: 38419, training_loss: 1.33571
Epoch: 1/10, step: 38439, training_loss: 1.41015
Epoch: 1/10, step: 38459, training_loss: 1.51295
Epoch: 1/10, step: 38479, training_loss: 1.49477
Epoch: 1/10, step: 38499, training_loss: 1.49089
Epoch: 1/10, step: 38519, training_loss: 1.44662
Epoch: 1/10, step: 38539, training_loss: 1.60800
Epoch: 1/10, step: 38559, training_loss: 1.44032
Epoch: 1/10, step: 38579, training_loss: 2.21627
Epoch: 1/10, step: 38599, training_loss: 1.44904
Epoch: 1/10, step: 38619, training_loss: 1.34887
Epoch: 1/10, step: 38639, training_loss: 1.94210
Epoch: 1/10, step: 38659, training_loss: 1.74825
Epoch: 1/10, step: 38679, training_loss: 1.18613
Epoch: 1/10, step: 38699, training_loss: 2.01505
Epoch: 1/10, step: 38719, training_loss: 1.39223
Epoch: 1/10, step: 38739, training_loss: 2.03297
Epoch: 1/10, step: 38759, training_loss: 1.69703
Epoch: 1/10, step: 38779, training_loss: 1.67055
Epoch: 1/10, step: 38799, training_loss: 1.91465
Epoch: 1/10, step: 38819, training_loss: 1.32833
Epoch: 1/10, step: 38839, training_loss: 2.48284
Epoch: 1/10, step: 38859, training_loss: 1.50494
Epoch: 1/10, step: 38879, training_loss: 1.82684
Epoch: 1/10, step: 38899, training_loss: 1.74937
Epoch: 1/10, step: 38919, training_loss: 1.65074
Epoch: 1/10, step: 38939, training_loss: 1.23992
Epoch: 1/10, step: 38959, training_loss: 1.33185
Epoch: 1/10, step: 38979, training_loss: 1.87034
Epoch: 1/10, step: 38999, training_loss: 1.94330
accuracy: 0.37, validation_loss: 1.7952783107757568, num_samples: 100
Epoch: 1/10, step: 39019, training_loss: 1.53221
Epoch: 1/10, step: 39039, training_loss: 2.12243
Epoch: 1/10, step: 39059, training_loss: 1.95076
Epoch: 1/10, step: 39079, training_loss: 1.47346
Epoch: 1/10, step: 39099, training_loss: 1.72298
Epoch: 1/10, step: 39119, training_loss: 1.72674
Epoch: 1/10, step: 39139, training_loss: 2.57906
Epoch: 1/10, step: 39159, training_loss: 1.07530
Epoch: 1/10, step: 39179, training_loss: 1.54557
Epoch: 1/10, step: 39199, training_loss: 0.92476
Epoch: 1/10, step: 39219, training_loss: 1.67096
Epoch: 1/10, step: 39239, training_loss: 2.45187
Epoch: 1/10, step: 39259, training_loss: 2.13389
Epoch: 1/10, step: 39279, training_loss: 1.15755
Epoch: 1/10, step: 39299, training_loss: 1.99685
Epoch: 1/10, step: 39319, training_loss: 1.15884
Epoch: 1/10, step: 39339, training_loss: 1.64614
Epoch: 1/10, step: 39359, training_loss: 1.97438
Epoch: 1/10, step: 39379, training_loss: 1.81621
Epoch: 1/10, step: 39399, training_loss: 1.86282
Epoch: 1/10, step: 39419, training_loss: 1.40094
Epoch: 1/10, step: 39439, training_loss: 1.66790
Epoch: 1/10, step: 39459, training_loss: 1.20701
Epoch: 1/10, step: 39479, training_loss: 1.14776
Epoch: 1/10, step: 39499, training_loss: 1.56246
Epoch: 1/10, step: 39519, training_loss: 1.52795
Epoch: 1/10, step: 39539, training_loss: 2.20359
Epoch: 1/10, step: 39559, training_loss: 1.19677
Epoch: 1/10, step: 39579, training_loss: 1.17302
Epoch: 1/10, step: 39599, training_loss: 1.49591
Epoch: 1/10, step: 39619, training_loss: 1.56095
Epoch: 1/10, step: 39639, training_loss: 1.62346
Epoch: 1/10, step: 39659, training_loss: 1.14386
Epoch: 1/10, step: 39679, training_loss: 1.65072
Epoch: 1/10, step: 39699, training_loss: 1.18314
Epoch: 1/10, step: 39719, training_loss: 2.14193
Epoch: 1/10, step: 39739, training_loss: 1.91702
Epoch: 1/10, step: 39759, training_loss: 1.31928
Epoch: 1/10, step: 39779, training_loss: 1.65138
Epoch: 1/10, step: 39799, training_loss: 1.80909
Epoch: 1/10, step: 39819, training_loss: 1.80179
Epoch: 1/10, step: 39839, training_loss: 2.16330
Epoch: 1/10, step: 39859, training_loss: 1.04973
Epoch: 1/10, step: 39879, training_loss: 0.99149
Epoch: 1/10, step: 39899, training_loss: 2.03504
Epoch: 1/10, step: 39919, training_loss: 1.27704
Epoch: 1/10, step: 39939, training_loss: 1.70980
Epoch: 1/10, step: 39959, training_loss: 2.11011
Epoch: 1/10, step: 39979, training_loss: 1.16310
Epoch: 1/10, step: 39999, training_loss: 1.14042
accuracy: 0.48, validation_loss: 1.575312852859497, num_samples: 100
Epoch: 1/10, step: 40019, training_loss: 2.69567
Epoch: 1/10, step: 40039, training_loss: 2.14103
Epoch: 1/10, step: 40059, training_loss: 1.67680
Epoch: 1/10, step: 40079, training_loss: 2.21623
Epoch: 1/10, step: 40099, training_loss: 1.45568
Epoch: 1/10, step: 40119, training_loss: 2.00757
Epoch: 1/10, step: 40139, training_loss: 1.48198
Epoch: 1/10, step: 40159, training_loss: 2.33397
Epoch: 1/10, step: 40179, training_loss: 1.67174
Epoch: 1/10, step: 40199, training_loss: 1.30355
Epoch: 1/10, step: 40219, training_loss: 1.45995
Epoch: 1/10, step: 40239, training_loss: 1.91545
Epoch: 1/10, step: 40259, training_loss: 1.46301
Epoch: 1/10, step: 40279, training_loss: 1.95403
Epoch: 1/10, step: 40299, training_loss: 1.47826
Epoch: 1/10, step: 40319, training_loss: 1.18618
Epoch: 1/10, step: 40339, training_loss: 1.74114
Epoch: 1/10, step: 40359, training_loss: 1.35134
Epoch: 1/10, step: 40379, training_loss: 1.76754
Epoch: 1/10, step: 40399, training_loss: 0.94015
Epoch: 1/10, step: 40419, training_loss: 1.25455
Epoch: 1/10, step: 40439, training_loss: 1.91794
Epoch: 1/10, step: 40459, training_loss: 1.11697
Epoch: 1/10, step: 40479, training_loss: 1.03021
Epoch: 1/10, step: 40499, training_loss: 0.88927
Epoch: 1/10, step: 40519, training_loss: 1.24804
Epoch: 1/10, step: 40539, training_loss: 1.23556
Epoch: 1/10, step: 40559, training_loss: 2.03096
Epoch: 1/10, step: 40579, training_loss: 2.11755
Epoch: 1/10, step: 40599, training_loss: 1.30758
Epoch: 1/10, step: 40619, training_loss: 1.51507
Epoch: 1/10, step: 40639, training_loss: 0.88821
Epoch: 1/10, step: 40659, training_loss: 1.43756
Epoch: 1/10, step: 40679, training_loss: 1.45878
Epoch: 1/10, step: 40699, training_loss: 1.36162
Epoch: 1/10, step: 40719, training_loss: 2.09998
Epoch: 1/10, step: 40739, training_loss: 1.23149
Epoch: 1/10, step: 40759, training_loss: 1.59355
Epoch: 1/10, step: 40779, training_loss: 1.26473
Epoch: 1/10, step: 40799, training_loss: 1.73557
Epoch: 1/10, step: 40819, training_loss: 1.96743
Epoch: 1/10, step: 40839, training_loss: 1.60826
Epoch: 1/10, step: 40859, training_loss: 2.25892
Epoch: 1/10, step: 40879, training_loss: 1.36221
Epoch: 1/10, step: 40899, training_loss: 1.20714
Epoch: 1/10, step: 40919, training_loss: 1.53687
Epoch: 1/10, step: 40939, training_loss: 1.83736
Epoch: 1/10, step: 40959, training_loss: 1.53813
Epoch: 1/10, step: 40979, training_loss: 1.38456
Epoch: 1/10, step: 40999, training_loss: 1.09494
accuracy: 0.5, validation_loss: 1.4008896350860596, num_samples: 100
Epoch: 1/10, step: 41019, training_loss: 1.88295
Epoch: 1/10, step: 41039, training_loss: 2.12397
Epoch: 1/10, step: 41059, training_loss: 1.83280
Epoch: 1/10, step: 41079, training_loss: 1.32160
Epoch: 1/10, step: 41099, training_loss: 1.50261
Epoch: 1/10, step: 41119, training_loss: 1.49408
Epoch: 1/10, step: 41139, training_loss: 1.25417
Epoch: 1/10, step: 41159, training_loss: 1.40319
Epoch: 1/10, step: 41179, training_loss: 1.98997
Epoch: 1/10, step: 41199, training_loss: 1.38346
Epoch: 1/10, step: 41219, training_loss: 1.00084
Epoch: 1/10, step: 41239, training_loss: 2.43690
Epoch: 1/10, step: 41259, training_loss: 1.12101
Epoch: 1/10, step: 41279, training_loss: 1.31165
Epoch: 1/10, step: 41299, training_loss: 1.74459
Epoch: 1/10, step: 41319, training_loss: 1.58487
Epoch: 1/10, step: 41339, training_loss: 1.63954
Epoch: 1/10, step: 41359, training_loss: 1.60046
Epoch: 1/10, step: 41379, training_loss: 1.54705
Epoch: 1/10, step: 41399, training_loss: 0.97231
Epoch: 1/10, step: 41419, training_loss: 0.95179
Epoch: 1/10, step: 41439, training_loss: 1.26632
Epoch: 1/10, step: 41459, training_loss: 0.87566
Epoch: 1/10, step: 41479, training_loss: 2.09732
Epoch: 1/10, step: 41499, training_loss: 0.72779
Epoch: 1/10, step: 41519, training_loss: 1.37976
Epoch: 1/10, step: 41539, training_loss: 1.60155
Epoch: 1/10, step: 41559, training_loss: 1.44636
Epoch: 1/10, step: 41579, training_loss: 1.64797
Epoch: 1/10, step: 41599, training_loss: 1.05825
Epoch: 1/10, step: 41619, training_loss: 1.67363
Epoch: 1/10, step: 41639, training_loss: 1.55947
Epoch: 1/10, step: 41659, training_loss: 1.02445
Epoch: 1/10, step: 41679, training_loss: 1.64105
Epoch: 1/10, step: 41699, training_loss: 1.55827
Epoch: 1/10, step: 41719, training_loss: 1.76827
Epoch: 1/10, step: 41739, training_loss: 1.68625
Epoch: 1/10, step: 41759, training_loss: 2.13556
Epoch: 1/10, step: 41779, training_loss: 2.18233
Epoch: 1/10, step: 41799, training_loss: 1.74041
Epoch: 1/10, step: 41819, training_loss: 1.50247
Epoch: 1/10, step: 41839, training_loss: 2.25506
Epoch: 1/10, step: 41859, training_loss: 0.99055
Epoch: 1/10, step: 41879, training_loss: 2.17976
Epoch: 1/10, step: 41899, training_loss: 2.04985
Epoch: 1/10, step: 41919, training_loss: 1.67567
Epoch: 1/10, step: 41939, training_loss: 1.98174
Epoch: 1/10, step: 41959, training_loss: 0.94608
Epoch: 1/10, step: 41979, training_loss: 1.47694
Epoch: 1/10, step: 41999, training_loss: 1.44046
accuracy: 0.44, validation_loss: 1.75311279296875, num_samples: 100
Epoch: 1/10, step: 42019, training_loss: 2.49507
Epoch: 1/10, step: 42039, training_loss: 1.53094
Epoch: 1/10, step: 42059, training_loss: 1.37645
Epoch: 1/10, step: 42079, training_loss: 1.60103
Epoch: 1/10, step: 42099, training_loss: 1.60943
Epoch: 1/10, step: 42119, training_loss: 1.15231
Epoch: 1/10, step: 42139, training_loss: 1.10500
Epoch: 1/10, step: 42159, training_loss: 1.63927
Epoch: 1/10, step: 42179, training_loss: 1.15252
Epoch: 1/10, step: 42199, training_loss: 1.64743
Epoch: 1/10, step: 42219, training_loss: 1.63590
Epoch: 1/10, step: 42239, training_loss: 2.20843
Epoch: 1/10, step: 42259, training_loss: 2.19629
Epoch: 1/10, step: 42279, training_loss: 3.09764
Epoch: 1/10, step: 42299, training_loss: 1.60641
Epoch: 1/10, step: 42319, training_loss: 1.88403
Epoch: 1/10, step: 42339, training_loss: 2.28292
Epoch: 1/10, step: 42359, training_loss: 1.55574
Epoch: 1/10, step: 42379, training_loss: 1.53638
Epoch: 1/10, step: 42399, training_loss: 2.02366
Epoch: 1/10, step: 42419, training_loss: 1.70875
Epoch: 1/10, step: 42439, training_loss: 1.28884
Epoch: 1/10, step: 42459, training_loss: 1.80271
Epoch: 1/10, step: 42479, training_loss: 0.91608
Epoch: 1/10, step: 42499, training_loss: 1.40076
Epoch: 1/10, step: 42519, training_loss: 1.36380
Epoch: 1/10, step: 42539, training_loss: 1.50167
Epoch: 1/10, step: 42559, training_loss: 1.72695
Epoch: 1/10, step: 42579, training_loss: 1.89330
Epoch: 1/10, step: 42599, training_loss: 1.68576
Epoch: 1/10, step: 42619, training_loss: 1.73016
Epoch: 1/10, step: 42639, training_loss: 1.55414
Epoch: 1/10, step: 42659, training_loss: 1.86683
Epoch: 1/10, step: 42679, training_loss: 1.18517
Epoch: 1/10, step: 42699, training_loss: 2.06409
Epoch: 1/10, step: 42719, training_loss: 0.97166
Epoch: 1/10, step: 42739, training_loss: 1.97583
Epoch: 1/10, step: 42759, training_loss: 1.39681
Epoch: 1/10, step: 42779, training_loss: 1.08364
Epoch: 1/10, step: 42799, training_loss: 1.32117
Epoch: 1/10, step: 42819, training_loss: 1.49761
Epoch: 1/10, step: 42839, training_loss: 1.54932
Epoch: 1/10, step: 42859, training_loss: 1.32426
Epoch: 1/10, step: 42879, training_loss: 1.70073
Epoch: 1/10, step: 42899, training_loss: 0.91422
Epoch: 1/10, step: 42919, training_loss: 1.66809
Epoch: 1/10, step: 42939, training_loss: 1.36816
Epoch: 1/10, step: 42959, training_loss: 1.92291
Epoch: 1/10, step: 42979, training_loss: 1.88340
Epoch: 1/10, step: 42999, training_loss: 1.10938
accuracy: 0.55, validation_loss: 1.4026439189910889, num_samples: 100
Epoch: 1/10, step: 43019, training_loss: 1.64765
Epoch: 1/10, step: 43039, training_loss: 1.63686
Epoch: 1/10, step: 43059, training_loss: 1.98187
Epoch: 1/10, step: 43079, training_loss: 1.12303
Epoch: 1/10, step: 43099, training_loss: 1.64013
Epoch: 1/10, step: 43119, training_loss: 1.27729
Epoch: 1/10, step: 43139, training_loss: 1.40380
Epoch: 1/10, step: 43159, training_loss: 1.31133
Epoch: 1/10, step: 43179, training_loss: 1.98808
Epoch: 1/10, step: 43199, training_loss: 1.51479
Epoch: 1/10, step: 43219, training_loss: 1.88727
Epoch: 1/10, step: 43239, training_loss: 2.72011
Epoch: 1/10, step: 43259, training_loss: 1.46047
Epoch: 1/10, step: 43279, training_loss: 2.10062
Epoch: 1/10, step: 43299, training_loss: 1.17992
Epoch: 1/10, step: 43319, training_loss: 1.46855
Epoch: 1/10, step: 43339, training_loss: 1.92246
Epoch: 1/10, step: 43359, training_loss: 1.30350
Epoch: 1/10, step: 43379, training_loss: 2.14534
Epoch: 1/10, step: 43399, training_loss: 1.37024
Epoch: 1/10, step: 43419, training_loss: 1.84648
Epoch: 1/10, step: 43439, training_loss: 2.09977
Epoch: 1/10, step: 43459, training_loss: 1.40714
Epoch: 1/10, step: 43479, training_loss: 1.55102
Epoch: 1/10, step: 43499, training_loss: 2.08472
Epoch: 1/10, step: 43519, training_loss: 1.80354
Epoch: 1/10, step: 43539, training_loss: 1.98541
Epoch: 1/10, step: 43559, training_loss: 1.13671
Epoch: 1/10, step: 43579, training_loss: 1.49714
Epoch: 1/10, step: 43599, training_loss: 1.54699
Epoch: 1/10, step: 43619, training_loss: 2.11027
Epoch: 1/10, step: 43639, training_loss: 1.30237
Epoch: 1/10, step: 43659, training_loss: 1.51529
Epoch: 1/10, step: 43679, training_loss: 1.48289
Epoch: 1/10, step: 43699, training_loss: 1.48994
Epoch: 1/10, step: 43719, training_loss: 1.21977
Epoch: 1/10, step: 43739, training_loss: 1.30774
Epoch: 1/10, step: 43759, training_loss: 1.80037
Epoch: 1/10, step: 43779, training_loss: 1.15724
Epoch: 1/10, step: 43799, training_loss: 0.79684
Epoch: 1/10, step: 43819, training_loss: 1.73279
Epoch: 1/10, step: 43839, training_loss: 2.28415
Epoch: 1/10, step: 43859, training_loss: 1.30203
Epoch: 1/10, step: 43879, training_loss: 1.54453
Epoch: 1/10, step: 43899, training_loss: 1.10783
Epoch: 1/10, step: 43919, training_loss: 1.56581
Epoch: 1/10, step: 43939, training_loss: 1.94870
Epoch: 1/10, step: 43959, training_loss: 1.64136
Epoch: 1/10, step: 43979, training_loss: 1.65006
Epoch: 1/10, step: 43999, training_loss: 1.44729
accuracy: 0.39, validation_loss: 1.7791346311569214, num_samples: 100
Epoch: 1/10, step: 44019, training_loss: 1.65043
Epoch: 1/10, step: 44039, training_loss: 1.79909
Epoch: 1/10, step: 44059, training_loss: 2.08660
Epoch: 1/10, step: 44079, training_loss: 2.03215
Epoch: 1/10, step: 44099, training_loss: 1.56232
Epoch: 1/10, step: 44119, training_loss: 1.25641
Epoch: 1/10, step: 44139, training_loss: 1.82887
Epoch: 1/10, step: 44159, training_loss: 1.56520
Epoch: 1/10, step: 44179, training_loss: 2.13909
Epoch: 1/10, step: 44199, training_loss: 0.85297
Epoch: 1/10, step: 44219, training_loss: 1.72372
Epoch: 1/10, step: 44239, training_loss: 1.25439
Epoch: 1/10, step: 44259, training_loss: 1.59875
Epoch: 1/10, step: 44279, training_loss: 1.64037
Epoch: 1/10, step: 44299, training_loss: 2.09389
Epoch: 1/10, step: 44319, training_loss: 1.64989
Epoch: 1/10, step: 44339, training_loss: 1.67234
Epoch: 1/10, step: 44359, training_loss: 1.80429
Epoch: 1/10, step: 44379, training_loss: 1.91726
Epoch: 1/10, step: 44399, training_loss: 1.89448
Epoch: 1/10, step: 44419, training_loss: 1.28383
Epoch: 1/10, step: 44439, training_loss: 1.97328
Epoch: 1/10, step: 44459, training_loss: 2.62424
Epoch: 1/10, step: 44479, training_loss: 1.84461
Epoch: 1/10, step: 44499, training_loss: 1.42066
Epoch: 1/10, step: 44519, training_loss: 1.97225
Epoch: 1/10, step: 44539, training_loss: 1.73577
Epoch: 1/10, step: 44559, training_loss: 2.02917
Epoch: 1/10, step: 44579, training_loss: 2.11123
Epoch: 1/10, step: 44599, training_loss: 1.54173
Epoch: 1/10, step: 44619, training_loss: 1.49979
Epoch: 1/10, step: 44639, training_loss: 1.67039
Epoch: 1/10, step: 44659, training_loss: 1.73351
Epoch: 1/10, step: 44679, training_loss: 1.90880
Epoch: 1/10, step: 44699, training_loss: 1.08593
Epoch: 1/10, step: 44719, training_loss: 1.57233
Epoch: 1/10, step: 44739, training_loss: 1.12463
Epoch: 1/10, step: 44759, training_loss: 1.10194
Epoch: 1/10, step: 44779, training_loss: 1.32815
Epoch: 1/10, step: 44799, training_loss: 1.52385
Epoch: 1/10, step: 44819, training_loss: 1.54152
Epoch: 1/10, step: 44839, training_loss: 2.37664
Epoch: 1/10, step: 44859, training_loss: 1.54818
Epoch: 1/10, step: 44879, training_loss: 1.68503
Epoch: 1/10, step: 44899, training_loss: 1.79507
Epoch: 1/10, step: 44919, training_loss: 1.58098
Epoch: 1/10, step: 44939, training_loss: 1.40949
Epoch: 1/10, step: 44959, training_loss: 1.89450
Epoch: 1/10, step: 44979, training_loss: 1.31181
Epoch: 1/10, step: 44999, training_loss: 1.49572
accuracy: 0.55, validation_loss: 1.483485460281372, num_samples: 100
Epoch: 1/10, step: 45019, training_loss: 1.34982
Epoch: 1/10, step: 45039, training_loss: 2.51757
Epoch: 1/10, step: 45059, training_loss: 1.98239
Epoch: 1/10, step: 45079, training_loss: 1.42577
Epoch: 1/10, step: 45099, training_loss: 1.19055
Epoch: 1/10, step: 45119, training_loss: 2.21837
Epoch: 1/10, step: 45139, training_loss: 1.50402
Epoch: 1/10, step: 45159, training_loss: 1.67451
Epoch: 1/10, step: 45179, training_loss: 1.04339
Epoch: 1/10, step: 45199, training_loss: 1.52272
Epoch: 1/10, step: 45219, training_loss: 1.24638
Epoch: 1/10, step: 45239, training_loss: 1.44237
Epoch: 1/10, step: 45259, training_loss: 2.14744
Epoch: 1/10, step: 45279, training_loss: 1.93199
Epoch: 1/10, step: 45299, training_loss: 1.21547
Epoch: 1/10, step: 45319, training_loss: 1.08561
Epoch: 1/10, step: 45339, training_loss: 1.67419
Epoch: 1/10, step: 45359, training_loss: 1.63076
Epoch: 1/10, step: 45379, training_loss: 1.40911
Epoch: 1/10, step: 45399, training_loss: 1.13642
Epoch: 1/10, step: 45419, training_loss: 0.96783
Epoch: 1/10, step: 45439, training_loss: 1.85630
Epoch: 1/10, step: 45459, training_loss: 1.47700
Epoch: 1/10, step: 45479, training_loss: 2.79972
Epoch: 1/10, step: 45499, training_loss: 1.82363
Epoch: 1/10, step: 45519, training_loss: 1.35450
Epoch: 1/10, step: 45539, training_loss: 1.17096
Epoch: 1/10, step: 45559, training_loss: 2.21802
Epoch: 1/10, step: 45579, training_loss: 1.62349
Epoch: 1/10, step: 45599, training_loss: 1.69810
Epoch: 1/10, step: 45619, training_loss: 2.06631
Epoch: 1/10, step: 45639, training_loss: 2.13654
Epoch: 1/10, step: 45659, training_loss: 1.54399
Epoch: 1/10, step: 45679, training_loss: 1.73263
Epoch: 1/10, step: 45699, training_loss: 1.01190
Epoch: 1/10, step: 45719, training_loss: 1.33818
Epoch: 1/10, step: 45739, training_loss: 1.27506
Epoch: 1/10, step: 45759, training_loss: 1.46577
Epoch: 1/10, step: 45779, training_loss: 1.91835
Epoch: 1/10, step: 45799, training_loss: 1.77319
Epoch: 1/10, step: 45819, training_loss: 1.86085
Epoch: 1/10, step: 45839, training_loss: 2.19111
Epoch: 1/10, step: 45859, training_loss: 1.40084
Epoch: 1/10, step: 45879, training_loss: 0.75402
Epoch: 1/10, step: 45899, training_loss: 1.35124
Epoch: 1/10, step: 45919, training_loss: 1.12949
Epoch: 1/10, step: 45939, training_loss: 2.19257
Epoch: 1/10, step: 45959, training_loss: 1.38540
Epoch: 1/10, step: 45979, training_loss: 2.29288
Epoch: 1/10, step: 45999, training_loss: 1.44969
accuracy: 0.47, validation_loss: 1.543015956878662, num_samples: 100
Epoch: 1/10, step: 46019, training_loss: 1.38362
Epoch: 1/10, step: 46039, training_loss: 0.98095
Epoch: 1/10, step: 46059, training_loss: 1.33559
Epoch: 1/10, step: 46079, training_loss: 1.97051
Epoch: 1/10, step: 46099, training_loss: 1.99409
Epoch: 1/10, step: 46119, training_loss: 1.58618
Epoch: 1/10, step: 46139, training_loss: 1.53761
Epoch: 1/10, step: 46159, training_loss: 2.22133
Epoch: 1/10, step: 46179, training_loss: 1.31233
Epoch: 1/10, step: 46199, training_loss: 1.60720
Epoch: 1/10, step: 46219, training_loss: 1.13780
Epoch: 1/10, step: 46239, training_loss: 1.67085
Epoch: 1/10, step: 46259, training_loss: 1.14432
Epoch: 1/10, step: 46279, training_loss: 2.19205
Epoch: 1/10, step: 46299, training_loss: 1.87324
Epoch: 1/10, step: 46319, training_loss: 1.35999
Epoch: 1/10, step: 46339, training_loss: 1.35767
Epoch: 1/10, step: 46359, training_loss: 1.46872
Epoch: 1/10, step: 46379, training_loss: 1.52908
Epoch: 1/10, step: 46399, training_loss: 1.78934
Epoch: 1/10, step: 46419, training_loss: 1.62770
Epoch: 1/10, step: 46439, training_loss: 1.41981
Epoch: 1/10, step: 46459, training_loss: 1.24952
Epoch: 1/10, step: 46479, training_loss: 1.92092
Epoch: 1/10, step: 46499, training_loss: 1.65884
Epoch: 1/10, step: 46519, training_loss: 1.67785
Epoch: 1/10, step: 46539, training_loss: 2.36628
Epoch: 1/10, step: 46559, training_loss: 1.91202
Epoch: 1/10, step: 46579, training_loss: 1.41669
Epoch: 1/10, step: 46599, training_loss: 1.43302
Epoch: 1/10, step: 46619, training_loss: 1.34109
Epoch: 1/10, step: 46639, training_loss: 1.61797
Epoch: 1/10, step: 46659, training_loss: 1.18771
Epoch: 1/10, step: 46679, training_loss: 1.14753
Epoch: 1/10, step: 46699, training_loss: 1.73651
Epoch: 1/10, step: 46719, training_loss: 1.53216
Epoch: 1/10, step: 46739, training_loss: 1.49778
Epoch: 1/10, step: 46759, training_loss: 1.27427
Epoch: 1/10, step: 46779, training_loss: 1.75616
Epoch: 1/10, step: 46799, training_loss: 1.24906
Epoch: 1/10, step: 46819, training_loss: 1.51360
Epoch: 1/10, step: 46839, training_loss: 1.72089
Epoch: 1/10, step: 46859, training_loss: 2.12483
Epoch: 1/10, step: 46879, training_loss: 1.03477
Epoch: 1/10, step: 46899, training_loss: 1.23191
Epoch: 1/10, step: 46919, training_loss: 1.74537
Epoch: 1/10, step: 46939, training_loss: 2.13162
Epoch: 1/10, step: 46959, training_loss: 1.77156
Epoch: 1/10, step: 46979, training_loss: 1.54096
Epoch: 1/10, step: 46999, training_loss: 1.52307
accuracy: 0.42, validation_loss: 1.6867480278015137, num_samples: 100
Epoch: 1/10, step: 47019, training_loss: 1.72732
Epoch: 1/10, step: 47039, training_loss: 1.15824
Epoch: 1/10, step: 47059, training_loss: 1.66835
Epoch: 1/10, step: 47079, training_loss: 1.71835
Epoch: 1/10, step: 47099, training_loss: 1.24313
Epoch: 1/10, step: 47119, training_loss: 1.50873
Epoch: 1/10, step: 47139, training_loss: 1.38247
Epoch: 1/10, step: 47159, training_loss: 1.76861
Epoch: 1/10, step: 47179, training_loss: 1.65082
Epoch: 1/10, step: 47199, training_loss: 1.69578
Epoch: 1/10, step: 47219, training_loss: 1.13311
Epoch: 1/10, step: 47239, training_loss: 1.68284
Epoch: 1/10, step: 47259, training_loss: 2.25671
Epoch: 1/10, step: 47279, training_loss: 2.60089
Epoch: 1/10, step: 47299, training_loss: 1.83891
Epoch: 1/10, step: 47319, training_loss: 1.80932
Epoch: 1/10, step: 47339, training_loss: 1.59155
Epoch: 1/10, step: 47359, training_loss: 1.68605
Epoch: 1/10, step: 47379, training_loss: 1.97253
Epoch: 1/10, step: 47399, training_loss: 2.09291
Epoch: 1/10, step: 47419, training_loss: 1.78313
Epoch: 1/10, step: 47439, training_loss: 1.46879
Epoch: 1/10, step: 47459, training_loss: 1.03268
Epoch: 1/10, step: 47479, training_loss: 1.42602
Epoch: 1/10, step: 47499, training_loss: 1.74236
Epoch: 1/10, step: 47519, training_loss: 1.19178
Epoch: 1/10, step: 47539, training_loss: 1.03398
Epoch: 1/10, step: 47559, training_loss: 0.91866
Epoch: 1/10, step: 47579, training_loss: 1.28024
Epoch: 1/10, step: 47599, training_loss: 1.65251
Epoch: 1/10, step: 47619, training_loss: 1.64059
Epoch: 1/10, step: 47639, training_loss: 2.72486
Epoch: 1/10, step: 47659, training_loss: 2.33705
Epoch: 1/10, step: 47679, training_loss: 1.16543
Epoch: 1/10, step: 47699, training_loss: 1.16446
Epoch: 1/10, step: 47719, training_loss: 1.52944
Epoch: 1/10, step: 47739, training_loss: 1.26032
Epoch: 1/10, step: 47759, training_loss: 1.24026
Epoch: 1/10, step: 47779, training_loss: 1.14332
Epoch: 1/10, step: 47799, training_loss: 1.53792
Epoch: 1/10, step: 47819, training_loss: 1.40253
Epoch: 1/10, step: 47839, training_loss: 1.17941
Epoch: 1/10, step: 47859, training_loss: 1.02144
Epoch: 1/10, step: 47879, training_loss: 1.98394
Epoch: 1/10, step: 47899, training_loss: 1.42747
Epoch: 1/10, step: 47919, training_loss: 1.25939
Epoch: 1/10, step: 47939, training_loss: 1.56050
Epoch: 1/10, step: 47959, training_loss: 1.51721
Epoch: 1/10, step: 47979, training_loss: 1.52182
Epoch: 1/10, step: 47999, training_loss: 1.32360
accuracy: 0.42, validation_loss: 1.6784427165985107, num_samples: 100
Epoch: 1/10, step: 48019, training_loss: 1.40970
Epoch: 1/10, step: 48039, training_loss: 1.38415
Epoch: 1/10, step: 48059, training_loss: 1.68904
Epoch: 1/10, step: 48079, training_loss: 1.84435
Epoch: 1/10, step: 48099, training_loss: 2.46623
Epoch: 1/10, step: 48119, training_loss: 1.38188
Epoch: 1/10, step: 48139, training_loss: 1.49458
Epoch: 1/10, step: 48159, training_loss: 2.05773
Epoch: 1/10, step: 48179, training_loss: 2.56637
Epoch: 1/10, step: 48199, training_loss: 1.76096
Epoch: 1/10, step: 48219, training_loss: 2.45266
Epoch: 1/10, step: 48239, training_loss: 1.50703
Epoch: 1/10, step: 48259, training_loss: 0.97417
Epoch: 1/10, step: 48279, training_loss: 1.70315
Epoch: 1/10, step: 48299, training_loss: 1.24888
Epoch: 1/10, step: 48319, training_loss: 1.65845
Epoch: 1/10, step: 48339, training_loss: 1.62758
Epoch: 1/10, step: 48359, training_loss: 1.48425
Epoch: 1/10, step: 48379, training_loss: 0.98239
Epoch: 1/10, step: 48399, training_loss: 1.73094
Epoch: 1/10, step: 48419, training_loss: 1.18473
Epoch: 1/10, step: 48439, training_loss: 0.99375
Epoch: 1/10, step: 48459, training_loss: 1.26292
Epoch: 1/10, step: 48479, training_loss: 1.48433
Epoch: 1/10, step: 48499, training_loss: 2.82799
Epoch: 1/10, step: 48519, training_loss: 1.99127
Epoch: 1/10, step: 48539, training_loss: 1.28693
Epoch: 1/10, step: 48559, training_loss: 2.60173
Epoch: 1/10, step: 48579, training_loss: 1.39530
Epoch: 1/10, step: 48599, training_loss: 1.77997
Epoch: 1/10, step: 48619, training_loss: 1.30254
Epoch: 1/10, step: 48639, training_loss: 1.69455
Epoch: 1/10, step: 48659, training_loss: 2.18934
Epoch: 1/10, step: 48679, training_loss: 2.04674
Epoch: 1/10, step: 48699, training_loss: 1.16024
Epoch: 1/10, step: 48719, training_loss: 1.20466
Epoch: 1/10, step: 48739, training_loss: 1.67334
Epoch: 1/10, step: 48759, training_loss: 2.53177
Epoch: 1/10, step: 48779, training_loss: 2.32951
Epoch: 1/10, step: 48799, training_loss: 1.91997
Epoch: 1/10, step: 48819, training_loss: 1.47908
Epoch: 1/10, step: 48839, training_loss: 1.49117
Epoch: 1/10, step: 48859, training_loss: 1.49195
Epoch: 1/10, step: 48879, training_loss: 2.34375
Epoch: 1/10, step: 48899, training_loss: 1.30599
Epoch: 1/10, step: 48919, training_loss: 1.36726
Epoch: 1/10, step: 48939, training_loss: 2.01578
Epoch: 1/10, step: 48959, training_loss: 1.56634
Epoch: 1/10, step: 48979, training_loss: 1.95685
Epoch: 1/10, step: 48999, training_loss: 1.13991
accuracy: 0.52, validation_loss: 1.5691511631011963, num_samples: 100
Epoch: 1/10, step: 49019, training_loss: 1.67172
Epoch: 1/10, step: 49039, training_loss: 1.06472
Epoch: 1/10, step: 49059, training_loss: 2.73918
Epoch: 1/10, step: 49079, training_loss: 1.96750
Epoch: 1/10, step: 49099, training_loss: 2.06261
Epoch: 1/10, step: 49119, training_loss: 1.95831
Epoch: 1/10, step: 49139, training_loss: 1.16705
Epoch: 1/10, step: 49159, training_loss: 1.78509
Epoch: 1/10, step: 49179, training_loss: 1.14798
Epoch: 1/10, step: 49199, training_loss: 1.79186
Epoch: 1/10, step: 49219, training_loss: 1.49814
Epoch: 1/10, step: 49239, training_loss: 1.84858
Epoch: 1/10, step: 49259, training_loss: 1.89693
Epoch: 1/10, step: 49279, training_loss: 2.15515
Epoch: 1/10, step: 49299, training_loss: 2.10120
Epoch: 1/10, step: 49319, training_loss: 1.49058
Epoch: 1/10, step: 49339, training_loss: 1.43356
Epoch: 1/10, step: 49359, training_loss: 1.51590
Epoch: 1/10, step: 49379, training_loss: 2.09062
Epoch: 1/10, step: 49399, training_loss: 1.39925
Epoch: 1/10, step: 49419, training_loss: 1.90944
Epoch: 1/10, step: 49439, training_loss: 1.54630
Epoch: 1/10, step: 49459, training_loss: 1.12223
Epoch: 1/10, step: 49479, training_loss: 1.33571
Epoch: 1/10, step: 49499, training_loss: 1.50504
Epoch: 1/10, step: 49519, training_loss: 1.64870
Epoch: 1/10, step: 49539, training_loss: 1.52118
Epoch: 1/10, step: 49559, training_loss: 1.33253
Epoch: 1/10, step: 49579, training_loss: 2.62158
Epoch: 1/10, step: 49599, training_loss: 2.05445
Epoch: 1/10, step: 49619, training_loss: 1.28919
Epoch: 1/10, step: 49639, training_loss: 1.16559
Epoch: 1/10, step: 49659, training_loss: 1.60724
Epoch: 1/10, step: 49679, training_loss: 2.07295
Epoch: 1/10, step: 49699, training_loss: 1.21549
Epoch: 1/10, step: 49719, training_loss: 1.71854
Epoch: 1/10, step: 49739, training_loss: 1.09762
Epoch: 1/10, step: 49759, training_loss: 2.15141
Epoch: 1/10, step: 49779, training_loss: 1.19651
Epoch: 1/10, step: 49799, training_loss: 1.63867
Epoch: 1/10, step: 49819, training_loss: 1.44916
Epoch: 1/10, step: 49839, training_loss: 1.87738
Epoch: 1/10, step: 49859, training_loss: 1.34746
Epoch: 1/10, step: 49879, training_loss: 1.49838
Epoch: 1/10, step: 49899, training_loss: 1.41273
Epoch: 1/10, step: 49919, training_loss: 1.42832
Epoch: 1/10, step: 49939, training_loss: 1.44882
Epoch: 1/10, step: 49959, training_loss: 1.64478
Epoch: 1/10, step: 49979, training_loss: 1.96626
Epoch: 1/10, step: 49999, training_loss: 0.91113
accuracy: 0.57, validation_loss: 1.3655118942260742, num_samples: 100
Epoch: 1/10, step: 50019, training_loss: 1.78347
Epoch: 1/10, step: 50039, training_loss: 1.16459
Epoch: 1/10, step: 50059, training_loss: 2.35960
Epoch: 1/10, step: 50079, training_loss: 1.31236
Epoch: 1/10, step: 50099, training_loss: 1.41879
Epoch: 1/10, step: 50119, training_loss: 1.83395
Epoch: 1/10, step: 50139, training_loss: 1.64606
Epoch: 1/10, step: 50159, training_loss: 2.02180
Epoch: 1/10, step: 50179, training_loss: 2.00148
Epoch: 1/10, step: 50199, training_loss: 1.59860
Epoch: 1/10, step: 50219, training_loss: 1.67923
Epoch: 1/10, step: 50239, training_loss: 1.49533
Epoch: 1/10, step: 50259, training_loss: 1.46059
Epoch: 1/10, step: 50279, training_loss: 1.80633
Epoch: 1/10, step: 50299, training_loss: 1.06372
Epoch: 1/10, step: 50319, training_loss: 0.86457
Epoch: 1/10, step: 50339, training_loss: 1.25158
Epoch: 1/10, step: 50359, training_loss: 1.69170
Epoch: 1/10, step: 50379, training_loss: 1.30189
Epoch: 1/10, step: 50399, training_loss: 1.46492
Epoch: 1/10, step: 50419, training_loss: 1.55315
Epoch: 1/10, step: 50439, training_loss: 1.42681
Epoch: 1/10, step: 50459, training_loss: 2.15286
Epoch: 1/10, step: 50479, training_loss: 1.26748
Epoch: 1/10, step: 50499, training_loss: 1.83552
Epoch: 1/10, step: 50519, training_loss: 1.41849
Epoch: 1/10, step: 50539, training_loss: 2.15723
Epoch: 1/10, step: 50559, training_loss: 1.67804
Epoch: 1/10, step: 50579, training_loss: 1.91619
Epoch: 1/10, step: 50599, training_loss: 1.84410
Epoch: 1/10, step: 50619, training_loss: 1.51826
Epoch: 1/10, step: 50639, training_loss: 2.19575
Epoch: 1/10, step: 50659, training_loss: 2.29414
Epoch: 1/10, step: 50679, training_loss: 1.51043
Epoch: 1/10, step: 50699, training_loss: 1.61238
Epoch: 1/10, step: 50719, training_loss: 2.00302
Epoch: 1/10, step: 50739, training_loss: 1.99550
Epoch: 1/10, step: 50759, training_loss: 1.07474
Epoch: 1/10, step: 50779, training_loss: 1.15569
Epoch: 1/10, step: 50799, training_loss: 1.36758
Epoch: 1/10, step: 50819, training_loss: 1.79665
Epoch: 1/10, step: 50839, training_loss: 1.78679
Epoch: 1/10, step: 50859, training_loss: 1.71403
Epoch: 1/10, step: 50879, training_loss: 1.57285
Epoch: 1/10, step: 50899, training_loss: 0.85506
Epoch: 1/10, step: 50919, training_loss: 1.41304
Epoch: 1/10, step: 50939, training_loss: 1.82165
Epoch: 1/10, step: 50959, training_loss: 1.21717
Epoch: 1/10, step: 50979, training_loss: 1.81127
Epoch: 1/10, step: 50999, training_loss: 1.18060
accuracy: 0.54, validation_loss: 1.6010241508483887, num_samples: 100
Epoch: 1/10, step: 51019, training_loss: 2.02719
Epoch: 1/10, step: 51039, training_loss: 2.19254
Epoch: 1/10, step: 51059, training_loss: 1.24069
Epoch: 1/10, step: 51079, training_loss: 0.91014
Epoch: 1/10, step: 51099, training_loss: 2.12341
Epoch: 1/10, step: 51119, training_loss: 2.43850
Epoch: 1/10, step: 51139, training_loss: 2.65976
Epoch: 1/10, step: 51159, training_loss: 1.45611
Epoch: 1/10, step: 51179, training_loss: 1.84673
Epoch: 1/10, step: 51199, training_loss: 1.62603
Epoch: 1/10, step: 51219, training_loss: 1.91386
Epoch: 1/10, step: 51239, training_loss: 1.72747
Epoch: 1/10, step: 51259, training_loss: 2.14813
Epoch: 1/10, step: 51279, training_loss: 1.60101
Epoch: 1/10, step: 51299, training_loss: 1.37925
Epoch: 1/10, step: 51319, training_loss: 1.30421
Epoch: 1/10, step: 51339, training_loss: 1.26875
Epoch: 1/10, step: 51359, training_loss: 0.97867
Epoch: 1/10, step: 51379, training_loss: 1.34058
Epoch: 1/10, step: 51399, training_loss: 2.01492
Epoch: 1/10, step: 51419, training_loss: 1.91875
Epoch: 1/10, step: 51439, training_loss: 2.22452
Epoch: 1/10, step: 51459, training_loss: 1.96056
Epoch: 1/10, step: 51479, training_loss: 1.12367
Epoch: 1/10, step: 51499, training_loss: 1.56063
Epoch: 1/10, step: 51519, training_loss: 1.38444
Epoch: 1/10, step: 51539, training_loss: 1.28837
Epoch: 1/10, step: 51559, training_loss: 0.75830
Epoch: 1/10, step: 51579, training_loss: 1.53270
Epoch: 1/10, step: 51599, training_loss: 1.17930
Epoch: 1/10, step: 51619, training_loss: 1.48429
Epoch: 1/10, step: 51639, training_loss: 1.35662
Epoch: 1/10, step: 51659, training_loss: 1.76209
Epoch: 1/10, step: 51679, training_loss: 1.78896
Epoch: 1/10, step: 51699, training_loss: 1.21968
Epoch: 1/10, step: 51719, training_loss: 1.33423
Epoch: 1/10, step: 51739, training_loss: 2.40970
Epoch: 1/10, step: 51759, training_loss: 1.29007
Epoch: 1/10, step: 51779, training_loss: 2.00193
Epoch: 1/10, step: 51799, training_loss: 1.53438
Epoch: 1/10, step: 51819, training_loss: 1.21415
Epoch: 1/10, step: 51839, training_loss: 1.35750
Epoch: 1/10, step: 51859, training_loss: 1.36505
Epoch: 1/10, step: 51879, training_loss: 1.96366
Epoch: 1/10, step: 51899, training_loss: 2.43235
Epoch: 1/10, step: 51919, training_loss: 1.28266
Epoch: 1/10, step: 51939, training_loss: 1.39924
Epoch: 1/10, step: 51959, training_loss: 1.28619
Epoch: 1/10, step: 51979, training_loss: 2.45421
Epoch: 1/10, step: 51999, training_loss: 1.27764
accuracy: 0.44, validation_loss: 1.6122599840164185, num_samples: 100
Epoch: 1/10, step: 52019, training_loss: 1.93744
Epoch: 1/10, step: 52039, training_loss: 1.20389
Epoch: 1/10, step: 52059, training_loss: 1.74341
Epoch: 1/10, step: 52079, training_loss: 1.57913
Epoch: 1/10, step: 52099, training_loss: 2.36668
Epoch: 1/10, step: 52119, training_loss: 1.74249
Epoch: 1/10, step: 52139, training_loss: 1.86422
Epoch: 1/10, step: 52159, training_loss: 1.74231
Epoch: 1/10, step: 52179, training_loss: 1.53085
Epoch: 1/10, step: 52199, training_loss: 2.04568
Epoch: 1/10, step: 52219, training_loss: 1.38864
Epoch: 1/10, step: 52239, training_loss: 1.43052
Epoch: 1/10, step: 52259, training_loss: 2.54927
Epoch: 1/10, step: 52279, training_loss: 1.50177
Epoch: 1/10, step: 52299, training_loss: 1.62359
Epoch: 1/10, step: 52319, training_loss: 1.45464
Epoch: 1/10, step: 52339, training_loss: 1.46740
Epoch: 1/10, step: 52359, training_loss: 1.65956
Epoch: 1/10, step: 52379, training_loss: 1.73425
Epoch: 1/10, step: 52399, training_loss: 1.04969
Epoch: 1/10, step: 52419, training_loss: 1.94066
Epoch: 1/10, step: 52439, training_loss: 1.32881
Epoch: 1/10, step: 52459, training_loss: 1.39764
Epoch: 1/10, step: 52479, training_loss: 1.89267
Epoch: 1/10, step: 52499, training_loss: 1.05500
Epoch: 1/10, step: 52519, training_loss: 1.45687
Epoch: 1/10, step: 52539, training_loss: 2.28817
Epoch: 1/10, step: 52559, training_loss: 2.10902
Epoch: 1/10, step: 52579, training_loss: 1.39457
Epoch: 1/10, step: 52599, training_loss: 1.93514
Epoch: 1/10, step: 52619, training_loss: 1.41926
Epoch: 1/10, step: 52639, training_loss: 1.17343
Epoch: 1/10, step: 52659, training_loss: 1.39630
Epoch: 1/10, step: 52679, training_loss: 1.90741
Epoch: 1/10, step: 52699, training_loss: 1.60404
Epoch: 1/10, step: 52719, training_loss: 1.77670
Epoch: 1/10, step: 52739, training_loss: 1.65889
Epoch: 1/10, step: 52759, training_loss: 1.31752
Epoch: 1/10, step: 52779, training_loss: 1.50125
Epoch: 1/10, step: 52799, training_loss: 1.65462
Epoch: 1/10, step: 52819, training_loss: 1.64236
Epoch: 1/10, step: 52839, training_loss: 2.00706
Epoch: 1/10, step: 52859, training_loss: 1.46796
Epoch: 1/10, step: 52879, training_loss: 1.59141
Epoch: 1/10, step: 52899, training_loss: 1.71581
Epoch: 1/10, step: 52919, training_loss: 1.35579
Epoch: 1/10, step: 52939, training_loss: 2.08782
Epoch: 1/10, step: 52959, training_loss: 1.44910
Epoch: 1/10, step: 52979, training_loss: 1.46104
Epoch: 1/10, step: 52999, training_loss: 1.30286
accuracy: 0.56, validation_loss: 1.4544780254364014, num_samples: 100
Epoch: 1/10, step: 53019, training_loss: 1.38001
Epoch: 1/10, step: 53039, training_loss: 1.80135
Epoch: 1/10, step: 53059, training_loss: 2.47976
Epoch: 1/10, step: 53079, training_loss: 1.55648
Epoch: 1/10, step: 53099, training_loss: 1.85860
Epoch: 1/10, step: 53119, training_loss: 1.35686
Epoch: 1/10, step: 53139, training_loss: 1.57391
Epoch: 1/10, step: 53159, training_loss: 1.40694
Epoch: 1/10, step: 53179, training_loss: 1.57555
Epoch: 1/10, step: 53199, training_loss: 1.28889
Epoch: 1/10, step: 53219, training_loss: 1.62981
Epoch: 1/10, step: 53239, training_loss: 1.04585
Epoch: 1/10, step: 53259, training_loss: 1.55107
Epoch: 1/10, step: 53279, training_loss: 1.67839
Epoch: 1/10, step: 53299, training_loss: 1.60904
Epoch: 1/10, step: 53319, training_loss: 2.12452
Epoch: 1/10, step: 53339, training_loss: 2.07812
Epoch: 1/10, step: 53359, training_loss: 2.29355
Epoch: 1/10, step: 53379, training_loss: 2.26250
Epoch: 1/10, step: 53399, training_loss: 1.15071
Epoch: 1/10, step: 53419, training_loss: 1.37963
Epoch: 1/10, step: 53439, training_loss: 2.14511
Epoch: 1/10, step: 53459, training_loss: 1.56776
Epoch: 1/10, step: 53479, training_loss: 1.79831
Epoch: 1/10, step: 53499, training_loss: 0.89555
Epoch: 1/10, step: 53519, training_loss: 1.65101
Epoch: 1/10, step: 53539, training_loss: 1.61701
Epoch: 1/10, step: 53559, training_loss: 1.01951
Epoch: 1/10, step: 53579, training_loss: 1.80549
Epoch: 1/10, step: 53599, training_loss: 1.73167
Epoch: 1/10, step: 53619, training_loss: 1.69652
Epoch: 1/10, step: 53639, training_loss: 1.91348
Epoch: 1/10, step: 53659, training_loss: 1.67809
Epoch: 1/10, step: 53679, training_loss: 1.94233
Epoch: 1/10, step: 53699, training_loss: 1.41409
Epoch: 1/10, step: 53719, training_loss: 1.68459
Epoch: 1/10, step: 53739, training_loss: 2.22404
Epoch: 1/10, step: 53759, training_loss: 1.20334
Epoch: 1/10, step: 53779, training_loss: 0.93864
Epoch: 1/10, step: 53799, training_loss: 1.30420
Epoch: 1/10, step: 53819, training_loss: 1.86376
Epoch: 1/10, step: 53839, training_loss: 2.02857
Epoch: 1/10, step: 53859, training_loss: 1.77247
Epoch: 1/10, step: 53879, training_loss: 1.46494
Epoch: 1/10, step: 53899, training_loss: 2.11471
Epoch: 1/10, step: 53919, training_loss: 1.73128
Epoch: 1/10, step: 53939, training_loss: 1.52953
Epoch: 1/10, step: 53959, training_loss: 1.73733
Epoch: 1/10, step: 53979, training_loss: 1.24830
Epoch: 1/10, step: 53999, training_loss: 0.87626
accuracy: 0.49, validation_loss: 1.4471893310546875, num_samples: 100
Epoch: 1/10, step: 54019, training_loss: 1.38500
Epoch: 1/10, step: 54039, training_loss: 1.25441
Epoch: 1/10, step: 54059, training_loss: 1.59307
Epoch: 1/10, step: 54079, training_loss: 1.47325
Epoch: 1/10, step: 54099, training_loss: 1.95006
Epoch: 1/10, step: 54119, training_loss: 1.49829
Epoch: 1/10, step: 54139, training_loss: 1.47219
Epoch: 1/10, step: 54159, training_loss: 2.21347
Epoch: 1/10, step: 54179, training_loss: 1.96635
Epoch: 1/10, step: 54199, training_loss: 2.13356
Epoch: 1/10, step: 54219, training_loss: 1.30103
Epoch: 1/10, step: 54239, training_loss: 1.88736
Epoch: 1/10, step: 54259, training_loss: 1.56073
Epoch: 1/10, step: 54279, training_loss: 0.88515
Epoch: 1/10, step: 54299, training_loss: 1.21147
Epoch: 1/10, step: 54319, training_loss: 1.70790
Epoch: 1/10, step: 54339, training_loss: 1.27082
Epoch: 1/10, step: 54359, training_loss: 2.28975
Epoch: 1/10, step: 54379, training_loss: 1.41102
Epoch: 1/10, step: 54399, training_loss: 1.18794
Epoch: 1/10, step: 54419, training_loss: 1.03850
Epoch: 1/10, step: 54439, training_loss: 1.51925
Epoch: 1/10, step: 54459, training_loss: 1.89623
Epoch: 1/10, step: 54479, training_loss: 2.05571
Epoch: 1/10, step: 54499, training_loss: 1.47986
Epoch: 1/10, step: 54519, training_loss: 1.91277
Epoch: 1/10, step: 54539, training_loss: 1.85026
Epoch: 1/10, step: 54559, training_loss: 1.85635
Epoch: 1/10, step: 54579, training_loss: 1.32272
Epoch: 1/10, step: 54599, training_loss: 1.22744
Epoch: 1/10, step: 54619, training_loss: 0.96661
Epoch: 1/10, step: 54639, training_loss: 1.43142
Epoch: 1/10, step: 54659, training_loss: 1.45449
Epoch: 1/10, step: 54679, training_loss: 1.48800
Epoch: 1/10, step: 54699, training_loss: 2.21611
Epoch: 1/10, step: 54719, training_loss: 1.59400
Epoch: 1/10, step: 54739, training_loss: 2.21943
Epoch: 1/10, step: 54759, training_loss: 1.84259
Epoch: 1/10, step: 54779, training_loss: 1.41938
Epoch: 1/10, step: 54799, training_loss: 1.26643
Epoch: 1/10, step: 54819, training_loss: 1.58089
Epoch: 1/10, step: 54839, training_loss: 1.95848
Epoch: 1/10, step: 54859, training_loss: 1.70133
Epoch: 1/10, step: 54879, training_loss: 1.64405
Epoch: 1/10, step: 54899, training_loss: 0.83615
Epoch: 1/10, step: 54919, training_loss: 1.65766
Epoch: 1/10, step: 54939, training_loss: 2.21656
Epoch: 1/10, step: 54959, training_loss: 1.22146
Epoch: 1/10, step: 54979, training_loss: 1.95433
Epoch: 1/10, step: 54999, training_loss: 1.45517
accuracy: 0.58, validation_loss: 1.3375978469848633, num_samples: 100
Epoch: 1/10, step: 55019, training_loss: 1.89279
Epoch: 1/10, step: 55039, training_loss: 2.04242
Epoch: 1/10, step: 55059, training_loss: 1.24046
Epoch: 1/10, step: 55079, training_loss: 1.52382
Epoch: 1/10, step: 55099, training_loss: 1.48670
Epoch: 1/10, step: 55119, training_loss: 0.85743
Epoch: 1/10, step: 55139, training_loss: 1.52206
Epoch: 1/10, step: 55159, training_loss: 2.35448
Epoch: 1/10, step: 55179, training_loss: 1.57116
Epoch: 1/10, step: 55199, training_loss: 1.00852
Epoch: 1/10, step: 55219, training_loss: 1.81049
Epoch: 1/10, step: 55239, training_loss: 1.46518
Epoch: 1/10, step: 55259, training_loss: 1.75055
Epoch: 1/10, step: 55279, training_loss: 2.01954
Epoch: 1/10, step: 55299, training_loss: 1.67946
Epoch: 1/10, step: 55319, training_loss: 2.24913
Epoch: 1/10, step: 55339, training_loss: 2.02237
Epoch: 1/10, step: 55359, training_loss: 1.27858
Epoch: 1/10, step: 55379, training_loss: 1.65316
Epoch: 1/10, step: 55399, training_loss: 1.58773
Epoch: 1/10, step: 55419, training_loss: 1.10572
Epoch: 1/10, step: 55439, training_loss: 1.45862
Epoch: 1/10, step: 55459, training_loss: 1.24875
Epoch: 1/10, step: 55479, training_loss: 1.43423
Epoch: 1/10, step: 55499, training_loss: 1.07952
Epoch: 1/10, step: 55519, training_loss: 1.29307
Epoch: 1/10, step: 55539, training_loss: 1.66319
Epoch: 1/10, step: 55559, training_loss: 1.61968
Epoch: 1/10, step: 55579, training_loss: 1.63817
Epoch: 1/10, step: 55599, training_loss: 1.19598
Epoch: 1/10, step: 55619, training_loss: 1.42625
Epoch: 1/10, step: 55639, training_loss: 1.58380
Epoch: 1/10, step: 55659, training_loss: 1.52248
Epoch: 1/10, step: 55679, training_loss: 1.21620
Epoch: 1/10, step: 55699, training_loss: 1.38932
Epoch: 1/10, step: 55719, training_loss: 1.26039
Epoch: 1/10, step: 55739, training_loss: 2.01383
Epoch: 1/10, step: 55759, training_loss: 2.37593
Epoch: 1/10, step: 55779, training_loss: 1.24443
Epoch: 1/10, step: 55799, training_loss: 1.57925
Epoch: 1/10, step: 55819, training_loss: 1.77371
Epoch: 1/10, step: 55839, training_loss: 1.78874
Epoch: 1/10, step: 55859, training_loss: 1.05328
Epoch: 1/10, step: 55879, training_loss: 2.20298
Epoch: 1/10, step: 55899, training_loss: 1.31197
Epoch: 1/10, step: 55919, training_loss: 1.62639
Epoch: 1/10, step: 55939, training_loss: 2.24029
Epoch: 1/10, step: 55959, training_loss: 1.78243
Epoch: 1/10, step: 55979, training_loss: 1.42532
Epoch: 1/10, step: 55999, training_loss: 1.53949
accuracy: 0.47, validation_loss: 1.464377760887146, num_samples: 100
Epoch: 1/10, step: 56019, training_loss: 1.97033
Epoch: 1/10, step: 56039, training_loss: 1.99500
Epoch: 1/10, step: 56059, training_loss: 0.61379
Epoch: 1/10, step: 56079, training_loss: 1.29756
Epoch: 1/10, step: 56099, training_loss: 1.39040
Epoch: 1/10, step: 56119, training_loss: 1.76615
Epoch: 1/10, step: 56139, training_loss: 1.87383
Epoch: 1/10, step: 56159, training_loss: 1.50608
Epoch: 1/10, step: 56179, training_loss: 1.18630
Epoch: 1/10, step: 56199, training_loss: 1.77495
Epoch: 1/10, step: 56219, training_loss: 1.15364
Epoch: 1/10, step: 56239, training_loss: 1.51056
Epoch: 1/10, step: 56259, training_loss: 1.77155
Epoch: 1/10, step: 56279, training_loss: 1.52027
Epoch: 1/10, step: 56299, training_loss: 1.65008
Epoch: 1/10, step: 56319, training_loss: 1.64825
Epoch: 1/10, step: 56339, training_loss: 1.12404
Epoch: 1/10, step: 56359, training_loss: 1.66798
Epoch: 1/10, step: 56379, training_loss: 1.86653
Epoch: 1/10, step: 56399, training_loss: 1.24643
Epoch: 1/10, step: 56419, training_loss: 1.72512
Epoch: 1/10, step: 56439, training_loss: 1.54863
Epoch: 1/10, step: 56459, training_loss: 1.12731
Epoch: 1/10, step: 56479, training_loss: 2.18491
Epoch: 1/10, step: 56499, training_loss: 1.69276
Epoch: 1/10, step: 56519, training_loss: 1.34449
Epoch: 1/10, step: 56539, training_loss: 2.20579
Epoch: 1/10, step: 56559, training_loss: 1.57452
Epoch: 1/10, step: 56579, training_loss: 1.18496
Epoch: 1/10, step: 56599, training_loss: 1.37557
Epoch: 1/10, step: 56619, training_loss: 1.56744
Epoch: 1/10, step: 56639, training_loss: 1.96408
Epoch: 1/10, step: 56659, training_loss: 1.33413
Epoch: 1/10, step: 56679, training_loss: 2.04755
Epoch: 1/10, step: 56699, training_loss: 2.44271
Epoch: 1/10, step: 56719, training_loss: 1.66917
Epoch: 1/10, step: 56739, training_loss: 1.31504
Epoch: 1/10, step: 56759, training_loss: 1.72259
Epoch: 1/10, step: 56779, training_loss: 1.61058
Epoch: 1/10, step: 56799, training_loss: 2.04760
Epoch: 1/10, step: 56819, training_loss: 1.58598
Epoch: 1/10, step: 56839, training_loss: 1.93232
Epoch: 1/10, step: 56859, training_loss: 0.90502
Epoch: 1/10, step: 56879, training_loss: 1.66637
Epoch: 1/10, step: 56899, training_loss: 1.26673
Epoch: 1/10, step: 56919, training_loss: 2.01664
Epoch: 1/10, step: 56939, training_loss: 1.83444
Epoch: 1/10, step: 56959, training_loss: 1.48381
Epoch: 1/10, step: 56979, training_loss: 1.90066
Epoch: 1/10, step: 56999, training_loss: 1.46759
accuracy: 0.5, validation_loss: 1.5732007026672363, num_samples: 100
Epoch: 1/10, step: 57019, training_loss: 1.43182
Epoch: 1/10, step: 57039, training_loss: 1.59946
Epoch: 1/10, step: 57059, training_loss: 2.01445
Epoch: 1/10, step: 57079, training_loss: 2.03199
Epoch: 1/10, step: 57099, training_loss: 1.75461
Epoch: 1/10, step: 57119, training_loss: 1.92987
Epoch: 1/10, step: 57139, training_loss: 1.38751
Epoch: 1/10, step: 57159, training_loss: 1.04868
Epoch: 1/10, step: 57179, training_loss: 1.53609
Epoch: 1/10, step: 57199, training_loss: 1.11577
Epoch: 1/10, step: 57219, training_loss: 1.45010
Epoch: 1/10, step: 57239, training_loss: 1.51351
Epoch: 1/10, step: 57259, training_loss: 1.67820
Epoch: 1/10, step: 57279, training_loss: 2.04281
Epoch: 1/10, step: 57299, training_loss: 1.17391
Epoch: 1/10, step: 57319, training_loss: 1.57949
Epoch: 1/10, step: 57339, training_loss: 1.63988
Epoch: 1/10, step: 57359, training_loss: 1.34044
Epoch: 1/10, step: 57379, training_loss: 2.11162
Epoch: 1/10, step: 57399, training_loss: 0.71417
Epoch: 1/10, step: 57419, training_loss: 1.71285
Epoch: 1/10, step: 57439, training_loss: 1.90690
Epoch: 1/10, step: 57459, training_loss: 1.36110
Epoch: 1/10, step: 57479, training_loss: 2.07255
Epoch: 1/10, step: 57499, training_loss: 1.38420
Epoch: 1/10, step: 57519, training_loss: 0.98274
Epoch: 1/10, step: 57539, training_loss: 2.01302
Epoch: 1/10, step: 57559, training_loss: 1.49815
Epoch: 1/10, step: 57579, training_loss: 1.49495
Epoch: 1/10, step: 57599, training_loss: 2.13858
Epoch: 1/10, step: 57619, training_loss: 1.35717
Epoch: 1/10, step: 57639, training_loss: 1.27705
Epoch: 1/10, step: 57659, training_loss: 1.34630
Epoch: 1/10, step: 57679, training_loss: 1.10956
Epoch: 1/10, step: 57699, training_loss: 1.16057
Epoch: 1/10, step: 57719, training_loss: 1.75605
Epoch: 1/10, step: 57739, training_loss: 2.73417
Epoch: 1/10, step: 57759, training_loss: 1.20167
Epoch: 1/10, step: 57779, training_loss: 0.62161
Epoch: 1/10, step: 57799, training_loss: 1.27216
Epoch: 1/10, step: 57819, training_loss: 1.07158
Epoch: 1/10, step: 57839, training_loss: 2.17860
Epoch: 1/10, step: 57859, training_loss: 1.54947
Epoch: 1/10, step: 57879, training_loss: 1.99830
Epoch: 1/10, step: 57899, training_loss: 2.14343
Epoch: 1/10, step: 57919, training_loss: 1.09917
Epoch: 1/10, step: 57939, training_loss: 1.26378
Epoch: 1/10, step: 57959, training_loss: 1.60965
Epoch: 1/10, step: 57979, training_loss: 1.93108
Epoch: 1/10, step: 57999, training_loss: 1.34648
accuracy: 0.47, validation_loss: 1.4613269567489624, num_samples: 100
Epoch: 1/10, step: 58019, training_loss: 2.01220
Epoch: 1/10, step: 58039, training_loss: 1.33953
Epoch: 1/10, step: 58059, training_loss: 1.43733
Epoch: 1/10, step: 58079, training_loss: 1.37354
Epoch: 1/10, step: 58099, training_loss: 1.27114
Epoch: 1/10, step: 58119, training_loss: 1.31854
Epoch: 1/10, step: 58139, training_loss: 1.44696
Epoch: 1/10, step: 58159, training_loss: 1.20869
Epoch: 1/10, step: 58179, training_loss: 1.94291
Epoch: 1/10, step: 58199, training_loss: 1.68449
Epoch: 1/10, step: 58219, training_loss: 1.74303
Epoch: 1/10, step: 58239, training_loss: 1.54762
Epoch: 1/10, step: 58259, training_loss: 0.84318
Epoch: 1/10, step: 58279, training_loss: 0.68421
Epoch: 1/10, step: 58299, training_loss: 1.92569
Epoch: 1/10, step: 58319, training_loss: 1.99178
Epoch: 1/10, step: 58339, training_loss: 1.28177
Epoch: 1/10, step: 58359, training_loss: 1.55006
Epoch: 1/10, step: 58379, training_loss: 0.79946
Epoch: 1/10, step: 58399, training_loss: 1.38073
Epoch: 1/10, step: 58419, training_loss: 2.00607
Epoch: 1/10, step: 58439, training_loss: 1.45005
Epoch: 1/10, step: 58459, training_loss: 1.96937
Epoch: 1/10, step: 58479, training_loss: 1.02495
Epoch: 1/10, step: 58499, training_loss: 1.46805
Epoch: 1/10, step: 58519, training_loss: 1.83404
Epoch: 1/10, step: 58539, training_loss: 1.52592
Epoch: 1/10, step: 58559, training_loss: 1.89994
Epoch: 1/10, step: 58579, training_loss: 1.35350
Epoch: 1/10, step: 58599, training_loss: 1.90038
Epoch: 1/10, step: 58619, training_loss: 1.36659
Epoch: 1/10, step: 58639, training_loss: 1.65470
Epoch: 1/10, step: 58659, training_loss: 1.57885
Epoch: 1/10, step: 58679, training_loss: 1.61179
Epoch: 1/10, step: 58699, training_loss: 1.71487
Epoch: 1/10, step: 58719, training_loss: 1.44328
Epoch: 1/10, step: 58739, training_loss: 1.25722
Epoch: 1/10, step: 58759, training_loss: 1.23943
Epoch: 1/10, step: 58779, training_loss: 1.78195
Epoch: 1/10, step: 58799, training_loss: 1.47660
Epoch: 1/10, step: 58819, training_loss: 2.19619
Epoch: 1/10, step: 58839, training_loss: 1.39406
Epoch: 1/10, step: 58859, training_loss: 1.69817
Epoch: 1/10, step: 58879, training_loss: 1.52445
Epoch: 1/10, step: 58899, training_loss: 2.50942
Epoch: 1/10, step: 58919, training_loss: 1.99132
Epoch: 1/10, step: 58939, training_loss: 1.48021
Epoch: 1/10, step: 58959, training_loss: 0.92351
Epoch: 1/10, step: 58979, training_loss: 1.83289
Epoch: 1/10, step: 58999, training_loss: 1.79925
accuracy: 0.49, validation_loss: 1.2877671718597412, num_samples: 100
Epoch: 1/10, step: 59019, training_loss: 0.90875
Epoch: 1/10, step: 59039, training_loss: 1.71327
Epoch: 1/10, step: 59059, training_loss: 1.26180
Epoch: 1/10, step: 59079, training_loss: 1.57738
Epoch: 1/10, step: 59099, training_loss: 1.38584
Epoch: 1/10, step: 59119, training_loss: 1.75818
Epoch: 1/10, step: 59139, training_loss: 1.51110
Epoch: 1/10, step: 59159, training_loss: 1.49447
Epoch: 1/10, step: 59179, training_loss: 1.87892
Epoch: 1/10, step: 59199, training_loss: 1.12431
Epoch: 1/10, step: 59219, training_loss: 1.71970
Epoch: 1/10, step: 59239, training_loss: 1.35170
Epoch: 1/10, step: 59259, training_loss: 1.43956
Epoch: 1/10, step: 59279, training_loss: 1.48383
Epoch: 1/10, step: 59299, training_loss: 1.44735
Epoch: 1/10, step: 59319, training_loss: 0.88337
Epoch: 1/10, step: 59339, training_loss: 1.78129
Epoch: 1/10, step: 59359, training_loss: 1.83409
Epoch: 1/10, step: 59379, training_loss: 1.98151
Epoch: 1/10, step: 59399, training_loss: 1.47148
Epoch: 1/10, step: 59419, training_loss: 1.48996
Epoch: 1/10, step: 59439, training_loss: 0.88301
Epoch: 1/10, step: 59459, training_loss: 1.68439
Epoch: 1/10, step: 59479, training_loss: 1.05317
Epoch: 1/10, step: 59499, training_loss: 1.37660
Epoch: 1/10, step: 59519, training_loss: 1.71883
Epoch: 1/10, step: 59539, training_loss: 1.98863
Epoch: 1/10, step: 59559, training_loss: 1.57537
Epoch: 1/10, step: 59579, training_loss: 1.44673
Epoch: 1/10, step: 59599, training_loss: 1.71019
Epoch: 1/10, step: 59619, training_loss: 1.82256
Epoch: 1/10, step: 59639, training_loss: 0.89290
Epoch: 1/10, step: 59659, training_loss: 1.73008
Epoch: 1/10, step: 59679, training_loss: 1.94711
Epoch: 1/10, step: 59699, training_loss: 1.33290
Epoch: 1/10, step: 59719, training_loss: 2.09707
Epoch: 1/10, step: 59739, training_loss: 1.19644
Epoch: 1/10, step: 59759, training_loss: 1.18001
Epoch: 1/10, step: 59779, training_loss: 2.00294
Epoch: 1/10, step: 59799, training_loss: 1.38193
Epoch: 1/10, step: 59819, training_loss: 0.80820
Epoch: 1/10, step: 59839, training_loss: 1.01920
Epoch: 1/10, step: 59859, training_loss: 1.00409
Epoch: 1/10, step: 59879, training_loss: 1.24713
Epoch: 1/10, step: 59899, training_loss: 1.63651
Epoch: 1/10, step: 59919, training_loss: 1.11969
Epoch: 1/10, step: 59939, training_loss: 0.88759
Epoch: 1/10, step: 59959, training_loss: 1.25771
Epoch: 1/10, step: 59979, training_loss: 2.21192
Epoch: 1/10, step: 59999, training_loss: 1.91699
accuracy: 0.45, validation_loss: 1.6602760553359985, num_samples: 100
Epoch: 1/10, step: 60019, training_loss: 1.51761
Epoch: 1/10, step: 60039, training_loss: 1.69951
Epoch: 1/10, step: 60059, training_loss: 1.62631
Epoch: 1/10, step: 60079, training_loss: 2.10663
Epoch: 1/10, step: 60099, training_loss: 1.59268
Epoch: 1/10, step: 60119, training_loss: 1.61870
Epoch: 1/10, step: 60139, training_loss: 1.70129
Epoch: 1/10, step: 60159, training_loss: 2.32171
Epoch: 1/10, step: 60179, training_loss: 1.21847
Epoch: 1/10, step: 60199, training_loss: 1.39393
Epoch: 1/10, step: 60219, training_loss: 1.91255
Epoch: 1/10, step: 60239, training_loss: 1.30425
Epoch: 1/10, step: 60259, training_loss: 2.04127
Epoch: 1/10, step: 60279, training_loss: 1.74461
Epoch: 1/10, step: 60299, training_loss: 1.35671
Epoch: 1/10, step: 60319, training_loss: 1.08549
Epoch: 1/10, step: 60339, training_loss: 1.71765
Epoch: 1/10, step: 60359, training_loss: 1.09830
Epoch: 1/10, step: 60379, training_loss: 0.82691
Epoch: 1/10, step: 60399, training_loss: 1.19338
Epoch: 1/10, step: 60419, training_loss: 1.62135
Epoch: 1/10, step: 60439, training_loss: 1.71780
Epoch: 1/10, step: 60459, training_loss: 1.99337
Epoch: 1/10, step: 60479, training_loss: 2.16862
Epoch: 1/10, step: 60499, training_loss: 1.81547
Epoch: 1/10, step: 60519, training_loss: 1.55660
Epoch: 1/10, step: 60539, training_loss: 1.49797
Epoch: 1/10, step: 60559, training_loss: 0.65059
Epoch: 1/10, step: 60579, training_loss: 1.25583
Epoch: 1/10, step: 60599, training_loss: 1.67233
Epoch: 1/10, step: 60619, training_loss: 1.28947
Epoch: 1/10, step: 60639, training_loss: 1.39509
Epoch: 1/10, step: 60659, training_loss: 1.63682
Epoch: 1/10, step: 60679, training_loss: 1.22246
Epoch: 1/10, step: 60699, training_loss: 1.54650
Epoch: 1/10, step: 60719, training_loss: 1.92752
Epoch: 1/10, step: 60739, training_loss: 1.50030
Epoch: 1/10, step: 60759, training_loss: 0.87632
Epoch: 1/10, step: 60779, training_loss: 2.12749
Epoch: 1/10, step: 60799, training_loss: 1.10590
Epoch: 1/10, step: 60819, training_loss: 1.58583
Epoch: 1/10, step: 60839, training_loss: 1.31789
Epoch: 1/10, step: 60859, training_loss: 1.94629
Epoch: 1/10, step: 60879, training_loss: 0.74416
Epoch: 1/10, step: 60899, training_loss: 1.51749
Epoch: 1/10, step: 60919, training_loss: 1.29441
Epoch: 1/10, step: 60939, training_loss: 2.35514
Epoch: 1/10, step: 60959, training_loss: 1.54406
Epoch: 1/10, step: 60979, training_loss: 1.28541
Epoch: 1/10, step: 60999, training_loss: 0.98726
accuracy: 0.46, validation_loss: 1.567717432975769, num_samples: 100
Epoch: 1/10, step: 61019, training_loss: 0.96531
Epoch: 1/10, step: 61039, training_loss: 1.05085
Epoch: 1/10, step: 61059, training_loss: 1.55551
Epoch: 1/10, step: 61079, training_loss: 1.14729
Epoch: 1/10, step: 61099, training_loss: 1.08571
Epoch: 1/10, step: 61119, training_loss: 1.02824
Epoch: 1/10, step: 61139, training_loss: 1.07476
Epoch: 1/10, step: 61159, training_loss: 2.34641
Epoch: 1/10, step: 61179, training_loss: 1.08387
Epoch: 1/10, step: 61199, training_loss: 1.77845
Epoch: 1/10, step: 61219, training_loss: 1.49693
Epoch: 1/10, step: 61239, training_loss: 1.60119
Epoch: 1/10, step: 61259, training_loss: 1.51386
Epoch: 1/10, step: 61279, training_loss: 1.13481
Epoch: 1/10, step: 61299, training_loss: 1.53331
Epoch: 1/10, step: 61319, training_loss: 1.62462
Epoch: 1/10, step: 61339, training_loss: 2.38979
Epoch: 1/10, step: 61359, training_loss: 1.02308
Epoch: 1/10, step: 61379, training_loss: 1.34907
Epoch: 1/10, step: 61399, training_loss: 1.94625
Epoch: 1/10, step: 61419, training_loss: 1.64166
Epoch: 1/10, step: 61439, training_loss: 0.94245
Epoch: 1/10, step: 61459, training_loss: 1.68084
Epoch: 1/10, step: 61479, training_loss: 1.00676
Epoch: 1/10, step: 61499, training_loss: 2.31732
Epoch: 1/10, step: 61519, training_loss: 1.62708
Epoch: 1/10, step: 61539, training_loss: 1.04386
Epoch: 1/10, step: 61559, training_loss: 0.96953
Epoch: 1/10, step: 61579, training_loss: 1.23948
Epoch: 1/10, step: 61599, training_loss: 1.90749
Epoch: 1/10, step: 61619, training_loss: 2.27511
Epoch: 1/10, step: 61639, training_loss: 0.90848
Epoch: 1/10, step: 61659, training_loss: 1.55815
Epoch: 1/10, step: 61679, training_loss: 1.39581
Epoch: 1/10, step: 61699, training_loss: 1.41552
Epoch: 1/10, step: 61719, training_loss: 1.98450
Epoch: 1/10, step: 61739, training_loss: 1.85273
Epoch: 1/10, step: 61759, training_loss: 0.83071
Epoch: 1/10, step: 61779, training_loss: 1.49585
Epoch: 1/10, step: 61799, training_loss: 1.61730
Epoch: 1/10, step: 61819, training_loss: 1.63964
Epoch: 1/10, step: 61839, training_loss: 1.76615
Epoch: 1/10, step: 61859, training_loss: 1.35105
Epoch: 1/10, step: 61879, training_loss: 1.02436
Epoch: 1/10, step: 61899, training_loss: 1.34510
Epoch: 1/10, step: 61919, training_loss: 1.66665
Epoch: 1/10, step: 61939, training_loss: 1.71139
Epoch: 1/10, step: 61959, training_loss: 1.91369
Epoch: 1/10, step: 61979, training_loss: 1.59968
Epoch: 1/10, step: 61999, training_loss: 1.05334
accuracy: 0.43, validation_loss: 1.515708327293396, num_samples: 100
Epoch: 1/10, step: 62019, training_loss: 1.24319
Epoch: 1/10, step: 62039, training_loss: 1.73428
Epoch: 1/10, step: 62059, training_loss: 1.69249
Epoch: 1/10, step: 62079, training_loss: 1.83741
Epoch: 1/10, step: 62099, training_loss: 1.24405
Epoch: 1/10, step: 62119, training_loss: 2.17133
Epoch: 1/10, step: 62139, training_loss: 1.85936
Epoch: 1/10, step: 62159, training_loss: 1.71580
Epoch: 1/10, step: 62179, training_loss: 1.23262
Epoch: 1/10, step: 62199, training_loss: 1.47217
Epoch: 1/10, step: 62219, training_loss: 1.25341
Epoch: 1/10, step: 62239, training_loss: 1.19208
Epoch: 1/10, step: 62259, training_loss: 1.98096
Epoch: 1/10, step: 62279, training_loss: 1.64648
Epoch: 1/10, step: 62299, training_loss: 1.55205
Epoch: 1/10, step: 62319, training_loss: 1.29835
Epoch: 1/10, step: 62339, training_loss: 1.57083
Epoch: 1/10, step: 62359, training_loss: 1.44904
Epoch: 1/10, step: 62379, training_loss: 1.89694
Epoch: 1/10, step: 62399, training_loss: 1.53607
Epoch: 1/10, step: 62419, training_loss: 1.00473
Epoch: 1/10, step: 62439, training_loss: 1.85450
Epoch: 1/10, step: 62459, training_loss: 1.48764
Epoch: 1/10, step: 62479, training_loss: 1.41694
Epoch: 1/10, step: 62499, training_loss: 1.56320
Epoch: 1/10, step: 62519, training_loss: 1.61125
Epoch: 1/10, step: 62539, training_loss: 1.78025
Epoch: 1/10, step: 62559, training_loss: 1.46417
Epoch: 1/10, step: 62579, training_loss: 1.94903
Epoch: 1/10, step: 62599, training_loss: 1.53100
Epoch: 1/10, step: 62619, training_loss: 1.52620
Epoch: 1/10, step: 62639, training_loss: 0.87377
Epoch: 1/10, step: 62659, training_loss: 0.93518
Epoch: 1/10, step: 62679, training_loss: 1.53955
Epoch: 1/10, step: 62699, training_loss: 1.50891
Epoch: 1/10, step: 62719, training_loss: 1.71980
Epoch: 1/10, step: 62739, training_loss: 1.99586
Epoch: 1/10, step: 62759, training_loss: 2.30888
Epoch: 1/10, step: 62779, training_loss: 1.45660
Epoch: 1/10, step: 62799, training_loss: 1.94483
Epoch: 1/10, step: 62819, training_loss: 1.69711
Epoch: 1/10, step: 62839, training_loss: 1.14816
Epoch: 1/10, step: 62859, training_loss: 1.66149
Epoch: 1/10, step: 62879, training_loss: 1.31365
Epoch: 1/10, step: 62899, training_loss: 1.60749
Epoch: 1/10, step: 62919, training_loss: 2.32811
Epoch: 1/10, step: 62939, training_loss: 1.61502
Epoch: 1/10, step: 62959, training_loss: 1.86237
Epoch: 1/10, step: 62979, training_loss: 2.17224
Epoch: 1/10, step: 62999, training_loss: 1.72295
accuracy: 0.46, validation_loss: 1.582318902015686, num_samples: 100
Epoch: 1/10, step: 63019, training_loss: 0.91623
Epoch: 1/10, step: 63039, training_loss: 1.28017
Epoch: 1/10, step: 63059, training_loss: 1.50601
Epoch: 1/10, step: 63079, training_loss: 1.60080
Epoch: 1/10, step: 63099, training_loss: 1.75529
Epoch: 1/10, step: 63119, training_loss: 0.75911
Epoch: 1/10, step: 63139, training_loss: 1.39480
Epoch: 1/10, step: 63159, training_loss: 1.46311
Epoch: 1/10, step: 63179, training_loss: 1.84372
Epoch: 1/10, step: 63199, training_loss: 1.42647
Epoch: 1/10, step: 63219, training_loss: 1.68517
Epoch: 1/10, step: 63239, training_loss: 1.88438
Epoch: 1/10, step: 63259, training_loss: 1.55452
Epoch: 1/10, step: 63279, training_loss: 2.06749
Epoch: 1/10, step: 63299, training_loss: 1.67236
Epoch: 1/10, step: 63319, training_loss: 1.83521
Epoch: 1/10, step: 63339, training_loss: 1.14995
Epoch: 1/10, step: 63359, training_loss: 1.24813
Epoch: 1/10, step: 63379, training_loss: 1.32816
Epoch: 1/10, step: 63399, training_loss: 0.81814
Epoch: 1/10, step: 63419, training_loss: 1.53429
Epoch: 1/10, step: 63439, training_loss: 1.42804
Epoch: 1/10, step: 63459, training_loss: 1.55965
Epoch: 1/10, step: 63479, training_loss: 1.31813
Epoch: 1/10, step: 63499, training_loss: 1.47056
Epoch: 1/10, step: 63519, training_loss: 1.70000
Epoch: 1/10, step: 63539, training_loss: 1.87510
Epoch: 1/10, step: 63559, training_loss: 1.07596
Epoch: 1/10, step: 63579, training_loss: 1.77159
Epoch: 1/10, step: 63599, training_loss: 1.39064
Epoch: 1/10, step: 63619, training_loss: 1.76023
Epoch: 1/10, step: 63639, training_loss: 1.32349
Epoch: 1/10, step: 63659, training_loss: 1.56142
Epoch: 1/10, step: 63679, training_loss: 2.20560
Epoch: 1/10, step: 63699, training_loss: 2.37042
Epoch: 1/10, step: 63719, training_loss: 1.11634
Epoch: 1/10, step: 63739, training_loss: 1.53243
Epoch: 1/10, step: 63759, training_loss: 1.18951
Epoch: 1/10, step: 63779, training_loss: 1.63099
Epoch: 1/10, step: 63799, training_loss: 1.85126
Epoch: 1/10, step: 63819, training_loss: 2.25171
Epoch: 1/10, step: 63839, training_loss: 1.15705
Epoch: 1/10, step: 63859, training_loss: 1.84591
Epoch: 1/10, step: 63879, training_loss: 1.70889
Epoch: 1/10, step: 63899, training_loss: 1.81554
Epoch: 1/10, step: 63919, training_loss: 1.63458
Epoch: 1/10, step: 63939, training_loss: 1.65111
Epoch: 1/10, step: 63959, training_loss: 1.70518
Epoch: 1/10, step: 63979, training_loss: 1.55985
Epoch: 1/10, step: 63999, training_loss: 1.29532
accuracy: 0.55, validation_loss: 1.194056510925293, num_samples: 100
Epoch: 1/10, step: 64019, training_loss: 1.45255
Epoch: 1/10, step: 64039, training_loss: 1.78792
Epoch: 1/10, step: 64059, training_loss: 1.59600
Epoch: 1/10, step: 64079, training_loss: 1.85952
Epoch: 1/10, step: 64099, training_loss: 1.58474
Epoch: 1/10, step: 64119, training_loss: 1.41264
Epoch: 1/10, step: 64139, training_loss: 0.94432
Epoch: 1/10, step: 64159, training_loss: 2.18272
Epoch: 1/10, step: 64179, training_loss: 1.79908
Epoch: 1/10, step: 64199, training_loss: 1.96492
Epoch: 1/10, step: 64219, training_loss: 1.68280
Epoch: 1/10, step: 64239, training_loss: 1.16106
Epoch: 1/10, step: 64259, training_loss: 1.23524
Epoch: 1/10, step: 64279, training_loss: 1.65900
Epoch: 1/10, step: 64299, training_loss: 1.11177
Epoch: 1/10, step: 64319, training_loss: 0.87453
Epoch: 1/10, step: 64339, training_loss: 2.09242
Epoch: 1/10, step: 64359, training_loss: 1.05823
Epoch: 1/10, step: 64379, training_loss: 1.47540
Epoch: 1/10, step: 64399, training_loss: 1.44906
Epoch: 1/10, step: 64419, training_loss: 1.33889
Epoch: 1/10, step: 64439, training_loss: 1.50532
Epoch: 1/10, step: 64459, training_loss: 1.33519
Epoch: 1/10, step: 64479, training_loss: 2.06597
Epoch: 1/10, step: 64499, training_loss: 0.82540
Epoch: 1/10, step: 64519, training_loss: 1.33084
Epoch: 1/10, step: 64539, training_loss: 1.17201
Epoch: 1/10, step: 64559, training_loss: 1.60974
Epoch: 1/10, step: 64579, training_loss: 1.64670
Epoch: 1/10, step: 64599, training_loss: 1.47312
Epoch: 1/10, step: 64619, training_loss: 1.18385
Epoch: 1/10, step: 64639, training_loss: 1.60665
Epoch: 1/10, step: 64659, training_loss: 1.58908
Epoch: 1/10, step: 64679, training_loss: 1.41153
Epoch: 1/10, step: 64699, training_loss: 1.40667
Epoch: 1/10, step: 64719, training_loss: 1.88723
Epoch: 1/10, step: 64739, training_loss: 0.80738
Epoch: 1/10, step: 64759, training_loss: 1.28323
Epoch: 1/10, step: 64779, training_loss: 1.78355
Epoch: 1/10, step: 64799, training_loss: 1.11970
Epoch: 1/10, step: 64819, training_loss: 1.88500
Epoch: 1/10, step: 64839, training_loss: 1.08135
Epoch: 1/10, step: 64859, training_loss: 1.39262
Epoch: 1/10, step: 64879, training_loss: 1.44703
Epoch: 1/10, step: 64899, training_loss: 1.24580
Epoch: 1/10, step: 64919, training_loss: 1.82136
Epoch: 1/10, step: 64939, training_loss: 1.78375
Epoch: 1/10, step: 64959, training_loss: 1.68583
Epoch: 1/10, step: 64979, training_loss: 1.80336
Epoch: 1/10, step: 64999, training_loss: 1.41798
accuracy: 0.51, validation_loss: 1.6744519472122192, num_samples: 100
Epoch: 1/10, step: 65019, training_loss: 2.07511
Epoch: 1/10, step: 65039, training_loss: 1.84542
Epoch: 1/10, step: 65059, training_loss: 1.29378
Epoch: 1/10, step: 65079, training_loss: 1.60425
Epoch: 1/10, step: 65099, training_loss: 2.00613
Epoch: 1/10, step: 65119, training_loss: 1.36754
Epoch: 1/10, step: 65139, training_loss: 1.43447
Epoch: 1/10, step: 65159, training_loss: 1.15678
Epoch: 1/10, step: 65179, training_loss: 1.27813
Epoch: 1/10, step: 65199, training_loss: 1.36370
Epoch: 1/10, step: 65219, training_loss: 1.34043
Epoch: 1/10, step: 65239, training_loss: 1.67874
Epoch: 1/10, step: 65259, training_loss: 1.62156
Epoch: 1/10, step: 65279, training_loss: 2.13668
Epoch: 1/10, step: 65299, training_loss: 1.44828
Epoch: 1/10, step: 65319, training_loss: 2.35687
Epoch: 1/10, step: 65339, training_loss: 1.42932
Epoch: 1/10, step: 65359, training_loss: 2.21927
Epoch: 1/10, step: 65379, training_loss: 1.15727
Epoch: 1/10, step: 65399, training_loss: 1.83877
Epoch: 1/10, step: 65419, training_loss: 1.70141
Epoch: 1/10, step: 65439, training_loss: 1.46762
Epoch: 1/10, step: 65459, training_loss: 1.32677
Epoch: 1/10, step: 65479, training_loss: 1.84750
Epoch: 1/10, step: 65499, training_loss: 2.21444
Epoch: 1/10, step: 65519, training_loss: 1.18679
Epoch: 1/10, step: 65539, training_loss: 2.18978
Epoch: 1/10, step: 65559, training_loss: 1.81038
Epoch: 1/10, step: 65579, training_loss: 1.63007
Epoch: 1/10, step: 65599, training_loss: 1.10209
Epoch: 1/10, step: 65619, training_loss: 1.59755
Epoch: 1/10, step: 65639, training_loss: 2.11077
Epoch: 1/10, step: 65659, training_loss: 1.68047
Epoch: 1/10, step: 65679, training_loss: 1.10359
Epoch: 1/10, step: 65699, training_loss: 2.17692
Epoch: 1/10, step: 65719, training_loss: 1.90718
Epoch: 1/10, step: 65739, training_loss: 1.14446
Epoch: 1/10, step: 65759, training_loss: 2.09239
Epoch: 1/10, step: 65779, training_loss: 1.97488
Epoch: 1/10, step: 65799, training_loss: 1.46998
Epoch: 1/10, step: 65819, training_loss: 1.33314
Epoch: 1/10, step: 65839, training_loss: 1.71669
Epoch: 1/10, step: 65859, training_loss: 0.91185
Epoch: 1/10, step: 65879, training_loss: 1.75152
Epoch: 1/10, step: 65899, training_loss: 1.67624
Epoch: 1/10, step: 65919, training_loss: 1.69882
Epoch: 1/10, step: 65939, training_loss: 1.56228
Epoch: 1/10, step: 65959, training_loss: 1.30868
Epoch: 1/10, step: 65979, training_loss: 1.21463
Epoch: 1/10, step: 65999, training_loss: 0.95498
accuracy: 0.48, validation_loss: 1.440847635269165, num_samples: 100
Epoch: 1/10, step: 66019, training_loss: 1.38697
Epoch: 1/10, step: 66039, training_loss: 1.46240
Epoch: 1/10, step: 66059, training_loss: 1.71443
Epoch: 1/10, step: 66079, training_loss: 1.81727
Epoch: 1/10, step: 66099, training_loss: 0.66870
Epoch: 1/10, step: 66119, training_loss: 1.28238
Epoch: 1/10, step: 66139, training_loss: 1.89740
Epoch: 1/10, step: 66159, training_loss: 1.71423
Epoch: 1/10, step: 66179, training_loss: 1.52590
Epoch: 1/10, step: 66199, training_loss: 1.21173
Epoch: 1/10, step: 66219, training_loss: 1.27737
Epoch: 1/10, step: 66239, training_loss: 1.39203
Epoch: 1/10, step: 66259, training_loss: 0.97671
Epoch: 1/10, step: 66279, training_loss: 0.89665
Epoch: 1/10, step: 66299, training_loss: 1.02606
Epoch: 1/10, step: 66319, training_loss: 1.36944
Epoch: 1/10, step: 66339, training_loss: 1.15377
Epoch: 1/10, step: 66359, training_loss: 1.29152
Epoch: 1/10, step: 66379, training_loss: 1.52793
Epoch: 1/10, step: 66399, training_loss: 1.14543
Epoch: 1/10, step: 66419, training_loss: 0.62934
Epoch: 1/10, step: 66439, training_loss: 2.00131
Epoch: 1/10, step: 66459, training_loss: 1.84791
Epoch: 1/10, step: 66479, training_loss: 1.39915
Epoch: 1/10, step: 66499, training_loss: 1.34701
Epoch: 1/10, step: 66519, training_loss: 1.88809
Epoch: 1/10, step: 66539, training_loss: 1.97823
Epoch: 1/10, step: 66559, training_loss: 1.48171
Epoch: 1/10, step: 66579, training_loss: 1.79358
Epoch: 1/10, step: 66599, training_loss: 1.31253
Epoch: 1/10, step: 66619, training_loss: 1.76387
Epoch: 1/10, step: 66639, training_loss: 1.02051
Epoch: 1/10, step: 66659, training_loss: 1.84915
Epoch: 1/10, step: 66679, training_loss: 1.66676
Epoch: 1/10, step: 66699, training_loss: 1.36674
Epoch: 1/10, step: 66719, training_loss: 1.00030
Epoch: 1/10, step: 66739, training_loss: 1.90008
Epoch: 1/10, step: 66759, training_loss: 1.77143
Epoch: 1/10, step: 66779, training_loss: 1.60450
Epoch: 1/10, step: 66799, training_loss: 1.94596
Epoch: 1/10, step: 66819, training_loss: 1.27586
Epoch: 1/10, step: 66839, training_loss: 1.49000
Epoch: 1/10, step: 66859, training_loss: 1.17310
Epoch: 1/10, step: 66879, training_loss: 1.33102
Epoch: 1/10, step: 66899, training_loss: 1.78069
Epoch: 1/10, step: 66919, training_loss: 0.63225
Epoch: 1/10, step: 66939, training_loss: 1.05949
Epoch: 1/10, step: 66959, training_loss: 1.40865
Epoch: 1/10, step: 66979, training_loss: 1.68237
Epoch: 1/10, step: 66999, training_loss: 1.47650
accuracy: 0.51, validation_loss: 1.4771875143051147, num_samples: 100
Epoch: 1/10, step: 67019, training_loss: 1.80330
Epoch: 1/10, step: 67039, training_loss: 1.24269
Epoch: 1/10, step: 67059, training_loss: 1.80564
Epoch: 1/10, step: 67079, training_loss: 2.16998
Epoch: 1/10, step: 67099, training_loss: 1.07312
Epoch: 1/10, step: 67119, training_loss: 1.56122
Epoch: 1/10, step: 67139, training_loss: 1.75208
Epoch: 1/10, step: 67159, training_loss: 1.42673
Epoch: 1/10, step: 67179, training_loss: 1.59413
Epoch: 1/10, step: 67199, training_loss: 1.60487
Epoch: 1/10, step: 67219, training_loss: 1.05687
Epoch: 1/10, step: 67239, training_loss: 0.78579
Epoch: 1/10, step: 67259, training_loss: 1.45926
Epoch: 1/10, step: 67279, training_loss: 0.71894
Epoch: 1/10, step: 67299, training_loss: 1.24618
Epoch: 1/10, step: 67319, training_loss: 1.30887
Epoch: 1/10, step: 67339, training_loss: 2.47788
Epoch: 1/10, step: 67359, training_loss: 2.08824
Epoch: 1/10, step: 67379, training_loss: 2.02834
Epoch: 1/10, step: 67399, training_loss: 1.20535
Epoch: 1/10, step: 67419, training_loss: 1.43635
Epoch: 1/10, step: 67439, training_loss: 1.53291
Epoch: 1/10, step: 67459, training_loss: 1.64817
Epoch: 1/10, step: 67479, training_loss: 1.00282
Epoch: 1/10, step: 67499, training_loss: 2.38727
Epoch: 1/10, step: 67519, training_loss: 1.91207
Epoch: 1/10, step: 67539, training_loss: 1.14464
Epoch: 1/10, step: 67559, training_loss: 1.24682
Epoch: 1/10, step: 67579, training_loss: 2.02681
Epoch: 1/10, step: 67599, training_loss: 1.32979
Epoch: 1/10, step: 67619, training_loss: 1.29034
Epoch: 1/10, step: 67639, training_loss: 0.95328
Epoch: 1/10, step: 67659, training_loss: 1.43847
Epoch: 1/10, step: 67679, training_loss: 1.69280
Epoch: 1/10, step: 67699, training_loss: 1.66153
Epoch: 1/10, step: 67719, training_loss: 1.31128
Epoch: 1/10, step: 67739, training_loss: 1.10715
Epoch: 1/10, step: 67759, training_loss: 1.24463
Epoch: 1/10, step: 67779, training_loss: 1.29684
Epoch: 1/10, step: 67799, training_loss: 1.57631
Epoch: 1/10, step: 67819, training_loss: 1.86242
Epoch: 1/10, step: 67839, training_loss: 1.45606
Epoch: 1/10, step: 67859, training_loss: 1.12737
Epoch: 1/10, step: 67879, training_loss: 1.57519
Epoch: 1/10, step: 67899, training_loss: 1.30485
Epoch: 1/10, step: 67919, training_loss: 1.49225
Epoch: 1/10, step: 67939, training_loss: 1.24714
Epoch: 1/10, step: 67959, training_loss: 1.03521
Epoch: 1/10, step: 67979, training_loss: 0.98447
Epoch: 1/10, step: 67999, training_loss: 1.95356
accuracy: 0.5, validation_loss: 1.3268156051635742, num_samples: 100
Epoch: 1/10, step: 68019, training_loss: 0.93511
Epoch: 1/10, step: 68039, training_loss: 1.33467
Epoch: 1/10, step: 68059, training_loss: 1.16805
Epoch: 1/10, step: 68079, training_loss: 2.24102
Epoch: 1/10, step: 68099, training_loss: 2.22802
Epoch: 1/10, step: 68119, training_loss: 0.75649
Epoch: 1/10, step: 68139, training_loss: 0.44795
Epoch: 1/10, step: 68159, training_loss: 1.10766
Epoch: 1/10, step: 68179, training_loss: 1.12738
Epoch: 1/10, step: 68199, training_loss: 1.06028
Epoch: 1/10, step: 68219, training_loss: 1.54753
Epoch: 1/10, step: 68239, training_loss: 1.52201
Epoch: 1/10, step: 68259, training_loss: 1.23135
Epoch: 1/10, step: 68279, training_loss: 1.15957
Epoch: 1/10, step: 68299, training_loss: 1.53369
Epoch: 1/10, step: 68319, training_loss: 1.51171
Epoch: 1/10, step: 68339, training_loss: 2.05289
Epoch: 1/10, step: 68359, training_loss: 1.69645
Epoch: 1/10, step: 68379, training_loss: 2.04110
Epoch: 1/10, step: 68399, training_loss: 0.98790
Epoch: 1/10, step: 68419, training_loss: 1.08422
Epoch: 1/10, step: 68439, training_loss: 1.93504
Epoch: 1/10, step: 68459, training_loss: 1.10996
Epoch: 1/10, step: 68479, training_loss: 1.61728
Epoch: 1/10, step: 68499, training_loss: 1.70217
Epoch: 1/10, step: 68519, training_loss: 1.88628
Epoch: 1/10, step: 68539, training_loss: 1.54001
Epoch: 1/10, step: 68559, training_loss: 1.80160
Epoch: 1/10, step: 68579, training_loss: 1.44801
Epoch: 1/10, step: 68599, training_loss: 1.59077
Epoch: 1/10, step: 68619, training_loss: 1.43961
Epoch: 1/10, step: 68639, training_loss: 0.77601
Epoch: 1/10, step: 68659, training_loss: 1.28664
Epoch: 1/10, step: 68679, training_loss: 1.14747
Epoch: 1/10, step: 68699, training_loss: 1.19990
Epoch: 1/10, step: 68719, training_loss: 1.19372
Epoch: 1/10, step: 68739, training_loss: 1.74105
Epoch: 1/10, step: 68759, training_loss: 1.09803
Epoch: 1/10, step: 68779, training_loss: 1.10605
Epoch: 1/10, step: 68799, training_loss: 1.56116
Epoch: 1/10, step: 68819, training_loss: 1.11233
Epoch: 1/10, step: 68839, training_loss: 1.06817
Epoch: 1/10, step: 68859, training_loss: 1.66312
Epoch: 1/10, step: 68879, training_loss: 1.86095
Epoch: 1/10, step: 68899, training_loss: 1.81192
Epoch: 1/10, step: 68919, training_loss: 0.83973
Epoch: 1/10, step: 68939, training_loss: 1.68414
Epoch: 1/10, step: 68959, training_loss: 1.20229
Epoch: 1/10, step: 68979, training_loss: 1.59012
Epoch: 1/10, step: 68999, training_loss: 1.28176
accuracy: 0.53, validation_loss: 1.3650399446487427, num_samples: 100
Epoch: 1/10, step: 69019, training_loss: 1.66851
Epoch: 1/10, step: 69039, training_loss: 1.60666
Epoch: 1/10, step: 69059, training_loss: 2.34845
Epoch: 1/10, step: 69079, training_loss: 1.65718
Epoch: 1/10, step: 69099, training_loss: 0.98285
Epoch: 1/10, step: 69119, training_loss: 1.25544
Epoch: 1/10, step: 69139, training_loss: 1.34720
Epoch: 1/10, step: 69159, training_loss: 1.58598
Epoch: 1/10, step: 69179, training_loss: 1.18752
Epoch: 1/10, step: 69199, training_loss: 1.48399
Epoch: 1/10, step: 69219, training_loss: 1.78246
Epoch: 1/10, step: 69239, training_loss: 1.84180
Epoch: 1/10, step: 69259, training_loss: 0.95909
Epoch: 1/10, step: 69279, training_loss: 1.62157
Epoch: 1/10, step: 69299, training_loss: 1.19285
Epoch: 1/10, step: 69319, training_loss: 1.02369
Epoch: 1/10, step: 69339, training_loss: 1.56451
Epoch: 1/10, step: 69359, training_loss: 1.49784
Epoch: 1/10, step: 69379, training_loss: 1.22746
Epoch: 1/10, step: 69399, training_loss: 1.20299
Epoch: 1/10, step: 69419, training_loss: 1.69024
Epoch: 1/10, step: 69439, training_loss: 1.71677
Epoch: 1/10, step: 69459, training_loss: 1.43235
Epoch: 1/10, step: 69479, training_loss: 1.65311
Epoch: 1/10, step: 69499, training_loss: 1.33332
Epoch: 1/10, step: 69519, training_loss: 1.77943
Epoch: 1/10, step: 69539, training_loss: 1.56627
Epoch: 1/10, step: 69559, training_loss: 1.33360
Epoch: 1/10, step: 69579, training_loss: 1.17959
Epoch: 1/10, step: 69599, training_loss: 0.74376
Epoch: 1/10, step: 69619, training_loss: 2.03638
Epoch: 1/10, step: 69639, training_loss: 1.16424
Epoch: 1/10, step: 69659, training_loss: 1.67166
Epoch: 1/10, step: 69679, training_loss: 1.68545
Epoch: 1/10, step: 69699, training_loss: 1.06074
Epoch: 1/10, step: 69719, training_loss: 1.19339
Epoch: 1/10, step: 69739, training_loss: 1.48160
Epoch: 1/10, step: 69759, training_loss: 1.66013
Epoch: 1/10, step: 69779, training_loss: 1.72967
Epoch: 1/10, step: 69799, training_loss: 2.14194
Epoch: 1/10, step: 69819, training_loss: 1.62520
Epoch: 1/10, step: 69839, training_loss: 2.49039
Epoch: 1/10, step: 69859, training_loss: 1.57577
Epoch: 1/10, step: 69879, training_loss: 1.61541
Epoch: 1/10, step: 69899, training_loss: 1.42910
Epoch: 1/10, step: 69919, training_loss: 1.08862
Epoch: 1/10, step: 69939, training_loss: 0.97179
Epoch: 1/10, step: 69959, training_loss: 1.06618
Epoch: 1/10, step: 69979, training_loss: 1.15309
Epoch: 1/10, step: 69999, training_loss: 1.46186
accuracy: 0.49, validation_loss: 1.6654826402664185, num_samples: 100
Epoch: 1/10, step: 70019, training_loss: 1.76697
Epoch: 1/10, step: 70039, training_loss: 1.11187
Epoch: 1/10, step: 70059, training_loss: 0.80816
Epoch: 1/10, step: 70079, training_loss: 1.53321
Epoch: 1/10, step: 70099, training_loss: 1.68969
Epoch: 1/10, step: 70119, training_loss: 1.89888
Epoch: 1/10, step: 70139, training_loss: 1.59071
Epoch: 1/10, step: 70159, training_loss: 1.32915
Epoch: 1/10, step: 70179, training_loss: 1.27687
Epoch: 1/10, step: 70199, training_loss: 1.01726
Epoch: 1/10, step: 70219, training_loss: 1.24373
Epoch: 1/10, step: 70239, training_loss: 1.47175
Epoch: 1/10, step: 70259, training_loss: 1.61837
Epoch: 1/10, step: 70279, training_loss: 0.82853
Epoch: 1/10, step: 70299, training_loss: 1.55042
Epoch: 1/10, step: 70319, training_loss: 1.28587
Epoch: 1/10, step: 70339, training_loss: 1.35765
Epoch: 1/10, step: 70359, training_loss: 1.42206
Epoch: 1/10, step: 70379, training_loss: 1.92084
Epoch: 1/10, step: 70399, training_loss: 1.20188
Epoch: 1/10, step: 70419, training_loss: 1.86156
Epoch: 1/10, step: 70439, training_loss: 1.14903
Epoch: 1/10, step: 70459, training_loss: 0.91958
Epoch: 1/10, step: 70479, training_loss: 2.10735
Epoch: 1/10, step: 70499, training_loss: 1.05100
Epoch: 1/10, step: 70519, training_loss: 1.30947
Epoch: 1/10, step: 70539, training_loss: 1.13373
Epoch: 1/10, step: 70559, training_loss: 1.14686
Epoch: 1/10, step: 70579, training_loss: 1.37736
Epoch: 1/10, step: 70599, training_loss: 1.81701
Epoch: 1/10, step: 70619, training_loss: 1.31290
Epoch: 1/10, step: 70639, training_loss: 1.40619
Epoch: 1/10, step: 70659, training_loss: 1.15599
Epoch: 1/10, step: 70679, training_loss: 1.38334
Epoch: 1/10, step: 70699, training_loss: 1.53388
Epoch: 1/10, step: 70719, training_loss: 2.22468
Epoch: 1/10, step: 70739, training_loss: 1.38054
Epoch: 1/10, step: 70759, training_loss: 1.78905
Epoch: 1/10, step: 70779, training_loss: 1.36293
Epoch: 1/10, step: 70799, training_loss: 1.66470
Epoch: 1/10, step: 70819, training_loss: 1.53246
Epoch: 1/10, step: 70839, training_loss: 1.10703
Epoch: 1/10, step: 70859, training_loss: 1.42174
Epoch: 1/10, step: 70879, training_loss: 0.98306
Epoch: 1/10, step: 70899, training_loss: 1.51431
Epoch: 1/10, step: 70919, training_loss: 1.24815
Epoch: 1/10, step: 70939, training_loss: 1.51147
Epoch: 1/10, step: 70959, training_loss: 1.47012
Epoch: 1/10, step: 70979, training_loss: 1.01523
Epoch: 1/10, step: 70999, training_loss: 1.42596
accuracy: 0.4, validation_loss: 1.6561030149459839, num_samples: 100
Epoch: 1/10, step: 71019, training_loss: 1.12408
Epoch: 1/10, step: 71039, training_loss: 1.74208
Epoch: 1/10, step: 71059, training_loss: 2.60756
Epoch: 1/10, step: 71079, training_loss: 1.85144
Epoch: 1/10, step: 71099, training_loss: 2.08574
Epoch: 1/10, step: 71119, training_loss: 1.51072
Epoch: 1/10, step: 71139, training_loss: 1.20208
Epoch: 1/10, step: 71159, training_loss: 0.89116
Epoch: 1/10, step: 71179, training_loss: 1.63787
Epoch: 1/10, step: 71199, training_loss: 1.31965
Epoch: 1/10, step: 71219, training_loss: 1.46292
Epoch: 1/10, step: 71239, training_loss: 1.02242
Epoch: 1/10, step: 71259, training_loss: 1.59003
Epoch: 1/10, step: 71279, training_loss: 1.75973
Epoch: 1/10, step: 71299, training_loss: 2.10658
Epoch: 1/10, step: 71319, training_loss: 1.69555
Epoch: 1/10, step: 71339, training_loss: 1.24760
Epoch: 1/10, step: 71359, training_loss: 1.21235
Epoch: 1/10, step: 71379, training_loss: 1.77732
Epoch: 1/10, step: 71399, training_loss: 1.50986
Epoch: 1/10, step: 71419, training_loss: 1.28631
Epoch: 1/10, step: 71439, training_loss: 1.21143
Epoch: 1/10, step: 71459, training_loss: 1.40587
Epoch: 1/10, step: 71479, training_loss: 1.18445
Epoch: 1/10, step: 71499, training_loss: 2.01659
Epoch: 1/10, step: 71519, training_loss: 1.73634
Epoch: 1/10, step: 71539, training_loss: 0.99762
Epoch: 1/10, step: 71559, training_loss: 1.13576
Epoch: 1/10, step: 71579, training_loss: 1.47436
Epoch: 1/10, step: 71599, training_loss: 1.24505
Epoch: 1/10, step: 71619, training_loss: 1.32087
Epoch: 1/10, step: 71639, training_loss: 1.48950
Epoch: 1/10, step: 71659, training_loss: 1.42293
Epoch: 1/10, step: 71679, training_loss: 1.75874
Epoch: 1/10, step: 71699, training_loss: 1.21263
Epoch: 1/10, step: 71719, training_loss: 1.91573
Epoch: 1/10, step: 71739, training_loss: 1.67823
Epoch: 1/10, step: 71759, training_loss: 1.79371
Epoch: 1/10, step: 71779, training_loss: 1.73153
Epoch: 1/10, step: 71799, training_loss: 1.68200
Epoch: 1/10, step: 71819, training_loss: 1.41256
Epoch: 1/10, step: 71839, training_loss: 1.48324
Epoch: 1/10, step: 71859, training_loss: 1.97295
Epoch: 1/10, step: 71879, training_loss: 1.81560
Epoch: 1/10, step: 71899, training_loss: 1.11656
Epoch: 1/10, step: 71919, training_loss: 1.69596
Epoch: 1/10, step: 71939, training_loss: 1.19000
Epoch: 1/10, step: 71959, training_loss: 1.60366
Epoch: 1/10, step: 71979, training_loss: 1.44633
Epoch: 1/10, step: 71999, training_loss: 1.30329
accuracy: 0.45, validation_loss: 1.4107662439346313, num_samples: 100
Epoch: 1/10, step: 72019, training_loss: 1.33467
Epoch: 1/10, step: 72039, training_loss: 1.54979
Epoch: 1/10, step: 72059, training_loss: 1.04128
Epoch: 1/10, step: 72079, training_loss: 1.62358
Epoch: 1/10, step: 72099, training_loss: 1.97034
Epoch: 1/10, step: 72119, training_loss: 1.55226
Epoch: 1/10, step: 72139, training_loss: 2.11135
Epoch: 1/10, step: 72159, training_loss: 2.14975
Epoch: 1/10, step: 72179, training_loss: 1.97143
Epoch: 1/10, step: 72199, training_loss: 1.00647
Epoch: 1/10, step: 72219, training_loss: 1.36789
Epoch: 1/10, step: 72239, training_loss: 1.60869
Epoch: 1/10, step: 72259, training_loss: 1.69499
Epoch: 1/10, step: 72279, training_loss: 1.63654
Epoch: 1/10, step: 72299, training_loss: 1.17415
Epoch: 1/10, step: 72319, training_loss: 1.79222
Epoch: 1/10, step: 72339, training_loss: 1.12609
Epoch: 1/10, step: 72359, training_loss: 0.88112
Epoch: 1/10, step: 72379, training_loss: 1.82330
Epoch: 1/10, step: 72399, training_loss: 1.33809
Epoch: 1/10, step: 72419, training_loss: 1.75465
Epoch: 1/10, step: 72439, training_loss: 1.18997
Epoch: 1/10, step: 72459, training_loss: 1.35944
Epoch: 1/10, step: 72479, training_loss: 1.13001
Epoch: 1/10, step: 72499, training_loss: 1.22228
Epoch: 1/10, step: 72519, training_loss: 1.34779
Epoch: 1/10, step: 72539, training_loss: 1.62063
Epoch: 1/10, step: 72559, training_loss: 1.74674
Epoch: 1/10, step: 72579, training_loss: 1.48256
Epoch: 1/10, step: 72599, training_loss: 1.27917
Epoch: 1/10, step: 72619, training_loss: 1.63665
Epoch: 1/10, step: 72639, training_loss: 1.43488
Epoch: 1/10, step: 72659, training_loss: 1.60106
Epoch: 1/10, step: 72679, training_loss: 1.50058
Epoch: 1/10, step: 72699, training_loss: 1.57193
Epoch: 1/10, step: 72719, training_loss: 1.24389
Epoch: 1/10, step: 72739, training_loss: 1.70692
Epoch: 1/10, step: 72759, training_loss: 1.32362
Epoch: 1/10, step: 72779, training_loss: 1.98435
Epoch: 1/10, step: 72799, training_loss: 1.75807
Epoch: 1/10, step: 72819, training_loss: 1.40933
Epoch: 1/10, step: 72839, training_loss: 1.48581
Epoch: 1/10, step: 72859, training_loss: 1.59434
Epoch: 1/10, step: 72879, training_loss: 1.24136
Epoch: 1/10, step: 72899, training_loss: 1.14626
Epoch: 1/10, step: 72919, training_loss: 1.62388
Epoch: 1/10, step: 72939, training_loss: 1.59815
Epoch: 1/10, step: 72959, training_loss: 1.09437
Epoch: 1/10, step: 72979, training_loss: 1.24866
Epoch: 1/10, step: 72999, training_loss: 1.81144
accuracy: 0.56, validation_loss: 1.3707334995269775, num_samples: 100
Epoch: 1/10, step: 73019, training_loss: 1.50232
Epoch: 1/10, step: 73039, training_loss: 2.32549
Epoch: 1/10, step: 73059, training_loss: 1.40203
Epoch: 1/10, step: 73079, training_loss: 1.47434
Epoch: 1/10, step: 73099, training_loss: 1.80953
Epoch: 1/10, step: 73119, training_loss: 1.13211
Epoch: 1/10, step: 73139, training_loss: 1.64970
Epoch: 1/10, step: 73159, training_loss: 2.09503
Epoch: 1/10, step: 73179, training_loss: 1.50884
Epoch: 1/10, step: 73199, training_loss: 1.37742
Epoch: 1/10, step: 73219, training_loss: 1.53413
Epoch: 1/10, step: 73239, training_loss: 1.37373
Epoch: 1/10, step: 73259, training_loss: 1.38670
Epoch: 1/10, step: 73279, training_loss: 1.70655
Epoch: 1/10, step: 73299, training_loss: 1.08203
Epoch: 1/10, step: 73319, training_loss: 1.03790
Epoch: 1/10, step: 73339, training_loss: 1.54247
Epoch: 1/10, step: 73359, training_loss: 0.98238
Epoch: 1/10, step: 73379, training_loss: 1.25777
Epoch: 1/10, step: 73399, training_loss: 1.79548
Epoch: 1/10, step: 73419, training_loss: 1.71185
Epoch: 1/10, step: 73439, training_loss: 1.41004
Epoch: 1/10, step: 73459, training_loss: 0.55883
Epoch: 1/10, step: 73479, training_loss: 1.01399
Epoch: 1/10, step: 73499, training_loss: 1.56590
Epoch: 1/10, step: 73519, training_loss: 1.74343
Epoch: 1/10, step: 73539, training_loss: 1.30493
Epoch: 1/10, step: 73559, training_loss: 1.78253
Epoch: 1/10, step: 73579, training_loss: 0.94377
Epoch: 1/10, step: 73599, training_loss: 1.19609
Epoch: 1/10, step: 73619, training_loss: 1.20419
Epoch: 1/10, step: 73639, training_loss: 1.64065
Epoch: 1/10, step: 73659, training_loss: 1.67724
Epoch: 1/10, step: 73679, training_loss: 1.50234
Epoch: 1/10, step: 73699, training_loss: 1.79497
Epoch: 1/10, step: 73719, training_loss: 1.75982
Epoch: 1/10, step: 73739, training_loss: 1.81284
Epoch: 1/10, step: 73759, training_loss: 1.16563
Epoch: 1/10, step: 73779, training_loss: 1.81674
Epoch: 1/10, step: 73799, training_loss: 1.47421
Epoch: 1/10, step: 73819, training_loss: 0.98983
Epoch: 1/10, step: 73839, training_loss: 2.19041
Epoch: 1/10, step: 73859, training_loss: 1.55038
Epoch: 1/10, step: 73879, training_loss: 1.36477
Epoch: 1/10, step: 73899, training_loss: 1.16931
Epoch: 1/10, step: 73919, training_loss: 1.09175
Epoch: 1/10, step: 73939, training_loss: 0.58024
Epoch: 1/10, step: 73959, training_loss: 1.24163
Epoch: 1/10, step: 73979, training_loss: 1.47949
Epoch: 1/10, step: 73999, training_loss: 1.17441
accuracy: 0.5, validation_loss: 1.7166568040847778, num_samples: 100
Epoch: 1/10, step: 74019, training_loss: 1.65681
Epoch: 1/10, step: 74039, training_loss: 1.65389
Epoch: 1/10, step: 74059, training_loss: 1.31516
Epoch: 1/10, step: 74079, training_loss: 1.77914
Epoch: 1/10, step: 74099, training_loss: 1.95605
Epoch: 1/10, step: 74119, training_loss: 1.73355
Epoch: 1/10, step: 74139, training_loss: 0.93586
Epoch: 1/10, step: 74159, training_loss: 1.67522
Epoch: 1/10, step: 74179, training_loss: 1.66945
Epoch: 1/10, step: 74199, training_loss: 1.01391
Epoch: 1/10, step: 74219, training_loss: 1.50670
Epoch: 1/10, step: 74239, training_loss: 1.65018
Epoch: 1/10, step: 74259, training_loss: 1.45328
Epoch: 1/10, step: 74279, training_loss: 1.20090
Epoch: 1/10, step: 74299, training_loss: 1.13854
Epoch: 1/10, step: 74319, training_loss: 1.48437
Epoch: 1/10, step: 74339, training_loss: 1.36745
Epoch: 1/10, step: 74359, training_loss: 1.39439
Epoch: 1/10, step: 74379, training_loss: 1.20273
Epoch: 1/10, step: 74399, training_loss: 2.12214
Epoch: 1/10, step: 74419, training_loss: 1.79332
Epoch: 1/10, step: 74439, training_loss: 1.52348
Epoch: 1/10, step: 74459, training_loss: 1.33173
Epoch: 1/10, step: 74479, training_loss: 1.57243
Epoch: 1/10, step: 74499, training_loss: 1.33656
Epoch: 1/10, step: 74519, training_loss: 1.06546
Epoch: 1/10, step: 74539, training_loss: 1.35262
Epoch: 1/10, step: 74559, training_loss: 2.27012
Epoch: 1/10, step: 74579, training_loss: 1.53158
Epoch: 1/10, step: 74599, training_loss: 0.78950
Epoch: 1/10, step: 74619, training_loss: 1.55228
Epoch: 1/10, step: 74639, training_loss: 1.89838
Epoch: 1/10, step: 74659, training_loss: 0.80943
Epoch: 1/10, step: 74679, training_loss: 1.21806
Epoch: 1/10, step: 74699, training_loss: 1.51353
Epoch: 1/10, step: 74719, training_loss: 1.01155
Epoch: 1/10, step: 74739, training_loss: 1.33765
Epoch: 1/10, step: 74759, training_loss: 1.63279
Epoch: 1/10, step: 74779, training_loss: 1.18450
Epoch: 1/10, step: 74799, training_loss: 1.30124
Epoch: 1/10, step: 74819, training_loss: 1.52093
Epoch: 1/10, step: 74839, training_loss: 1.41020
Epoch: 1/10, step: 74859, training_loss: 0.83797
Epoch: 1/10, step: 74879, training_loss: 1.68570
Epoch: 1/10, step: 74899, training_loss: 1.54043
Epoch: 1/10, step: 74919, training_loss: 1.52241
Epoch: 1/10, step: 74939, training_loss: 1.49890
Epoch: 1/10, step: 74959, training_loss: 1.01599
Epoch: 1/10, step: 74979, training_loss: 1.98588
Epoch: 1/10, step: 74999, training_loss: 1.62274
accuracy: 0.47, validation_loss: 1.6814266443252563, num_samples: 100
Epoch: 1/10, step: 75019, training_loss: 1.65236
Epoch: 1/10, step: 75039, training_loss: 1.47995
Epoch: 1/10, step: 75059, training_loss: 1.27420
Epoch: 1/10, step: 75079, training_loss: 1.52428
Epoch: 1/10, step: 75099, training_loss: 1.60170
Epoch: 1/10, step: 75119, training_loss: 1.58463
Epoch: 1/10, step: 75139, training_loss: 1.50960
Epoch: 1/10, step: 75159, training_loss: 2.12676
Epoch: 1/10, step: 75179, training_loss: 1.29754
Epoch: 1/10, step: 75199, training_loss: 1.83779
Epoch: 1/10, step: 75219, training_loss: 1.89712
Epoch: 1/10, step: 75239, training_loss: 1.66416
Epoch: 1/10, step: 75259, training_loss: 1.56655
Epoch: 1/10, step: 75279, training_loss: 1.28867
Epoch: 1/10, step: 75299, training_loss: 1.16691
Epoch: 1/10, step: 75319, training_loss: 1.56028
Epoch: 1/10, step: 75339, training_loss: 1.72435
Epoch: 1/10, step: 75359, training_loss: 1.70140
Epoch: 1/10, step: 75379, training_loss: 1.89221
Epoch: 1/10, step: 75399, training_loss: 0.67198
Epoch: 1/10, step: 75419, training_loss: 1.24530
Epoch: 1/10, step: 75439, training_loss: 1.72913
Epoch: 1/10, step: 75459, training_loss: 1.39065
Epoch: 1/10, step: 75479, training_loss: 1.79905
Epoch: 1/10, step: 75499, training_loss: 1.02660
Epoch: 1/10, step: 75519, training_loss: 1.26939
Epoch: 1/10, step: 75539, training_loss: 1.34458
Epoch: 1/10, step: 75559, training_loss: 1.29542
Epoch: 1/10, step: 75579, training_loss: 1.30954
Epoch: 1/10, step: 75599, training_loss: 1.63775
Epoch: 1/10, step: 75619, training_loss: 1.48633
Epoch: 1/10, step: 75639, training_loss: 1.87224
Epoch: 1/10, step: 75659, training_loss: 1.21987
Epoch: 1/10, step: 75679, training_loss: 0.81680
Epoch: 1/10, step: 75699, training_loss: 1.27261
Epoch: 1/10, step: 75719, training_loss: 1.40316
Epoch: 1/10, step: 75739, training_loss: 1.61087
Epoch: 1/10, step: 75759, training_loss: 1.24406
Epoch: 1/10, step: 75779, training_loss: 0.95038
Epoch: 1/10, step: 75799, training_loss: 1.45036
Epoch: 1/10, step: 75819, training_loss: 1.56451
Epoch: 1/10, step: 75839, training_loss: 2.30586
Epoch: 1/10, step: 75859, training_loss: 1.22699
Epoch: 1/10, step: 75879, training_loss: 1.44104
Epoch: 1/10, step: 75899, training_loss: 1.18140
Epoch: 1/10, step: 75919, training_loss: 1.39806
Epoch: 1/10, step: 75939, training_loss: 1.53517
Epoch: 1/10, step: 75959, training_loss: 1.53771
Epoch: 1/10, step: 75979, training_loss: 1.21178
Epoch: 1/10, step: 75999, training_loss: 1.42096
accuracy: 0.49, validation_loss: 1.4111180305480957, num_samples: 100
Epoch: 1/10, step: 76019, training_loss: 1.68562
Epoch: 1/10, step: 76039, training_loss: 1.69650
Epoch: 1/10, step: 76059, training_loss: 1.25275
Epoch: 1/10, step: 76079, training_loss: 1.16037
Epoch: 1/10, step: 76099, training_loss: 1.22236
Epoch: 1/10, step: 76119, training_loss: 1.45685
Epoch: 1/10, step: 76139, training_loss: 0.78896
Epoch: 1/10, step: 76159, training_loss: 1.46565
Epoch: 1/10, step: 76179, training_loss: 2.22117
Epoch: 1/10, step: 76199, training_loss: 0.98714
Epoch: 1/10, step: 76219, training_loss: 2.02676
Epoch: 1/10, step: 76239, training_loss: 2.04105
Epoch: 1/10, step: 76259, training_loss: 1.63159
Epoch: 1/10, step: 76279, training_loss: 0.92496
Epoch: 1/10, step: 76299, training_loss: 0.97159
Epoch: 1/10, step: 76319, training_loss: 1.73072
Epoch: 1/10, step: 76339, training_loss: 1.38554
Epoch: 1/10, step: 76359, training_loss: 2.42177
Epoch: 1/10, step: 76379, training_loss: 1.71093
Epoch: 1/10, step: 76399, training_loss: 1.83407
Epoch: 1/10, step: 76419, training_loss: 1.24528
Epoch: 1/10, step: 76439, training_loss: 1.10364
Epoch: 1/10, step: 76459, training_loss: 1.32157
Epoch: 1/10, step: 76479, training_loss: 1.15118
Epoch: 1/10, step: 76499, training_loss: 1.91272
Epoch: 1/10, step: 76519, training_loss: 1.64627
Epoch: 1/10, step: 76539, training_loss: 0.74123
Epoch: 1/10, step: 76559, training_loss: 2.05390
Epoch: 1/10, step: 76579, training_loss: 1.29529
Epoch: 1/10, step: 76599, training_loss: 0.79424
Epoch: 1/10, step: 76619, training_loss: 0.93065
Epoch: 1/10, step: 76639, training_loss: 2.34560
Epoch: 1/10, step: 76659, training_loss: 1.61188
Epoch: 1/10, step: 76679, training_loss: 1.26770
Epoch: 1/10, step: 76699, training_loss: 0.50286
Epoch: 1/10, step: 76719, training_loss: 1.27278
Epoch: 1/10, step: 76739, training_loss: 1.63101
Epoch: 1/10, step: 76759, training_loss: 1.79002
Epoch: 1/10, step: 76779, training_loss: 0.91318
Epoch: 1/10, step: 76799, training_loss: 2.03100
Epoch: 1/10, step: 76819, training_loss: 1.08564
Epoch: 1/10, step: 76839, training_loss: 1.32584
Epoch: 1/10, step: 76859, training_loss: 1.47677
Epoch: 1/10, step: 76879, training_loss: 2.06931
Epoch: 1/10, step: 76899, training_loss: 1.35086
Epoch: 1/10, step: 76919, training_loss: 2.30764
Epoch: 1/10, step: 76939, training_loss: 1.26929
Epoch: 1/10, step: 76959, training_loss: 1.39660
Epoch: 1/10, step: 76979, training_loss: 1.93431
Epoch: 1/10, step: 76999, training_loss: 0.85836
accuracy: 0.5, validation_loss: 1.2864588499069214, num_samples: 100
Epoch: 1/10, step: 77019, training_loss: 2.35844
Epoch: 1/10, step: 77039, training_loss: 1.32813
Epoch: 1/10, step: 77059, training_loss: 1.63733
Epoch: 1/10, step: 77079, training_loss: 0.73884
Epoch: 1/10, step: 77099, training_loss: 0.80748
Epoch: 1/10, step: 77119, training_loss: 2.44875
Epoch: 1/10, step: 77139, training_loss: 1.82579
Epoch: 1/10, step: 77159, training_loss: 1.68004
Epoch: 1/10, step: 77179, training_loss: 2.08005
Epoch: 1/10, step: 77199, training_loss: 2.11220
Epoch: 1/10, step: 77219, training_loss: 2.38215
Epoch: 1/10, step: 77239, training_loss: 1.32592
Epoch: 1/10, step: 77259, training_loss: 1.20469
Epoch: 1/10, step: 77279, training_loss: 0.82012
Epoch: 1/10, step: 77299, training_loss: 1.18788
Epoch: 1/10, step: 77319, training_loss: 1.30720
Epoch: 1/10, step: 77339, training_loss: 1.64429
Epoch: 1/10, step: 77359, training_loss: 2.20950
Epoch: 1/10, step: 77379, training_loss: 1.54085
Epoch: 1/10, step: 77399, training_loss: 0.93399
Epoch: 1/10, step: 77419, training_loss: 1.85413
Epoch: 1/10, step: 77439, training_loss: 1.29955
Epoch: 1/10, step: 77459, training_loss: 1.40657
Epoch: 1/10, step: 77479, training_loss: 1.51585
Epoch: 1/10, step: 77499, training_loss: 1.75704
Epoch: 1/10, step: 77519, training_loss: 1.25418
Epoch: 1/10, step: 77539, training_loss: 1.31229
Epoch: 1/10, step: 77559, training_loss: 1.09469
Epoch: 1/10, step: 77579, training_loss: 1.58961
Epoch: 1/10, step: 77599, training_loss: 1.62982
Epoch: 1/10, step: 77619, training_loss: 1.60450
Epoch: 1/10, step: 77639, training_loss: 1.02811
Epoch: 1/10, step: 77659, training_loss: 1.74405
Epoch: 1/10, step: 77679, training_loss: 0.79064
Epoch: 1/10, step: 77699, training_loss: 1.54618
Epoch: 1/10, step: 77719, training_loss: 1.90365
Epoch: 1/10, step: 77739, training_loss: 2.24229
Epoch: 1/10, step: 77759, training_loss: 1.79843
Epoch: 1/10, step: 77779, training_loss: 1.92464
Epoch: 1/10, step: 77799, training_loss: 1.26783
Epoch: 1/10, step: 77819, training_loss: 1.07068
Epoch: 1/10, step: 77839, training_loss: 1.55920
Epoch: 1/10, step: 77859, training_loss: 1.39410
Epoch: 1/10, step: 77879, training_loss: 1.21333
Epoch: 1/10, step: 77899, training_loss: 1.25663
Epoch: 1/10, step: 77919, training_loss: 1.45551
Epoch: 1/10, step: 77939, training_loss: 2.28879
Epoch: 1/10, step: 77959, training_loss: 1.30818
Epoch: 1/10, step: 77979, training_loss: 1.98953
Epoch: 1/10, step: 77999, training_loss: 1.42634
accuracy: 0.5, validation_loss: 1.3821696043014526, num_samples: 100
Epoch: 1/10, step: 78019, training_loss: 1.19917
Epoch: 1/10, step: 78039, training_loss: 0.93793
Epoch: 1/10, step: 78059, training_loss: 1.04461
Epoch: 1/10, step: 78079, training_loss: 1.95262
Epoch: 1/10, step: 78099, training_loss: 1.78009
Epoch: 1/10, step: 78119, training_loss: 1.89927
Epoch: 1/10, step: 78139, training_loss: 1.83814
Epoch: 1/10, step: 78159, training_loss: 1.03953
Epoch: 1/10, step: 78179, training_loss: 0.98697
Epoch: 1/10, step: 78199, training_loss: 2.48557
Epoch: 1/10, step: 78219, training_loss: 1.38736
Epoch: 1/10, step: 78239, training_loss: 1.31212
Epoch: 1/10, step: 78259, training_loss: 1.11985
Epoch: 1/10, step: 78279, training_loss: 1.19382
Epoch: 1/10, step: 78299, training_loss: 1.31511
Epoch: 1/10, step: 78319, training_loss: 2.14918
Epoch: 1/10, step: 78339, training_loss: 1.54714
Epoch: 1/10, step: 78359, training_loss: 1.37701
Epoch: 1/10, step: 78379, training_loss: 1.40101
Epoch: 1/10, step: 78399, training_loss: 1.59425
Epoch: 1/10, step: 78419, training_loss: 1.44991
Epoch: 1/10, step: 78439, training_loss: 1.41473
Epoch: 1/10, step: 78459, training_loss: 1.50958
Epoch: 1/10, step: 78479, training_loss: 1.24170
Epoch: 1/10, step: 78499, training_loss: 1.30028
Epoch: 1/10, step: 78519, training_loss: 1.79903
Epoch: 1/10, step: 78539, training_loss: 1.69486
Epoch: 1/10, step: 78559, training_loss: 1.36735
Epoch: 1/10, step: 78579, training_loss: 1.62833
Epoch: 1/10, step: 78599, training_loss: 1.83270
Epoch: 1/10, step: 78619, training_loss: 1.78816
Epoch: 1/10, step: 78639, training_loss: 0.70536
Epoch: 1/10, step: 78659, training_loss: 1.78904
Epoch: 1/10, step: 78679, training_loss: 1.63022
Epoch: 1/10, step: 78699, training_loss: 1.81179
Epoch: 1/10, step: 78719, training_loss: 1.69008
Epoch: 1/10, step: 78739, training_loss: 1.68914
Epoch: 1/10, step: 78759, training_loss: 1.59249
Epoch: 1/10, step: 78779, training_loss: 1.43144
Epoch: 1/10, step: 78799, training_loss: 1.77231
Epoch: 1/10, step: 78819, training_loss: 1.45482
Epoch: 1/10, step: 78839, training_loss: 1.62028
Epoch: 1/10, step: 78859, training_loss: 1.49149
Epoch: 1/10, step: 78879, training_loss: 1.75071
Epoch: 1/10, step: 78899, training_loss: 1.26988
Epoch: 1/10, step: 78919, training_loss: 1.84398
Epoch: 1/10, step: 78939, training_loss: 1.45193
Epoch: 1/10, step: 78959, training_loss: 1.16387
Epoch: 1/10, step: 78979, training_loss: 1.46981
Epoch: 1/10, step: 78999, training_loss: 0.72574
accuracy: 0.59, validation_loss: 1.2408215999603271, num_samples: 100
Epoch: 1/10, step: 79019, training_loss: 1.62855
Epoch: 1/10, step: 79039, training_loss: 2.25718
Epoch: 1/10, step: 79059, training_loss: 1.96127
Epoch: 1/10, step: 79079, training_loss: 1.15967
Epoch: 1/10, step: 79099, training_loss: 1.45709
Epoch: 1/10, step: 79119, training_loss: 0.93907
Epoch: 1/10, step: 79139, training_loss: 1.51232
Epoch: 1/10, step: 79159, training_loss: 2.60744
Epoch: 1/10, step: 79179, training_loss: 1.53817
Epoch: 1/10, step: 79199, training_loss: 1.96113
Epoch: 1/10, step: 79219, training_loss: 1.23104
Epoch: 1/10, step: 79239, training_loss: 1.28974
Epoch: 1/10, step: 79259, training_loss: 1.25692
Epoch: 1/10, step: 79279, training_loss: 1.19761
Epoch: 1/10, step: 79299, training_loss: 2.04392
Epoch: 1/10, step: 79319, training_loss: 1.34636
Epoch: 1/10, step: 79339, training_loss: 1.66929
Epoch: 1/10, step: 79359, training_loss: 1.37846
Epoch: 1/10, step: 79379, training_loss: 0.47596
Epoch: 1/10, step: 79399, training_loss: 1.44601
Epoch: 1/10, step: 79419, training_loss: 1.32932
Epoch: 1/10, step: 79439, training_loss: 2.02098
Epoch: 1/10, step: 79459, training_loss: 1.13831
Epoch: 1/10, step: 79479, training_loss: 1.44692
Epoch: 1/10, step: 79499, training_loss: 1.66092
Epoch: 1/10, step: 79519, training_loss: 1.15850
Epoch: 1/10, step: 79539, training_loss: 0.85901
Epoch: 1/10, step: 79559, training_loss: 1.55694
Epoch: 1/10, step: 79579, training_loss: 1.94645
Epoch: 1/10, step: 79599, training_loss: 1.13204
Epoch: 1/10, step: 79619, training_loss: 1.70060
Epoch: 1/10, step: 79639, training_loss: 1.19205
Epoch: 1/10, step: 79659, training_loss: 1.76628
Epoch: 1/10, step: 79679, training_loss: 1.33673
Epoch: 1/10, step: 79699, training_loss: 1.62713
Epoch: 1/10, step: 79719, training_loss: 1.24856
Epoch: 1/10, step: 79739, training_loss: 1.21958
Epoch: 1/10, step: 79759, training_loss: 1.10487
Epoch: 1/10, step: 79779, training_loss: 1.63588
Epoch: 1/10, step: 79799, training_loss: 1.68541
Epoch: 1/10, step: 79819, training_loss: 1.84120
Epoch: 1/10, step: 79839, training_loss: 1.43526
Epoch: 1/10, step: 79859, training_loss: 1.41329
Epoch: 1/10, step: 79879, training_loss: 1.31564
Epoch: 1/10, step: 79899, training_loss: 1.22832
Epoch: 1/10, step: 79919, training_loss: 1.35658
Epoch: 1/10, step: 79939, training_loss: 2.43558
Epoch: 1/10, step: 79959, training_loss: 1.78264
Epoch: 1/10, step: 79979, training_loss: 1.57065
Epoch: 1/10, step: 79999, training_loss: 1.57198
accuracy: 0.49, validation_loss: 1.550066351890564, num_samples: 100
Epoch: 1/10, step: 80019, training_loss: 2.12612
Epoch: 1/10, step: 80039, training_loss: 0.70887
Epoch: 1/10, step: 80059, training_loss: 0.92784
Epoch: 1/10, step: 80079, training_loss: 1.29249
Epoch: 1/10, step: 80099, training_loss: 1.67414
Epoch: 1/10, step: 80119, training_loss: 1.62752
Epoch: 1/10, step: 80139, training_loss: 1.75673
Epoch: 1/10, step: 80159, training_loss: 1.36111
Epoch: 1/10, step: 80179, training_loss: 1.44080
Epoch: 1/10, step: 80199, training_loss: 1.41997
Epoch: 1/10, step: 80219, training_loss: 1.34448
Epoch: 1/10, step: 80239, training_loss: 1.41010
Epoch: 1/10, step: 80259, training_loss: 1.22068
Epoch: 1/10, step: 80279, training_loss: 1.94231
Epoch: 1/10, step: 80299, training_loss: 1.48150
Epoch: 1/10, step: 80319, training_loss: 1.60725
Epoch: 1/10, step: 80339, training_loss: 1.14849
Epoch: 1/10, step: 80359, training_loss: 1.20884
Epoch: 1/10, step: 80379, training_loss: 1.75687
Epoch: 1/10, step: 80399, training_loss: 1.36301
Epoch: 1/10, step: 80419, training_loss: 1.60804
Epoch: 1/10, step: 80439, training_loss: 0.98689
Epoch: 1/10, step: 80459, training_loss: 0.90788
Epoch: 1/10, step: 80479, training_loss: 1.65889
Epoch: 1/10, step: 80499, training_loss: 1.39256
Epoch: 1/10, step: 80519, training_loss: 1.79007
Epoch: 1/10, step: 80539, training_loss: 1.39325
Epoch: 1/10, step: 80559, training_loss: 1.36556
Epoch: 1/10, step: 80579, training_loss: 1.84456
Epoch: 1/10, step: 80599, training_loss: 1.51879
Epoch: 1/10, step: 80619, training_loss: 1.22709
Epoch: 1/10, step: 80639, training_loss: 1.66942
Epoch: 1/10, step: 80659, training_loss: 1.59272
Epoch: 1/10, step: 80679, training_loss: 1.75586
Epoch: 1/10, step: 80699, training_loss: 1.22799
Epoch: 1/10, step: 80719, training_loss: 1.14566
Epoch: 1/10, step: 80739, training_loss: 1.34658
Epoch: 1/10, step: 80759, training_loss: 1.68697
Epoch: 1/10, step: 80779, training_loss: 1.47705
Epoch: 1/10, step: 80799, training_loss: 1.72086
Epoch: 1/10, step: 80819, training_loss: 1.29160
Epoch: 1/10, step: 80839, training_loss: 0.93699
Epoch: 1/10, step: 80859, training_loss: 1.95991
Epoch: 1/10, step: 80879, training_loss: 1.35667
Epoch: 1/10, step: 80899, training_loss: 1.72489
Epoch: 1/10, step: 80919, training_loss: 1.43197
Epoch: 1/10, step: 80939, training_loss: 2.31008
Epoch: 1/10, step: 80959, training_loss: 1.60756
Epoch: 1/10, step: 80979, training_loss: 1.33785
Epoch: 1/10, step: 80999, training_loss: 1.33740
accuracy: 0.48, validation_loss: 1.549252986907959, num_samples: 100
Epoch: 1/10, step: 81019, training_loss: 1.28523
Epoch: 1/10, step: 81039, training_loss: 1.98332
Epoch: 1/10, step: 81059, training_loss: 1.38490
Epoch: 1/10, step: 81079, training_loss: 1.66522
Epoch: 1/10, step: 81099, training_loss: 0.70510
Epoch: 1/10, step: 81119, training_loss: 1.48499
Epoch: 1/10, step: 81139, training_loss: 1.20874
Epoch: 1/10, step: 81159, training_loss: 1.33810
Epoch: 1/10, step: 81179, training_loss: 3.15956
Epoch: 1/10, step: 81199, training_loss: 0.73599
Epoch: 1/10, step: 81219, training_loss: 1.32905
Epoch: 1/10, step: 81239, training_loss: 1.62633
Epoch: 1/10, step: 81259, training_loss: 1.24571
Epoch: 1/10, step: 81279, training_loss: 1.62028
Epoch: 1/10, step: 81299, training_loss: 1.48448
Epoch: 1/10, step: 81319, training_loss: 1.84721
Epoch: 1/10, step: 81339, training_loss: 1.25379
Epoch: 1/10, step: 81359, training_loss: 1.53558
Epoch: 1/10, step: 81379, training_loss: 1.11152
Epoch: 1/10, step: 81399, training_loss: 0.82257
Epoch: 1/10, step: 81419, training_loss: 1.57403
Epoch: 1/10, step: 81439, training_loss: 1.33958
Epoch: 1/10, step: 81459, training_loss: 1.81434
Epoch: 1/10, step: 81479, training_loss: 0.61530
Epoch: 1/10, step: 81499, training_loss: 1.47686
Epoch: 1/10, step: 81519, training_loss: 1.74922
Epoch: 1/10, step: 81539, training_loss: 1.91780
Epoch: 1/10, step: 81559, training_loss: 1.34884
Epoch: 1/10, step: 81579, training_loss: 0.88951
Epoch: 1/10, step: 81599, training_loss: 0.95466
Epoch: 1/10, step: 81619, training_loss: 1.35542
Epoch: 1/10, step: 81639, training_loss: 1.15084
Epoch: 1/10, step: 81659, training_loss: 1.24665
Epoch: 1/10, step: 81679, training_loss: 1.11968
Epoch: 1/10, step: 81699, training_loss: 1.00213
Epoch: 1/10, step: 81719, training_loss: 1.60326
Epoch: 1/10, step: 81739, training_loss: 1.17604
Epoch: 1/10, step: 81759, training_loss: 1.04900
Epoch: 1/10, step: 81779, training_loss: 1.18950
Epoch: 1/10, step: 81799, training_loss: 1.42363
Epoch: 1/10, step: 81819, training_loss: 1.91596
Epoch: 1/10, step: 81839, training_loss: 1.27314
Epoch: 1/10, step: 81859, training_loss: 1.22948
Epoch: 1/10, step: 81879, training_loss: 1.13895
Epoch: 1/10, step: 81899, training_loss: 1.08350
Epoch: 1/10, step: 81919, training_loss: 1.81330
Epoch: 1/10, step: 81939, training_loss: 2.09072
Epoch: 1/10, step: 81959, training_loss: 1.34375
Epoch: 1/10, step: 81979, training_loss: 1.44258
Epoch: 1/10, step: 81999, training_loss: 1.07794
accuracy: 0.49, validation_loss: 1.4178740978240967, num_samples: 100
Epoch: 1/10, step: 82019, training_loss: 1.37544
Epoch: 1/10, step: 82039, training_loss: 1.21777
Epoch: 1/10, step: 82059, training_loss: 1.25819
Epoch: 1/10, step: 82079, training_loss: 1.58193
Epoch: 1/10, step: 82099, training_loss: 0.56832
Epoch: 1/10, step: 82119, training_loss: 2.07497
Epoch: 1/10, step: 82139, training_loss: 1.25170
Epoch: 1/10, step: 82159, training_loss: 1.79730
Epoch: 1/10, step: 82179, training_loss: 1.28062
Epoch: 1/10, step: 82199, training_loss: 1.82912
Epoch: 1/10, step: 82219, training_loss: 1.38991
Epoch: 1/10, step: 82239, training_loss: 1.38226
Epoch: 1/10, step: 82259, training_loss: 2.19785
Epoch: 1/10, step: 82279, training_loss: 1.40746
Epoch: 1/10, step: 82299, training_loss: 1.53713
Epoch: 1/10, step: 82319, training_loss: 1.87610
Epoch: 1/10, step: 82339, training_loss: 1.84929
Epoch: 1/10, step: 82359, training_loss: 1.24810
Epoch: 1/10, step: 82379, training_loss: 1.27030
Epoch: 1/10, step: 82399, training_loss: 2.41664
Epoch: 1/10, step: 82419, training_loss: 1.65295
Epoch: 1/10, step: 82439, training_loss: 0.92941
Epoch: 1/10, step: 82459, training_loss: 1.09961
Epoch: 1/10, step: 82479, training_loss: 2.11620
Epoch: 1/10, step: 82499, training_loss: 1.67963
Epoch: 1/10, step: 82519, training_loss: 1.72659
Epoch: 1/10, step: 82539, training_loss: 1.35629
Epoch: 1/10, step: 82559, training_loss: 1.25420
Epoch: 1/10, step: 82579, training_loss: 1.28915
Epoch: 1/10, step: 82599, training_loss: 1.16159
Epoch: 1/10, step: 82619, training_loss: 1.46560
Epoch: 1/10, step: 82639, training_loss: 1.35912
Epoch: 1/10, step: 82659, training_loss: 1.06396
Epoch: 1/10, step: 82679, training_loss: 1.67589
Epoch: 1/10, step: 82699, training_loss: 1.26842
Epoch: 1/10, step: 82719, training_loss: 0.91442
Epoch: 1/10, step: 82739, training_loss: 1.57271
Epoch: 1/10, step: 82759, training_loss: 1.50896
Epoch: 1/10, step: 82779, training_loss: 1.09947
Epoch: 1/10, step: 82799, training_loss: 1.35464
Epoch: 1/10, step: 82819, training_loss: 1.64365
Epoch: 1/10, step: 82839, training_loss: 1.71996
Epoch: 1/10, step: 82859, training_loss: 0.93079
Epoch: 1/10, step: 82879, training_loss: 1.06813
Epoch: 1/10, step: 82899, training_loss: 1.77012
Epoch: 1/10, step: 82919, training_loss: 1.01081
Epoch: 1/10, step: 82939, training_loss: 1.83067
Epoch: 1/10, step: 82959, training_loss: 1.39889
Epoch: 1/10, step: 82979, training_loss: 1.28923
Epoch: 1/10, step: 82999, training_loss: 1.38971
accuracy: 0.5, validation_loss: 1.3705635070800781, num_samples: 100
Epoch: 1/10, step: 83019, training_loss: 0.99473
Epoch: 1/10, step: 83039, training_loss: 1.92460
Epoch: 1/10, step: 83059, training_loss: 1.45339
Epoch: 1/10, step: 83079, training_loss: 1.69939
Epoch: 1/10, step: 83099, training_loss: 1.80745
Epoch: 1/10, step: 83119, training_loss: 1.69732
Epoch: 1/10, step: 83139, training_loss: 1.39627
Epoch: 1/10, step: 83159, training_loss: 1.53689
Epoch: 1/10, step: 83179, training_loss: 1.51820
Epoch: 1/10, step: 83199, training_loss: 1.24155
Epoch: 1/10, step: 83219, training_loss: 1.24888
Epoch: 1/10, step: 83239, training_loss: 0.86997
Epoch: 1/10, step: 83259, training_loss: 1.69708
Epoch: 1/10, step: 83279, training_loss: 1.81759
Epoch: 1/10, step: 83299, training_loss: 1.55719
Epoch: 1/10, step: 83319, training_loss: 1.24648
Epoch: 1/10, step: 83339, training_loss: 1.57310
Epoch: 1/10, step: 83359, training_loss: 1.48064
Epoch: 1/10, step: 83379, training_loss: 1.59419
Epoch: 1/10, step: 83399, training_loss: 1.29547
Epoch: 1/10, step: 83419, training_loss: 1.13665
Epoch: 1/10, step: 83439, training_loss: 2.07428
Epoch: 1/10, step: 83459, training_loss: 0.85704
Epoch: 1/10, step: 83479, training_loss: 1.75068
Epoch: 1/10, step: 83499, training_loss: 1.95895
Epoch: 1/10, step: 83519, training_loss: 1.81096
Epoch: 1/10, step: 83539, training_loss: 1.06685
Epoch: 1/10, step: 83559, training_loss: 1.50254
Epoch: 1/10, step: 83579, training_loss: 1.87101
Epoch: 1/10, step: 83599, training_loss: 1.21180
Epoch: 1/10, step: 83619, training_loss: 0.98895
Epoch: 1/10, step: 83639, training_loss: 1.28551
Epoch: 1/10, step: 83659, training_loss: 1.81039
Epoch: 1/10, step: 83679, training_loss: 1.18788
Epoch: 1/10, step: 83699, training_loss: 0.91726
Epoch: 1/10, step: 83719, training_loss: 0.88140
Epoch: 1/10, step: 83739, training_loss: 1.11629
Epoch: 1/10, step: 83759, training_loss: 1.40467
Epoch: 1/10, step: 83779, training_loss: 1.45203
Epoch: 1/10, step: 83799, training_loss: 1.20259
Epoch: 1/10, step: 83819, training_loss: 1.17273
Epoch: 1/10, step: 83839, training_loss: 1.09456
Epoch: 1/10, step: 83859, training_loss: 1.24469
Epoch: 1/10, step: 83879, training_loss: 1.97131
Epoch: 1/10, step: 83899, training_loss: 0.80953
Epoch: 1/10, step: 83919, training_loss: 1.89795
Epoch: 1/10, step: 83939, training_loss: 2.68678
Epoch: 1/10, step: 83959, training_loss: 1.21265
Epoch: 1/10, step: 83979, training_loss: 1.65782
Epoch: 1/10, step: 83999, training_loss: 1.52779
accuracy: 0.47, validation_loss: 1.393561840057373, num_samples: 100
Epoch: 1/10, step: 84019, training_loss: 1.66115
Epoch: 1/10, step: 84039, training_loss: 2.29133
Epoch: 1/10, step: 84059, training_loss: 1.59936
Epoch: 1/10, step: 84079, training_loss: 1.47006
Epoch: 1/10, step: 84099, training_loss: 1.55628
Epoch: 1/10, step: 84119, training_loss: 1.49128
Epoch: 1/10, step: 84139, training_loss: 1.44156
Epoch: 1/10, step: 84159, training_loss: 2.20251
Epoch: 1/10, step: 84179, training_loss: 1.29292
Epoch: 1/10, step: 84199, training_loss: 1.77023
Epoch: 1/10, step: 84219, training_loss: 1.47689
Epoch: 1/10, step: 84239, training_loss: 1.26064
Epoch: 1/10, step: 84259, training_loss: 1.52239
Epoch: 1/10, step: 84279, training_loss: 1.84167
Epoch: 1/10, step: 84299, training_loss: 1.18145
Epoch: 1/10, step: 84319, training_loss: 1.78893
Epoch: 1/10, step: 84339, training_loss: 1.75438
Epoch: 1/10, step: 84359, training_loss: 1.53063
Epoch: 1/10, step: 84379, training_loss: 1.08249
Epoch: 1/10, step: 84399, training_loss: 1.48449
Epoch: 1/10, step: 84419, training_loss: 0.92904
Epoch: 1/10, step: 84439, training_loss: 0.66477
Epoch: 1/10, step: 84459, training_loss: 1.11929
Epoch: 1/10, step: 84479, training_loss: 2.01692
Epoch: 1/10, step: 84499, training_loss: 1.31695
Epoch: 1/10, step: 84519, training_loss: 1.02052
Epoch: 1/10, step: 84539, training_loss: 1.03390
Epoch: 1/10, step: 84559, training_loss: 1.75504
Epoch: 1/10, step: 84579, training_loss: 2.30888
Epoch: 1/10, step: 84599, training_loss: 1.56881
Epoch: 1/10, step: 84619, training_loss: 1.20381
Epoch: 1/10, step: 84639, training_loss: 2.15623
Epoch: 1/10, step: 84659, training_loss: 1.35783
Epoch: 1/10, step: 84679, training_loss: 1.34820
Epoch: 1/10, step: 84699, training_loss: 1.05749
Epoch: 1/10, step: 84719, training_loss: 1.41812
Epoch: 1/10, step: 84739, training_loss: 1.03657
Epoch: 1/10, step: 84759, training_loss: 1.35763
Epoch: 1/10, step: 84779, training_loss: 1.36763
Epoch: 1/10, step: 84799, training_loss: 1.20549
Epoch: 1/10, step: 84819, training_loss: 1.17573
Epoch: 1/10, step: 84839, training_loss: 2.13333
Epoch: 1/10, step: 84859, training_loss: 2.10547
Epoch: 1/10, step: 84879, training_loss: 1.29705
Epoch: 1/10, step: 84899, training_loss: 1.49487
Epoch: 1/10, step: 84919, training_loss: 1.16731
Epoch: 1/10, step: 84939, training_loss: 1.23967
Epoch: 1/10, step: 84959, training_loss: 1.26228
Epoch: 1/10, step: 84979, training_loss: 1.30147
Epoch: 1/10, step: 84999, training_loss: 1.66688
accuracy: 0.42, validation_loss: 1.7050286531448364, num_samples: 100
Epoch: 1/10, step: 85019, training_loss: 1.37570
Epoch: 1/10, step: 85039, training_loss: 1.50234
Epoch: 1/10, step: 85059, training_loss: 1.61897
Epoch: 1/10, step: 85079, training_loss: 2.28213
Epoch: 1/10, step: 85099, training_loss: 1.70775
Epoch: 1/10, step: 85119, training_loss: 2.20237
Epoch: 1/10, step: 85139, training_loss: 1.09642
Epoch: 1/10, step: 85159, training_loss: 1.33509
Epoch: 1/10, step: 85179, training_loss: 1.63666
Epoch: 1/10, step: 85199, training_loss: 1.15924
Epoch: 1/10, step: 85219, training_loss: 1.32028
Epoch: 1/10, step: 85239, training_loss: 1.43846
Epoch: 1/10, step: 85259, training_loss: 1.29171
Epoch: 1/10, step: 85279, training_loss: 1.68412
Epoch: 1/10, step: 85299, training_loss: 1.63030
Epoch: 1/10, step: 85319, training_loss: 1.97204
Epoch: 1/10, step: 85339, training_loss: 1.23545
Epoch: 1/10, step: 85359, training_loss: 1.40103
Epoch: 1/10, step: 85379, training_loss: 1.16045
Epoch: 1/10, step: 85399, training_loss: 1.36398
Epoch: 1/10, step: 85419, training_loss: 1.71935
Epoch: 1/10, step: 85439, training_loss: 1.57925
Epoch: 1/10, step: 85459, training_loss: 2.00314
Epoch: 1/10, step: 85479, training_loss: 2.49129
Epoch: 1/10, step: 85499, training_loss: 1.28742
Epoch: 1/10, step: 85519, training_loss: 1.97884
Epoch: 1/10, step: 85539, training_loss: 2.09457
Epoch: 1/10, step: 85559, training_loss: 0.99097
Epoch: 1/10, step: 85579, training_loss: 1.75598
Epoch: 1/10, step: 85599, training_loss: 1.43429
Epoch: 1/10, step: 85619, training_loss: 1.69083
Epoch: 1/10, step: 85639, training_loss: 1.78719
Epoch: 1/10, step: 85659, training_loss: 1.26619
Epoch: 1/10, step: 85679, training_loss: 1.52350
Epoch: 1/10, step: 85699, training_loss: 1.36800
Epoch: 1/10, step: 85719, training_loss: 1.52199
Epoch: 1/10, step: 85739, training_loss: 1.38853
Epoch: 1/10, step: 85759, training_loss: 1.14720
Epoch: 1/10, step: 85779, training_loss: 1.92287
Epoch: 1/10, step: 85799, training_loss: 1.84162
Epoch: 1/10, step: 85819, training_loss: 1.59217
Epoch: 1/10, step: 85839, training_loss: 1.42934
Epoch: 1/10, step: 85859, training_loss: 1.48414
Epoch: 1/10, step: 85879, training_loss: 0.94756
Epoch: 1/10, step: 85899, training_loss: 1.76080
Epoch: 1/10, step: 85919, training_loss: 1.37463
Epoch: 1/10, step: 85939, training_loss: 1.05265
Epoch: 1/10, step: 85959, training_loss: 1.25845
Epoch: 1/10, step: 85979, training_loss: 1.56667
Epoch: 1/10, step: 85999, training_loss: 1.69563
accuracy: 0.45, validation_loss: 1.6646180152893066, num_samples: 100
Epoch: 1/10, step: 86019, training_loss: 0.98427
Epoch: 1/10, step: 86039, training_loss: 1.48947
Epoch: 1/10, step: 86059, training_loss: 1.55728
Epoch: 1/10, step: 86079, training_loss: 1.72133
Epoch: 1/10, step: 86099, training_loss: 1.58507
Epoch: 1/10, step: 86119, training_loss: 1.38804
Epoch: 1/10, step: 86139, training_loss: 1.52799
Epoch: 1/10, step: 86159, training_loss: 1.64753
Epoch: 1/10, step: 86179, training_loss: 1.32414
Epoch: 1/10, step: 86199, training_loss: 0.97234
Epoch: 1/10, step: 86219, training_loss: 1.98779
Epoch: 1/10, step: 86239, training_loss: 1.70964
Epoch: 1/10, step: 86259, training_loss: 1.35120
Epoch: 1/10, step: 86279, training_loss: 1.38901
Epoch: 1/10, step: 86299, training_loss: 1.94606
Epoch: 1/10, step: 86319, training_loss: 1.13845
Epoch: 1/10, step: 86339, training_loss: 1.58396
Epoch: 1/10, step: 86359, training_loss: 1.55174
Epoch: 1/10, step: 86379, training_loss: 0.73868
Epoch: 1/10, step: 86399, training_loss: 1.53149
Epoch: 1/10, step: 86419, training_loss: 1.13642
Epoch: 1/10, step: 86439, training_loss: 2.27595
Epoch: 1/10, step: 86459, training_loss: 1.29520
Epoch: 1/10, step: 86479, training_loss: 0.99845
Epoch: 1/10, step: 86499, training_loss: 1.67227
Epoch: 1/10, step: 86519, training_loss: 1.24750
Epoch: 1/10, step: 86539, training_loss: 0.71206
Epoch: 1/10, step: 86559, training_loss: 1.08307
Epoch: 1/10, step: 86579, training_loss: 1.94163
Epoch: 1/10, step: 86599, training_loss: 1.08632
Epoch: 1/10, step: 86619, training_loss: 1.14881
Epoch: 1/10, step: 86639, training_loss: 1.35870
Epoch: 1/10, step: 86659, training_loss: 1.93217
Epoch: 1/10, step: 86679, training_loss: 1.55019
Epoch: 1/10, step: 86699, training_loss: 1.52684
Epoch: 1/10, step: 86719, training_loss: 1.92526
Epoch: 1/10, step: 86739, training_loss: 1.14907
Epoch: 1/10, step: 86759, training_loss: 1.73212
Epoch: 1/10, step: 86779, training_loss: 1.50069
Epoch: 1/10, step: 86799, training_loss: 1.20250
Epoch: 1/10, step: 86819, training_loss: 1.38006
Epoch: 1/10, step: 86839, training_loss: 1.41291
Epoch: 1/10, step: 86859, training_loss: 1.27765
Epoch: 1/10, step: 86879, training_loss: 1.42673
Epoch: 1/10, step: 86899, training_loss: 1.29719
Epoch: 1/10, step: 86919, training_loss: 1.46443
Epoch: 1/10, step: 86939, training_loss: 1.63622
Epoch: 1/10, step: 86959, training_loss: 1.56673
Epoch: 1/10, step: 86979, training_loss: 2.10688
Epoch: 1/10, step: 86999, training_loss: 1.39761
accuracy: 0.42, validation_loss: 1.63240647315979, num_samples: 100
Epoch: 1/10, step: 87019, training_loss: 1.30287
Epoch: 1/10, step: 87039, training_loss: 0.91172
Epoch: 1/10, step: 87059, training_loss: 1.73341
Epoch: 1/10, step: 87079, training_loss: 1.19284
Epoch: 1/10, step: 87099, training_loss: 1.71475
Epoch: 1/10, step: 87119, training_loss: 1.75530
Epoch: 1/10, step: 87139, training_loss: 1.36457
Epoch: 1/10, step: 87159, training_loss: 0.84778
Epoch: 1/10, step: 87179, training_loss: 1.69255
Epoch: 1/10, step: 87199, training_loss: 1.06704
Epoch: 1/10, step: 87219, training_loss: 1.58036
Epoch: 1/10, step: 87239, training_loss: 1.46563
Epoch: 1/10, step: 87259, training_loss: 1.83810
Epoch: 1/10, step: 87279, training_loss: 1.50468
Epoch: 1/10, step: 87299, training_loss: 1.28131
Epoch: 1/10, step: 87319, training_loss: 1.29948
Epoch: 1/10, step: 87339, training_loss: 1.32087
Epoch: 1/10, step: 87359, training_loss: 1.30184
Epoch: 1/10, step: 87379, training_loss: 1.40815
Epoch: 1/10, step: 87399, training_loss: 1.34410
Epoch: 1/10, step: 87419, training_loss: 1.31790
Epoch: 1/10, step: 87439, training_loss: 2.30741
Epoch: 1/10, step: 87459, training_loss: 0.70663
Epoch: 1/10, step: 87479, training_loss: 1.06573
Epoch: 1/10, step: 87499, training_loss: 1.97801
Epoch: 1/10, step: 87519, training_loss: 1.19904
Epoch: 1/10, step: 87539, training_loss: 1.65985
Epoch: 1/10, step: 87559, training_loss: 1.51705
Epoch: 1/10, step: 87579, training_loss: 1.36113
Epoch: 1/10, step: 87599, training_loss: 1.55033
Epoch: 1/10, step: 87619, training_loss: 1.51734
Epoch: 1/10, step: 87639, training_loss: 1.75342
Epoch: 1/10, step: 87659, training_loss: 1.46139
Epoch: 1/10, step: 87679, training_loss: 0.88256
Epoch: 1/10, step: 87699, training_loss: 1.40907
Epoch: 1/10, step: 87719, training_loss: 1.06903
Epoch: 1/10, step: 87739, training_loss: 1.39596
Epoch: 1/10, step: 87759, training_loss: 1.81749
Epoch: 1/10, step: 87779, training_loss: 1.17966
Epoch: 1/10, step: 87799, training_loss: 2.14254
Epoch: 1/10, step: 87819, training_loss: 1.04490
Epoch: 1/10, step: 87839, training_loss: 2.11828
Epoch: 1/10, step: 87859, training_loss: 1.25460
Epoch: 1/10, step: 87879, training_loss: 1.02567
Epoch: 1/10, step: 87899, training_loss: 1.29979
Epoch: 1/10, step: 87919, training_loss: 1.38068
Epoch: 1/10, step: 87939, training_loss: 1.76324
Epoch: 1/10, step: 87959, training_loss: 1.12808
Epoch: 1/10, step: 87979, training_loss: 1.41547
Epoch: 1/10, step: 87999, training_loss: 1.46097
accuracy: 0.5, validation_loss: 1.2675820589065552, num_samples: 100
Epoch: 1/10, step: 88019, training_loss: 0.77643
Epoch: 1/10, step: 88039, training_loss: 1.29091
Epoch: 1/10, step: 88059, training_loss: 1.06605
Epoch: 1/10, step: 88079, training_loss: 1.58530
Epoch: 1/10, step: 88099, training_loss: 1.06582
Epoch: 1/10, step: 88119, training_loss: 1.58748
Epoch: 1/10, step: 88139, training_loss: 1.62676
Epoch: 1/10, step: 88159, training_loss: 1.22353
Epoch: 1/10, step: 88179, training_loss: 1.98029
Epoch: 1/10, step: 88199, training_loss: 1.27779
Epoch: 1/10, step: 88219, training_loss: 1.54497
Epoch: 1/10, step: 88239, training_loss: 1.63748
Epoch: 1/10, step: 88259, training_loss: 1.40248
Epoch: 1/10, step: 88279, training_loss: 1.02518
Epoch: 1/10, step: 88299, training_loss: 1.78540
Epoch: 1/10, step: 88319, training_loss: 1.28344
Epoch: 1/10, step: 88339, training_loss: 1.75730
Epoch: 1/10, step: 88359, training_loss: 1.44811
Epoch: 1/10, step: 88379, training_loss: 1.27200
Epoch: 1/10, step: 88399, training_loss: 1.55921
Epoch: 1/10, step: 88419, training_loss: 1.06823
Epoch: 1/10, step: 88439, training_loss: 1.11730
Epoch: 1/10, step: 88459, training_loss: 1.50754
Epoch: 1/10, step: 88479, training_loss: 1.84238
Epoch: 1/10, step: 88499, training_loss: 1.04173
Epoch: 1/10, step: 88519, training_loss: 1.36611
Epoch: 1/10, step: 88539, training_loss: 1.46437
Epoch: 1/10, step: 88559, training_loss: 2.23804
Epoch: 1/10, step: 88579, training_loss: 1.21332
Epoch: 1/10, step: 88599, training_loss: 1.31517
Epoch: 1/10, step: 88619, training_loss: 1.08606
Epoch: 1/10, step: 88639, training_loss: 0.88166
Epoch: 1/10, step: 88659, training_loss: 1.66900
Epoch: 1/10, step: 88679, training_loss: 1.10871
Epoch: 1/10, step: 88699, training_loss: 1.97545
Epoch: 1/10, step: 88719, training_loss: 1.87693
Epoch: 1/10, step: 88739, training_loss: 1.67215
Epoch: 1/10, step: 88759, training_loss: 1.14627
Epoch: 1/10, step: 88779, training_loss: 0.91353
Epoch: 1/10, step: 88799, training_loss: 1.22249
Epoch: 1/10, step: 88819, training_loss: 1.63714
Epoch: 1/10, step: 88839, training_loss: 0.99738
Epoch: 1/10, step: 88859, training_loss: 1.40902
Epoch: 1/10, step: 88879, training_loss: 1.78922
Epoch: 1/10, step: 88899, training_loss: 0.82145
Epoch: 1/10, step: 88919, training_loss: 1.44778
Epoch: 1/10, step: 88939, training_loss: 1.20877
Epoch: 1/10, step: 88959, training_loss: 1.52166
Epoch: 1/10, step: 88979, training_loss: 1.26214
Epoch: 1/10, step: 88999, training_loss: 1.91968
accuracy: 0.51, validation_loss: 1.3001725673675537, num_samples: 100
Epoch: 1/10, step: 89019, training_loss: 1.20175
Epoch: 1/10, step: 89039, training_loss: 1.41049
Epoch: 1/10, step: 89059, training_loss: 2.05691
Epoch: 1/10, step: 89079, training_loss: 1.27982
Epoch: 1/10, step: 89099, training_loss: 1.76579
Epoch: 1/10, step: 89119, training_loss: 1.51493
Epoch: 1/10, step: 89139, training_loss: 0.99786
Epoch: 1/10, step: 89159, training_loss: 1.27494
Epoch: 1/10, step: 89179, training_loss: 1.70168
Epoch: 1/10, step: 89199, training_loss: 1.38236
Epoch: 1/10, step: 89219, training_loss: 1.09823
Epoch: 1/10, step: 89239, training_loss: 1.66166
Epoch: 1/10, step: 89259, training_loss: 1.59744
Epoch: 1/10, step: 89279, training_loss: 1.23755
Epoch: 1/10, step: 89299, training_loss: 1.66221
Epoch: 1/10, step: 89319, training_loss: 1.63038
Epoch: 1/10, step: 89339, training_loss: 1.23368
Epoch: 1/10, step: 89359, training_loss: 1.73914
Epoch: 1/10, step: 89379, training_loss: 1.44992
Epoch: 1/10, step: 89399, training_loss: 1.26098
Epoch: 1/10, step: 89419, training_loss: 1.69662
Epoch: 1/10, step: 89439, training_loss: 1.87785
Epoch: 1/10, step: 89459, training_loss: 1.58925
Epoch: 1/10, step: 89479, training_loss: 1.49247
Epoch: 1/10, step: 89499, training_loss: 0.95737
Epoch: 1/10, step: 89519, training_loss: 1.72147
Epoch: 1/10, step: 89539, training_loss: 1.00396
Epoch: 1/10, step: 89559, training_loss: 1.21602
Epoch: 1/10, step: 89579, training_loss: 1.79883
Epoch: 1/10, step: 89599, training_loss: 0.94817
Epoch: 1/10, step: 89619, training_loss: 1.51832
Epoch: 1/10, step: 89639, training_loss: 1.05986
Epoch: 1/10, step: 89659, training_loss: 1.64279
Epoch: 1/10, step: 89679, training_loss: 2.30909
Epoch: 1/10, step: 89699, training_loss: 1.58000
Epoch: 1/10, step: 89719, training_loss: 1.29896
Epoch: 1/10, step: 89739, training_loss: 1.28236
Epoch: 1/10, step: 89759, training_loss: 1.30373
Epoch: 1/10, step: 89779, training_loss: 1.55101
Epoch: 1/10, step: 89799, training_loss: 1.55086
Epoch: 1/10, step: 89819, training_loss: 0.81948
Epoch: 1/10, step: 89839, training_loss: 1.30945
Epoch: 1/10, step: 89859, training_loss: 1.01876
Epoch: 1/10, step: 89879, training_loss: 1.36402
Epoch: 1/10, step: 89899, training_loss: 1.66239
Epoch: 1/10, step: 89919, training_loss: 0.87671
Epoch: 1/10, step: 89939, training_loss: 2.00821
Epoch: 1/10, step: 89959, training_loss: 1.59011
Epoch: 1/10, step: 89979, training_loss: 1.25469
Epoch: 1/10, step: 89999, training_loss: 1.19712
accuracy: 0.57, validation_loss: 1.1424763202667236, num_samples: 100
Epoch: 1/10, step: 90019, training_loss: 1.15803
Epoch: 1/10, step: 90039, training_loss: 1.12175
Epoch: 1/10, step: 90059, training_loss: 0.68889
Epoch: 1/10, step: 90079, training_loss: 0.82078
Epoch: 1/10, step: 90099, training_loss: 2.16051
Epoch: 1/10, step: 90119, training_loss: 1.02422
Epoch: 1/10, step: 90139, training_loss: 1.75712
Epoch: 1/10, step: 90159, training_loss: 1.25789
Epoch: 1/10, step: 90179, training_loss: 1.59229
Epoch: 1/10, step: 90199, training_loss: 1.55956
Epoch: 1/10, step: 90219, training_loss: 1.01512
Epoch: 1/10, step: 90239, training_loss: 0.85517
Epoch: 1/10, step: 90259, training_loss: 0.83555
Epoch: 1/10, step: 90279, training_loss: 1.40654
Epoch: 1/10, step: 90299, training_loss: 1.39838
Epoch: 1/10, step: 90319, training_loss: 1.82296
Epoch: 1/10, step: 90339, training_loss: 1.32279
Epoch: 1/10, step: 90359, training_loss: 1.65165
Epoch: 1/10, step: 90379, training_loss: 1.21022
Epoch: 1/10, step: 90399, training_loss: 1.09690
Epoch: 1/10, step: 90419, training_loss: 2.06467
Epoch: 1/10, step: 90439, training_loss: 1.42465
Epoch: 1/10, step: 90459, training_loss: 1.90981
Epoch: 1/10, step: 90479, training_loss: 1.53352
Epoch: 1/10, step: 90499, training_loss: 1.36932
Epoch: 1/10, step: 90519, training_loss: 1.48110
Epoch: 1/10, step: 90539, training_loss: 1.62236
Epoch: 1/10, step: 90559, training_loss: 1.07222
Epoch: 1/10, step: 90579, training_loss: 1.97669
Epoch: 1/10, step: 90599, training_loss: 1.69288
Epoch: 1/10, step: 90619, training_loss: 1.87105
Epoch: 1/10, step: 90639, training_loss: 1.33075
Epoch: 1/10, step: 90659, training_loss: 1.48305
Epoch: 1/10, step: 90679, training_loss: 0.90657
Epoch: 1/10, step: 90699, training_loss: 1.85958
Epoch: 1/10, step: 90719, training_loss: 0.69576
Epoch: 1/10, step: 90739, training_loss: 2.06191
Epoch: 1/10, step: 90759, training_loss: 2.00471
Epoch: 1/10, step: 90779, training_loss: 1.65387
Epoch: 1/10, step: 90799, training_loss: 1.31672
Epoch: 1/10, step: 90819, training_loss: 1.49060
Epoch: 1/10, step: 90839, training_loss: 1.85950
Epoch: 1/10, step: 90859, training_loss: 1.47408
Epoch: 1/10, step: 90879, training_loss: 1.94342
Epoch: 1/10, step: 90899, training_loss: 1.34808
Epoch: 1/10, step: 90919, training_loss: 0.96713
Epoch: 1/10, step: 90939, training_loss: 0.90959
Epoch: 1/10, step: 90959, training_loss: 1.35347
Epoch: 1/10, step: 90979, training_loss: 1.54287
Epoch: 1/10, step: 90999, training_loss: 1.35079
accuracy: 0.52, validation_loss: 1.3980140686035156, num_samples: 100
Epoch: 1/10, step: 91019, training_loss: 1.14176
Epoch: 1/10, step: 91039, training_loss: 1.56019
Epoch: 1/10, step: 91059, training_loss: 1.99055
Epoch: 1/10, step: 91079, training_loss: 1.62412
Epoch: 1/10, step: 91099, training_loss: 1.70722
Epoch: 1/10, step: 91119, training_loss: 1.72959
Epoch: 1/10, step: 91139, training_loss: 1.24622
Epoch: 1/10, step: 91159, training_loss: 1.46886
Epoch: 1/10, step: 91179, training_loss: 1.40977
Epoch: 1/10, step: 91199, training_loss: 1.24878
Epoch: 1/10, step: 91219, training_loss: 0.95486
Epoch: 1/10, step: 91239, training_loss: 1.06446
Epoch: 1/10, step: 91259, training_loss: 1.51376
Epoch: 1/10, step: 91279, training_loss: 1.42807
Epoch: 1/10, step: 91299, training_loss: 1.40083
Epoch: 1/10, step: 91319, training_loss: 1.20937
Epoch: 1/10, step: 91339, training_loss: 2.16948
Epoch: 1/10, step: 91359, training_loss: 1.77588
Epoch: 1/10, step: 91379, training_loss: 1.64571
Epoch: 1/10, step: 91399, training_loss: 0.73434
Epoch: 1/10, step: 91419, training_loss: 0.72674
Epoch: 1/10, step: 91439, training_loss: 1.63432
Epoch: 1/10, step: 91459, training_loss: 1.79491
Epoch: 1/10, step: 91479, training_loss: 1.24405
Epoch: 1/10, step: 91499, training_loss: 1.16019
Epoch: 1/10, step: 91519, training_loss: 1.49772
Epoch: 1/10, step: 91539, training_loss: 2.03042
Epoch: 1/10, step: 91559, training_loss: 2.03304
Epoch: 1/10, step: 91579, training_loss: 0.98641
Epoch: 1/10, step: 91599, training_loss: 1.23708
Epoch: 1/10, step: 91619, training_loss: 1.39515
Epoch: 1/10, step: 91639, training_loss: 1.37780
Epoch: 1/10, step: 91659, training_loss: 1.44054
Epoch: 1/10, step: 91679, training_loss: 2.12596
Epoch: 1/10, step: 91699, training_loss: 1.35422
Epoch: 1/10, step: 91719, training_loss: 1.33032
Epoch: 1/10, step: 91739, training_loss: 1.36144
Epoch: 1/10, step: 91759, training_loss: 0.88081
Epoch: 1/10, step: 91779, training_loss: 1.69699
Epoch: 1/10, step: 91799, training_loss: 1.54667
Epoch: 1/10, step: 91819, training_loss: 1.60987
Epoch: 1/10, step: 91839, training_loss: 2.04868
Epoch: 1/10, step: 91859, training_loss: 1.29150
Epoch: 1/10, step: 91879, training_loss: 0.97478
Epoch: 1/10, step: 91899, training_loss: 2.07472
Epoch: 1/10, step: 91919, training_loss: 1.07067
Epoch: 1/10, step: 91939, training_loss: 1.65094
Epoch: 1/10, step: 91959, training_loss: 2.17754
Epoch: 1/10, step: 91979, training_loss: 0.95843
Epoch: 1/10, step: 91999, training_loss: 1.46134
accuracy: 0.53, validation_loss: 1.3555303812026978, num_samples: 100
Epoch: 1/10, step: 92019, training_loss: 0.86398
Epoch: 1/10, step: 92039, training_loss: 1.52644
Epoch: 1/10, step: 92059, training_loss: 2.24812
Epoch: 1/10, step: 92079, training_loss: 0.88170
Epoch: 1/10, step: 92099, training_loss: 0.99475
Epoch: 1/10, step: 92119, training_loss: 1.31704
Epoch: 1/10, step: 92139, training_loss: 1.65565
Epoch: 1/10, step: 92159, training_loss: 1.66605
Epoch: 1/10, step: 92179, training_loss: 1.73168
Epoch: 1/10, step: 92199, training_loss: 1.33854
Epoch: 1/10, step: 92219, training_loss: 1.61708
Epoch: 1/10, step: 92239, training_loss: 1.09836
Epoch: 1/10, step: 92259, training_loss: 1.32297
Epoch: 1/10, step: 92279, training_loss: 1.06887
Epoch: 1/10, step: 92299, training_loss: 1.03517
Epoch: 1/10, step: 92319, training_loss: 1.48064
Epoch: 1/10, step: 92339, training_loss: 1.30933
Epoch: 1/10, step: 92359, training_loss: 1.50992
Epoch: 1/10, step: 92379, training_loss: 1.45526
Epoch: 1/10, step: 92399, training_loss: 1.21022
Epoch: 1/10, step: 92419, training_loss: 1.47616
Epoch: 1/10, step: 92439, training_loss: 1.82870
Epoch: 1/10, step: 92459, training_loss: 1.77611
Epoch: 1/10, step: 92479, training_loss: 1.34546
Epoch: 1/10, step: 92499, training_loss: 1.37018
Epoch: 1/10, step: 92519, training_loss: 1.30797
Epoch: 1/10, step: 92539, training_loss: 2.05514
Epoch: 1/10, step: 92559, training_loss: 1.63427
Epoch: 1/10, step: 92579, training_loss: 1.48102
Epoch: 1/10, step: 92599, training_loss: 1.48713
Epoch: 1/10, step: 92619, training_loss: 1.33823
Epoch: 1/10, step: 92639, training_loss: 1.52903
Epoch: 1/10, step: 92659, training_loss: 0.94085
Epoch: 1/10, step: 92679, training_loss: 1.46315
Epoch: 1/10, step: 92699, training_loss: 1.76196
Epoch: 1/10, step: 92719, training_loss: 1.74716
Epoch: 1/10, step: 92739, training_loss: 1.73467
Epoch: 1/10, step: 92759, training_loss: 1.50584
Epoch: 1/10, step: 92779, training_loss: 1.41505
Epoch: 1/10, step: 92799, training_loss: 1.45923
Epoch: 1/10, step: 92819, training_loss: 1.27622
Epoch: 1/10, step: 92839, training_loss: 1.85447
Epoch: 1/10, step: 92859, training_loss: 1.73014
Epoch: 1/10, step: 92879, training_loss: 2.01579
Epoch: 1/10, step: 92899, training_loss: 1.55878
Epoch: 1/10, step: 92919, training_loss: 1.20593
Epoch: 1/10, step: 92939, training_loss: 1.07339
Epoch: 1/10, step: 92959, training_loss: 1.60808
Epoch: 1/10, step: 92979, training_loss: 1.65220
Epoch: 1/10, step: 92999, training_loss: 1.27923
accuracy: 0.56, validation_loss: 1.2526572942733765, num_samples: 100
Epoch: 1/10, step: 93019, training_loss: 0.82637
Epoch: 1/10, step: 93039, training_loss: 0.97879
Epoch: 1/10, step: 93059, training_loss: 1.47507
Epoch: 1/10, step: 93079, training_loss: 1.15540
Epoch: 1/10, step: 93099, training_loss: 0.36609
Epoch: 1/10, step: 93119, training_loss: 2.02012
Epoch: 1/10, step: 93139, training_loss: 0.99956
Epoch: 1/10, step: 93159, training_loss: 1.71360
Epoch: 1/10, step: 93179, training_loss: 1.86457
Epoch: 1/10, step: 93199, training_loss: 1.34287
Epoch: 1/10, step: 93219, training_loss: 1.67140
Epoch: 1/10, step: 93239, training_loss: 1.08355
Epoch: 1/10, step: 93259, training_loss: 1.50315
Epoch: 1/10, step: 93279, training_loss: 1.06229
Epoch: 1/10, step: 93299, training_loss: 1.59206
Epoch: 1/10, step: 93319, training_loss: 2.07584
Epoch: 1/10, step: 93339, training_loss: 2.22562
Epoch: 1/10, step: 93359, training_loss: 2.14951
Epoch: 1/10, step: 93379, training_loss: 1.29004
Epoch: 1/10, step: 93399, training_loss: 1.40914
Epoch: 1/10, step: 93419, training_loss: 1.08642
Epoch: 1/10, step: 93439, training_loss: 1.79428
Epoch: 1/10, step: 93459, training_loss: 1.34147
Epoch: 1/10, step: 93479, training_loss: 0.99035
Epoch: 1/10, step: 93499, training_loss: 1.64137
Epoch: 1/10, step: 93519, training_loss: 1.50752
Epoch: 1/10, step: 93539, training_loss: 1.44016
Epoch: 1/10, step: 93559, training_loss: 1.88223
Epoch: 1/10, step: 93579, training_loss: 1.08629
Epoch: 1/10, step: 93599, training_loss: 1.55789
Epoch: 1/10, step: 93619, training_loss: 0.96031
Epoch: 1/10, step: 93639, training_loss: 1.26657
Epoch: 1/10, step: 93659, training_loss: 1.48557
Epoch: 1/10, step: 93679, training_loss: 0.94415
Epoch: 1/10, step: 93699, training_loss: 2.03849
Epoch: 1/10, step: 93719, training_loss: 1.48767
Epoch: 1/10, step: 93739, training_loss: 1.61093
Epoch: 1/10, step: 93759, training_loss: 1.46952
Epoch: 1/10, step: 93779, training_loss: 1.80628
Epoch: 1/10, step: 93799, training_loss: 1.44946
Epoch: 1/10, step: 93819, training_loss: 2.04315
Epoch: 1/10, step: 93839, training_loss: 1.23738
Epoch: 1/10, step: 93859, training_loss: 1.55488
Epoch: 1/10, step: 93879, training_loss: 1.66131
Epoch: 1/10, step: 93899, training_loss: 2.00648
Epoch: 1/10, step: 93919, training_loss: 0.95072
Epoch: 1/10, step: 93939, training_loss: 2.60426
Epoch: 1/10, step: 93959, training_loss: 1.30479
Epoch: 1/10, step: 93979, training_loss: 1.22443
Epoch: 1/10, step: 93999, training_loss: 1.78853
accuracy: 0.5, validation_loss: 1.391924262046814, num_samples: 100
Epoch: 1/10, step: 94019, training_loss: 1.67858
Epoch: 1/10, step: 94039, training_loss: 1.80990
Epoch: 1/10, step: 94059, training_loss: 1.24093
Epoch: 1/10, step: 94079, training_loss: 1.57983
Epoch: 1/10, step: 94099, training_loss: 1.55923
Epoch: 1/10, step: 94119, training_loss: 1.51949
Epoch: 1/10, step: 94139, training_loss: 1.75048
Epoch: 1/10, step: 94159, training_loss: 1.96639
Epoch: 1/10, step: 94179, training_loss: 1.49707
Epoch: 1/10, step: 94199, training_loss: 1.22263
Epoch: 1/10, step: 94219, training_loss: 1.26505
Epoch: 1/10, step: 94239, training_loss: 1.59303
Epoch: 1/10, step: 94259, training_loss: 2.00085
Epoch: 1/10, step: 94279, training_loss: 1.72830
Epoch: 1/10, step: 94299, training_loss: 1.24740
Epoch: 1/10, step: 94319, training_loss: 1.29932
Epoch: 1/10, step: 94339, training_loss: 1.92583
Epoch: 1/10, step: 94359, training_loss: 1.93307
Epoch: 1/10, step: 94379, training_loss: 1.40387
Epoch: 1/10, step: 94399, training_loss: 1.39444
Epoch: 1/10, step: 94419, training_loss: 0.78551
Epoch: 1/10, step: 94439, training_loss: 1.68871
Epoch: 1/10, step: 94459, training_loss: 1.20643
Epoch: 1/10, step: 94479, training_loss: 1.31314
Epoch: 1/10, step: 94499, training_loss: 0.92175
Epoch: 1/10, step: 94519, training_loss: 1.00203
Epoch: 1/10, step: 94539, training_loss: 1.52001
Epoch: 1/10, step: 94559, training_loss: 1.29809
Epoch: 1/10, step: 94579, training_loss: 0.86147
Epoch: 1/10, step: 94599, training_loss: 1.68770
Epoch: 1/10, step: 94619, training_loss: 1.64263
Epoch: 1/10, step: 94639, training_loss: 2.02935
Epoch: 1/10, step: 94659, training_loss: 1.44899
Epoch: 1/10, step: 94679, training_loss: 2.12303
Epoch: 1/10, step: 94699, training_loss: 1.35637
Epoch: 1/10, step: 94719, training_loss: 1.90536
Epoch: 1/10, step: 94739, training_loss: 1.18261
Epoch: 1/10, step: 94759, training_loss: 1.50256
Epoch: 1/10, step: 94779, training_loss: 1.27631
Epoch: 1/10, step: 94799, training_loss: 1.30614
Epoch: 1/10, step: 94819, training_loss: 1.10916
Epoch: 1/10, step: 94839, training_loss: 1.17575
Epoch: 1/10, step: 94859, training_loss: 1.34838
Epoch: 1/10, step: 94879, training_loss: 1.59456
Epoch: 1/10, step: 94899, training_loss: 1.85282
Epoch: 1/10, step: 94919, training_loss: 1.99365
Epoch: 1/10, step: 94939, training_loss: 1.55363
Epoch: 1/10, step: 94959, training_loss: 1.98942
Epoch: 1/10, step: 94979, training_loss: 1.82173
Epoch: 1/10, step: 94999, training_loss: 1.52921
accuracy: 0.49, validation_loss: 1.3473036289215088, num_samples: 100
Epoch: 1/10, step: 95019, training_loss: 1.91328
Epoch: 1/10, step: 95039, training_loss: 1.95686
Epoch: 1/10, step: 95059, training_loss: 0.96928
Epoch: 1/10, step: 95079, training_loss: 1.22135
Epoch: 1/10, step: 95099, training_loss: 1.42533
Epoch: 1/10, step: 95119, training_loss: 1.36374
Epoch: 1/10, step: 95139, training_loss: 1.83718
Epoch: 1/10, step: 95159, training_loss: 1.34904
Epoch: 1/10, step: 95179, training_loss: 1.30273
Epoch: 1/10, step: 95199, training_loss: 1.37980
Epoch: 1/10, step: 95219, training_loss: 1.56826
Epoch: 1/10, step: 95239, training_loss: 1.03123
Epoch: 1/10, step: 95259, training_loss: 0.96209
Epoch: 1/10, step: 95279, training_loss: 1.21499
Epoch: 1/10, step: 95299, training_loss: 1.51082
Epoch: 1/10, step: 95319, training_loss: 1.34894
Epoch: 1/10, step: 95339, training_loss: 0.93875
Epoch: 1/10, step: 95359, training_loss: 1.43802
Epoch: 1/10, step: 95379, training_loss: 1.04470
Epoch: 1/10, step: 95399, training_loss: 1.74853
Epoch: 1/10, step: 95419, training_loss: 1.84916
Epoch: 1/10, step: 95439, training_loss: 1.50112
Epoch: 1/10, step: 95459, training_loss: 1.52356
Epoch: 1/10, step: 95479, training_loss: 1.39341
Epoch: 1/10, step: 95499, training_loss: 1.99831
Epoch: 1/10, step: 95519, training_loss: 1.42583
Epoch: 1/10, step: 95539, training_loss: 1.62619
Epoch: 1/10, step: 95559, training_loss: 1.44489
Epoch: 1/10, step: 95579, training_loss: 1.01065
Epoch: 1/10, step: 95599, training_loss: 1.61296
Epoch: 1/10, step: 95619, training_loss: 1.43418
Epoch: 1/10, step: 95639, training_loss: 1.53698
Epoch: 1/10, step: 95659, training_loss: 1.80718
Epoch: 1/10, step: 95679, training_loss: 1.54696
Epoch: 1/10, step: 95699, training_loss: 1.08171
Epoch: 1/10, step: 95719, training_loss: 1.78385
Epoch: 1/10, step: 95739, training_loss: 1.36138
Epoch: 1/10, step: 95759, training_loss: 1.42594
Epoch: 1/10, step: 95779, training_loss: 1.67988
Epoch: 1/10, step: 95799, training_loss: 0.57191
Epoch: 1/10, step: 95819, training_loss: 1.87294
Epoch: 1/10, step: 95839, training_loss: 1.34027
Epoch: 1/10, step: 95859, training_loss: 1.78866
Epoch: 1/10, step: 95879, training_loss: 1.45727
Epoch: 1/10, step: 95899, training_loss: 2.33185
Epoch: 1/10, step: 95919, training_loss: 1.43492
Epoch: 1/10, step: 95939, training_loss: 1.30632
Epoch: 1/10, step: 95959, training_loss: 1.21021
Epoch: 1/10, step: 95979, training_loss: 1.07915
Epoch: 1/10, step: 95999, training_loss: 1.30749
accuracy: 0.49, validation_loss: 1.4644120931625366, num_samples: 100
Epoch: 1/10, step: 96019, training_loss: 1.68932
Epoch: 1/10, step: 96039, training_loss: 1.40471
Epoch: 1/10, step: 96059, training_loss: 2.26430
Epoch: 1/10, step: 96079, training_loss: 0.85722
Epoch: 1/10, step: 96099, training_loss: 1.07700
Epoch: 1/10, step: 96119, training_loss: 1.64310
Epoch: 1/10, step: 96139, training_loss: 1.40957
Epoch: 1/10, step: 96159, training_loss: 1.49927
Epoch: 1/10, step: 96179, training_loss: 1.79985
Epoch: 1/10, step: 96199, training_loss: 1.13011
Epoch: 1/10, step: 96219, training_loss: 1.93693
Epoch: 1/10, step: 96239, training_loss: 1.59184
Epoch: 1/10, step: 96259, training_loss: 1.94910
Epoch: 1/10, step: 96279, training_loss: 1.60433
Epoch: 1/10, step: 96299, training_loss: 1.75290
Epoch: 1/10, step: 96319, training_loss: 1.07139
Epoch: 1/10, step: 96339, training_loss: 0.88703
Epoch: 1/10, step: 96359, training_loss: 1.53286
Epoch: 1/10, step: 96379, training_loss: 1.63452
Epoch: 1/10, step: 96399, training_loss: 1.60246
Epoch: 1/10, step: 96419, training_loss: 1.08855
Epoch: 1/10, step: 96439, training_loss: 1.16199
Epoch: 1/10, step: 96459, training_loss: 1.30780
Epoch: 1/10, step: 96479, training_loss: 1.60803
Epoch: 1/10, step: 96499, training_loss: 1.77926
Epoch: 1/10, step: 96519, training_loss: 1.63828
Epoch: 1/10, step: 96539, training_loss: 1.30669
Epoch: 1/10, step: 96559, training_loss: 1.47465
Epoch: 1/10, step: 96579, training_loss: 1.83552
Epoch: 1/10, step: 96599, training_loss: 1.20017
Epoch: 1/10, step: 96619, training_loss: 1.29527
Epoch: 1/10, step: 96639, training_loss: 1.62879
Epoch: 1/10, step: 96659, training_loss: 1.19126
Epoch: 1/10, step: 96679, training_loss: 1.94427
Epoch: 1/10, step: 96699, training_loss: 1.86208
Epoch: 1/10, step: 96719, training_loss: 1.89398
Epoch: 1/10, step: 96739, training_loss: 1.60729
Epoch: 1/10, step: 96759, training_loss: 1.24625
Epoch: 1/10, step: 96779, training_loss: 0.97809
Epoch: 1/10, step: 96799, training_loss: 1.39510
Epoch: 1/10, step: 96819, training_loss: 1.67326
Epoch: 1/10, step: 96839, training_loss: 1.55356
Epoch: 1/10, step: 96859, training_loss: 1.93073
Epoch: 1/10, step: 96879, training_loss: 0.91935
Epoch: 1/10, step: 96899, training_loss: 1.88116
Epoch: 1/10, step: 96919, training_loss: 1.64305
Epoch: 1/10, step: 96939, training_loss: 1.11417
Epoch: 1/10, step: 96959, training_loss: 1.07099
Epoch: 1/10, step: 96979, training_loss: 1.96878
Epoch: 1/10, step: 96999, training_loss: 1.50295
accuracy: 0.44, validation_loss: 1.3770081996917725, num_samples: 100
Epoch: 1/10, step: 97019, training_loss: 0.92229
Epoch: 1/10, step: 97039, training_loss: 1.17871
Epoch: 1/10, step: 97059, training_loss: 1.14233
Epoch: 1/10, step: 97079, training_loss: 1.05359
Epoch: 1/10, step: 97099, training_loss: 1.29489
Epoch: 1/10, step: 97119, training_loss: 1.48821
Epoch: 1/10, step: 97139, training_loss: 1.25937
Epoch: 1/10, step: 97159, training_loss: 1.84219
Epoch: 1/10, step: 97179, training_loss: 1.65381
Epoch: 1/10, step: 97199, training_loss: 1.61314
Epoch: 1/10, step: 97219, training_loss: 1.42015
Epoch: 1/10, step: 97239, training_loss: 0.91393
Epoch: 1/10, step: 97259, training_loss: 1.79256
Epoch: 1/10, step: 97279, training_loss: 1.09728
Epoch: 1/10, step: 97299, training_loss: 1.37368
Epoch: 1/10, step: 97319, training_loss: 1.96791
Epoch: 1/10, step: 97339, training_loss: 1.24791
Epoch: 1/10, step: 97359, training_loss: 0.70683
Epoch: 1/10, step: 97379, training_loss: 1.18428
Epoch: 1/10, step: 97399, training_loss: 1.55297
Epoch: 1/10, step: 97419, training_loss: 1.50991
Epoch: 1/10, step: 97439, training_loss: 0.87510
Epoch: 1/10, step: 97459, training_loss: 1.50700
Epoch: 1/10, step: 97479, training_loss: 0.78865
Epoch: 1/10, step: 97499, training_loss: 1.67452
Epoch: 1/10, step: 97519, training_loss: 1.25876
Epoch: 1/10, step: 97539, training_loss: 1.79981
Epoch: 1/10, step: 97559, training_loss: 1.72129
Epoch: 1/10, step: 97579, training_loss: 1.22533
Epoch: 1/10, step: 97599, training_loss: 1.16431
Epoch: 1/10, step: 97619, training_loss: 2.05402
Epoch: 1/10, step: 97639, training_loss: 0.96505
Epoch: 1/10, step: 97659, training_loss: 1.69656
Epoch: 1/10, step: 97679, training_loss: 0.95319
Epoch: 1/10, step: 97699, training_loss: 2.00655
Epoch: 1/10, step: 97719, training_loss: 1.05012
Epoch: 1/10, step: 97739, training_loss: 1.23763
Epoch: 1/10, step: 97759, training_loss: 1.90722
Epoch: 1/10, step: 97779, training_loss: 2.12498
Epoch: 1/10, step: 97799, training_loss: 0.97519
Epoch: 1/10, step: 97819, training_loss: 1.89467
Epoch: 1/10, step: 97839, training_loss: 1.20525
Epoch: 1/10, step: 97859, training_loss: 1.89891
Epoch: 1/10, step: 97879, training_loss: 1.60290
Epoch: 1/10, step: 97899, training_loss: 1.53288
Epoch: 1/10, step: 97919, training_loss: 1.39048
Epoch: 1/10, step: 97939, training_loss: 1.29085
Epoch: 1/10, step: 97959, training_loss: 1.09906
Epoch: 1/10, step: 97979, training_loss: 1.25949
Epoch: 1/10, step: 97999, training_loss: 1.48112
accuracy: 0.49, validation_loss: 1.4454458951950073, num_samples: 100
Epoch: 1/10, step: 98019, training_loss: 1.83326
Epoch: 1/10, step: 98039, training_loss: 1.19106
Epoch: 1/10, step: 98059, training_loss: 1.48030
Epoch: 1/10, step: 98079, training_loss: 1.09060
Epoch: 1/10, step: 98099, training_loss: 1.26243
Epoch: 1/10, step: 98119, training_loss: 2.04250
Epoch: 1/10, step: 98139, training_loss: 1.04765
Epoch: 1/10, step: 98159, training_loss: 1.00874
Epoch: 1/10, step: 98179, training_loss: 1.12913
Epoch: 1/10, step: 98199, training_loss: 1.44690
Epoch: 1/10, step: 98219, training_loss: 1.64734
Epoch: 1/10, step: 98239, training_loss: 1.87887
Epoch: 1/10, step: 98259, training_loss: 1.38265
Epoch: 1/10, step: 98279, training_loss: 1.59974
Epoch: 1/10, step: 98299, training_loss: 1.99118
Epoch: 1/10, step: 98319, training_loss: 1.35628
Epoch: 1/10, step: 98339, training_loss: 1.31385
Epoch: 1/10, step: 98359, training_loss: 1.66538
Epoch: 1/10, step: 98379, training_loss: 1.79875
Epoch: 1/10, step: 98399, training_loss: 1.59326
Epoch: 1/10, step: 98419, training_loss: 1.55718
Epoch: 1/10, step: 98439, training_loss: 0.98164
Epoch: 1/10, step: 98459, training_loss: 1.34845
Epoch: 1/10, step: 98479, training_loss: 1.28828
Epoch: 1/10, step: 98499, training_loss: 1.28584
Epoch: 1/10, step: 98519, training_loss: 1.43414
Epoch: 1/10, step: 98539, training_loss: 0.77433
Epoch: 1/10, step: 98559, training_loss: 1.30921
Epoch: 1/10, step: 98579, training_loss: 1.36165
Epoch: 1/10, step: 98599, training_loss: 1.34195
Epoch: 1/10, step: 98619, training_loss: 0.98275
Epoch: 1/10, step: 98639, training_loss: 1.42753
Epoch: 1/10, step: 98659, training_loss: 1.10629
Epoch: 1/10, step: 98679, training_loss: 1.56707
Epoch: 1/10, step: 98699, training_loss: 1.46925
Epoch: 1/10, step: 98719, training_loss: 1.33014
Epoch: 1/10, step: 98739, training_loss: 0.93374
Epoch: 1/10, step: 98759, training_loss: 2.01694
Epoch: 1/10, step: 98779, training_loss: 1.45883
Epoch: 1/10, step: 98799, training_loss: 1.77335
Epoch: 1/10, step: 98819, training_loss: 1.52749
Epoch: 1/10, step: 98839, training_loss: 1.14840
Epoch: 1/10, step: 98859, training_loss: 2.05942
Epoch: 1/10, step: 98879, training_loss: 1.34496
Epoch: 1/10, step: 98899, training_loss: 1.70317
Epoch: 1/10, step: 98919, training_loss: 0.89444
Epoch: 1/10, step: 98939, training_loss: 0.91304
Epoch: 1/10, step: 98959, training_loss: 1.75075
Epoch: 1/10, step: 98979, training_loss: 1.75764
Epoch: 1/10, step: 98999, training_loss: 1.84860
accuracy: 0.5, validation_loss: 1.488294243812561, num_samples: 100
Epoch: 1/10, step: 99019, training_loss: 1.42685
Epoch: 1/10, step: 99039, training_loss: 0.83094
Epoch: 1/10, step: 99059, training_loss: 1.34098
Epoch: 1/10, step: 99079, training_loss: 2.34549
Epoch: 1/10, step: 99099, training_loss: 0.88972
Epoch: 1/10, step: 99119, training_loss: 2.12563
Epoch: 1/10, step: 99139, training_loss: 1.49895
Epoch: 1/10, step: 99159, training_loss: 1.47067
Epoch: 1/10, step: 99179, training_loss: 1.27365
Epoch: 1/10, step: 99199, training_loss: 2.58595
Epoch: 1/10, step: 99219, training_loss: 1.17068
Epoch: 1/10, step: 99239, training_loss: 1.49661
Epoch: 1/10, step: 99259, training_loss: 1.19664
Epoch: 1/10, step: 99279, training_loss: 1.68999
Epoch: 1/10, step: 99299, training_loss: 1.24387
Epoch: 1/10, step: 99319, training_loss: 2.07388
Epoch: 1/10, step: 99339, training_loss: 1.66235
Epoch: 1/10, step: 99359, training_loss: 1.18729
Epoch: 1/10, step: 99379, training_loss: 1.64787
Epoch: 1/10, step: 99399, training_loss: 1.03028
Epoch: 1/10, step: 99419, training_loss: 1.93122
Epoch: 1/10, step: 99439, training_loss: 1.53889
Epoch: 1/10, step: 99459, training_loss: 1.89113
Epoch: 1/10, step: 99479, training_loss: 2.07533
Epoch: 1/10, step: 99499, training_loss: 2.18733
Epoch: 1/10, step: 99519, training_loss: 1.24909
Epoch: 1/10, step: 99539, training_loss: 1.27463
Epoch: 1/10, step: 99559, training_loss: 1.24293
Epoch: 1/10, step: 99579, training_loss: 1.45558
Epoch: 1/10, step: 99599, training_loss: 0.96124
Epoch: 1/10, step: 99619, training_loss: 1.65256
Epoch: 1/10, step: 99639, training_loss: 1.60039
Epoch: 1/10, step: 99659, training_loss: 1.79887
Epoch: 1/10, step: 99679, training_loss: 1.27098
Epoch: 1/10, step: 99699, training_loss: 1.63871
Epoch: 1/10, step: 99719, training_loss: 1.38715
Epoch: 1/10, step: 99739, training_loss: 1.67674
Epoch: 1/10, step: 99759, training_loss: 1.58278
Epoch: 1/10, step: 99779, training_loss: 1.28747
Epoch: 1/10, step: 99799, training_loss: 1.00153
Epoch: 1/10, step: 99819, training_loss: 1.16689
Epoch: 1/10, step: 99839, training_loss: 1.22890
Epoch: 1/10, step: 99859, training_loss: 1.47985
Epoch: 1/10, step: 99879, training_loss: 1.05854
Epoch: 1/10, step: 99899, training_loss: 1.30673
Epoch: 1/10, step: 99919, training_loss: 1.23048
Epoch: 1/10, step: 99939, training_loss: 1.10738
Epoch: 1/10, step: 99959, training_loss: 1.98587
Epoch: 1/10, step: 99979, training_loss: 2.04329
Epoch: 1/10, step: 99999, training_loss: 1.51072
accuracy: 0.51, validation_loss: 1.4186794757843018, num_samples: 100
Epoch: 1/10, step: 100019, training_loss: 1.08950
Epoch: 1/10, step: 100039, training_loss: 1.69323
Epoch: 1/10, step: 100059, training_loss: 1.87950
Epoch: 1/10, step: 100079, training_loss: 1.40171
Epoch: 1/10, step: 100099, training_loss: 1.61736
Epoch: 1/10, step: 100119, training_loss: 0.73273
Epoch: 1/10, step: 100139, training_loss: 1.19449
Epoch: 1/10, step: 100159, training_loss: 1.12133
Epoch: 1/10, step: 100179, training_loss: 0.73952
Epoch: 1/10, step: 100199, training_loss: 0.79598
Epoch: 1/10, step: 100219, training_loss: 0.74451
Epoch: 1/10, step: 100239, training_loss: 1.25879
Epoch: 1/10, step: 100259, training_loss: 1.86761
Epoch: 1/10, step: 100279, training_loss: 1.76438
Epoch: 1/10, step: 100299, training_loss: 1.19975
Epoch: 1/10, step: 100319, training_loss: 1.08760
Epoch: 1/10, step: 100339, training_loss: 1.12457
Epoch: 1/10, step: 100359, training_loss: 0.83583
Epoch: 1/10, step: 100379, training_loss: 2.32455
Epoch: 1/10, step: 100399, training_loss: 1.38283
Epoch: 1/10, step: 100419, training_loss: 2.05326
Epoch: 1/10, step: 100439, training_loss: 1.39963
Epoch: 1/10, step: 100459, training_loss: 1.11514
Epoch: 1/10, step: 100479, training_loss: 1.07851
Epoch: 1/10, step: 100499, training_loss: 1.55673
Epoch: 1/10, step: 100519, training_loss: 0.70661
Epoch: 1/10, step: 100539, training_loss: 1.15083
Epoch: 1/10, step: 100559, training_loss: 1.35864
Epoch: 1/10, step: 100579, training_loss: 1.49144
Epoch: 1/10, step: 100599, training_loss: 1.57362
Epoch: 1/10, step: 100619, training_loss: 1.35697
Epoch: 1/10, step: 100639, training_loss: 1.90793
Epoch: 1/10, step: 100659, training_loss: 0.79163
Epoch: 1/10, step: 100679, training_loss: 0.77567
Epoch: 1/10, step: 100699, training_loss: 1.40795
Epoch: 1/10, step: 100719, training_loss: 1.35767
Epoch: 1/10, step: 100739, training_loss: 1.97691
Epoch: 1/10, step: 100759, training_loss: 1.25970
Epoch: 1/10, step: 100779, training_loss: 1.94228
Epoch: 1/10, step: 100799, training_loss: 1.41610
Epoch: 1/10, step: 100819, training_loss: 1.39102
Epoch: 1/10, step: 100839, training_loss: 1.54357
Epoch: 1/10, step: 100859, training_loss: 1.14120
Epoch: 1/10, step: 100879, training_loss: 1.19494
Epoch: 1/10, step: 100899, training_loss: 2.00011
Epoch: 1/10, step: 100919, training_loss: 1.36405
Epoch: 1/10, step: 100939, training_loss: 1.73814
Epoch: 1/10, step: 100959, training_loss: 0.83436
Epoch: 1/10, step: 100979, training_loss: 1.57070
Epoch: 1/10, step: 100999, training_loss: 1.37738
accuracy: 0.54, validation_loss: 1.3377554416656494, num_samples: 100
Epoch: 1/10, step: 101019, training_loss: 1.82406
Epoch: 1/10, step: 101039, training_loss: 1.39919
Epoch: 1/10, step: 101059, training_loss: 1.14180
Epoch: 1/10, step: 101079, training_loss: 1.97406
Epoch: 1/10, step: 101099, training_loss: 1.29210
Epoch: 1/10, step: 101119, training_loss: 1.05248
Epoch: 1/10, step: 101139, training_loss: 1.51822
Epoch: 1/10, step: 101159, training_loss: 1.98774
Epoch: 1/10, step: 101179, training_loss: 1.54797
Epoch: 1/10, step: 101199, training_loss: 1.41967
Epoch: 1/10, step: 101219, training_loss: 1.15131
Epoch: 1/10, step: 101239, training_loss: 1.51083
Epoch: 1/10, step: 101259, training_loss: 0.84951
Epoch: 1/10, step: 101279, training_loss: 1.20598
Epoch: 1/10, step: 101299, training_loss: 1.37280
Epoch: 1/10, step: 101319, training_loss: 1.58656
Epoch: 1/10, step: 101339, training_loss: 2.25992
Epoch: 1/10, step: 101359, training_loss: 1.84434
Epoch: 1/10, step: 101379, training_loss: 1.77720
Epoch: 1/10, step: 101399, training_loss: 1.39856
Epoch: 1/10, step: 101419, training_loss: 1.54220
Epoch: 1/10, step: 101439, training_loss: 1.23021
Epoch: 1/10, step: 101459, training_loss: 1.00866
Epoch: 1/10, step: 101479, training_loss: 1.91736
Epoch: 1/10, step: 101499, training_loss: 0.88631
Epoch: 1/10, step: 101519, training_loss: 1.62126
Epoch: 1/10, step: 101539, training_loss: 1.32013
Epoch: 1/10, step: 101559, training_loss: 1.37714
Epoch: 1/10, step: 101579, training_loss: 1.37404
Epoch: 1/10, step: 101599, training_loss: 1.36583
Epoch: 1/10, step: 101619, training_loss: 1.32007
Epoch: 1/10, step: 101639, training_loss: 1.50270
Epoch: 1/10, step: 101659, training_loss: 1.01576
Epoch: 1/10, step: 101679, training_loss: 1.38196
Epoch: 1/10, step: 101699, training_loss: 1.61144
Epoch: 1/10, step: 101719, training_loss: 1.48000
Epoch: 1/10, step: 101739, training_loss: 1.32353
Epoch: 1/10, step: 101759, training_loss: 1.90188
Epoch: 1/10, step: 101779, training_loss: 0.86331
Epoch: 1/10, step: 101799, training_loss: 1.27685
Epoch: 1/10, step: 101819, training_loss: 1.70876
Epoch: 1/10, step: 101839, training_loss: 1.27958
Epoch: 1/10, step: 101859, training_loss: 1.84431
Epoch: 1/10, step: 101879, training_loss: 1.46991
Epoch: 1/10, step: 101899, training_loss: 1.50403
Epoch: 1/10, step: 101919, training_loss: 1.70250
Epoch: 1/10, step: 101939, training_loss: 1.23209
Epoch: 1/10, step: 101959, training_loss: 1.61829
Epoch: 1/10, step: 101979, training_loss: 1.52180
Epoch: 1/10, step: 101999, training_loss: 1.18479
accuracy: 0.52, validation_loss: 1.4607841968536377, num_samples: 100
Epoch: 1/10, step: 102019, training_loss: 1.04411
Epoch: 1/10, step: 102039, training_loss: 1.13994
Epoch: 1/10, step: 102059, training_loss: 1.13252
Epoch: 1/10, step: 102079, training_loss: 0.84528
Epoch: 1/10, step: 102099, training_loss: 1.66640
Epoch: 1/10, step: 102119, training_loss: 1.72121
Epoch: 1/10, step: 102139, training_loss: 1.27382
Epoch: 1/10, step: 102159, training_loss: 0.78120
Epoch: 1/10, step: 102179, training_loss: 1.88426
Epoch: 1/10, step: 102199, training_loss: 1.28535
Epoch: 1/10, step: 102219, training_loss: 1.07839
Epoch: 1/10, step: 102239, training_loss: 1.11932
Epoch: 1/10, step: 102259, training_loss: 1.10243
Epoch: 1/10, step: 102279, training_loss: 1.11658
Epoch: 1/10, step: 102299, training_loss: 1.88255
Epoch: 1/10, step: 102319, training_loss: 1.46228
Epoch: 1/10, step: 102339, training_loss: 1.49181
Epoch: 1/10, step: 102359, training_loss: 1.62078
Epoch: 1/10, step: 102379, training_loss: 1.42049
Epoch: 1/10, step: 102399, training_loss: 1.73058
Epoch: 1/10, step: 102419, training_loss: 0.68417
Epoch: 1/10, step: 102439, training_loss: 1.87132
Epoch: 1/10, step: 102459, training_loss: 1.55453
Epoch: 1/10, step: 102479, training_loss: 1.29870
Epoch: 1/10, step: 102499, training_loss: 1.52558
Epoch: 1/10, step: 102519, training_loss: 1.28998
Epoch: 1/10, step: 102539, training_loss: 1.36404
Epoch: 1/10, step: 102559, training_loss: 2.39211
Epoch: 1/10, step: 102579, training_loss: 1.14953
Epoch: 1/10, step: 102599, training_loss: 0.86289
Epoch: 1/10, step: 102619, training_loss: 2.36262
Epoch: 1/10, step: 102639, training_loss: 0.95936
Epoch: 2/10, step: 19, training_loss: 0.60197
Epoch: 2/10, step: 39, training_loss: 1.39431
Epoch: 2/10, step: 59, training_loss: 1.22794
Epoch: 2/10, step: 79, training_loss: 1.75699
Epoch: 2/10, step: 99, training_loss: 1.82174
Epoch: 2/10, step: 119, training_loss: 1.17778
Epoch: 2/10, step: 139, training_loss: 1.33903
Epoch: 2/10, step: 159, training_loss: 1.48232
Epoch: 2/10, step: 179, training_loss: 1.05829
Epoch: 2/10, step: 199, training_loss: 1.81385
Epoch: 2/10, step: 219, training_loss: 0.84638
Epoch: 2/10, step: 239, training_loss: 1.21632
Epoch: 2/10, step: 259, training_loss: 1.12348
Epoch: 2/10, step: 279, training_loss: 1.70571
Epoch: 2/10, step: 299, training_loss: 1.63328
Epoch: 2/10, step: 319, training_loss: 1.73680
Epoch: 2/10, step: 339, training_loss: 0.90218
Epoch: 2/10, step: 359, training_loss: 1.44784
Epoch: 2/10, step: 379, training_loss: 0.98767
Epoch: 2/10, step: 399, training_loss: 2.01958
Epoch: 2/10, step: 419, training_loss: 1.77199
Epoch: 2/10, step: 439, training_loss: 1.43696
Epoch: 2/10, step: 459, training_loss: 2.04873
Epoch: 2/10, step: 479, training_loss: 1.16520
Epoch: 2/10, step: 499, training_loss: 1.78015
Epoch: 2/10, step: 519, training_loss: 0.96283
Epoch: 2/10, step: 539, training_loss: 1.77263
Epoch: 2/10, step: 559, training_loss: 0.92412
Epoch: 2/10, step: 579, training_loss: 1.64055
Epoch: 2/10, step: 599, training_loss: 1.56226
Epoch: 2/10, step: 619, training_loss: 1.32575
Epoch: 2/10, step: 639, training_loss: 1.40730
Epoch: 2/10, step: 659, training_loss: 1.42998
Epoch: 2/10, step: 679, training_loss: 1.57578
Epoch: 2/10, step: 699, training_loss: 0.91913
Epoch: 2/10, step: 719, training_loss: 1.38581
Epoch: 2/10, step: 739, training_loss: 1.50807
Epoch: 2/10, step: 759, training_loss: 1.03691
Epoch: 2/10, step: 779, training_loss: 1.47325
Epoch: 2/10, step: 799, training_loss: 1.92704
Epoch: 2/10, step: 819, training_loss: 1.36924
Epoch: 2/10, step: 839, training_loss: 1.33950
Epoch: 2/10, step: 859, training_loss: 1.93213
Epoch: 2/10, step: 879, training_loss: 1.58663
Epoch: 2/10, step: 899, training_loss: 1.56654
Epoch: 2/10, step: 919, training_loss: 2.14513
Epoch: 2/10, step: 939, training_loss: 1.22085
Epoch: 2/10, step: 959, training_loss: 1.41742
Epoch: 2/10, step: 979, training_loss: 1.71677
Epoch: 2/10, step: 999, training_loss: 1.53266
accuracy: 0.6, validation_loss: 1.4085251092910767, num_samples: 100
Epoch: 2/10, step: 1019, training_loss: 1.95212
Epoch: 2/10, step: 1039, training_loss: 1.09136
Epoch: 2/10, step: 1059, training_loss: 1.23109
Epoch: 2/10, step: 1079, training_loss: 1.74279
Epoch: 2/10, step: 1099, training_loss: 1.55148
Epoch: 2/10, step: 1119, training_loss: 1.20781
Epoch: 2/10, step: 1139, training_loss: 1.33186
Epoch: 2/10, step: 1159, training_loss: 1.36859
Epoch: 2/10, step: 1179, training_loss: 0.96718
Epoch: 2/10, step: 1199, training_loss: 1.25650
Epoch: 2/10, step: 1219, training_loss: 1.04221
Epoch: 2/10, step: 1239, training_loss: 1.72244
Epoch: 2/10, step: 1259, training_loss: 1.27731
Epoch: 2/10, step: 1279, training_loss: 1.39177
Epoch: 2/10, step: 1299, training_loss: 1.59646
Epoch: 2/10, step: 1319, training_loss: 1.33786
Epoch: 2/10, step: 1339, training_loss: 1.25685
Epoch: 2/10, step: 1359, training_loss: 0.82171
Epoch: 2/10, step: 1379, training_loss: 1.14233
Epoch: 2/10, step: 1399, training_loss: 1.67150
Epoch: 2/10, step: 1419, training_loss: 1.45413
Epoch: 2/10, step: 1439, training_loss: 1.77251
Epoch: 2/10, step: 1459, training_loss: 2.06607
Epoch: 2/10, step: 1479, training_loss: 1.57274
Epoch: 2/10, step: 1499, training_loss: 0.81159
Epoch: 2/10, step: 1519, training_loss: 1.52605
Epoch: 2/10, step: 1539, training_loss: 1.64809
Epoch: 2/10, step: 1559, training_loss: 1.15316
Epoch: 2/10, step: 1579, training_loss: 1.35216
Epoch: 2/10, step: 1599, training_loss: 1.00830
Epoch: 2/10, step: 1619, training_loss: 1.67297
Epoch: 2/10, step: 1639, training_loss: 1.74913
Epoch: 2/10, step: 1659, training_loss: 1.85261
Epoch: 2/10, step: 1679, training_loss: 1.93508
Epoch: 2/10, step: 1699, training_loss: 2.35567
Epoch: 2/10, step: 1719, training_loss: 1.69694
Epoch: 2/10, step: 1739, training_loss: 1.24182
Epoch: 2/10, step: 1759, training_loss: 1.46504
Epoch: 2/10, step: 1779, training_loss: 1.06085
Epoch: 2/10, step: 1799, training_loss: 1.04594
Epoch: 2/10, step: 1819, training_loss: 1.61126
Epoch: 2/10, step: 1839, training_loss: 1.74217
Epoch: 2/10, step: 1859, training_loss: 1.62998
Epoch: 2/10, step: 1879, training_loss: 1.95114
Epoch: 2/10, step: 1899, training_loss: 1.09210
Epoch: 2/10, step: 1919, training_loss: 1.64786
Epoch: 2/10, step: 1939, training_loss: 1.54720
Epoch: 2/10, step: 1959, training_loss: 1.75960
Epoch: 2/10, step: 1979, training_loss: 0.67972
Epoch: 2/10, step: 1999, training_loss: 1.44172
accuracy: 0.49, validation_loss: 1.53220796585083, num_samples: 100
Epoch: 2/10, step: 2019, training_loss: 0.76170
Epoch: 2/10, step: 2039, training_loss: 1.26888
Epoch: 2/10, step: 2059, training_loss: 1.30839
Epoch: 2/10, step: 2079, training_loss: 0.97406
Epoch: 2/10, step: 2099, training_loss: 1.04251
Epoch: 2/10, step: 2119, training_loss: 1.84252
Epoch: 2/10, step: 2139, training_loss: 1.20339
Epoch: 2/10, step: 2159, training_loss: 1.32410
Epoch: 2/10, step: 2179, training_loss: 1.44899
Epoch: 2/10, step: 2199, training_loss: 1.44214
Epoch: 2/10, step: 2219, training_loss: 1.60822
Epoch: 2/10, step: 2239, training_loss: 1.65417
Epoch: 2/10, step: 2259, training_loss: 1.76282
Epoch: 2/10, step: 2279, training_loss: 1.22700
Epoch: 2/10, step: 2299, training_loss: 1.18899
Epoch: 2/10, step: 2319, training_loss: 1.46314
Epoch: 2/10, step: 2339, training_loss: 1.94560
Epoch: 2/10, step: 2359, training_loss: 1.50832
Epoch: 2/10, step: 2379, training_loss: 1.90480
Epoch: 2/10, step: 2399, training_loss: 0.87841
Epoch: 2/10, step: 2419, training_loss: 1.09032
Epoch: 2/10, step: 2439, training_loss: 0.97755
Epoch: 2/10, step: 2459, training_loss: 1.45546
Epoch: 2/10, step: 2479, training_loss: 2.11810
Epoch: 2/10, step: 2499, training_loss: 1.60253
Epoch: 2/10, step: 2519, training_loss: 1.87877
Epoch: 2/10, step: 2539, training_loss: 1.10265
Epoch: 2/10, step: 2559, training_loss: 2.15056
Epoch: 2/10, step: 2579, training_loss: 0.95420
Epoch: 2/10, step: 2599, training_loss: 1.49997
Epoch: 2/10, step: 2619, training_loss: 2.00707
Epoch: 2/10, step: 2639, training_loss: 1.38757
Epoch: 2/10, step: 2659, training_loss: 1.87207
Epoch: 2/10, step: 2679, training_loss: 1.61499
Epoch: 2/10, step: 2699, training_loss: 1.25183
Epoch: 2/10, step: 2719, training_loss: 1.25983
Epoch: 2/10, step: 2739, training_loss: 1.71867
Epoch: 2/10, step: 2759, training_loss: 1.97988
Epoch: 2/10, step: 2779, training_loss: 1.34716
Epoch: 2/10, step: 2799, training_loss: 1.66882
Epoch: 2/10, step: 2819, training_loss: 2.30689
Epoch: 2/10, step: 2839, training_loss: 1.93857
Epoch: 2/10, step: 2859, training_loss: 1.29737
Epoch: 2/10, step: 2879, training_loss: 1.22678
Epoch: 2/10, step: 2899, training_loss: 1.48281
Epoch: 2/10, step: 2919, training_loss: 1.52145
Epoch: 2/10, step: 2939, training_loss: 2.04505
Epoch: 2/10, step: 2959, training_loss: 1.67471
Epoch: 2/10, step: 2979, training_loss: 1.48277
Epoch: 2/10, step: 2999, training_loss: 1.26684
accuracy: 0.54, validation_loss: 1.4330341815948486, num_samples: 100
Epoch: 2/10, step: 3019, training_loss: 2.29288
Epoch: 2/10, step: 3039, training_loss: 1.91545
Epoch: 2/10, step: 3059, training_loss: 1.46920
Epoch: 2/10, step: 3079, training_loss: 1.43081
Epoch: 2/10, step: 3099, training_loss: 1.59936
Epoch: 2/10, step: 3119, training_loss: 1.01761
Epoch: 2/10, step: 3139, training_loss: 1.35436
Epoch: 2/10, step: 3159, training_loss: 1.26384
Epoch: 2/10, step: 3179, training_loss: 1.22476
Epoch: 2/10, step: 3199, training_loss: 1.48388
Epoch: 2/10, step: 3219, training_loss: 1.87246
Epoch: 2/10, step: 3239, training_loss: 1.39157
Epoch: 2/10, step: 3259, training_loss: 2.24562
Epoch: 2/10, step: 3279, training_loss: 1.64053
Epoch: 2/10, step: 3299, training_loss: 0.99992
Epoch: 2/10, step: 3319, training_loss: 1.74477
Epoch: 2/10, step: 3339, training_loss: 1.16585
Epoch: 2/10, step: 3359, training_loss: 0.87046
Epoch: 2/10, step: 3379, training_loss: 1.54914
Epoch: 2/10, step: 3399, training_loss: 1.21867
Epoch: 2/10, step: 3419, training_loss: 1.17332
Epoch: 2/10, step: 3439, training_loss: 1.43176
Epoch: 2/10, step: 3459, training_loss: 1.54228
Epoch: 2/10, step: 3479, training_loss: 1.56159
Epoch: 2/10, step: 3499, training_loss: 1.69252
Epoch: 2/10, step: 3519, training_loss: 1.28035
Epoch: 2/10, step: 3539, training_loss: 1.07337
Epoch: 2/10, step: 3559, training_loss: 1.57867
Epoch: 2/10, step: 3579, training_loss: 1.87612
Epoch: 2/10, step: 3599, training_loss: 1.62337
Epoch: 2/10, step: 3619, training_loss: 1.55796
Epoch: 2/10, step: 3639, training_loss: 1.25923
Epoch: 2/10, step: 3659, training_loss: 1.75998
Epoch: 2/10, step: 3679, training_loss: 1.57882
Epoch: 2/10, step: 3699, training_loss: 0.94761
Epoch: 2/10, step: 3719, training_loss: 2.03025
Epoch: 2/10, step: 3739, training_loss: 1.68232
Epoch: 2/10, step: 3759, training_loss: 1.65203
Epoch: 2/10, step: 3779, training_loss: 1.85024
Epoch: 2/10, step: 3799, training_loss: 1.77649
Epoch: 2/10, step: 3819, training_loss: 1.13394
Epoch: 2/10, step: 3839, training_loss: 1.86494
Epoch: 2/10, step: 3859, training_loss: 1.49209
Epoch: 2/10, step: 3879, training_loss: 1.39001
Epoch: 2/10, step: 3899, training_loss: 1.45134
Epoch: 2/10, step: 3919, training_loss: 1.17734
Epoch: 2/10, step: 3939, training_loss: 1.24646
Epoch: 2/10, step: 3959, training_loss: 1.43661
Epoch: 2/10, step: 3979, training_loss: 1.28636
Epoch: 2/10, step: 3999, training_loss: 0.76068
accuracy: 0.46, validation_loss: 1.4647130966186523, num_samples: 100
Epoch: 2/10, step: 4019, training_loss: 0.78753
Epoch: 2/10, step: 4039, training_loss: 1.12669
Epoch: 2/10, step: 4059, training_loss: 1.28584
Epoch: 2/10, step: 4079, training_loss: 1.81925
Epoch: 2/10, step: 4099, training_loss: 1.34171
Epoch: 2/10, step: 4119, training_loss: 1.02022
Epoch: 2/10, step: 4139, training_loss: 1.34757
Epoch: 2/10, step: 4159, training_loss: 1.06645
Epoch: 2/10, step: 4179, training_loss: 1.65557
Epoch: 2/10, step: 4199, training_loss: 1.53932
Epoch: 2/10, step: 4219, training_loss: 1.12324
Epoch: 2/10, step: 4239, training_loss: 1.18819
Epoch: 2/10, step: 4259, training_loss: 1.36558
Epoch: 2/10, step: 4279, training_loss: 1.27086
Epoch: 2/10, step: 4299, training_loss: 1.93276
Epoch: 2/10, step: 4319, training_loss: 1.27143
Epoch: 2/10, step: 4339, training_loss: 1.26020
Epoch: 2/10, step: 4359, training_loss: 1.49117
Epoch: 2/10, step: 4379, training_loss: 1.21334
Epoch: 2/10, step: 4399, training_loss: 1.16278
Epoch: 2/10, step: 4419, training_loss: 1.36804
Epoch: 2/10, step: 4439, training_loss: 1.86653
Epoch: 2/10, step: 4459, training_loss: 1.31917
Epoch: 2/10, step: 4479, training_loss: 1.12869
Epoch: 2/10, step: 4499, training_loss: 1.14615
Epoch: 2/10, step: 4519, training_loss: 1.46219
Epoch: 2/10, step: 4539, training_loss: 2.08796
Epoch: 2/10, step: 4559, training_loss: 1.38979
Epoch: 2/10, step: 4579, training_loss: 1.43531
Epoch: 2/10, step: 4599, training_loss: 1.08401
Epoch: 2/10, step: 4619, training_loss: 1.36340
Epoch: 2/10, step: 4639, training_loss: 1.53152
Epoch: 2/10, step: 4659, training_loss: 1.29586
Epoch: 2/10, step: 4679, training_loss: 0.88624
Epoch: 2/10, step: 4699, training_loss: 1.25385
Epoch: 2/10, step: 4719, training_loss: 1.39615
Epoch: 2/10, step: 4739, training_loss: 1.49641
Epoch: 2/10, step: 4759, training_loss: 1.06965
Epoch: 2/10, step: 4779, training_loss: 1.83323
Epoch: 2/10, step: 4799, training_loss: 1.25102
Epoch: 2/10, step: 4819, training_loss: 1.06871
Epoch: 2/10, step: 4839, training_loss: 0.87034
Epoch: 2/10, step: 4859, training_loss: 1.26135
Epoch: 2/10, step: 4879, training_loss: 1.32799
Epoch: 2/10, step: 4899, training_loss: 1.93414
Epoch: 2/10, step: 4919, training_loss: 1.92288
Epoch: 2/10, step: 4939, training_loss: 1.61608
Epoch: 2/10, step: 4959, training_loss: 1.54202
Epoch: 2/10, step: 4979, training_loss: 0.72900
Epoch: 2/10, step: 4999, training_loss: 2.27071
accuracy: 0.4, validation_loss: 1.7803802490234375, num_samples: 100
Epoch: 2/10, step: 5019, training_loss: 1.29831
Epoch: 2/10, step: 5039, training_loss: 1.52783
Epoch: 2/10, step: 5059, training_loss: 1.73339
Epoch: 2/10, step: 5079, training_loss: 1.81250
Epoch: 2/10, step: 5099, training_loss: 1.46068
Epoch: 2/10, step: 5119, training_loss: 1.30706
Epoch: 2/10, step: 5139, training_loss: 2.17453
Epoch: 2/10, step: 5159, training_loss: 1.12327
Epoch: 2/10, step: 5179, training_loss: 0.82613
Epoch: 2/10, step: 5199, training_loss: 0.86143
Epoch: 2/10, step: 5219, training_loss: 1.50326
Epoch: 2/10, step: 5239, training_loss: 1.46541
Epoch: 2/10, step: 5259, training_loss: 1.54708
Epoch: 2/10, step: 5279, training_loss: 1.48031
Epoch: 2/10, step: 5299, training_loss: 1.32342
Epoch: 2/10, step: 5319, training_loss: 1.90593
Epoch: 2/10, step: 5339, training_loss: 1.61189
Epoch: 2/10, step: 5359, training_loss: 1.63179
Epoch: 2/10, step: 5379, training_loss: 1.46017
Epoch: 2/10, step: 5399, training_loss: 1.15518
Epoch: 2/10, step: 5419, training_loss: 1.45453
Epoch: 2/10, step: 5439, training_loss: 1.51988
Epoch: 2/10, step: 5459, training_loss: 1.43308
Epoch: 2/10, step: 5479, training_loss: 1.59886
Epoch: 2/10, step: 5499, training_loss: 1.62381
Epoch: 2/10, step: 5519, training_loss: 1.44901
Epoch: 2/10, step: 5539, training_loss: 2.14473
Epoch: 2/10, step: 5559, training_loss: 1.53386
Epoch: 2/10, step: 5579, training_loss: 1.37729
Epoch: 2/10, step: 5599, training_loss: 0.89549
Epoch: 2/10, step: 5619, training_loss: 1.41146
Epoch: 2/10, step: 5639, training_loss: 0.72174
Epoch: 2/10, step: 5659, training_loss: 1.45521
Epoch: 2/10, step: 5679, training_loss: 1.66155
Epoch: 2/10, step: 5699, training_loss: 1.10257
Epoch: 2/10, step: 5719, training_loss: 2.21156
Epoch: 2/10, step: 5739, training_loss: 1.32895
Epoch: 2/10, step: 5759, training_loss: 1.42371
Epoch: 2/10, step: 5779, training_loss: 1.65483
Epoch: 2/10, step: 5799, training_loss: 1.11115
Epoch: 2/10, step: 5819, training_loss: 1.55631
Epoch: 2/10, step: 5839, training_loss: 2.08539
Epoch: 2/10, step: 5859, training_loss: 1.98707
Epoch: 2/10, step: 5879, training_loss: 1.05633
Epoch: 2/10, step: 5899, training_loss: 1.52351
Epoch: 2/10, step: 5919, training_loss: 1.47678
Epoch: 2/10, step: 5939, training_loss: 1.46013
Epoch: 2/10, step: 5959, training_loss: 1.37602
Epoch: 2/10, step: 5979, training_loss: 1.95920
Epoch: 2/10, step: 5999, training_loss: 1.35668
accuracy: 0.59, validation_loss: 1.3597644567489624, num_samples: 100
Epoch: 2/10, step: 6019, training_loss: 1.99636
Epoch: 2/10, step: 6039, training_loss: 1.28325
Epoch: 2/10, step: 6059, training_loss: 1.41142
Epoch: 2/10, step: 6079, training_loss: 1.00763
Epoch: 2/10, step: 6099, training_loss: 1.11336
Epoch: 2/10, step: 6119, training_loss: 1.40200
Epoch: 2/10, step: 6139, training_loss: 1.30366
Epoch: 2/10, step: 6159, training_loss: 1.46398
Epoch: 2/10, step: 6179, training_loss: 1.47313
Epoch: 2/10, step: 6199, training_loss: 1.70771
Epoch: 2/10, step: 6219, training_loss: 1.24477
Epoch: 2/10, step: 6239, training_loss: 0.98021
Epoch: 2/10, step: 6259, training_loss: 1.52344
Epoch: 2/10, step: 6279, training_loss: 1.09539
Epoch: 2/10, step: 6299, training_loss: 1.28768
Epoch: 2/10, step: 6319, training_loss: 1.67470
Epoch: 2/10, step: 6339, training_loss: 0.95434
Epoch: 2/10, step: 6359, training_loss: 1.70480
Epoch: 2/10, step: 6379, training_loss: 2.00516
Epoch: 2/10, step: 6399, training_loss: 1.53765
Epoch: 2/10, step: 6419, training_loss: 1.14286
Epoch: 2/10, step: 6439, training_loss: 1.43240
Epoch: 2/10, step: 6459, training_loss: 2.14384
Epoch: 2/10, step: 6479, training_loss: 1.27493
Epoch: 2/10, step: 6499, training_loss: 1.18605
Epoch: 2/10, step: 6519, training_loss: 1.82853
Epoch: 2/10, step: 6539, training_loss: 1.07656
Epoch: 2/10, step: 6559, training_loss: 1.49821
Epoch: 2/10, step: 6579, training_loss: 0.91587
Epoch: 2/10, step: 6599, training_loss: 1.42580
Epoch: 2/10, step: 6619, training_loss: 1.67122
Epoch: 2/10, step: 6639, training_loss: 2.04542
Epoch: 2/10, step: 6659, training_loss: 0.77655
Epoch: 2/10, step: 6679, training_loss: 0.90354
Epoch: 2/10, step: 6699, training_loss: 1.17044
Epoch: 2/10, step: 6719, training_loss: 1.07517
Epoch: 2/10, step: 6739, training_loss: 1.47465
Epoch: 2/10, step: 6759, training_loss: 1.07858
Epoch: 2/10, step: 6779, training_loss: 1.43832
Epoch: 2/10, step: 6799, training_loss: 1.29154
Epoch: 2/10, step: 6819, training_loss: 1.48849
Epoch: 2/10, step: 6839, training_loss: 1.00869
Epoch: 2/10, step: 6859, training_loss: 1.12454
Epoch: 2/10, step: 6879, training_loss: 1.17842
Epoch: 2/10, step: 6899, training_loss: 1.10785
Epoch: 2/10, step: 6919, training_loss: 1.83546
Epoch: 2/10, step: 6939, training_loss: 1.39465
Epoch: 2/10, step: 6959, training_loss: 1.59707
Epoch: 2/10, step: 6979, training_loss: 1.09824
Epoch: 2/10, step: 6999, training_loss: 0.83553
accuracy: 0.51, validation_loss: 1.540158748626709, num_samples: 100
Epoch: 2/10, step: 7019, training_loss: 1.37780
Epoch: 2/10, step: 7039, training_loss: 1.66144
Epoch: 2/10, step: 7059, training_loss: 1.49555
Epoch: 2/10, step: 7079, training_loss: 1.81476
Epoch: 2/10, step: 7099, training_loss: 1.13995
Epoch: 2/10, step: 7119, training_loss: 1.11837
Epoch: 2/10, step: 7139, training_loss: 1.48449
Epoch: 2/10, step: 7159, training_loss: 0.91799
Epoch: 2/10, step: 7179, training_loss: 1.20480
Epoch: 2/10, step: 7199, training_loss: 1.52497
Epoch: 2/10, step: 7219, training_loss: 1.27316
Epoch: 2/10, step: 7239, training_loss: 2.17720
Epoch: 2/10, step: 7259, training_loss: 2.21837
Epoch: 2/10, step: 7279, training_loss: 1.74087
Epoch: 2/10, step: 7299, training_loss: 2.18762
Epoch: 2/10, step: 7319, training_loss: 1.51718
Epoch: 2/10, step: 7339, training_loss: 1.59046
Epoch: 2/10, step: 7359, training_loss: 1.56573
Epoch: 2/10, step: 7379, training_loss: 1.43908
Epoch: 2/10, step: 7399, training_loss: 1.12502
Epoch: 2/10, step: 7419, training_loss: 0.89266
Epoch: 2/10, step: 7439, training_loss: 1.97052
Epoch: 2/10, step: 7459, training_loss: 1.39038
Epoch: 2/10, step: 7479, training_loss: 1.20015
Epoch: 2/10, step: 7499, training_loss: 1.17222
Epoch: 2/10, step: 7519, training_loss: 1.89000
Epoch: 2/10, step: 7539, training_loss: 1.18405
Epoch: 2/10, step: 7559, training_loss: 1.39085
Epoch: 2/10, step: 7579, training_loss: 1.01442
Epoch: 2/10, step: 7599, training_loss: 1.73505
Epoch: 2/10, step: 7619, training_loss: 1.84519
Epoch: 2/10, step: 7639, training_loss: 1.40780
Epoch: 2/10, step: 7659, training_loss: 0.57612
Epoch: 2/10, step: 7679, training_loss: 1.21051
Epoch: 2/10, step: 7699, training_loss: 1.81728
Epoch: 2/10, step: 7719, training_loss: 1.51552
Epoch: 2/10, step: 7739, training_loss: 1.70448
Epoch: 2/10, step: 7759, training_loss: 1.43726
Epoch: 2/10, step: 7779, training_loss: 1.67906
Epoch: 2/10, step: 7799, training_loss: 1.65991
Epoch: 2/10, step: 7819, training_loss: 1.26566
Epoch: 2/10, step: 7839, training_loss: 1.89380
Epoch: 2/10, step: 7859, training_loss: 1.66167
Epoch: 2/10, step: 7879, training_loss: 1.15707
Epoch: 2/10, step: 7899, training_loss: 1.21713
Epoch: 2/10, step: 7919, training_loss: 1.50500
Epoch: 2/10, step: 7939, training_loss: 1.49062
Epoch: 2/10, step: 7959, training_loss: 1.94895
Epoch: 2/10, step: 7979, training_loss: 1.10268
Epoch: 2/10, step: 7999, training_loss: 1.79706
accuracy: 0.52, validation_loss: 1.45420241355896, num_samples: 100
Epoch: 2/10, step: 8019, training_loss: 1.32354
Epoch: 2/10, step: 8039, training_loss: 1.23700
Epoch: 2/10, step: 8059, training_loss: 1.03368
Epoch: 2/10, step: 8079, training_loss: 1.12561
Epoch: 2/10, step: 8099, training_loss: 2.09459
Epoch: 2/10, step: 8119, training_loss: 1.64180
Epoch: 2/10, step: 8139, training_loss: 1.98354
Epoch: 2/10, step: 8159, training_loss: 1.84030
Epoch: 2/10, step: 8179, training_loss: 1.95960
Epoch: 2/10, step: 8199, training_loss: 1.14449
Epoch: 2/10, step: 8219, training_loss: 1.46459
Epoch: 2/10, step: 8239, training_loss: 2.14204
Epoch: 2/10, step: 8259, training_loss: 2.10370
Epoch: 2/10, step: 8279, training_loss: 1.01377
Epoch: 2/10, step: 8299, training_loss: 1.82929
Epoch: 2/10, step: 8319, training_loss: 1.55200
Epoch: 2/10, step: 8339, training_loss: 1.57710
Epoch: 2/10, step: 8359, training_loss: 2.26722
Epoch: 2/10, step: 8379, training_loss: 1.30889
Epoch: 2/10, step: 8399, training_loss: 1.08958
Epoch: 2/10, step: 8419, training_loss: 1.42002
Epoch: 2/10, step: 8439, training_loss: 2.13603
Epoch: 2/10, step: 8459, training_loss: 0.82832
Epoch: 2/10, step: 8479, training_loss: 1.48556
Epoch: 2/10, step: 8499, training_loss: 1.63354
Epoch: 2/10, step: 8519, training_loss: 1.44383
Epoch: 2/10, step: 8539, training_loss: 1.29964
Epoch: 2/10, step: 8559, training_loss: 1.53369
Epoch: 2/10, step: 8579, training_loss: 1.11561
Epoch: 2/10, step: 8599, training_loss: 1.26072
Epoch: 2/10, step: 8619, training_loss: 1.33769
Epoch: 2/10, step: 8639, training_loss: 1.38670
Epoch: 2/10, step: 8659, training_loss: 0.89092
Epoch: 2/10, step: 8679, training_loss: 1.09627
Epoch: 2/10, step: 8699, training_loss: 1.19698
Epoch: 2/10, step: 8719, training_loss: 1.64625
Epoch: 2/10, step: 8739, training_loss: 1.53279
Epoch: 2/10, step: 8759, training_loss: 1.38567
Epoch: 2/10, step: 8779, training_loss: 1.38992
Epoch: 2/10, step: 8799, training_loss: 1.59799
Epoch: 2/10, step: 8819, training_loss: 1.25422
Epoch: 2/10, step: 8839, training_loss: 1.60362
Epoch: 2/10, step: 8859, training_loss: 1.27256
Epoch: 2/10, step: 8879, training_loss: 1.62680
Epoch: 2/10, step: 8899, training_loss: 1.55574
Epoch: 2/10, step: 8919, training_loss: 1.30214
Epoch: 2/10, step: 8939, training_loss: 1.74467
Epoch: 2/10, step: 8959, training_loss: 1.69491
Epoch: 2/10, step: 8979, training_loss: 1.38043
Epoch: 2/10, step: 8999, training_loss: 1.43865
accuracy: 0.54, validation_loss: 1.4538227319717407, num_samples: 100
Epoch: 2/10, step: 9019, training_loss: 1.28951
Epoch: 2/10, step: 9039, training_loss: 1.09241
Epoch: 2/10, step: 9059, training_loss: 1.55413
Epoch: 2/10, step: 9079, training_loss: 1.29221
Epoch: 2/10, step: 9099, training_loss: 1.66736
Epoch: 2/10, step: 9119, training_loss: 1.77450
Epoch: 2/10, step: 9139, training_loss: 1.29790
Epoch: 2/10, step: 9159, training_loss: 0.81748
Epoch: 2/10, step: 9179, training_loss: 1.32112
Epoch: 2/10, step: 9199, training_loss: 1.21671
Epoch: 2/10, step: 9219, training_loss: 1.21324
Epoch: 2/10, step: 9239, training_loss: 1.68134
Epoch: 2/10, step: 9259, training_loss: 1.09818
Epoch: 2/10, step: 9279, training_loss: 1.16419
Epoch: 2/10, step: 9299, training_loss: 1.60422
Epoch: 2/10, step: 9319, training_loss: 1.70898
Epoch: 2/10, step: 9339, training_loss: 1.57650
Epoch: 2/10, step: 9359, training_loss: 1.47622
Epoch: 2/10, step: 9379, training_loss: 2.08975
Epoch: 2/10, step: 9399, training_loss: 1.00625
Epoch: 2/10, step: 9419, training_loss: 1.82113
Epoch: 2/10, step: 9439, training_loss: 1.39003
Epoch: 2/10, step: 9459, training_loss: 1.28167
Epoch: 2/10, step: 9479, training_loss: 1.92750
Epoch: 2/10, step: 9499, training_loss: 1.78660
Epoch: 2/10, step: 9519, training_loss: 1.60698
Epoch: 2/10, step: 9539, training_loss: 1.62635
Epoch: 2/10, step: 9559, training_loss: 1.63618
Epoch: 2/10, step: 9579, training_loss: 1.68514
Epoch: 2/10, step: 9599, training_loss: 1.63678
Epoch: 2/10, step: 9619, training_loss: 1.30762
Epoch: 2/10, step: 9639, training_loss: 1.25607
Epoch: 2/10, step: 9659, training_loss: 1.22288
Epoch: 2/10, step: 9679, training_loss: 0.83449
Epoch: 2/10, step: 9699, training_loss: 1.13046
Epoch: 2/10, step: 9719, training_loss: 1.22637
Epoch: 2/10, step: 9739, training_loss: 1.51225
Epoch: 2/10, step: 9759, training_loss: 1.52340
Epoch: 2/10, step: 9779, training_loss: 1.37911
Epoch: 2/10, step: 9799, training_loss: 1.37979
Epoch: 2/10, step: 9819, training_loss: 1.74651
Epoch: 2/10, step: 9839, training_loss: 1.37611
Epoch: 2/10, step: 9859, training_loss: 1.78169
Epoch: 2/10, step: 9879, training_loss: 1.26891
Epoch: 2/10, step: 9899, training_loss: 1.23988
Epoch: 2/10, step: 9919, training_loss: 1.33192
Epoch: 2/10, step: 9939, training_loss: 1.50531
Epoch: 2/10, step: 9959, training_loss: 1.10573
Epoch: 2/10, step: 9979, training_loss: 0.92611
Epoch: 2/10, step: 9999, training_loss: 1.14412
accuracy: 0.53, validation_loss: 1.441820502281189, num_samples: 100
Epoch: 2/10, step: 10019, training_loss: 0.62963
Epoch: 2/10, step: 10039, training_loss: 1.33871
Epoch: 2/10, step: 10059, training_loss: 1.04335
Epoch: 2/10, step: 10079, training_loss: 1.25588
Epoch: 2/10, step: 10099, training_loss: 1.56095
Epoch: 2/10, step: 10119, training_loss: 1.24555
Epoch: 2/10, step: 10139, training_loss: 1.33145
Epoch: 2/10, step: 10159, training_loss: 1.47532
Epoch: 2/10, step: 10179, training_loss: 1.73570
Epoch: 2/10, step: 10199, training_loss: 1.57830
Epoch: 2/10, step: 10219, training_loss: 1.31458
Epoch: 2/10, step: 10239, training_loss: 1.11665
Epoch: 2/10, step: 10259, training_loss: 1.44865
Epoch: 2/10, step: 10279, training_loss: 1.10446
Epoch: 2/10, step: 10299, training_loss: 1.32469
Epoch: 2/10, step: 10319, training_loss: 1.46746
Epoch: 2/10, step: 10339, training_loss: 1.29028
Epoch: 2/10, step: 10359, training_loss: 1.11961
Epoch: 2/10, step: 10379, training_loss: 1.37095
Epoch: 2/10, step: 10399, training_loss: 1.28917
Epoch: 2/10, step: 10419, training_loss: 1.03639
Epoch: 2/10, step: 10439, training_loss: 1.33072
Epoch: 2/10, step: 10459, training_loss: 1.92500
Epoch: 2/10, step: 10479, training_loss: 1.24942
Epoch: 2/10, step: 10499, training_loss: 1.46827
Epoch: 2/10, step: 10519, training_loss: 1.64789
Epoch: 2/10, step: 10539, training_loss: 1.25204
Epoch: 2/10, step: 10559, training_loss: 1.22094
Epoch: 2/10, step: 10579, training_loss: 1.25707
Epoch: 2/10, step: 10599, training_loss: 1.03013
Epoch: 2/10, step: 10619, training_loss: 1.28987
Epoch: 2/10, step: 10639, training_loss: 2.03993
Epoch: 2/10, step: 10659, training_loss: 1.34254
Epoch: 2/10, step: 10679, training_loss: 1.51803
Epoch: 2/10, step: 10699, training_loss: 1.56366
Epoch: 2/10, step: 10719, training_loss: 1.96380
Epoch: 2/10, step: 10739, training_loss: 1.50879
Epoch: 2/10, step: 10759, training_loss: 2.19287
Epoch: 2/10, step: 10779, training_loss: 1.52072
Epoch: 2/10, step: 10799, training_loss: 1.80460
Epoch: 2/10, step: 10819, training_loss: 1.81502
Epoch: 2/10, step: 10839, training_loss: 1.52511
Epoch: 2/10, step: 10859, training_loss: 1.11694
Epoch: 2/10, step: 10879, training_loss: 1.47097
Epoch: 2/10, step: 10899, training_loss: 1.61960
Epoch: 2/10, step: 10919, training_loss: 1.61987
Epoch: 2/10, step: 10939, training_loss: 2.07964
Epoch: 2/10, step: 10959, training_loss: 1.52452
Epoch: 2/10, step: 10979, training_loss: 1.29090
Epoch: 2/10, step: 10999, training_loss: 1.44698
accuracy: 0.49, validation_loss: 1.4984890222549438, num_samples: 100
Epoch: 2/10, step: 11019, training_loss: 0.88032
Epoch: 2/10, step: 11039, training_loss: 1.50174
Epoch: 2/10, step: 11059, training_loss: 0.99323
Epoch: 2/10, step: 11079, training_loss: 1.81965
Epoch: 2/10, step: 11099, training_loss: 1.56460
Epoch: 2/10, step: 11119, training_loss: 1.34221
Epoch: 2/10, step: 11139, training_loss: 1.56593
Epoch: 2/10, step: 11159, training_loss: 1.33177
Epoch: 2/10, step: 11179, training_loss: 1.23660
Epoch: 2/10, step: 11199, training_loss: 1.34044
Epoch: 2/10, step: 11219, training_loss: 1.34907
Epoch: 2/10, step: 11239, training_loss: 1.72938
Epoch: 2/10, step: 11259, training_loss: 1.24023
Epoch: 2/10, step: 11279, training_loss: 1.37415
Epoch: 2/10, step: 11299, training_loss: 1.66027
Epoch: 2/10, step: 11319, training_loss: 1.73832
Epoch: 2/10, step: 11339, training_loss: 1.85094
Epoch: 2/10, step: 11359, training_loss: 1.05178
Epoch: 2/10, step: 11379, training_loss: 2.07037
Epoch: 2/10, step: 11399, training_loss: 0.73816
Epoch: 2/10, step: 11419, training_loss: 1.07577
Epoch: 2/10, step: 11439, training_loss: 1.63170
Epoch: 2/10, step: 11459, training_loss: 1.46029
Epoch: 2/10, step: 11479, training_loss: 1.60878
Epoch: 2/10, step: 11499, training_loss: 1.67002
Epoch: 2/10, step: 11519, training_loss: 1.29662
Epoch: 2/10, step: 11539, training_loss: 1.54023
Epoch: 2/10, step: 11559, training_loss: 1.14515
Epoch: 2/10, step: 11579, training_loss: 1.67811
Epoch: 2/10, step: 11599, training_loss: 2.04284
Epoch: 2/10, step: 11619, training_loss: 1.52922
Epoch: 2/10, step: 11639, training_loss: 2.65595
Epoch: 2/10, step: 11659, training_loss: 0.89217
Epoch: 2/10, step: 11679, training_loss: 1.06899
Epoch: 2/10, step: 11699, training_loss: 1.52535
Epoch: 2/10, step: 11719, training_loss: 1.46163
Epoch: 2/10, step: 11739, training_loss: 1.48030
Epoch: 2/10, step: 11759, training_loss: 1.28550
Epoch: 2/10, step: 11779, training_loss: 1.56644
Epoch: 2/10, step: 11799, training_loss: 1.48519
Epoch: 2/10, step: 11819, training_loss: 0.86980
Epoch: 2/10, step: 11839, training_loss: 1.28188
Epoch: 2/10, step: 11859, training_loss: 1.45375
Epoch: 2/10, step: 11879, training_loss: 2.12014
Epoch: 2/10, step: 11899, training_loss: 0.65824
Epoch: 2/10, step: 11919, training_loss: 0.97225
Epoch: 2/10, step: 11939, training_loss: 1.24406
Epoch: 2/10, step: 11959, training_loss: 1.41217
Epoch: 2/10, step: 11979, training_loss: 1.36939
Epoch: 2/10, step: 11999, training_loss: 0.73408
accuracy: 0.5, validation_loss: 1.4806627035140991, num_samples: 100
Epoch: 2/10, step: 12019, training_loss: 1.79606
Epoch: 2/10, step: 12039, training_loss: 1.12639
Epoch: 2/10, step: 12059, training_loss: 0.94037
Epoch: 2/10, step: 12079, training_loss: 1.24770
Epoch: 2/10, step: 12099, training_loss: 2.09241
Epoch: 2/10, step: 12119, training_loss: 1.52606
Epoch: 2/10, step: 12139, training_loss: 1.70988
Epoch: 2/10, step: 12159, training_loss: 1.33615
Epoch: 2/10, step: 12179, training_loss: 1.16784
Epoch: 2/10, step: 12199, training_loss: 1.80351
Epoch: 2/10, step: 12219, training_loss: 0.71265
Epoch: 2/10, step: 12239, training_loss: 1.38861
Epoch: 2/10, step: 12259, training_loss: 1.44394
Epoch: 2/10, step: 12279, training_loss: 1.27147
Epoch: 2/10, step: 12299, training_loss: 1.42662
Epoch: 2/10, step: 12319, training_loss: 1.72189
Epoch: 2/10, step: 12339, training_loss: 2.30668
Epoch: 2/10, step: 12359, training_loss: 1.21014
Epoch: 2/10, step: 12379, training_loss: 1.57258
Epoch: 2/10, step: 12399, training_loss: 1.68549
Epoch: 2/10, step: 12419, training_loss: 1.56501
Epoch: 2/10, step: 12439, training_loss: 1.74699
Epoch: 2/10, step: 12459, training_loss: 1.77390
Epoch: 2/10, step: 12479, training_loss: 1.68907
Epoch: 2/10, step: 12499, training_loss: 1.60778
Epoch: 2/10, step: 12519, training_loss: 0.96708
Epoch: 2/10, step: 12539, training_loss: 1.53818
Epoch: 2/10, step: 12559, training_loss: 1.46085
Epoch: 2/10, step: 12579, training_loss: 1.49214
Epoch: 2/10, step: 12599, training_loss: 1.33123
Epoch: 2/10, step: 12619, training_loss: 1.51869
Epoch: 2/10, step: 12639, training_loss: 1.23244
Epoch: 2/10, step: 12659, training_loss: 1.91411
Epoch: 2/10, step: 12679, training_loss: 1.25487
Epoch: 2/10, step: 12699, training_loss: 1.61303
Epoch: 2/10, step: 12719, training_loss: 0.74529
Epoch: 2/10, step: 12739, training_loss: 1.63476
Epoch: 2/10, step: 12759, training_loss: 1.94413
Epoch: 2/10, step: 12779, training_loss: 1.67238
Epoch: 2/10, step: 12799, training_loss: 0.87606
Epoch: 2/10, step: 12819, training_loss: 1.63100
Epoch: 2/10, step: 12839, training_loss: 1.69794
Epoch: 2/10, step: 12859, training_loss: 1.93409
Epoch: 2/10, step: 12879, training_loss: 1.41996
Epoch: 2/10, step: 12899, training_loss: 1.67954
Epoch: 2/10, step: 12919, training_loss: 1.60757
Epoch: 2/10, step: 12939, training_loss: 2.11176
Epoch: 2/10, step: 12959, training_loss: 1.56929
Epoch: 2/10, step: 12979, training_loss: 1.78545
Epoch: 2/10, step: 12999, training_loss: 1.47803
accuracy: 0.38, validation_loss: 1.8179526329040527, num_samples: 100
Epoch: 2/10, step: 13019, training_loss: 1.56413
Epoch: 2/10, step: 13039, training_loss: 1.38307
Epoch: 2/10, step: 13059, training_loss: 1.65718
Epoch: 2/10, step: 13079, training_loss: 1.43312
Epoch: 2/10, step: 13099, training_loss: 1.82581
Epoch: 2/10, step: 13119, training_loss: 1.37402
Epoch: 2/10, step: 13139, training_loss: 2.20236
Epoch: 2/10, step: 13159, training_loss: 1.93242
Epoch: 2/10, step: 13179, training_loss: 1.25731
Epoch: 2/10, step: 13199, training_loss: 1.01040
Epoch: 2/10, step: 13219, training_loss: 1.62234
Epoch: 2/10, step: 13239, training_loss: 0.78176
Epoch: 2/10, step: 13259, training_loss: 1.32277
Epoch: 2/10, step: 13279, training_loss: 1.58522
Epoch: 2/10, step: 13299, training_loss: 1.85463
Epoch: 2/10, step: 13319, training_loss: 1.56252
Epoch: 2/10, step: 13339, training_loss: 1.29050
Epoch: 2/10, step: 13359, training_loss: 1.35491
Epoch: 2/10, step: 13379, training_loss: 0.91708
Epoch: 2/10, step: 13399, training_loss: 1.74980
Epoch: 2/10, step: 13419, training_loss: 1.26664
Epoch: 2/10, step: 13439, training_loss: 1.53751
Epoch: 2/10, step: 13459, training_loss: 0.68025
Epoch: 2/10, step: 13479, training_loss: 1.83169
Epoch: 2/10, step: 13499, training_loss: 1.68190
Epoch: 2/10, step: 13519, training_loss: 1.50156
Epoch: 2/10, step: 13539, training_loss: 1.04569
Epoch: 2/10, step: 13559, training_loss: 1.95181
Epoch: 2/10, step: 13579, training_loss: 1.06687
Epoch: 2/10, step: 13599, training_loss: 1.49313
Epoch: 2/10, step: 13619, training_loss: 1.10621
Epoch: 2/10, step: 13639, training_loss: 1.31669
Epoch: 2/10, step: 13659, training_loss: 1.38835
Epoch: 2/10, step: 13679, training_loss: 1.72815
Epoch: 2/10, step: 13699, training_loss: 1.37673
Epoch: 2/10, step: 13719, training_loss: 1.03471
Epoch: 2/10, step: 13739, training_loss: 1.04582
Epoch: 2/10, step: 13759, training_loss: 1.35274
Epoch: 2/10, step: 13779, training_loss: 1.72173
Epoch: 2/10, step: 13799, training_loss: 1.84905
Epoch: 2/10, step: 13819, training_loss: 1.96418
Epoch: 2/10, step: 13839, training_loss: 1.35197
Epoch: 2/10, step: 13859, training_loss: 0.93146
Epoch: 2/10, step: 13879, training_loss: 1.42090
Epoch: 2/10, step: 13899, training_loss: 1.30833
Epoch: 2/10, step: 13919, training_loss: 1.59435
Epoch: 2/10, step: 13939, training_loss: 1.86924
Epoch: 2/10, step: 13959, training_loss: 1.11657
Epoch: 2/10, step: 13979, training_loss: 1.62649
Epoch: 2/10, step: 13999, training_loss: 1.45906
accuracy: 0.42, validation_loss: 1.6606074571609497, num_samples: 100
Epoch: 2/10, step: 14019, training_loss: 2.22644
Epoch: 2/10, step: 14039, training_loss: 2.00451
Epoch: 2/10, step: 14059, training_loss: 1.32591
Epoch: 2/10, step: 14079, training_loss: 2.06353
Epoch: 2/10, step: 14099, training_loss: 1.12111
Epoch: 2/10, step: 14119, training_loss: 1.47548
Epoch: 2/10, step: 14139, training_loss: 1.27125
Epoch: 2/10, step: 14159, training_loss: 1.70484
Epoch: 2/10, step: 14179, training_loss: 1.41200
Epoch: 2/10, step: 14199, training_loss: 1.31863
Epoch: 2/10, step: 14219, training_loss: 0.88305
Epoch: 2/10, step: 14239, training_loss: 1.68520
Epoch: 2/10, step: 14259, training_loss: 1.59789
Epoch: 2/10, step: 14279, training_loss: 1.52983
Epoch: 2/10, step: 14299, training_loss: 2.04462
Epoch: 2/10, step: 14319, training_loss: 1.08631
Epoch: 2/10, step: 14339, training_loss: 1.12959
Epoch: 2/10, step: 14359, training_loss: 1.51776
Epoch: 2/10, step: 14379, training_loss: 1.26102
Epoch: 2/10, step: 14399, training_loss: 1.36323
Epoch: 2/10, step: 14419, training_loss: 2.58109
Epoch: 2/10, step: 14439, training_loss: 1.86033
Epoch: 2/10, step: 14459, training_loss: 0.84866
Epoch: 2/10, step: 14479, training_loss: 1.72298
Epoch: 2/10, step: 14499, training_loss: 1.09292
Epoch: 2/10, step: 14519, training_loss: 1.40977
Epoch: 2/10, step: 14539, training_loss: 1.41546
Epoch: 2/10, step: 14559, training_loss: 1.33159
Epoch: 2/10, step: 14579, training_loss: 1.03716
Epoch: 2/10, step: 14599, training_loss: 1.98017
Epoch: 2/10, step: 14619, training_loss: 1.43836
Epoch: 2/10, step: 14639, training_loss: 1.28402
Epoch: 2/10, step: 14659, training_loss: 1.11235
Epoch: 2/10, step: 14679, training_loss: 1.62650
Epoch: 2/10, step: 14699, training_loss: 2.03529
Epoch: 2/10, step: 14719, training_loss: 1.21874
Epoch: 2/10, step: 14739, training_loss: 1.67875
Epoch: 2/10, step: 14759, training_loss: 1.16396
Epoch: 2/10, step: 14779, training_loss: 1.53425
Epoch: 2/10, step: 14799, training_loss: 1.51921
Epoch: 2/10, step: 14819, training_loss: 1.43651
Epoch: 2/10, step: 14839, training_loss: 1.86851
Epoch: 2/10, step: 14859, training_loss: 0.96010
Epoch: 2/10, step: 14879, training_loss: 1.91247
Epoch: 2/10, step: 14899, training_loss: 1.41018
Epoch: 2/10, step: 14919, training_loss: 1.20603
Epoch: 2/10, step: 14939, training_loss: 1.72227
Epoch: 2/10, step: 14959, training_loss: 1.10489
Epoch: 2/10, step: 14979, training_loss: 1.13862
Epoch: 2/10, step: 14999, training_loss: 0.81735
accuracy: 0.53, validation_loss: 1.3503787517547607, num_samples: 100
Epoch: 2/10, step: 15019, training_loss: 1.20400
Epoch: 2/10, step: 15039, training_loss: 1.26792
Epoch: 2/10, step: 15059, training_loss: 1.62255
Epoch: 2/10, step: 15079, training_loss: 1.02917
Epoch: 2/10, step: 15099, training_loss: 1.16401
Epoch: 2/10, step: 15119, training_loss: 1.34649
Epoch: 2/10, step: 15139, training_loss: 1.45101
Epoch: 2/10, step: 15159, training_loss: 1.97320
Epoch: 2/10, step: 15179, training_loss: 1.64007
Epoch: 2/10, step: 15199, training_loss: 0.48183
Epoch: 2/10, step: 15219, training_loss: 1.30932
Epoch: 2/10, step: 15239, training_loss: 1.14202
Epoch: 2/10, step: 15259, training_loss: 1.42608
Epoch: 2/10, step: 15279, training_loss: 0.80833
Epoch: 2/10, step: 15299, training_loss: 1.54548
Epoch: 2/10, step: 15319, training_loss: 1.22723
Epoch: 2/10, step: 15339, training_loss: 1.29111
Epoch: 2/10, step: 15359, training_loss: 0.94815
Epoch: 2/10, step: 15379, training_loss: 1.75697
Epoch: 2/10, step: 15399, training_loss: 1.30249
Epoch: 2/10, step: 15419, training_loss: 1.40960
Epoch: 2/10, step: 15439, training_loss: 1.80427
Epoch: 2/10, step: 15459, training_loss: 1.72343
Epoch: 2/10, step: 15479, training_loss: 1.11834
Epoch: 2/10, step: 15499, training_loss: 1.47549
Epoch: 2/10, step: 15519, training_loss: 1.73665
Epoch: 2/10, step: 15539, training_loss: 1.47568
Epoch: 2/10, step: 15559, training_loss: 0.75280
Epoch: 2/10, step: 15579, training_loss: 1.20266
Epoch: 2/10, step: 15599, training_loss: 1.36669
Epoch: 2/10, step: 15619, training_loss: 1.46408
Epoch: 2/10, step: 15639, training_loss: 2.16925
Epoch: 2/10, step: 15659, training_loss: 1.27489
Epoch: 2/10, step: 15679, training_loss: 1.79615
Epoch: 2/10, step: 15699, training_loss: 1.69634
Epoch: 2/10, step: 15719, training_loss: 1.99499
Epoch: 2/10, step: 15739, training_loss: 1.54517
Epoch: 2/10, step: 15759, training_loss: 1.80393
Epoch: 2/10, step: 15779, training_loss: 1.05958
Epoch: 2/10, step: 15799, training_loss: 1.57533
Epoch: 2/10, step: 15819, training_loss: 1.23356
Epoch: 2/10, step: 15839, training_loss: 0.80705
Epoch: 2/10, step: 15859, training_loss: 1.74458
Epoch: 2/10, step: 15879, training_loss: 0.43001
Epoch: 2/10, step: 15899, training_loss: 1.64940
Epoch: 2/10, step: 15919, training_loss: 1.29977
Epoch: 2/10, step: 15939, training_loss: 2.15139
Epoch: 2/10, step: 15959, training_loss: 0.73823
Epoch: 2/10, step: 15979, training_loss: 1.43944
Epoch: 2/10, step: 15999, training_loss: 1.53067
accuracy: 0.42, validation_loss: 1.799311637878418, num_samples: 100
Epoch: 2/10, step: 16019, training_loss: 1.18213
Epoch: 2/10, step: 16039, training_loss: 0.74233
Epoch: 2/10, step: 16059, training_loss: 1.22786
Epoch: 2/10, step: 16079, training_loss: 1.44220
Epoch: 2/10, step: 16099, training_loss: 1.68701
Epoch: 2/10, step: 16119, training_loss: 1.77975
Epoch: 2/10, step: 16139, training_loss: 1.61672
Epoch: 2/10, step: 16159, training_loss: 0.98667
Epoch: 2/10, step: 16179, training_loss: 1.51546
Epoch: 2/10, step: 16199, training_loss: 0.85286
Epoch: 2/10, step: 16219, training_loss: 2.44680
Epoch: 2/10, step: 16239, training_loss: 1.24975
Epoch: 2/10, step: 16259, training_loss: 1.66056
Epoch: 2/10, step: 16279, training_loss: 1.32613
Epoch: 2/10, step: 16299, training_loss: 0.89864
Epoch: 2/10, step: 16319, training_loss: 1.38988
Epoch: 2/10, step: 16339, training_loss: 1.49756
Epoch: 2/10, step: 16359, training_loss: 2.15582
Epoch: 2/10, step: 16379, training_loss: 0.90766
Epoch: 2/10, step: 16399, training_loss: 1.56900
Epoch: 2/10, step: 16419, training_loss: 1.51699
Epoch: 2/10, step: 16439, training_loss: 0.92269
Epoch: 2/10, step: 16459, training_loss: 1.04351
Epoch: 2/10, step: 16479, training_loss: 2.02372
Epoch: 2/10, step: 16499, training_loss: 1.11591
Epoch: 2/10, step: 16519, training_loss: 1.19385
Epoch: 2/10, step: 16539, training_loss: 2.10093
Epoch: 2/10, step: 16559, training_loss: 1.10305
Epoch: 2/10, step: 16579, training_loss: 1.70282
Epoch: 2/10, step: 16599, training_loss: 1.56709
Epoch: 2/10, step: 16619, training_loss: 1.30001
Epoch: 2/10, step: 16639, training_loss: 1.13080
Epoch: 2/10, step: 16659, training_loss: 1.47458
Epoch: 2/10, step: 16679, training_loss: 1.41830
Epoch: 2/10, step: 16799, training_loss: 1.76758
Epoch: 2/10, step: 16819, training_loss: 1.28866
Epoch: 2/10, step: 16839, training_loss: 1.43244
Epoch: 2/10, step: 16859, training_loss: 1.31108
Epoch: 2/10, step: 16879, training_loss: 1.20538
Epoch: 2/10, step: 16899, training_loss: 1.60854
Epoch: 2/10, step: 16919, training_loss: 1.28954
Epoch: 2/10, step: 16939, training_loss: 1.90976
Epoch: 2/10, step: 16959, training_loss: 1.37292
Epoch: 2/10, step: 16979, training_loss: 0.95035
Epoch: 2/10, step: 16999, training_loss: 1.73914
accuracy: 0.49, validation_loss: 1.4546301364898682, num_samples: 100
Epoch: 2/10, step: 17019, training_loss: 1.57775
Epoch: 2/10, step: 17039, training_loss: 1.24155
Epoch: 2/10, step: 17059, training_loss: 1.27813
Epoch: 2/10, step: 17079, training_loss: 1.40389
Epoch: 2/10, step: 17099, training_loss: 1.42579
Epoch: 2/10, step: 17119, training_loss: 1.00141
Epoch: 2/10, step: 17139, training_loss: 1.92084
Epoch: 2/10, step: 17159, training_loss: 1.42600
Epoch: 2/10, step: 17179, training_loss: 1.36567
Epoch: 2/10, step: 17199, training_loss: 1.43633
Epoch: 2/10, step: 17219, training_loss: 1.76059
Epoch: 2/10, step: 17239, training_loss: 1.61419
Epoch: 2/10, step: 17259, training_loss: 1.12658
Epoch: 2/10, step: 17279, training_loss: 1.48452
Epoch: 2/10, step: 17299, training_loss: 2.07276
Epoch: 2/10, step: 17319, training_loss: 1.51488
Epoch: 2/10, step: 17339, training_loss: 1.31596
Epoch: 2/10, step: 17359, training_loss: 1.64547
Epoch: 2/10, step: 17379, training_loss: 0.97296
Epoch: 2/10, step: 17399, training_loss: 1.16419
Epoch: 2/10, step: 17419, training_loss: 1.59335
Epoch: 2/10, step: 17439, training_loss: 1.84908
Epoch: 2/10, step: 17459, training_loss: 1.16233
Epoch: 2/10, step: 17479, training_loss: 1.57992
Epoch: 2/10, step: 17499, training_loss: 1.23631
Epoch: 2/10, step: 17519, training_loss: 1.13340
Epoch: 2/10, step: 17539, training_loss: 1.26032
Epoch: 2/10, step: 17559, training_loss: 1.40773
Epoch: 2/10, step: 17579, training_loss: 1.30895
Epoch: 2/10, step: 17599, training_loss: 1.42196
Epoch: 2/10, step: 17619, training_loss: 1.72483
Epoch: 2/10, step: 17639, training_loss: 1.72024
Epoch: 2/10, step: 17659, training_loss: 1.29511
Epoch: 2/10, step: 17679, training_loss: 0.68942
Epoch: 2/10, step: 17699, training_loss: 1.91553
Epoch: 2/10, step: 17719, training_loss: 1.16999
Epoch: 2/10, step: 17739, training_loss: 2.02540
Epoch: 2/10, step: 17759, training_loss: 0.95438
Epoch: 2/10, step: 17779, training_loss: 1.00624
Epoch: 2/10, step: 17799, training_loss: 1.85262
Epoch: 2/10, step: 17819, training_loss: 1.31212
Epoch: 2/10, step: 17839, training_loss: 0.75582
Epoch: 2/10, step: 17859, training_loss: 2.16998
Epoch: 2/10, step: 17879, training_loss: 1.54530
Epoch: 2/10, step: 17899, training_loss: 1.61780
Epoch: 2/10, step: 17919, training_loss: 0.48032
Epoch: 2/10, step: 17939, training_loss: 1.68374
Epoch: 2/10, step: 17959, training_loss: 1.84370
Epoch: 2/10, step: 17979, training_loss: 1.44367
Epoch: 2/10, step: 17999, training_loss: 1.71635
accuracy: 0.48, validation_loss: 1.3263812065124512, num_samples: 100
Epoch: 2/10, step: 18019, training_loss: 1.34508
Epoch: 2/10, step: 18039, training_loss: 1.97238
Epoch: 2/10, step: 18059, training_loss: 1.26346
Epoch: 2/10, step: 18079, training_loss: 1.58551
Epoch: 2/10, step: 18099, training_loss: 1.44511
Epoch: 2/10, step: 18119, training_loss: 1.71656
Epoch: 2/10, step: 18139, training_loss: 1.40393
Epoch: 2/10, step: 18159, training_loss: 1.70200
Epoch: 2/10, step: 18179, training_loss: 1.25145
Epoch: 2/10, step: 18199, training_loss: 1.06711
Epoch: 2/10, step: 18219, training_loss: 1.07517
Epoch: 2/10, step: 18239, training_loss: 1.63108
Epoch: 2/10, step: 18259, training_loss: 0.84404
Epoch: 2/10, step: 18279, training_loss: 1.62734
Epoch: 2/10, step: 18299, training_loss: 1.40904
Epoch: 2/10, step: 18319, training_loss: 0.74690
Epoch: 2/10, step: 18339, training_loss: 1.29579
Epoch: 2/10, step: 18359, training_loss: 1.35418
Epoch: 2/10, step: 18379, training_loss: 2.03073
Epoch: 2/10, step: 18399, training_loss: 1.32022
Epoch: 2/10, step: 18419, training_loss: 1.81850
Epoch: 2/10, step: 18439, training_loss: 1.13223
Epoch: 2/10, step: 18459, training_loss: 0.90346
Epoch: 2/10, step: 18479, training_loss: 1.11514
Epoch: 2/10, step: 18499, training_loss: 1.73843
Epoch: 2/10, step: 18519, training_loss: 0.92621
Epoch: 2/10, step: 18539, training_loss: 1.23065
Epoch: 2/10, step: 18559, training_loss: 1.23631
Epoch: 2/10, step: 18579, training_loss: 1.86483
Epoch: 2/10, step: 18599, training_loss: 0.95197
Epoch: 2/10, step: 18619, training_loss: 1.45264
Epoch: 2/10, step: 18639, training_loss: 1.14957
Epoch: 2/10, step: 18659, training_loss: 1.04630
Epoch: 2/10, step: 18679, training_loss: 0.96247
Epoch: 2/10, step: 18699, training_loss: 1.83219
Epoch: 2/10, step: 18719, training_loss: 1.45330
Epoch: 2/10, step: 18739, training_loss: 1.44792
Epoch: 2/10, step: 18759, training_loss: 1.31077
Epoch: 2/10, step: 18779, training_loss: 1.70028
Epoch: 2/10, step: 18799, training_loss: 1.06924
Epoch: 2/10, step: 18819, training_loss: 1.09216
Epoch: 2/10, step: 18839, training_loss: 1.56665
Epoch: 2/10, step: 18859, training_loss: 1.20175
Epoch: 2/10, step: 18879, training_loss: 1.47885
Epoch: 2/10, step: 18899, training_loss: 0.96964
Epoch: 2/10, step: 18919, training_loss: 1.29162
Epoch: 2/10, step: 18939, training_loss: 1.56960
Epoch: 2/10, step: 18959, training_loss: 2.15890
Epoch: 2/10, step: 18979, training_loss: 2.23460
Epoch: 2/10, step: 18999, training_loss: 1.73331
accuracy: 0.48, validation_loss: 1.535635232925415, num_samples: 100
Epoch: 2/10, step: 19019, training_loss: 1.36821
Epoch: 2/10, step: 19039, training_loss: 1.22261
Epoch: 2/10, step: 19059, training_loss: 1.17660
Epoch: 2/10, step: 19079, training_loss: 0.97241
Epoch: 2/10, step: 19099, training_loss: 1.34254
Epoch: 2/10, step: 19119, training_loss: 1.53572
Epoch: 2/10, step: 19139, training_loss: 1.68350
Epoch: 2/10, step: 19159, training_loss: 0.99665
Epoch: 2/10, step: 19179, training_loss: 1.03548
Epoch: 2/10, step: 19199, training_loss: 1.63915
Epoch: 2/10, step: 19219, training_loss: 0.85623
Epoch: 2/10, step: 19239, training_loss: 2.12127
Epoch: 2/10, step: 19259, training_loss: 1.24394
Epoch: 2/10, step: 19279, training_loss: 1.09384
Epoch: 2/10, step: 19299, training_loss: 1.35490
Epoch: 2/10, step: 19319, training_loss: 1.15233
Epoch: 2/10, step: 19339, training_loss: 1.09989
Epoch: 2/10, step: 19359, training_loss: 1.49924
Epoch: 2/10, step: 19379, training_loss: 2.00062
Epoch: 2/10, step: 19399, training_loss: 1.39662
Epoch: 2/10, step: 19419, training_loss: 1.66271
Epoch: 2/10, step: 19439, training_loss: 1.78548
Epoch: 2/10, step: 19459, training_loss: 1.52847
Epoch: 2/10, step: 19479, training_loss: 0.83950
Epoch: 2/10, step: 19499, training_loss: 1.51674
Epoch: 2/10, step: 19519, training_loss: 1.55200
Epoch: 2/10, step: 19539, training_loss: 1.67874
Epoch: 2/10, step: 19559, training_loss: 1.39018
Epoch: 2/10, step: 19579, training_loss: 1.29110
Epoch: 2/10, step: 19599, training_loss: 1.30399
Epoch: 2/10, step: 19619, training_loss: 1.09355
Epoch: 2/10, step: 19639, training_loss: 1.34138
Epoch: 2/10, step: 19659, training_loss: 1.50588
Epoch: 2/10, step: 19679, training_loss: 1.96284
Epoch: 2/10, step: 19699, training_loss: 1.74239
Epoch: 2/10, step: 19719, training_loss: 1.44174
Epoch: 2/10, step: 19739, training_loss: 1.83239
Epoch: 2/10, step: 19759, training_loss: 1.73517
Epoch: 2/10, step: 19779, training_loss: 0.99243
Epoch: 2/10, step: 19799, training_loss: 1.97001
Epoch: 2/10, step: 19819, training_loss: 1.69040
Epoch: 2/10, step: 19839, training_loss: 1.11734
Epoch: 2/10, step: 19859, training_loss: 1.94908
Epoch: 2/10, step: 19879, training_loss: 1.38940
Epoch: 2/10, step: 19899, training_loss: 1.11796
Epoch: 2/10, step: 19919, training_loss: 1.02123
Epoch: 2/10, step: 19939, training_loss: 1.59944
Epoch: 2/10, step: 19959, training_loss: 1.50766
Epoch: 2/10, step: 19979, training_loss: 1.44829
Epoch: 2/10, step: 19999, training_loss: 1.12081
accuracy: 0.45, validation_loss: 1.6791718006134033, num_samples: 100
Epoch: 2/10, step: 20019, training_loss: 1.33367
Epoch: 2/10, step: 20039, training_loss: 1.21777
Epoch: 2/10, step: 20059, training_loss: 0.81970
Epoch: 2/10, step: 20079, training_loss: 1.88125
Epoch: 2/10, step: 20099, training_loss: 1.52971
Epoch: 2/10, step: 20119, training_loss: 1.42357
Epoch: 2/10, step: 20139, training_loss: 1.46066
Epoch: 2/10, step: 20159, training_loss: 1.41934
Epoch: 2/10, step: 20179, training_loss: 1.42420
Epoch: 2/10, step: 20199, training_loss: 1.34497
Epoch: 2/10, step: 20219, training_loss: 1.52474
Epoch: 2/10, step: 20239, training_loss: 0.96762
Epoch: 2/10, step: 20259, training_loss: 1.64212
Epoch: 2/10, step: 20279, training_loss: 1.49058
Epoch: 2/10, step: 20299, training_loss: 1.46331
Epoch: 2/10, step: 20319, training_loss: 1.42325
Epoch: 2/10, step: 20339, training_loss: 1.34732
Epoch: 2/10, step: 20359, training_loss: 1.66343
Epoch: 2/10, step: 20379, training_loss: 1.75284
Epoch: 2/10, step: 20399, training_loss: 2.02120
Epoch: 2/10, step: 20419, training_loss: 1.22255
Epoch: 2/10, step: 20439, training_loss: 1.44875
Epoch: 2/10, step: 20459, training_loss: 1.46949
Epoch: 2/10, step: 20479, training_loss: 2.19769
Epoch: 2/10, step: 20499, training_loss: 1.63937
Epoch: 2/10, step: 20519, training_loss: 1.44603
Epoch: 2/10, step: 20539, training_loss: 0.95915
Epoch: 2/10, step: 20559, training_loss: 1.28702
Epoch: 2/10, step: 20579, training_loss: 1.04978
Epoch: 2/10, step: 20599, training_loss: 1.33703
Epoch: 2/10, step: 20619, training_loss: 1.03794
Epoch: 2/10, step: 20639, training_loss: 1.52903
Epoch: 2/10, step: 20659, training_loss: 1.01353
Epoch: 2/10, step: 20679, training_loss: 1.28106
Epoch: 2/10, step: 20699, training_loss: 1.52115
Epoch: 2/10, step: 20719, training_loss: 1.32881
Epoch: 2/10, step: 20739, training_loss: 1.60202
Epoch: 2/10, step: 20759, training_loss: 1.24613
Epoch: 2/10, step: 20779, training_loss: 1.46398
Epoch: 2/10, step: 20799, training_loss: 1.61130
Epoch: 2/10, step: 20819, training_loss: 1.61732
Epoch: 2/10, step: 20839, training_loss: 1.38734
Epoch: 2/10, step: 20859, training_loss: 1.58701
Epoch: 2/10, step: 20879, training_loss: 1.87073
Epoch: 2/10, step: 20899, training_loss: 1.49486
Epoch: 2/10, step: 20919, training_loss: 1.37333
Epoch: 2/10, step: 20939, training_loss: 1.02323
Epoch: 2/10, step: 20959, training_loss: 1.49806
Epoch: 2/10, step: 20979, training_loss: 1.10388
Epoch: 2/10, step: 20999, training_loss: 1.51743
accuracy: 0.48, validation_loss: 1.390981912612915, num_samples: 100
Epoch: 2/10, step: 21019, training_loss: 1.61807
Epoch: 2/10, step: 21039, training_loss: 1.12540
Epoch: 2/10, step: 21059, training_loss: 0.98750
Epoch: 2/10, step: 21079, training_loss: 1.54142
Epoch: 2/10, step: 21099, training_loss: 1.20603
Epoch: 2/10, step: 21119, training_loss: 1.30677
Epoch: 2/10, step: 21139, training_loss: 2.12132
Epoch: 2/10, step: 21159, training_loss: 1.19018
Epoch: 2/10, step: 21179, training_loss: 1.10308
Epoch: 2/10, step: 21199, training_loss: 1.84379
Epoch: 2/10, step: 21219, training_loss: 1.25181
Epoch: 2/10, step: 21239, training_loss: 1.44022
Epoch: 2/10, step: 21259, training_loss: 1.99828
Epoch: 2/10, step: 21279, training_loss: 1.21451
Epoch: 2/10, step: 21299, training_loss: 1.33784
Epoch: 2/10, step: 21319, training_loss: 1.45566
Epoch: 2/10, step: 21339, training_loss: 1.32961
Epoch: 2/10, step: 21359, training_loss: 1.97642
Epoch: 2/10, step: 21379, training_loss: 1.26581
Epoch: 2/10, step: 21399, training_loss: 1.33113
Epoch: 2/10, step: 21419, training_loss: 0.67641
Epoch: 2/10, step: 21439, training_loss: 1.47588
Epoch: 2/10, step: 21459, training_loss: 1.15414
Epoch: 2/10, step: 21479, training_loss: 1.65025
Epoch: 2/10, step: 21499, training_loss: 1.54507
Epoch: 2/10, step: 21519, training_loss: 1.21721
Epoch: 2/10, step: 21539, training_loss: 1.65631
Epoch: 2/10, step: 21559, training_loss: 0.86866
Epoch: 2/10, step: 21579, training_loss: 1.49006
Epoch: 2/10, step: 21599, training_loss: 1.49820
Epoch: 2/10, step: 21619, training_loss: 1.85624
Epoch: 2/10, step: 21639, training_loss: 0.92820
Epoch: 2/10, step: 21659, training_loss: 1.30726
Epoch: 2/10, step: 21679, training_loss: 1.13988
Epoch: 2/10, step: 21699, training_loss: 1.61303
Epoch: 2/10, step: 21719, training_loss: 2.08326
Epoch: 2/10, step: 21739, training_loss: 1.87404
Epoch: 2/10, step: 21759, training_loss: 1.20908
Epoch: 2/10, step: 21779, training_loss: 1.45599
Epoch: 2/10, step: 21799, training_loss: 2.11281
Epoch: 2/10, step: 21819, training_loss: 1.09609
Epoch: 2/10, step: 21839, training_loss: 0.82277
Epoch: 2/10, step: 21859, training_loss: 1.78582
Epoch: 2/10, step: 21879, training_loss: 1.81678
Epoch: 2/10, step: 21899, training_loss: 1.05639
Epoch: 2/10, step: 21919, training_loss: 1.49226
Epoch: 2/10, step: 21939, training_loss: 1.16901
Epoch: 2/10, step: 21959, training_loss: 1.35954
Epoch: 2/10, step: 21979, training_loss: 1.26554
Epoch: 2/10, step: 21999, training_loss: 1.06395
accuracy: 0.54, validation_loss: 1.523188829421997, num_samples: 100
Epoch: 2/10, step: 22019, training_loss: 0.94957
Epoch: 2/10, step: 22039, training_loss: 1.16802
Epoch: 2/10, step: 22059, training_loss: 1.22595
Epoch: 2/10, step: 22079, training_loss: 1.62233
Epoch: 2/10, step: 22099, training_loss: 1.84517
Epoch: 2/10, step: 22119, training_loss: 1.52240
Epoch: 2/10, step: 22139, training_loss: 1.48152
Epoch: 2/10, step: 22159, training_loss: 2.00836
Epoch: 2/10, step: 22179, training_loss: 1.23534
Epoch: 2/10, step: 22199, training_loss: 1.13486
Epoch: 2/10, step: 22219, training_loss: 1.68721
Epoch: 2/10, step: 22239, training_loss: 1.78846
Epoch: 2/10, step: 22259, training_loss: 1.62114
Epoch: 2/10, step: 22279, training_loss: 1.13456
Epoch: 2/10, step: 22299, training_loss: 1.68395
Epoch: 2/10, step: 22319, training_loss: 1.45838
Epoch: 2/10, step: 22339, training_loss: 1.13241
Epoch: 2/10, step: 22359, training_loss: 0.90333
Epoch: 2/10, step: 22379, training_loss: 1.63804
Epoch: 2/10, step: 22399, training_loss: 1.23665
Epoch: 2/10, step: 22419, training_loss: 0.87187
Epoch: 2/10, step: 22439, training_loss: 1.59076
Epoch: 2/10, step: 22459, training_loss: 1.38401
Epoch: 2/10, step: 22479, training_loss: 1.01474
Epoch: 2/10, step: 22499, training_loss: 1.31094
Epoch: 2/10, step: 22519, training_loss: 1.32954
Epoch: 2/10, step: 22539, training_loss: 1.85742
Epoch: 2/10, step: 22559, training_loss: 1.45164
Epoch: 2/10, step: 22579, training_loss: 1.44633
Epoch: 2/10, step: 22599, training_loss: 0.72748
Epoch: 2/10, step: 22619, training_loss: 1.78740
Epoch: 2/10, step: 22639, training_loss: 1.74593
Epoch: 2/10, step: 22659, training_loss: 1.08990
Epoch: 2/10, step: 22679, training_loss: 1.02366
Epoch: 2/10, step: 22699, training_loss: 1.58731
Epoch: 2/10, step: 22719, training_loss: 2.00419
Epoch: 2/10, step: 22739, training_loss: 1.49203
Epoch: 2/10, step: 22759, training_loss: 2.47821
Epoch: 2/10, step: 22779, training_loss: 0.99321
Epoch: 2/10, step: 22799, training_loss: 1.11197
Epoch: 2/10, step: 22819, training_loss: 1.93336
Epoch: 2/10, step: 22839, training_loss: 1.03931
Epoch: 2/10, step: 22859, training_loss: 1.02638
Epoch: 2/10, step: 22879, training_loss: 2.19898
Epoch: 2/10, step: 22899, training_loss: 1.52633
Epoch: 2/10, step: 22919, training_loss: 1.79992
Epoch: 2/10, step: 22939, training_loss: 1.96064
Epoch: 2/10, step: 22959, training_loss: 0.85609
Epoch: 2/10, step: 22979, training_loss: 1.44608
Epoch: 2/10, step: 22999, training_loss: 1.13993
accuracy: 0.56, validation_loss: 1.3513787984848022, num_samples: 100
Epoch: 2/10, step: 23019, training_loss: 2.08241
Epoch: 2/10, step: 23039, training_loss: 1.49793
Epoch: 2/10, step: 23059, training_loss: 1.55622
Epoch: 2/10, step: 23079, training_loss: 1.95434
Epoch: 2/10, step: 23099, training_loss: 1.30754
Epoch: 2/10, step: 23119, training_loss: 1.62076
Epoch: 2/10, step: 23139, training_loss: 1.36407
Epoch: 2/10, step: 23159, training_loss: 1.88017
Epoch: 2/10, step: 23179, training_loss: 1.23340
Epoch: 2/10, step: 23199, training_loss: 1.83834
Epoch: 2/10, step: 23219, training_loss: 1.61917
Epoch: 2/10, step: 23239, training_loss: 1.64314
Epoch: 2/10, step: 23259, training_loss: 1.38394
Epoch: 2/10, step: 23279, training_loss: 0.94806
Epoch: 2/10, step: 23299, training_loss: 1.32877
Epoch: 2/10, step: 23319, training_loss: 1.43361
Epoch: 2/10, step: 23339, training_loss: 1.41744
Epoch: 2/10, step: 23359, training_loss: 1.59241
Epoch: 2/10, step: 23379, training_loss: 1.03783
Epoch: 2/10, step: 23399, training_loss: 0.99857
Epoch: 2/10, step: 23419, training_loss: 1.22094
Epoch: 2/10, step: 23439, training_loss: 1.69109
Epoch: 2/10, step: 23459, training_loss: 1.45218
Epoch: 2/10, step: 23479, training_loss: 1.50006
Epoch: 2/10, step: 23499, training_loss: 1.56615
Epoch: 2/10, step: 23519, training_loss: 1.91843
Epoch: 2/10, step: 23539, training_loss: 2.09571
Epoch: 2/10, step: 23559, training_loss: 2.05696
Epoch: 2/10, step: 23579, training_loss: 1.24539
Epoch: 2/10, step: 23599, training_loss: 1.09457
Epoch: 2/10, step: 23619, training_loss: 0.77083
Epoch: 2/10, step: 23639, training_loss: 2.07062
Epoch: 2/10, step: 23659, training_loss: 1.65010
Epoch: 2/10, step: 23679, training_loss: 1.47395
Epoch: 2/10, step: 23699, training_loss: 1.08762
Epoch: 2/10, step: 23719, training_loss: 1.55429
Epoch: 2/10, step: 23739, training_loss: 0.88434
Epoch: 2/10, step: 23759, training_loss: 1.58596
Epoch: 2/10, step: 23779, training_loss: 0.80399
Epoch: 2/10, step: 23799, training_loss: 1.71869
Epoch: 2/10, step: 23819, training_loss: 1.39538
Epoch: 2/10, step: 23839, training_loss: 1.62689
Epoch: 2/10, step: 23859, training_loss: 1.59812
Epoch: 2/10, step: 23879, training_loss: 1.63263
Epoch: 2/10, step: 23899, training_loss: 1.23906
Epoch: 2/10, step: 23919, training_loss: 1.03208
Epoch: 2/10, step: 23939, training_loss: 1.36644
Epoch: 2/10, step: 23959, training_loss: 1.32147
Epoch: 2/10, step: 23979, training_loss: 1.08836
Epoch: 2/10, step: 23999, training_loss: 1.76993
accuracy: 0.52, validation_loss: 1.6308221817016602, num_samples: 100
Epoch: 2/10, step: 24019, training_loss: 1.63323
Epoch: 2/10, step: 24039, training_loss: 2.35210
Epoch: 2/10, step: 24059, training_loss: 2.04591
Epoch: 2/10, step: 24079, training_loss: 1.17707
Epoch: 2/10, step: 24099, training_loss: 1.51649
Epoch: 2/10, step: 24119, training_loss: 1.55315
Epoch: 2/10, step: 24139, training_loss: 1.65060
Epoch: 2/10, step: 24159, training_loss: 1.37483
Epoch: 2/10, step: 24179, training_loss: 1.15557
Epoch: 2/10, step: 24199, training_loss: 1.61107
Epoch: 2/10, step: 24219, training_loss: 1.28440
Epoch: 2/10, step: 24239, training_loss: 1.60414
Epoch: 2/10, step: 24259, training_loss: 1.55054
Epoch: 2/10, step: 24279, training_loss: 1.44515
Epoch: 2/10, step: 24299, training_loss: 1.42050
Epoch: 2/10, step: 24319, training_loss: 0.88960
Epoch: 2/10, step: 24339, training_loss: 1.73821
Epoch: 2/10, step: 24359, training_loss: 1.11013
Epoch: 2/10, step: 24379, training_loss: 1.30203
Epoch: 2/10, step: 24399, training_loss: 1.25011
Epoch: 2/10, step: 24419, training_loss: 1.21427
Epoch: 2/10, step: 24439, training_loss: 0.83174
Epoch: 2/10, step: 24459, training_loss: 1.04222
Epoch: 2/10, step: 24479, training_loss: 1.26978
Epoch: 2/10, step: 24499, training_loss: 1.68711
Epoch: 2/10, step: 24519, training_loss: 0.99832
Epoch: 2/10, step: 24539, training_loss: 1.90436
Epoch: 2/10, step: 24559, training_loss: 1.24270
Epoch: 2/10, step: 24579, training_loss: 1.66680
Epoch: 2/10, step: 24599, training_loss: 1.07100
Epoch: 2/10, step: 24619, training_loss: 1.92505
Epoch: 2/10, step: 24639, training_loss: 0.95273
Epoch: 2/10, step: 24659, training_loss: 1.27038
Epoch: 2/10, step: 24679, training_loss: 1.66200
Epoch: 2/10, step: 24699, training_loss: 1.03134
Epoch: 2/10, step: 24719, training_loss: 1.70394
Epoch: 2/10, step: 24739, training_loss: 1.36752
Epoch: 2/10, step: 24759, training_loss: 1.53305
Epoch: 2/10, step: 24779, training_loss: 1.57419
Epoch: 2/10, step: 24799, training_loss: 1.20233
Epoch: 2/10, step: 24819, training_loss: 1.56373
Epoch: 2/10, step: 24839, training_loss: 1.26005
Epoch: 2/10, step: 24859, training_loss: 1.36414
Epoch: 2/10, step: 24879, training_loss: 1.47058
Epoch: 2/10, step: 24899, training_loss: 1.79695
Epoch: 2/10, step: 24919, training_loss: 1.41592
Epoch: 2/10, step: 24939, training_loss: 1.15379
Epoch: 2/10, step: 24959, training_loss: 2.20911
Epoch: 2/10, step: 24979, training_loss: 1.50054
Epoch: 2/10, step: 24999, training_loss: 1.04329
accuracy: 0.5, validation_loss: 1.3817551136016846, num_samples: 100
Epoch: 2/10, step: 25019, training_loss: 0.85681
Epoch: 2/10, step: 25039, training_loss: 1.72279
Epoch: 2/10, step: 25059, training_loss: 1.51557
Epoch: 2/10, step: 25079, training_loss: 2.15813
Epoch: 2/10, step: 25099, training_loss: 1.97473
Epoch: 2/10, step: 25119, training_loss: 1.44842
Epoch: 2/10, step: 25139, training_loss: 1.33861
Epoch: 2/10, step: 25159, training_loss: 1.09709
Epoch: 2/10, step: 25179, training_loss: 1.19581
Epoch: 2/10, step: 25199, training_loss: 1.09754
Epoch: 2/10, step: 25219, training_loss: 1.67694
Epoch: 2/10, step: 25239, training_loss: 1.26099
Epoch: 2/10, step: 25259, training_loss: 0.93693
Epoch: 2/10, step: 25279, training_loss: 0.95315
Epoch: 2/10, step: 25299, training_loss: 0.87188
Epoch: 2/10, step: 25319, training_loss: 1.70137
Epoch: 2/10, step: 25339, training_loss: 1.38040
Epoch: 2/10, step: 25359, training_loss: 1.55622
Epoch: 2/10, step: 25379, training_loss: 1.79884
Epoch: 2/10, step: 25399, training_loss: 1.72792
Epoch: 2/10, step: 25419, training_loss: 1.43773
Epoch: 2/10, step: 25439, training_loss: 1.39128
Epoch: 2/10, step: 25459, training_loss: 2.50854
Epoch: 2/10, step: 25479, training_loss: 2.08814
Epoch: 2/10, step: 25499, training_loss: 1.58069
Epoch: 2/10, step: 25519, training_loss: 1.58425
Epoch: 2/10, step: 25539, training_loss: 1.60357
Epoch: 2/10, step: 25559, training_loss: 1.64854
Epoch: 2/10, step: 25579, training_loss: 1.69471
Epoch: 2/10, step: 25599, training_loss: 1.50887
Epoch: 2/10, step: 25619, training_loss: 1.07518
Epoch: 2/10, step: 25639, training_loss: 1.17160
Epoch: 2/10, step: 25659, training_loss: 1.37863
Epoch: 2/10, step: 25679, training_loss: 1.42758
Epoch: 2/10, step: 25699, training_loss: 1.55317
Epoch: 2/10, step: 25719, training_loss: 1.29178
Epoch: 2/10, step: 25739, training_loss: 1.28422
Epoch: 2/10, step: 25759, training_loss: 1.13705
Epoch: 2/10, step: 25779, training_loss: 1.37335
Epoch: 2/10, step: 25799, training_loss: 1.63438
Epoch: 2/10, step: 25819, training_loss: 1.28462
Epoch: 2/10, step: 25839, training_loss: 1.39368
Epoch: 2/10, step: 25859, training_loss: 1.53763
Epoch: 2/10, step: 25879, training_loss: 1.16328
Epoch: 2/10, step: 25899, training_loss: 1.73813
Epoch: 2/10, step: 25919, training_loss: 0.98867
Epoch: 2/10, step: 25939, training_loss: 1.35414
Epoch: 2/10, step: 25959, training_loss: 1.42224
Epoch: 2/10, step: 25979, training_loss: 1.54098
Epoch: 2/10, step: 25999, training_loss: 1.64957
accuracy: 0.5, validation_loss: 1.5275148153305054, num_samples: 100
Epoch: 2/10, step: 26019, training_loss: 1.10032
Epoch: 2/10, step: 26039, training_loss: 1.39450
Epoch: 2/10, step: 26059, training_loss: 2.03254
Epoch: 2/10, step: 26079, training_loss: 0.59748
Epoch: 2/10, step: 26099, training_loss: 1.61135
Epoch: 2/10, step: 26119, training_loss: 2.06503
Epoch: 2/10, step: 26139, training_loss: 0.63643
Epoch: 2/10, step: 26159, training_loss: 2.00432
Epoch: 2/10, step: 26179, training_loss: 1.96171
Epoch: 2/10, step: 26199, training_loss: 1.58961
Epoch: 2/10, step: 26219, training_loss: 1.55061
Epoch: 2/10, step: 26239, training_loss: 1.49521
Epoch: 2/10, step: 26259, training_loss: 1.81167
Epoch: 2/10, step: 26279, training_loss: 1.38669
Epoch: 2/10, step: 26299, training_loss: 1.14007
Epoch: 2/10, step: 26319, training_loss: 1.04894
Epoch: 2/10, step: 26339, training_loss: 1.38926
Epoch: 2/10, step: 26359, training_loss: 1.43631
Epoch: 2/10, step: 26379, training_loss: 1.28025
Epoch: 2/10, step: 26399, training_loss: 1.27225
Epoch: 2/10, step: 26419, training_loss: 1.27449
Epoch: 2/10, step: 26439, training_loss: 1.86445
Epoch: 2/10, step: 26459, training_loss: 1.25432
Epoch: 2/10, step: 26479, training_loss: 2.00278
Epoch: 2/10, step: 26499, training_loss: 1.55273
Epoch: 2/10, step: 26519, training_loss: 1.58036
Epoch: 2/10, step: 26539, training_loss: 1.43579
Epoch: 2/10, step: 26559, training_loss: 1.50334
Epoch: 2/10, step: 26579, training_loss: 1.31708
Epoch: 2/10, step: 26599, training_loss: 0.83125
Epoch: 2/10, step: 26619, training_loss: 2.24094
Epoch: 2/10, step: 26639, training_loss: 1.57862
Epoch: 2/10, step: 26659, training_loss: 1.81750
Epoch: 2/10, step: 26679, training_loss: 1.83777
Epoch: 2/10, step: 26699, training_loss: 2.04407
Epoch: 2/10, step: 26719, training_loss: 1.43402
Epoch: 2/10, step: 26739, training_loss: 0.77566
Epoch: 2/10, step: 26759, training_loss: 1.68757
Epoch: 2/10, step: 26779, training_loss: 0.83993
Epoch: 2/10, step: 26799, training_loss: 1.43132
Epoch: 2/10, step: 26819, training_loss: 1.11294
Epoch: 2/10, step: 26839, training_loss: 1.79532
Epoch: 2/10, step: 26859, training_loss: 1.42954
Epoch: 2/10, step: 26879, training_loss: 1.53000
Epoch: 2/10, step: 26899, training_loss: 2.03903
Epoch: 2/10, step: 26919, training_loss: 1.26621
Epoch: 2/10, step: 26939, training_loss: 0.98882
Epoch: 2/10, step: 26959, training_loss: 1.69251
Epoch: 2/10, step: 26979, training_loss: 1.51375
Epoch: 2/10, step: 26999, training_loss: 1.02556
accuracy: 0.53, validation_loss: 1.4376407861709595, num_samples: 100
Epoch: 2/10, step: 27019, training_loss: 1.30502
Epoch: 2/10, step: 27039, training_loss: 1.39591
Epoch: 2/10, step: 27059, training_loss: 1.27224
Epoch: 2/10, step: 27079, training_loss: 1.45308
Epoch: 2/10, step: 27099, training_loss: 1.65661
Epoch: 2/10, step: 27119, training_loss: 1.49346
Epoch: 2/10, step: 27139, training_loss: 1.79518
Epoch: 2/10, step: 27159, training_loss: 1.65273
Epoch: 2/10, step: 27179, training_loss: 0.95881
Epoch: 2/10, step: 27199, training_loss: 1.74567
Epoch: 2/10, step: 27219, training_loss: 0.86624
Epoch: 2/10, step: 27239, training_loss: 2.64043
Epoch: 2/10, step: 27259, training_loss: 1.24358
Epoch: 2/10, step: 27279, training_loss: 1.60260
Epoch: 2/10, step: 27299, training_loss: 1.41773
Epoch: 2/10, step: 27319, training_loss: 2.05851
Epoch: 2/10, step: 27339, training_loss: 1.51159
Epoch: 2/10, step: 27359, training_loss: 1.35459
Epoch: 2/10, step: 27379, training_loss: 1.08150
Epoch: 2/10, step: 27399, training_loss: 2.62624
Epoch: 2/10, step: 27419, training_loss: 1.06141
Epoch: 2/10, step: 27439, training_loss: 1.61243
Epoch: 2/10, step: 27459, training_loss: 1.27843
Epoch: 2/10, step: 27479, training_loss: 2.21993
Epoch: 2/10, step: 27499, training_loss: 2.05172
Epoch: 2/10, step: 27519, training_loss: 1.50463
Epoch: 2/10, step: 27539, training_loss: 2.26517
Epoch: 2/10, step: 27559, training_loss: 1.25999
Epoch: 2/10, step: 27579, training_loss: 0.80964
Epoch: 2/10, step: 27599, training_loss: 0.73873
Epoch: 2/10, step: 27619, training_loss: 1.09952
Epoch: 2/10, step: 27639, training_loss: 1.53135
Epoch: 2/10, step: 27659, training_loss: 1.16878
Epoch: 2/10, step: 27679, training_loss: 1.05605
Epoch: 2/10, step: 27699, training_loss: 1.45335
Epoch: 2/10, step: 27719, training_loss: 1.13153
Epoch: 2/10, step: 27739, training_loss: 1.53266
Epoch: 2/10, step: 27759, training_loss: 1.20859
Epoch: 2/10, step: 27779, training_loss: 1.13244
Epoch: 2/10, step: 27799, training_loss: 1.38930
Epoch: 2/10, step: 27819, training_loss: 1.32163
Epoch: 2/10, step: 27839, training_loss: 1.40798
Epoch: 2/10, step: 27859, training_loss: 1.62018
Epoch: 2/10, step: 27879, training_loss: 1.77504
Epoch: 2/10, step: 27899, training_loss: 0.98404
Epoch: 2/10, step: 27919, training_loss: 1.03504
Epoch: 2/10, step: 27939, training_loss: 2.29564
Epoch: 2/10, step: 27959, training_loss: 1.08586
Epoch: 2/10, step: 27979, training_loss: 1.92328
Epoch: 2/10, step: 27999, training_loss: 2.20448
accuracy: 0.53, validation_loss: 1.3454852104187012, num_samples: 100
Epoch: 2/10, step: 28019, training_loss: 1.22054
Epoch: 2/10, step: 28039, training_loss: 1.44095
Epoch: 2/10, step: 28059, training_loss: 2.49782
Epoch: 2/10, step: 28079, training_loss: 1.52600
Epoch: 2/10, step: 28099, training_loss: 1.51329
Epoch: 2/10, step: 28119, training_loss: 1.61708
Epoch: 2/10, step: 28139, training_loss: 1.00410
Epoch: 2/10, step: 28159, training_loss: 2.21854
Epoch: 2/10, step: 28179, training_loss: 1.37640
Epoch: 2/10, step: 28199, training_loss: 2.43556
Epoch: 2/10, step: 28219, training_loss: 2.03729
Epoch: 2/10, step: 28239, training_loss: 1.23872
Epoch: 2/10, step: 28259, training_loss: 0.98706
Epoch: 2/10, step: 28279, training_loss: 1.33153
Epoch: 2/10, step: 28299, training_loss: 1.45361
Epoch: 2/10, step: 28319, training_loss: 1.15653
Epoch: 2/10, step: 28339, training_loss: 1.18509
Epoch: 2/10, step: 28359, training_loss: 1.75251
Epoch: 2/10, step: 28379, training_loss: 1.32140
Epoch: 2/10, step: 28399, training_loss: 1.86322
Epoch: 2/10, step: 28419, training_loss: 0.69961
Epoch: 2/10, step: 28439, training_loss: 1.66815
Epoch: 2/10, step: 28459, training_loss: 1.48810
Epoch: 2/10, step: 28479, training_loss: 1.40624
Epoch: 2/10, step: 28499, training_loss: 1.81364
Epoch: 2/10, step: 28519, training_loss: 0.87023
Epoch: 2/10, step: 28539, training_loss: 1.62562
Epoch: 2/10, step: 28559, training_loss: 1.44114
Epoch: 2/10, step: 28579, training_loss: 1.65503
Epoch: 2/10, step: 28599, training_loss: 1.11746
Epoch: 2/10, step: 28619, training_loss: 1.26267
Epoch: 2/10, step: 28639, training_loss: 2.34148
Epoch: 2/10, step: 28659, training_loss: 1.95881
Epoch: 2/10, step: 28679, training_loss: 1.49856
Epoch: 2/10, step: 28699, training_loss: 1.09199
Epoch: 2/10, step: 28719, training_loss: 1.71529
Epoch: 2/10, step: 28739, training_loss: 1.10150
Epoch: 2/10, step: 28759, training_loss: 1.11802
Epoch: 2/10, step: 28779, training_loss: 1.25064
Epoch: 2/10, step: 28799, training_loss: 0.81796
Epoch: 2/10, step: 28819, training_loss: 1.34502
Epoch: 2/10, step: 28839, training_loss: 1.28477
Epoch: 2/10, step: 28859, training_loss: 1.79117
Epoch: 2/10, step: 28879, training_loss: 1.55021
Epoch: 2/10, step: 28899, training_loss: 1.63995
Epoch: 2/10, step: 28919, training_loss: 1.09663
Epoch: 2/10, step: 28939, training_loss: 0.96593
Epoch: 2/10, step: 28959, training_loss: 1.60417
Epoch: 2/10, step: 28979, training_loss: 1.66640
Epoch: 2/10, step: 28999, training_loss: 1.18417
accuracy: 0.48, validation_loss: 1.6623640060424805, num_samples: 100
Epoch: 2/10, step: 29019, training_loss: 1.07330
Epoch: 2/10, step: 29039, training_loss: 1.76040
Epoch: 2/10, step: 29059, training_loss: 1.69133
Epoch: 2/10, step: 29079, training_loss: 0.96452
Epoch: 2/10, step: 29099, training_loss: 1.27702
Epoch: 2/10, step: 29119, training_loss: 1.37321
Epoch: 2/10, step: 29139, training_loss: 1.16330
Epoch: 2/10, step: 29159, training_loss: 0.88470
Epoch: 2/10, step: 29179, training_loss: 1.71557
Epoch: 2/10, step: 29199, training_loss: 1.19436
Epoch: 2/10, step: 29219, training_loss: 1.44408
Epoch: 2/10, step: 29239, training_loss: 2.01790
Epoch: 2/10, step: 29259, training_loss: 1.59115
Epoch: 2/10, step: 29279, training_loss: 1.21942
Epoch: 2/10, step: 29299, training_loss: 2.21067
Epoch: 2/10, step: 29319, training_loss: 1.46702
Epoch: 2/10, step: 29339, training_loss: 1.72619
Epoch: 2/10, step: 29359, training_loss: 1.05972
Epoch: 2/10, step: 29379, training_loss: 2.01614
Epoch: 2/10, step: 29399, training_loss: 0.92984
Epoch: 2/10, step: 29419, training_loss: 2.02432
Epoch: 2/10, step: 29439, training_loss: 0.89998
Epoch: 2/10, step: 29459, training_loss: 1.49359
Epoch: 2/10, step: 29479, training_loss: 1.91521
Epoch: 2/10, step: 29499, training_loss: 1.35506
Epoch: 2/10, step: 29519, training_loss: 0.80998
Epoch: 2/10, step: 29539, training_loss: 0.67314
Epoch: 2/10, step: 29559, training_loss: 0.90051
Epoch: 2/10, step: 29579, training_loss: 1.98251
Epoch: 2/10, step: 29599, training_loss: 1.60010
Epoch: 2/10, step: 29619, training_loss: 1.48300
Epoch: 2/10, step: 29639, training_loss: 1.26143
Epoch: 2/10, step: 29659, training_loss: 1.61324
Epoch: 2/10, step: 29679, training_loss: 1.47451
Epoch: 2/10, step: 29699, training_loss: 1.23109
Epoch: 2/10, step: 29719, training_loss: 1.32228
Epoch: 2/10, step: 29739, training_loss: 1.78020
Epoch: 2/10, step: 29759, training_loss: 1.51099
Epoch: 2/10, step: 29779, training_loss: 1.10916
Epoch: 2/10, step: 29799, training_loss: 1.38879
Epoch: 2/10, step: 29819, training_loss: 0.95802
Epoch: 2/10, step: 29839, training_loss: 1.79994
Epoch: 2/10, step: 29859, training_loss: 1.34326
Epoch: 2/10, step: 29879, training_loss: 1.85831
Epoch: 2/10, step: 29899, training_loss: 1.33340
Epoch: 2/10, step: 29919, training_loss: 1.34447
Epoch: 2/10, step: 29939, training_loss: 1.21635
Epoch: 2/10, step: 29959, training_loss: 1.36646
Epoch: 2/10, step: 29979, training_loss: 1.98077
Epoch: 2/10, step: 29999, training_loss: 0.87896
accuracy: 0.52, validation_loss: 1.458982229232788, num_samples: 100
Epoch: 2/10, step: 30019, training_loss: 0.83244
Epoch: 2/10, step: 30039, training_loss: 1.29140
Epoch: 2/10, step: 30059, training_loss: 1.52166
Epoch: 2/10, step: 30079, training_loss: 1.66181
Epoch: 2/10, step: 30099, training_loss: 1.06168
Epoch: 2/10, step: 30119, training_loss: 1.31029
Epoch: 2/10, step: 30139, training_loss: 1.00055
Epoch: 2/10, step: 30159, training_loss: 1.33434
Epoch: 2/10, step: 30179, training_loss: 1.41257
Epoch: 2/10, step: 30199, training_loss: 1.14638
Epoch: 2/10, step: 30219, training_loss: 1.36554
Epoch: 2/10, step: 30239, training_loss: 0.71139
Epoch: 2/10, step: 30259, training_loss: 1.64870
Epoch: 2/10, step: 30279, training_loss: 1.46260
Epoch: 2/10, step: 30299, training_loss: 1.60381
Epoch: 2/10, step: 30319, training_loss: 1.25961
Epoch: 2/10, step: 30339, training_loss: 1.49406
Epoch: 2/10, step: 30359, training_loss: 1.45144
Epoch: 2/10, step: 30379, training_loss: 2.07601
Epoch: 2/10, step: 30399, training_loss: 1.59809
Epoch: 2/10, step: 30419, training_loss: 2.33733
Epoch: 2/10, step: 30439, training_loss: 1.52835
Epoch: 2/10, step: 30459, training_loss: 1.97684
Epoch: 2/10, step: 30479, training_loss: 1.75666
Epoch: 2/10, step: 30499, training_loss: 1.11509
Epoch: 2/10, step: 30519, training_loss: 1.07915
Epoch: 2/10, step: 30539, training_loss: 1.23522
Epoch: 2/10, step: 30559, training_loss: 1.35680
Epoch: 2/10, step: 30579, training_loss: 1.81882
Epoch: 2/10, step: 30599, training_loss: 1.10266
Epoch: 2/10, step: 30619, training_loss: 1.55908
Epoch: 2/10, step: 30639, training_loss: 1.30458
Epoch: 2/10, step: 30659, training_loss: 1.77033
Epoch: 2/10, step: 30679, training_loss: 1.51225
Epoch: 2/10, step: 30699, training_loss: 1.14232
Epoch: 2/10, step: 30719, training_loss: 1.35347
Epoch: 2/10, step: 30739, training_loss: 2.24760
Epoch: 2/10, step: 30759, training_loss: 1.59248
Epoch: 2/10, step: 30779, training_loss: 1.06933
Epoch: 2/10, step: 30799, training_loss: 0.72918
Epoch: 2/10, step: 30819, training_loss: 1.32001
Epoch: 2/10, step: 30839, training_loss: 1.14415
Epoch: 2/10, step: 30859, training_loss: 1.20871
Epoch: 2/10, step: 30879, training_loss: 0.98590
Epoch: 2/10, step: 30899, training_loss: 1.28516
Epoch: 2/10, step: 30919, training_loss: 1.38461
Epoch: 2/10, step: 30939, training_loss: 1.58361
Epoch: 2/10, step: 30959, training_loss: 1.19479
Epoch: 2/10, step: 30979, training_loss: 2.01880
Epoch: 2/10, step: 30999, training_loss: 1.19312
accuracy: 0.49, validation_loss: 1.4737904071807861, num_samples: 100
Epoch: 2/10, step: 31019, training_loss: 1.37978
Epoch: 2/10, step: 31039, training_loss: 0.92828
Epoch: 2/10, step: 31059, training_loss: 0.97153
Epoch: 2/10, step: 31079, training_loss: 1.75306
Epoch: 2/10, step: 31099, training_loss: 2.11959
Epoch: 2/10, step: 31119, training_loss: 2.49501
Epoch: 2/10, step: 31139, training_loss: 1.18792
Epoch: 2/10, step: 31159, training_loss: 1.66352
Epoch: 2/10, step: 31179, training_loss: 1.50786
Epoch: 2/10, step: 31199, training_loss: 1.57229
Epoch: 2/10, step: 31219, training_loss: 1.60299
Epoch: 2/10, step: 31239, training_loss: 1.97995
Epoch: 2/10, step: 31259, training_loss: 1.52423
Epoch: 2/10, step: 31279, training_loss: 1.18539
Epoch: 2/10, step: 31299, training_loss: 0.67313
Epoch: 2/10, step: 31319, training_loss: 1.48011
Epoch: 2/10, step: 31339, training_loss: 1.73288
Epoch: 2/10, step: 31359, training_loss: 1.62755
Epoch: 2/10, step: 31379, training_loss: 1.60434
Epoch: 2/10, step: 31399, training_loss: 1.65365
Epoch: 2/10, step: 31419, training_loss: 1.73822
Epoch: 2/10, step: 31439, training_loss: 0.78366
Epoch: 2/10, step: 31459, training_loss: 1.22138
Epoch: 2/10, step: 31479, training_loss: 1.60942
Epoch: 2/10, step: 31499, training_loss: 1.58538
Epoch: 2/10, step: 31519, training_loss: 1.01353
Epoch: 2/10, step: 31539, training_loss: 1.48140
Epoch: 2/10, step: 31559, training_loss: 1.41043
Epoch: 2/10, step: 31579, training_loss: 1.83051
Epoch: 2/10, step: 31599, training_loss: 1.55894
Epoch: 2/10, step: 31619, training_loss: 1.08250
Epoch: 2/10, step: 31639, training_loss: 1.32968
Epoch: 2/10, step: 31659, training_loss: 0.95007
Epoch: 2/10, step: 31679, training_loss: 2.02634
Epoch: 2/10, step: 31699, training_loss: 1.08859
Epoch: 2/10, step: 31719, training_loss: 1.22867
Epoch: 2/10, step: 31739, training_loss: 1.37512
Epoch: 2/10, step: 31759, training_loss: 0.88772
Epoch: 2/10, step: 31779, training_loss: 1.48241
Epoch: 2/10, step: 31799, training_loss: 1.28969
Epoch: 2/10, step: 31819, training_loss: 1.19910
Epoch: 2/10, step: 31839, training_loss: 1.30946
Epoch: 2/10, step: 31859, training_loss: 1.48256
Epoch: 2/10, step: 31879, training_loss: 1.23627
Epoch: 2/10, step: 31899, training_loss: 1.37254
Epoch: 2/10, step: 31919, training_loss: 1.40190
Epoch: 2/10, step: 31939, training_loss: 1.78008
Epoch: 2/10, step: 31959, training_loss: 1.46197
Epoch: 2/10, step: 31979, training_loss: 0.91542
Epoch: 2/10, step: 31999, training_loss: 1.70275
accuracy: 0.55, validation_loss: 1.3204556703567505, num_samples: 100
Epoch: 2/10, step: 32019, training_loss: 1.46625
Epoch: 2/10, step: 32039, training_loss: 1.01285
Epoch: 2/10, step: 32059, training_loss: 1.75121
Epoch: 2/10, step: 32079, training_loss: 1.83701
Epoch: 2/10, step: 32099, training_loss: 1.25384
Epoch: 2/10, step: 32119, training_loss: 1.60003
Epoch: 2/10, step: 32139, training_loss: 1.12766
Epoch: 2/10, step: 32159, training_loss: 1.77412
Epoch: 2/10, step: 32179, training_loss: 1.65492
Epoch: 2/10, step: 32199, training_loss: 1.77818
Epoch: 2/10, step: 32219, training_loss: 1.37672
Epoch: 2/10, step: 32239, training_loss: 1.73683
Epoch: 2/10, step: 32259, training_loss: 1.43153
Epoch: 2/10, step: 32279, training_loss: 2.06259
Epoch: 2/10, step: 32299, training_loss: 1.73571
Epoch: 2/10, step: 32319, training_loss: 1.57185
Epoch: 2/10, step: 32339, training_loss: 1.63377
Epoch: 2/10, step: 32359, training_loss: 1.20481
Epoch: 2/10, step: 32379, training_loss: 1.29624
Epoch: 2/10, step: 32399, training_loss: 1.07857
Epoch: 2/10, step: 32419, training_loss: 2.10315
Epoch: 2/10, step: 32439, training_loss: 1.15907
Epoch: 2/10, step: 32459, training_loss: 1.31598
Epoch: 2/10, step: 32479, training_loss: 1.06243
Epoch: 2/10, step: 32499, training_loss: 1.24061
Epoch: 2/10, step: 32519, training_loss: 1.19499
Epoch: 2/10, step: 32539, training_loss: 1.05801
Epoch: 2/10, step: 32559, training_loss: 1.38814
Epoch: 2/10, step: 32579, training_loss: 1.62298
Epoch: 2/10, step: 32599, training_loss: 1.12334
Epoch: 2/10, step: 32619, training_loss: 1.25182
Epoch: 2/10, step: 32639, training_loss: 1.01673
Epoch: 2/10, step: 32659, training_loss: 1.03342
Epoch: 2/10, step: 32679, training_loss: 0.65342
Epoch: 2/10, step: 32699, training_loss: 0.93772
Epoch: 2/10, step: 32719, training_loss: 1.34452
Epoch: 2/10, step: 32739, training_loss: 1.31378
Epoch: 2/10, step: 32759, training_loss: 1.56003
Epoch: 2/10, step: 32779, training_loss: 1.52152
Epoch: 2/10, step: 32799, training_loss: 1.21402
Epoch: 2/10, step: 32819, training_loss: 1.12708
Epoch: 2/10, step: 32839, training_loss: 1.63417
Epoch: 2/10, step: 32859, training_loss: 1.80095
Epoch: 2/10, step: 32879, training_loss: 1.13633
Epoch: 2/10, step: 32899, training_loss: 1.55753
Epoch: 2/10, step: 32919, training_loss: 1.63381
Epoch: 2/10, step: 32939, training_loss: 2.15147
Epoch: 2/10, step: 32959, training_loss: 1.64395
Epoch: 2/10, step: 32979, training_loss: 1.40108
Epoch: 2/10, step: 32999, training_loss: 1.72970
accuracy: 0.49, validation_loss: 1.5065693855285645, num_samples: 100
Epoch: 2/10, step: 33019, training_loss: 1.85873
Epoch: 2/10, step: 33039, training_loss: 1.19625
Epoch: 2/10, step: 33059, training_loss: 1.12360
Epoch: 2/10, step: 33079, training_loss: 0.94097
Epoch: 2/10, step: 33099, training_loss: 1.41002
Epoch: 2/10, step: 33119, training_loss: 1.83631
Epoch: 2/10, step: 33139, training_loss: 1.48708
Epoch: 2/10, step: 33159, training_loss: 1.61995
Epoch: 2/10, step: 33179, training_loss: 1.08100
Epoch: 2/10, step: 33199, training_loss: 0.86061
Epoch: 2/10, step: 33219, training_loss: 1.03036
Epoch: 2/10, step: 33239, training_loss: 1.08260
Epoch: 2/10, step: 33259, training_loss: 1.10561
Epoch: 2/10, step: 33279, training_loss: 1.15369
Epoch: 2/10, step: 33299, training_loss: 1.17633
Epoch: 2/10, step: 33319, training_loss: 2.04261
Epoch: 2/10, step: 33339, training_loss: 1.42575
Epoch: 2/10, step: 33359, training_loss: 1.50916
Epoch: 2/10, step: 33379, training_loss: 1.55617
Epoch: 2/10, step: 33399, training_loss: 1.19016
Epoch: 2/10, step: 33419, training_loss: 1.66955
Epoch: 2/10, step: 33439, training_loss: 1.42252
Epoch: 2/10, step: 33459, training_loss: 1.61149
Epoch: 2/10, step: 33479, training_loss: 1.75314
Epoch: 2/10, step: 33499, training_loss: 1.42539
Epoch: 2/10, step: 33519, training_loss: 1.43219
Epoch: 2/10, step: 33539, training_loss: 1.43854
Epoch: 2/10, step: 33559, training_loss: 1.49252
Epoch: 2/10, step: 33579, training_loss: 2.11976
Epoch: 2/10, step: 33599, training_loss: 1.49593
Epoch: 2/10, step: 33619, training_loss: 1.35794
Epoch: 2/10, step: 33639, training_loss: 1.58774
Epoch: 2/10, step: 33659, training_loss: 1.82855
Epoch: 2/10, step: 33679, training_loss: 1.22288
Epoch: 2/10, step: 33699, training_loss: 0.88446
Epoch: 2/10, step: 33719, training_loss: 1.24026
Epoch: 2/10, step: 33739, training_loss: 1.23636
Epoch: 2/10, step: 33759, training_loss: 1.84355
Epoch: 2/10, step: 33779, training_loss: 1.70889
Epoch: 2/10, step: 33799, training_loss: 0.97442
Epoch: 2/10, step: 33819, training_loss: 1.12414
Epoch: 2/10, step: 33839, training_loss: 1.52714
Epoch: 2/10, step: 33859, training_loss: 1.32770
Epoch: 2/10, step: 33879, training_loss: 1.86425
Epoch: 2/10, step: 33899, training_loss: 1.46433
Epoch: 2/10, step: 33919, training_loss: 1.78195
Epoch: 2/10, step: 33939, training_loss: 1.54349
Epoch: 2/10, step: 33959, training_loss: 1.51705
Epoch: 2/10, step: 33979, training_loss: 1.20670
Epoch: 2/10, step: 33999, training_loss: 1.19319
accuracy: 0.53, validation_loss: 1.3803929090499878, num_samples: 100
Epoch: 2/10, step: 34019, training_loss: 1.42972
Epoch: 2/10, step: 34039, training_loss: 1.16286
Epoch: 2/10, step: 34059, training_loss: 2.11267
Epoch: 2/10, step: 34079, training_loss: 1.39435
Epoch: 2/10, step: 34099, training_loss: 1.99364
Epoch: 2/10, step: 34119, training_loss: 0.90353
Epoch: 2/10, step: 34139, training_loss: 1.86949
Epoch: 2/10, step: 34159, training_loss: 1.75696
Epoch: 2/10, step: 34179, training_loss: 1.05801
Epoch: 2/10, step: 34199, training_loss: 1.57787
Epoch: 2/10, step: 34219, training_loss: 1.15643
Epoch: 2/10, step: 34239, training_loss: 1.23505
Epoch: 2/10, step: 34259, training_loss: 1.27415
Epoch: 2/10, step: 34279, training_loss: 1.11277
Epoch: 2/10, step: 34299, training_loss: 1.67332
Epoch: 2/10, step: 34319, training_loss: 1.27181
Epoch: 2/10, step: 34339, training_loss: 1.46916
Epoch: 2/10, step: 34359, training_loss: 1.12794
Epoch: 2/10, step: 34379, training_loss: 1.94428
Epoch: 2/10, step: 34399, training_loss: 2.26037
Epoch: 2/10, step: 34419, training_loss: 1.02331
Epoch: 2/10, step: 34439, training_loss: 1.37600
Epoch: 2/10, step: 34459, training_loss: 1.71093
Epoch: 2/10, step: 34479, training_loss: 1.65004
Epoch: 2/10, step: 34499, training_loss: 1.42157
Epoch: 2/10, step: 34519, training_loss: 1.03834
Epoch: 2/10, step: 34539, training_loss: 1.53633
Epoch: 2/10, step: 34559, training_loss: 1.01385
Epoch: 2/10, step: 34579, training_loss: 0.74654
Epoch: 2/10, step: 34599, training_loss: 2.45265
Epoch: 2/10, step: 34619, training_loss: 1.43335
Epoch: 2/10, step: 34639, training_loss: 1.69438
Epoch: 2/10, step: 34659, training_loss: 1.33293
Epoch: 2/10, step: 34679, training_loss: 1.85940
Epoch: 2/10, step: 34699, training_loss: 1.62798
Epoch: 2/10, step: 34719, training_loss: 1.22644
Epoch: 2/10, step: 34739, training_loss: 1.56325
Epoch: 2/10, step: 34759, training_loss: 1.94518
Epoch: 2/10, step: 34779, training_loss: 1.45369
Epoch: 2/10, step: 34799, training_loss: 2.08179
Epoch: 2/10, step: 34819, training_loss: 1.06274
Epoch: 2/10, step: 34839, training_loss: 1.97863
Epoch: 2/10, step: 34859, training_loss: 1.11099
Epoch: 2/10, step: 34879, training_loss: 1.45731
Epoch: 2/10, step: 34899, training_loss: 1.69853
Epoch: 2/10, step: 34919, training_loss: 1.75958
Epoch: 2/10, step: 34939, training_loss: 1.69925
Epoch: 2/10, step: 34959, training_loss: 1.37110
Epoch: 2/10, step: 34979, training_loss: 1.38061
Epoch: 2/10, step: 34999, training_loss: 1.58536
accuracy: 0.45, validation_loss: 1.5483653545379639, num_samples: 100
Epoch: 2/10, step: 35019, training_loss: 1.36920
Epoch: 2/10, step: 35039, training_loss: 0.83070
Epoch: 2/10, step: 35059, training_loss: 1.79241
Epoch: 2/10, step: 35079, training_loss: 1.53185
Epoch: 2/10, step: 35099, training_loss: 1.37249
Epoch: 2/10, step: 35119, training_loss: 1.45074
Epoch: 2/10, step: 35139, training_loss: 1.23585
Epoch: 2/10, step: 35159, training_loss: 0.93247
Epoch: 2/10, step: 35179, training_loss: 1.30478
Epoch: 2/10, step: 35199, training_loss: 0.77974
Epoch: 2/10, step: 35219, training_loss: 2.02289
Epoch: 2/10, step: 35239, training_loss: 1.64166
Epoch: 2/10, step: 35259, training_loss: 1.04681
Epoch: 2/10, step: 35279, training_loss: 1.38656
Epoch: 2/10, step: 35299, training_loss: 1.80285
Epoch: 2/10, step: 35319, training_loss: 1.46060
Epoch: 2/10, step: 35339, training_loss: 1.60649
Epoch: 2/10, step: 35359, training_loss: 1.75764
Epoch: 2/10, step: 35379, training_loss: 1.37288
Epoch: 2/10, step: 35399, training_loss: 0.73977
Epoch: 2/10, step: 35419, training_loss: 1.03288
Epoch: 2/10, step: 35439, training_loss: 0.86097
Epoch: 2/10, step: 35459, training_loss: 2.04790
Epoch: 2/10, step: 35479, training_loss: 1.31943
Epoch: 2/10, step: 35499, training_loss: 1.83502
Epoch: 2/10, step: 35519, training_loss: 2.00643
Epoch: 2/10, step: 35539, training_loss: 1.34329
Epoch: 2/10, step: 35559, training_loss: 1.87302
Epoch: 2/10, step: 35579, training_loss: 1.92596
Epoch: 2/10, step: 35599, training_loss: 1.49527
Epoch: 2/10, step: 35619, training_loss: 0.98722
Epoch: 2/10, step: 35639, training_loss: 1.51365
Epoch: 2/10, step: 35659, training_loss: 1.50263
Epoch: 2/10, step: 35679, training_loss: 0.99523
Epoch: 2/10, step: 35699, training_loss: 1.63970
Epoch: 2/10, step: 35719, training_loss: 1.35583
Epoch: 2/10, step: 35739, training_loss: 1.57137
Epoch: 2/10, step: 35759, training_loss: 1.92141
Epoch: 2/10, step: 35779, training_loss: 1.55513
Epoch: 2/10, step: 35799, training_loss: 1.33591
Epoch: 2/10, step: 35819, training_loss: 1.92115
Epoch: 2/10, step: 35839, training_loss: 0.65720
Epoch: 2/10, step: 35859, training_loss: 1.54201
Epoch: 2/10, step: 35879, training_loss: 1.55643
Epoch: 2/10, step: 35899, training_loss: 1.59726
Epoch: 2/10, step: 35919, training_loss: 1.61916
Epoch: 2/10, step: 35939, training_loss: 2.58670
Epoch: 2/10, step: 35959, training_loss: 1.33508
Epoch: 2/10, step: 35979, training_loss: 1.54644
Epoch: 2/10, step: 35999, training_loss: 1.21491
accuracy: 0.5, validation_loss: 1.4736911058425903, num_samples: 100
Epoch: 2/10, step: 36019, training_loss: 1.47243
Epoch: 2/10, step: 36039, training_loss: 0.98504
Epoch: 2/10, step: 36059, training_loss: 1.80386
Epoch: 2/10, step: 36079, training_loss: 1.37564
Epoch: 2/10, step: 36099, training_loss: 1.72845
Epoch: 2/10, step: 36119, training_loss: 1.59475
Epoch: 2/10, step: 36139, training_loss: 1.75084
Epoch: 2/10, step: 36159, training_loss: 1.58662
Epoch: 2/10, step: 36179, training_loss: 1.56887
Epoch: 2/10, step: 36199, training_loss: 0.89369
Epoch: 2/10, step: 36219, training_loss: 1.09933
Epoch: 2/10, step: 36239, training_loss: 1.03203
Epoch: 2/10, step: 36259, training_loss: 1.88680
Epoch: 2/10, step: 36279, training_loss: 1.26713
Epoch: 2/10, step: 36299, training_loss: 1.05940
Epoch: 2/10, step: 36319, training_loss: 1.30021
Epoch: 2/10, step: 36339, training_loss: 1.20352
Epoch: 2/10, step: 36359, training_loss: 1.50881
Epoch: 2/10, step: 36379, training_loss: 1.52144
Epoch: 2/10, step: 36399, training_loss: 1.00518
Epoch: 2/10, step: 36419, training_loss: 1.78374
Epoch: 2/10, step: 36439, training_loss: 1.42129
Epoch: 2/10, step: 36459, training_loss: 1.23788
Epoch: 2/10, step: 36479, training_loss: 1.49057
Epoch: 2/10, step: 36499, training_loss: 1.76687
Epoch: 2/10, step: 36519, training_loss: 1.48513
Epoch: 2/10, step: 36539, training_loss: 1.48044
Epoch: 2/10, step: 36559, training_loss: 1.87020
Epoch: 2/10, step: 36579, training_loss: 1.91913
Epoch: 2/10, step: 36599, training_loss: 0.95710
Epoch: 2/10, step: 36619, training_loss: 1.59092
Epoch: 2/10, step: 36639, training_loss: 1.58004
Epoch: 2/10, step: 36659, training_loss: 1.45706
Epoch: 2/10, step: 36679, training_loss: 1.45275
Epoch: 2/10, step: 36699, training_loss: 1.14648
Epoch: 2/10, step: 36719, training_loss: 1.57519
Epoch: 2/10, step: 36739, training_loss: 1.62836
Epoch: 2/10, step: 36759, training_loss: 2.07558
Epoch: 2/10, step: 36779, training_loss: 1.34078
Epoch: 2/10, step: 36799, training_loss: 0.91759
Epoch: 2/10, step: 36819, training_loss: 0.94777
Epoch: 2/10, step: 36839, training_loss: 1.80790
Epoch: 2/10, step: 36859, training_loss: 2.11327
Epoch: 2/10, step: 36879, training_loss: 1.58722
Epoch: 2/10, step: 36899, training_loss: 1.54511
Epoch: 2/10, step: 36919, training_loss: 1.81120
Epoch: 2/10, step: 36939, training_loss: 1.48408
Epoch: 2/10, step: 36959, training_loss: 2.20398
Epoch: 2/10, step: 36979, training_loss: 1.69988
Epoch: 2/10, step: 36999, training_loss: 2.08394
accuracy: 0.48, validation_loss: 1.4835275411605835, num_samples: 100
Epoch: 2/10, step: 37019, training_loss: 1.73624
Epoch: 2/10, step: 37039, training_loss: 1.56795
Epoch: 2/10, step: 37059, training_loss: 1.20411
Epoch: 2/10, step: 37079, training_loss: 1.88869
Epoch: 2/10, step: 37099, training_loss: 0.92252
Epoch: 2/10, step: 37119, training_loss: 1.49507
Epoch: 2/10, step: 37139, training_loss: 1.05505
Epoch: 2/10, step: 37159, training_loss: 1.00428
Epoch: 2/10, step: 37179, training_loss: 0.97418
Epoch: 2/10, step: 37199, training_loss: 1.75049
Epoch: 2/10, step: 37219, training_loss: 2.01237
Epoch: 2/10, step: 37239, training_loss: 1.57018
Epoch: 2/10, step: 37259, training_loss: 1.58448
Epoch: 2/10, step: 37279, training_loss: 1.68861
Epoch: 2/10, step: 37299, training_loss: 1.67832
Epoch: 2/10, step: 37319, training_loss: 1.62683
Epoch: 2/10, step: 37339, training_loss: 1.82189
Epoch: 2/10, step: 37359, training_loss: 0.99698
Epoch: 2/10, step: 37379, training_loss: 1.99495
Epoch: 2/10, step: 37399, training_loss: 1.31858
Epoch: 2/10, step: 37419, training_loss: 1.84505
Epoch: 2/10, step: 37439, training_loss: 1.38019
Epoch: 2/10, step: 37459, training_loss: 1.86127
Epoch: 2/10, step: 37479, training_loss: 1.23163
Epoch: 2/10, step: 37499, training_loss: 1.02607
Epoch: 2/10, step: 37519, training_loss: 1.68336
Epoch: 2/10, step: 37539, training_loss: 1.75591
Epoch: 2/10, step: 37559, training_loss: 1.02547
Epoch: 2/10, step: 37579, training_loss: 1.50066
Epoch: 2/10, step: 37599, training_loss: 1.38457
Epoch: 2/10, step: 37619, training_loss: 0.99177
Epoch: 2/10, step: 37639, training_loss: 2.10839
Epoch: 2/10, step: 37659, training_loss: 1.70709
Epoch: 2/10, step: 37679, training_loss: 1.33059
Epoch: 2/10, step: 37699, training_loss: 1.06639
Epoch: 2/10, step: 37719, training_loss: 1.77460
Epoch: 2/10, step: 37739, training_loss: 1.23481
Epoch: 2/10, step: 37759, training_loss: 1.88033
Epoch: 2/10, step: 37779, training_loss: 0.80563
Epoch: 2/10, step: 37799, training_loss: 1.48828
Epoch: 2/10, step: 37819, training_loss: 1.64769
Epoch: 2/10, step: 37839, training_loss: 1.16830
Epoch: 2/10, step: 37859, training_loss: 1.54794
Epoch: 2/10, step: 37879, training_loss: 1.89362
Epoch: 2/10, step: 37899, training_loss: 1.54643
Epoch: 2/10, step: 37919, training_loss: 0.95767
Epoch: 2/10, step: 37939, training_loss: 1.58637
Epoch: 2/10, step: 37959, training_loss: 1.75455
Epoch: 2/10, step: 37979, training_loss: 1.14583
Epoch: 2/10, step: 37999, training_loss: 1.35046
accuracy: 0.45, validation_loss: 1.585534691810608, num_samples: 100
Epoch: 2/10, step: 38019, training_loss: 1.33440
Epoch: 2/10, step: 38039, training_loss: 1.23073
Epoch: 2/10, step: 38059, training_loss: 1.54522
Epoch: 2/10, step: 38079, training_loss: 1.16029
Epoch: 2/10, step: 38099, training_loss: 1.56799
Epoch: 2/10, step: 38119, training_loss: 1.39403
Epoch: 2/10, step: 38139, training_loss: 1.40943
Epoch: 2/10, step: 38159, training_loss: 1.10188
Epoch: 2/10, step: 38179, training_loss: 1.50351
Epoch: 2/10, step: 38199, training_loss: 1.51512
Epoch: 2/10, step: 38219, training_loss: 0.94427
Epoch: 2/10, step: 38239, training_loss: 1.01208
Epoch: 2/10, step: 38259, training_loss: 1.31212
Epoch: 2/10, step: 38279, training_loss: 1.81602
Epoch: 2/10, step: 38299, training_loss: 1.19369
Epoch: 2/10, step: 38319, training_loss: 2.09574
Epoch: 2/10, step: 38339, training_loss: 1.54523
Epoch: 2/10, step: 38359, training_loss: 1.86931
Epoch: 2/10, step: 38379, training_loss: 1.68215
Epoch: 2/10, step: 38399, training_loss: 1.58760
Epoch: 2/10, step: 38419, training_loss: 1.36756
Epoch: 2/10, step: 38439, training_loss: 1.25655
Epoch: 2/10, step: 38459, training_loss: 1.21797
Epoch: 2/10, step: 38479, training_loss: 1.45265
Epoch: 2/10, step: 38499, training_loss: 1.48043
Epoch: 2/10, step: 38519, training_loss: 1.34451
Epoch: 2/10, step: 38539, training_loss: 1.29525
Epoch: 2/10, step: 38559, training_loss: 1.17217
Epoch: 2/10, step: 38579, training_loss: 1.86834
Epoch: 2/10, step: 38599, training_loss: 1.41562
Epoch: 2/10, step: 38619, training_loss: 1.12436
Epoch: 2/10, step: 38639, training_loss: 2.01061
Epoch: 2/10, step: 38659, training_loss: 1.73567
Epoch: 2/10, step: 38679, training_loss: 0.88001
Epoch: 2/10, step: 38699, training_loss: 1.50261
Epoch: 2/10, step: 38719, training_loss: 1.32560
Epoch: 2/10, step: 38739, training_loss: 1.53248
Epoch: 2/10, step: 38759, training_loss: 1.28763
Epoch: 2/10, step: 38779, training_loss: 1.39608
Epoch: 2/10, step: 38799, training_loss: 1.91830
Epoch: 2/10, step: 38819, training_loss: 1.05670
Epoch: 2/10, step: 38839, training_loss: 2.33691
Epoch: 2/10, step: 38859, training_loss: 1.42860
Epoch: 2/10, step: 38879, training_loss: 1.48584
Epoch: 2/10, step: 38899, training_loss: 1.54628
Epoch: 2/10, step: 38919, training_loss: 1.42185
Epoch: 2/10, step: 38939, training_loss: 1.16329
Epoch: 2/10, step: 38959, training_loss: 1.43197
Epoch: 2/10, step: 38979, training_loss: 1.62652
Epoch: 2/10, step: 38999, training_loss: 1.89739
accuracy: 0.52, validation_loss: 1.5263667106628418, num_samples: 100
Epoch: 2/10, step: 39019, training_loss: 1.49300
Epoch: 2/10, step: 39039, training_loss: 1.87049
Epoch: 2/10, step: 39059, training_loss: 1.71051
Epoch: 2/10, step: 39079, training_loss: 1.33849
Epoch: 2/10, step: 39099, training_loss: 1.43960
Epoch: 2/10, step: 39119, training_loss: 1.50406
Epoch: 2/10, step: 39139, training_loss: 1.88519
Epoch: 2/10, step: 39159, training_loss: 1.00247
Epoch: 2/10, step: 39179, training_loss: 1.17487
Epoch: 2/10, step: 39199, training_loss: 0.92942
Epoch: 2/10, step: 39219, training_loss: 1.39799
Epoch: 2/10, step: 39239, training_loss: 1.86626
Epoch: 2/10, step: 39259, training_loss: 2.16064
Epoch: 2/10, step: 39279, training_loss: 1.11398
Epoch: 2/10, step: 39299, training_loss: 1.64682
Epoch: 2/10, step: 39319, training_loss: 1.08291
Epoch: 2/10, step: 39339, training_loss: 1.66336
Epoch: 2/10, step: 39359, training_loss: 1.96045
Epoch: 2/10, step: 39379, training_loss: 1.77905
Epoch: 2/10, step: 39399, training_loss: 1.64861
Epoch: 2/10, step: 39419, training_loss: 1.14672
Epoch: 2/10, step: 39439, training_loss: 1.45776
Epoch: 2/10, step: 39459, training_loss: 0.88863
Epoch: 2/10, step: 39479, training_loss: 1.04457
Epoch: 2/10, step: 39499, training_loss: 1.58234
Epoch: 2/10, step: 39519, training_loss: 1.06201
Epoch: 2/10, step: 39539, training_loss: 1.90354
Epoch: 2/10, step: 39559, training_loss: 0.95956
Epoch: 2/10, step: 39579, training_loss: 0.86528
Epoch: 2/10, step: 39599, training_loss: 1.44766
Epoch: 2/10, step: 39619, training_loss: 1.23681
Epoch: 2/10, step: 39639, training_loss: 1.46262
Epoch: 2/10, step: 39659, training_loss: 1.14137
Epoch: 2/10, step: 39679, training_loss: 1.62271
Epoch: 2/10, step: 39699, training_loss: 1.08198
Epoch: 2/10, step: 39719, training_loss: 1.57029
Epoch: 2/10, step: 39739, training_loss: 1.62725
Epoch: 2/10, step: 39759, training_loss: 1.00752
Epoch: 2/10, step: 39779, training_loss: 1.36193
Epoch: 2/10, step: 39799, training_loss: 1.56751
Epoch: 2/10, step: 39819, training_loss: 1.84490
Epoch: 2/10, step: 39839, training_loss: 2.21240
Epoch: 2/10, step: 39859, training_loss: 1.06458
Epoch: 2/10, step: 39879, training_loss: 0.85574
Epoch: 2/10, step: 39899, training_loss: 1.56361
Epoch: 2/10, step: 39919, training_loss: 1.19291
Epoch: 2/10, step: 39939, training_loss: 1.65819
Epoch: 2/10, step: 39959, training_loss: 1.64049
Epoch: 2/10, step: 39979, training_loss: 1.10566
Epoch: 2/10, step: 39999, training_loss: 1.11593
accuracy: 0.53, validation_loss: 1.296902060508728, num_samples: 100
Epoch: 2/10, step: 40019, training_loss: 2.47998
Epoch: 2/10, step: 40039, training_loss: 1.79216
Epoch: 2/10, step: 40059, training_loss: 1.43688
Epoch: 2/10, step: 40079, training_loss: 1.77166
Epoch: 2/10, step: 40099, training_loss: 1.19604
Epoch: 2/10, step: 40119, training_loss: 1.49385
Epoch: 2/10, step: 40139, training_loss: 1.16261
Epoch: 2/10, step: 40159, training_loss: 2.02965
Epoch: 2/10, step: 40179, training_loss: 1.33268
Epoch: 2/10, step: 40199, training_loss: 1.36132
Epoch: 2/10, step: 40219, training_loss: 1.45108
Epoch: 2/10, step: 40239, training_loss: 1.58725
Epoch: 2/10, step: 40259, training_loss: 1.40183
Epoch: 2/10, step: 40279, training_loss: 1.86227
Epoch: 2/10, step: 40299, training_loss: 1.58399
Epoch: 2/10, step: 40319, training_loss: 1.20887
Epoch: 2/10, step: 40339, training_loss: 1.26134
Epoch: 2/10, step: 40359, training_loss: 1.40579
Epoch: 2/10, step: 40379, training_loss: 1.63612
Epoch: 2/10, step: 40399, training_loss: 0.87823
Epoch: 2/10, step: 40419, training_loss: 1.20932
Epoch: 2/10, step: 40439, training_loss: 1.61471
Epoch: 2/10, step: 40459, training_loss: 0.99187
Epoch: 2/10, step: 40479, training_loss: 1.00596
Epoch: 2/10, step: 40499, training_loss: 0.84906
Epoch: 2/10, step: 40519, training_loss: 1.17964
Epoch: 2/10, step: 40539, training_loss: 0.94080
Epoch: 2/10, step: 40559, training_loss: 1.75159
Epoch: 2/10, step: 40579, training_loss: 2.06646
Epoch: 2/10, step: 40599, training_loss: 1.30642
Epoch: 2/10, step: 40619, training_loss: 1.48030
Epoch: 2/10, step: 40639, training_loss: 0.85986
Epoch: 2/10, step: 40659, training_loss: 1.45199
Epoch: 2/10, step: 40679, training_loss: 1.39918
Epoch: 2/10, step: 40699, training_loss: 1.30374
Epoch: 2/10, step: 40719, training_loss: 1.78706
Epoch: 2/10, step: 40739, training_loss: 1.27174
Epoch: 2/10, step: 40759, training_loss: 1.57046
Epoch: 2/10, step: 40779, training_loss: 1.24746
Epoch: 2/10, step: 40799, training_loss: 1.47631
Epoch: 2/10, step: 40819, training_loss: 1.94130
Epoch: 2/10, step: 40839, training_loss: 1.44706
Epoch: 2/10, step: 40859, training_loss: 1.55905
Epoch: 2/10, step: 40879, training_loss: 1.39198
Epoch: 2/10, step: 40899, training_loss: 0.94281
Epoch: 2/10, step: 40919, training_loss: 1.27021
Epoch: 2/10, step: 40939, training_loss: 1.49576
Epoch: 2/10, step: 40959, training_loss: 1.62309
Epoch: 2/10, step: 40979, training_loss: 1.02549
Epoch: 2/10, step: 40999, training_loss: 1.06061
accuracy: 0.54, validation_loss: 1.3015425205230713, num_samples: 100
Epoch: 2/10, step: 41019, training_loss: 1.40934
Epoch: 2/10, step: 41039, training_loss: 1.79318
Epoch: 2/10, step: 41059, training_loss: 1.80276
Epoch: 2/10, step: 41079, training_loss: 1.11677
Epoch: 2/10, step: 41099, training_loss: 1.16697
Epoch: 2/10, step: 41119, training_loss: 1.50126
Epoch: 2/10, step: 41139, training_loss: 0.87491
Epoch: 2/10, step: 41159, training_loss: 1.32945
Epoch: 2/10, step: 41179, training_loss: 2.05638
Epoch: 2/10, step: 41199, training_loss: 1.43046
Epoch: 2/10, step: 41219, training_loss: 0.96912
Epoch: 2/10, step: 41239, training_loss: 1.50882
Epoch: 2/10, step: 41259, training_loss: 1.11651
Epoch: 2/10, step: 41279, training_loss: 1.04969
Epoch: 2/10, step: 41299, training_loss: 1.47460
Epoch: 2/10, step: 41319, training_loss: 1.54029
Epoch: 2/10, step: 41339, training_loss: 1.54372
Epoch: 2/10, step: 41359, training_loss: 1.33978
Epoch: 2/10, step: 41379, training_loss: 1.49328
Epoch: 2/10, step: 41399, training_loss: 0.93541
Epoch: 2/10, step: 41419, training_loss: 0.92884
Epoch: 2/10, step: 41439, training_loss: 1.00513
Epoch: 2/10, step: 41459, training_loss: 0.81204
Epoch: 2/10, step: 41479, training_loss: 1.84255
Epoch: 2/10, step: 41499, training_loss: 0.67970
Epoch: 2/10, step: 41519, training_loss: 1.08245
Epoch: 2/10, step: 41539, training_loss: 1.53040
Epoch: 2/10, step: 41559, training_loss: 1.49354
Epoch: 2/10, step: 41579, training_loss: 1.60423
Epoch: 2/10, step: 41599, training_loss: 0.98918
Epoch: 2/10, step: 41619, training_loss: 1.43728
Epoch: 2/10, step: 41639, training_loss: 1.46070
Epoch: 2/10, step: 41659, training_loss: 0.97770
Epoch: 2/10, step: 41679, training_loss: 1.01792
Epoch: 2/10, step: 41699, training_loss: 1.39625
Epoch: 2/10, step: 41719, training_loss: 1.51841
Epoch: 2/10, step: 41739, training_loss: 1.70809
Epoch: 2/10, step: 41759, training_loss: 1.52424
Epoch: 2/10, step: 41779, training_loss: 1.63498
Epoch: 2/10, step: 41799, training_loss: 1.83721
Epoch: 2/10, step: 41819, training_loss: 1.39927
Epoch: 2/10, step: 41839, training_loss: 2.14870
Epoch: 2/10, step: 41859, training_loss: 0.99286
Epoch: 2/10, step: 41879, training_loss: 2.23657
Epoch: 2/10, step: 41899, training_loss: 1.53260
Epoch: 2/10, step: 41919, training_loss: 1.14149
Epoch: 2/10, step: 41939, training_loss: 1.97030
Epoch: 2/10, step: 41959, training_loss: 0.76050
Epoch: 2/10, step: 41979, training_loss: 0.96376
Epoch: 2/10, step: 41999, training_loss: 1.34355
accuracy: 0.48, validation_loss: 1.4299490451812744, num_samples: 100
Epoch: 2/10, step: 42019, training_loss: 2.15928
Epoch: 2/10, step: 42039, training_loss: 1.36568
Epoch: 2/10, step: 42059, training_loss: 1.39989
Epoch: 2/10, step: 42079, training_loss: 1.24747
Epoch: 2/10, step: 42099, training_loss: 1.58547
Epoch: 2/10, step: 42119, training_loss: 1.22094
Epoch: 2/10, step: 42139, training_loss: 1.08432
Epoch: 2/10, step: 42159, training_loss: 1.38968
Epoch: 2/10, step: 42179, training_loss: 1.13454
Epoch: 2/10, step: 42199, training_loss: 1.66798
Epoch: 2/10, step: 42219, training_loss: 1.58663
Epoch: 2/10, step: 42239, training_loss: 2.13258
Epoch: 2/10, step: 42259, training_loss: 1.98430
Epoch: 2/10, step: 42279, training_loss: 2.26266
Epoch: 2/10, step: 42299, training_loss: 1.37411
Epoch: 2/10, step: 42319, training_loss: 1.52591
Epoch: 2/10, step: 42339, training_loss: 2.05307
Epoch: 2/10, step: 42359, training_loss: 1.28444
Epoch: 2/10, step: 42379, training_loss: 1.10359
Epoch: 2/10, step: 42399, training_loss: 1.82503
Epoch: 2/10, step: 42419, training_loss: 1.45199
Epoch: 2/10, step: 42439, training_loss: 1.26947
Epoch: 2/10, step: 42459, training_loss: 1.32473
Epoch: 2/10, step: 42479, training_loss: 0.97499
Epoch: 2/10, step: 42499, training_loss: 1.01384
Epoch: 2/10, step: 42519, training_loss: 1.11703
Epoch: 2/10, step: 42539, training_loss: 1.33394
Epoch: 2/10, step: 42559, training_loss: 1.19333
Epoch: 2/10, step: 42579, training_loss: 1.81632
Epoch: 2/10, step: 42599, training_loss: 1.64679
Epoch: 2/10, step: 42619, training_loss: 1.25277
Epoch: 2/10, step: 42639, training_loss: 1.54784
Epoch: 2/10, step: 42659, training_loss: 1.86678
Epoch: 2/10, step: 42679, training_loss: 1.22455
Epoch: 2/10, step: 42699, training_loss: 1.78843
Epoch: 2/10, step: 42719, training_loss: 0.99327
Epoch: 2/10, step: 42739, training_loss: 1.95355
Epoch: 2/10, step: 42759, training_loss: 1.30389
Epoch: 2/10, step: 42779, training_loss: 0.84991
Epoch: 2/10, step: 42799, training_loss: 1.28737
Epoch: 2/10, step: 42819, training_loss: 1.43601
Epoch: 2/10, step: 42839, training_loss: 1.25698
Epoch: 2/10, step: 42859, training_loss: 1.24202
Epoch: 2/10, step: 42879, training_loss: 1.33931
Epoch: 2/10, step: 42899, training_loss: 0.75000
Epoch: 2/10, step: 42919, training_loss: 1.58166
Epoch: 2/10, step: 42939, training_loss: 1.33629
Epoch: 2/10, step: 42959, training_loss: 1.61389
Epoch: 2/10, step: 42979, training_loss: 1.97058
Epoch: 2/10, step: 42999, training_loss: 0.67749
accuracy: 0.53, validation_loss: 1.3042265176773071, num_samples: 100
Epoch: 2/10, step: 43019, training_loss: 1.34675
Epoch: 2/10, step: 43039, training_loss: 1.37756
Epoch: 2/10, step: 43059, training_loss: 1.50407
Epoch: 2/10, step: 43079, training_loss: 0.90151
Epoch: 2/10, step: 43099, training_loss: 1.29621
Epoch: 2/10, step: 43119, training_loss: 1.37028
Epoch: 2/10, step: 43139, training_loss: 1.41938
Epoch: 2/10, step: 43159, training_loss: 0.99959
Epoch: 2/10, step: 43179, training_loss: 1.70092
Epoch: 2/10, step: 43199, training_loss: 1.49548
Epoch: 2/10, step: 43219, training_loss: 1.53834
Epoch: 2/10, step: 43239, training_loss: 2.48627
Epoch: 2/10, step: 43259, training_loss: 1.39466
Epoch: 2/10, step: 43279, training_loss: 2.12002
Epoch: 2/10, step: 43299, training_loss: 1.16085
Epoch: 2/10, step: 43319, training_loss: 1.17417
Epoch: 2/10, step: 43339, training_loss: 1.79452
Epoch: 2/10, step: 43359, training_loss: 1.25796
Epoch: 2/10, step: 43379, training_loss: 2.08061
Epoch: 2/10, step: 43399, training_loss: 1.24821
Epoch: 2/10, step: 43419, training_loss: 1.32110
Epoch: 2/10, step: 43439, training_loss: 2.03438
Epoch: 2/10, step: 43459, training_loss: 1.22769
Epoch: 2/10, step: 43479, training_loss: 1.55256
Epoch: 2/10, step: 43499, training_loss: 2.03817
Epoch: 2/10, step: 43519, training_loss: 1.56024
Epoch: 2/10, step: 43539, training_loss: 1.59434
Epoch: 2/10, step: 43559, training_loss: 1.12041
Epoch: 2/10, step: 43579, training_loss: 1.44614
Epoch: 2/10, step: 43599, training_loss: 1.52711
Epoch: 2/10, step: 43619, training_loss: 2.05043
Epoch: 2/10, step: 43639, training_loss: 0.89772
Epoch: 2/10, step: 43659, training_loss: 1.44246
Epoch: 2/10, step: 43679, training_loss: 1.50006
Epoch: 2/10, step: 43699, training_loss: 1.38484
Epoch: 2/10, step: 43719, training_loss: 1.15471
Epoch: 2/10, step: 43739, training_loss: 1.33181
Epoch: 2/10, step: 43759, training_loss: 1.75982
Epoch: 2/10, step: 43779, training_loss: 1.12684
Epoch: 2/10, step: 43799, training_loss: 0.63149
Epoch: 2/10, step: 43819, training_loss: 1.71768
Epoch: 2/10, step: 43839, training_loss: 2.23203
Epoch: 2/10, step: 43859, training_loss: 1.02647
Epoch: 2/10, step: 43879, training_loss: 1.28134
Epoch: 2/10, step: 43899, training_loss: 1.06983
Epoch: 2/10, step: 43919, training_loss: 1.29334
Epoch: 2/10, step: 43939, training_loss: 1.61653
Epoch: 2/10, step: 43959, training_loss: 1.64834
Epoch: 2/10, step: 43979, training_loss: 1.65808
Epoch: 2/10, step: 43999, training_loss: 1.02534
accuracy: 0.51, validation_loss: 1.4529995918273926, num_samples: 100
Epoch: 2/10, step: 44019, training_loss: 1.39216
Epoch: 2/10, step: 44039, training_loss: 1.73671
Epoch: 2/10, step: 44059, training_loss: 1.54424
Epoch: 2/10, step: 44079, training_loss: 1.85475
Epoch: 2/10, step: 44099, training_loss: 1.57416
Epoch: 2/10, step: 44119, training_loss: 0.72306
Epoch: 2/10, step: 44139, training_loss: 1.53891
Epoch: 2/10, step: 44159, training_loss: 1.37593
Epoch: 2/10, step: 44179, training_loss: 1.89650
Epoch: 2/10, step: 44199, training_loss: 0.78158
Epoch: 2/10, step: 44219, training_loss: 1.83356
Epoch: 2/10, step: 44239, training_loss: 0.97938
Epoch: 2/10, step: 44259, training_loss: 1.56495
Epoch: 2/10, step: 44279, training_loss: 1.09944
Epoch: 2/10, step: 44299, training_loss: 1.74696
Epoch: 2/10, step: 44319, training_loss: 1.39690
Epoch: 2/10, step: 44339, training_loss: 1.53618
Epoch: 2/10, step: 44359, training_loss: 1.54307
Epoch: 2/10, step: 44379, training_loss: 1.61728
Epoch: 2/10, step: 44399, training_loss: 1.40482
Epoch: 2/10, step: 44419, training_loss: 1.26581
Epoch: 2/10, step: 44439, training_loss: 1.76644
Epoch: 2/10, step: 44459, training_loss: 2.06789
Epoch: 2/10, step: 44479, training_loss: 1.62550
Epoch: 2/10, step: 44499, training_loss: 1.02757
Epoch: 2/10, step: 44519, training_loss: 2.01823
Epoch: 2/10, step: 44539, training_loss: 1.72296
Epoch: 2/10, step: 44559, training_loss: 1.55995
Epoch: 2/10, step: 44579, training_loss: 1.83948
Epoch: 2/10, step: 44599, training_loss: 1.53559
Epoch: 2/10, step: 44619, training_loss: 0.94472
Epoch: 2/10, step: 44639, training_loss: 1.61543
Epoch: 2/10, step: 44659, training_loss: 1.73592
Epoch: 2/10, step: 44679, training_loss: 1.31853
Epoch: 2/10, step: 44699, training_loss: 1.09115
Epoch: 2/10, step: 44719, training_loss: 1.50605
Epoch: 2/10, step: 44739, training_loss: 1.13477
Epoch: 2/10, step: 44759, training_loss: 1.10332
Epoch: 2/10, step: 44779, training_loss: 1.14928
Epoch: 2/10, step: 44799, training_loss: 1.48414
Epoch: 2/10, step: 44819, training_loss: 1.15032
Epoch: 2/10, step: 44839, training_loss: 1.99831
Epoch: 2/10, step: 44859, training_loss: 1.30748
Epoch: 2/10, step: 44879, training_loss: 1.66044
Epoch: 2/10, step: 44899, training_loss: 1.48898
Epoch: 2/10, step: 44919, training_loss: 1.39442
Epoch: 2/10, step: 44939, training_loss: 1.28853
Epoch: 2/10, step: 44959, training_loss: 1.84715
Epoch: 2/10, step: 44979, training_loss: 1.28955
Epoch: 2/10, step: 44999, training_loss: 1.26597
accuracy: 0.49, validation_loss: 1.2927783727645874, num_samples: 100
Epoch: 2/10, step: 45019, training_loss: 1.31744
Epoch: 2/10, step: 45039, training_loss: 2.30105
Epoch: 2/10, step: 45059, training_loss: 1.71508
Epoch: 2/10, step: 45079, training_loss: 1.37019
Epoch: 2/10, step: 45099, training_loss: 1.02778
Epoch: 2/10, step: 45119, training_loss: 1.69071
Epoch: 2/10, step: 45139, training_loss: 1.44171
Epoch: 2/10, step: 45159, training_loss: 1.70868
Epoch: 2/10, step: 45179, training_loss: 0.81707
Epoch: 2/10, step: 45199, training_loss: 1.27246
Epoch: 2/10, step: 45219, training_loss: 1.13877
Epoch: 2/10, step: 45239, training_loss: 1.40918
Epoch: 2/10, step: 45259, training_loss: 2.00550
Epoch: 2/10, step: 45279, training_loss: 1.63256
Epoch: 2/10, step: 45299, training_loss: 1.16128
Epoch: 2/10, step: 45319, training_loss: 0.99610
Epoch: 2/10, step: 45339, training_loss: 1.10049
Epoch: 2/10, step: 45359, training_loss: 1.19425
Epoch: 2/10, step: 45379, training_loss: 1.00536
Epoch: 2/10, step: 45399, training_loss: 0.84390
Epoch: 2/10, step: 45419, training_loss: 0.94642
Epoch: 2/10, step: 45439, training_loss: 1.48453
Epoch: 2/10, step: 45459, training_loss: 1.36110
Epoch: 2/10, step: 45479, training_loss: 2.45092
Epoch: 2/10, step: 45499, training_loss: 1.61267
Epoch: 2/10, step: 45519, training_loss: 1.19537
Epoch: 2/10, step: 45539, training_loss: 1.17607
Epoch: 2/10, step: 45559, training_loss: 1.97308
Epoch: 2/10, step: 45579, training_loss: 1.50669
Epoch: 2/10, step: 45599, training_loss: 1.65851
Epoch: 2/10, step: 45619, training_loss: 1.72690
Epoch: 2/10, step: 45639, training_loss: 1.77239
Epoch: 2/10, step: 45659, training_loss: 1.47171
Epoch: 2/10, step: 45679, training_loss: 1.71003
Epoch: 2/10, step: 45699, training_loss: 1.09098
Epoch: 2/10, step: 45719, training_loss: 1.25277
Epoch: 2/10, step: 45739, training_loss: 1.15990
Epoch: 2/10, step: 45759, training_loss: 1.50325
Epoch: 2/10, step: 45779, training_loss: 1.84628
Epoch: 2/10, step: 45799, training_loss: 1.83025
Epoch: 2/10, step: 45819, training_loss: 1.62864
Epoch: 2/10, step: 45839, training_loss: 1.71106
Epoch: 2/10, step: 45859, training_loss: 1.41663
Epoch: 2/10, step: 45879, training_loss: 0.67249
Epoch: 2/10, step: 45899, training_loss: 1.26136
Epoch: 2/10, step: 45919, training_loss: 0.77407
Epoch: 2/10, step: 45939, training_loss: 2.06905
Epoch: 2/10, step: 45959, training_loss: 1.03622
Epoch: 2/10, step: 45979, training_loss: 2.25599
Epoch: 2/10, step: 45999, training_loss: 1.36288
accuracy: 0.55, validation_loss: 1.3361527919769287, num_samples: 100
Epoch: 2/10, step: 46019, training_loss: 1.29679
Epoch: 2/10, step: 46039, training_loss: 0.93395
Epoch: 2/10, step: 46059, training_loss: 1.32690
Epoch: 2/10, step: 46079, training_loss: 1.72110
Epoch: 2/10, step: 46099, training_loss: 1.47100
Epoch: 2/10, step: 46119, training_loss: 1.22309
Epoch: 2/10, step: 46139, training_loss: 1.09944
Epoch: 2/10, step: 46159, training_loss: 2.02124
Epoch: 2/10, step: 46179, training_loss: 1.24721
Epoch: 2/10, step: 46199, training_loss: 1.33873
Epoch: 2/10, step: 46219, training_loss: 1.11843
Epoch: 2/10, step: 46239, training_loss: 1.39515
Epoch: 2/10, step: 46259, training_loss: 1.21030
Epoch: 2/10, step: 46279, training_loss: 2.17958
Epoch: 2/10, step: 46299, training_loss: 1.91345
Epoch: 2/10, step: 46319, training_loss: 1.34977
Epoch: 2/10, step: 46339, training_loss: 1.30898
Epoch: 2/10, step: 46359, training_loss: 1.02440
Epoch: 2/10, step: 46379, training_loss: 1.36287
Epoch: 2/10, step: 46399, training_loss: 1.53896
Epoch: 2/10, step: 46419, training_loss: 1.16452
Epoch: 2/10, step: 46439, training_loss: 1.34109
Epoch: 2/10, step: 46459, training_loss: 0.73790
Epoch: 2/10, step: 46479, training_loss: 1.19180
Epoch: 2/10, step: 46499, training_loss: 1.72226
Epoch: 2/10, step: 46519, training_loss: 1.61099
Epoch: 2/10, step: 46539, training_loss: 2.35352
Epoch: 2/10, step: 46559, training_loss: 1.68035
Epoch: 2/10, step: 46579, training_loss: 1.10933
Epoch: 2/10, step: 46599, training_loss: 1.49080
Epoch: 2/10, step: 46619, training_loss: 1.28478
Epoch: 2/10, step: 46639, training_loss: 1.39389
Epoch: 2/10, step: 46659, training_loss: 1.15070
Epoch: 2/10, step: 46679, training_loss: 0.86767
Epoch: 2/10, step: 46699, training_loss: 1.75944
Epoch: 2/10, step: 46719, training_loss: 1.25295
Epoch: 2/10, step: 46739, training_loss: 1.43196
Epoch: 2/10, step: 46759, training_loss: 0.95593
Epoch: 2/10, step: 46779, training_loss: 1.53993
Epoch: 2/10, step: 46799, training_loss: 1.18177
Epoch: 2/10, step: 46819, training_loss: 1.29653
Epoch: 2/10, step: 46839, training_loss: 1.64053
Epoch: 2/10, step: 46859, training_loss: 1.83721
Epoch: 2/10, step: 46879, training_loss: 0.92765
Epoch: 2/10, step: 46899, training_loss: 1.18876
Epoch: 2/10, step: 46919, training_loss: 1.61598
Epoch: 2/10, step: 46939, training_loss: 1.92304
Epoch: 2/10, step: 46959, training_loss: 1.50422
Epoch: 2/10, step: 46979, training_loss: 1.45497
Epoch: 2/10, step: 46999, training_loss: 1.29699
accuracy: 0.49, validation_loss: 1.4224072694778442, num_samples: 100
Epoch: 2/10, step: 47019, training_loss: 1.53390
Epoch: 2/10, step: 47039, training_loss: 1.15254
Epoch: 2/10, step: 47059, training_loss: 1.31970
Epoch: 2/10, step: 47079, training_loss: 1.64421
Epoch: 2/10, step: 47099, training_loss: 1.18998
Epoch: 2/10, step: 47119, training_loss: 1.46110
Epoch: 2/10, step: 47139, training_loss: 1.33094
Epoch: 2/10, step: 47159, training_loss: 1.42122
Epoch: 2/10, step: 47179, training_loss: 1.36360
Epoch: 2/10, step: 47199, training_loss: 1.47258
Epoch: 2/10, step: 47219, training_loss: 1.08277
Epoch: 2/10, step: 47239, training_loss: 1.61779
Epoch: 2/10, step: 47259, training_loss: 2.24660
Epoch: 2/10, step: 47279, training_loss: 1.90079
Epoch: 2/10, step: 47299, training_loss: 1.41252
Epoch: 2/10, step: 47319, training_loss: 1.54326
Epoch: 2/10, step: 47339, training_loss: 1.56021
Epoch: 2/10, step: 47359, training_loss: 1.56214
Epoch: 2/10, step: 47379, training_loss: 1.74677
Epoch: 2/10, step: 47399, training_loss: 1.52437
Epoch: 2/10, step: 47419, training_loss: 1.74679
Epoch: 2/10, step: 47439, training_loss: 0.98763
Epoch: 2/10, step: 47459, training_loss: 1.12821
Epoch: 2/10, step: 47479, training_loss: 1.34822
Epoch: 2/10, step: 47499, training_loss: 1.52054
Epoch: 2/10, step: 47519, training_loss: 0.86888
Epoch: 2/10, step: 47539, training_loss: 0.95573
Epoch: 2/10, step: 47559, training_loss: 0.68506
Epoch: 2/10, step: 47579, training_loss: 1.17586
Epoch: 2/10, step: 47599, training_loss: 1.68249
Epoch: 2/10, step: 47619, training_loss: 1.59427
Epoch: 2/10, step: 47639, training_loss: 2.24434
Epoch: 2/10, step: 47659, training_loss: 2.30409
Epoch: 2/10, step: 47679, training_loss: 1.27404
Epoch: 2/10, step: 47699, training_loss: 1.13902
Epoch: 2/10, step: 47719, training_loss: 1.22379
Epoch: 2/10, step: 47739, training_loss: 0.80547
Epoch: 2/10, step: 47759, training_loss: 1.18057
Epoch: 2/10, step: 47779, training_loss: 1.10576
Epoch: 2/10, step: 47799, training_loss: 1.22880
Epoch: 2/10, step: 47819, training_loss: 1.41237
Epoch: 2/10, step: 47839, training_loss: 1.25669
Epoch: 2/10, step: 47859, training_loss: 1.00550
Epoch: 2/10, step: 47879, training_loss: 1.99901
Epoch: 2/10, step: 47899, training_loss: 1.43995
Epoch: 2/10, step: 47919, training_loss: 1.20182
Epoch: 2/10, step: 47939, training_loss: 1.62090
Epoch: 2/10, step: 47959, training_loss: 1.47357
Epoch: 2/10, step: 47979, training_loss: 1.47263
Epoch: 2/10, step: 47999, training_loss: 1.25428
accuracy: 0.53, validation_loss: 1.4248957633972168, num_samples: 100
Epoch: 2/10, step: 48019, training_loss: 1.43920
Epoch: 2/10, step: 48039, training_loss: 1.19217
Epoch: 2/10, step: 48059, training_loss: 1.25345
Epoch: 2/10, step: 48079, training_loss: 1.57485
Epoch: 2/10, step: 48099, training_loss: 2.13957
Epoch: 2/10, step: 48119, training_loss: 1.16981
Epoch: 2/10, step: 48139, training_loss: 1.39875
Epoch: 2/10, step: 48159, training_loss: 1.73625
Epoch: 2/10, step: 48179, training_loss: 2.32843
Epoch: 2/10, step: 48199, training_loss: 1.69402
Epoch: 2/10, step: 48219, training_loss: 2.18920
Epoch: 2/10, step: 48239, training_loss: 1.46979
Epoch: 2/10, step: 48259, training_loss: 0.72291
Epoch: 2/10, step: 48279, training_loss: 1.20093
Epoch: 2/10, step: 48299, training_loss: 1.16412
Epoch: 2/10, step: 48319, training_loss: 1.44111
Epoch: 2/10, step: 48339, training_loss: 1.55855
Epoch: 2/10, step: 48359, training_loss: 1.40027
Epoch: 2/10, step: 48379, training_loss: 0.94920
Epoch: 2/10, step: 48399, training_loss: 1.22940
Epoch: 2/10, step: 48419, training_loss: 0.94806
Epoch: 2/10, step: 48439, training_loss: 0.61041
Epoch: 2/10, step: 48459, training_loss: 1.10540
Epoch: 2/10, step: 48479, training_loss: 1.32440
Epoch: 2/10, step: 48499, training_loss: 2.84157
Epoch: 2/10, step: 48519, training_loss: 1.74568
Epoch: 2/10, step: 48539, training_loss: 1.23371
Epoch: 2/10, step: 48559, training_loss: 2.29082
Epoch: 2/10, step: 48579, training_loss: 1.46379
Epoch: 2/10, step: 48599, training_loss: 1.46832
Epoch: 2/10, step: 48619, training_loss: 1.16616
Epoch: 2/10, step: 48639, training_loss: 1.65831
Epoch: 2/10, step: 48659, training_loss: 1.94546
Epoch: 2/10, step: 48679, training_loss: 1.60039
Epoch: 2/10, step: 48699, training_loss: 1.11385
Epoch: 2/10, step: 48719, training_loss: 1.21246
Epoch: 2/10, step: 48739, training_loss: 1.65314
Epoch: 2/10, step: 48759, training_loss: 2.05075
Epoch: 2/10, step: 48779, training_loss: 2.14468
Epoch: 2/10, step: 48799, training_loss: 1.81594
Epoch: 2/10, step: 48819, training_loss: 1.52868
Epoch: 2/10, step: 48839, training_loss: 1.46033
Epoch: 2/10, step: 48859, training_loss: 1.20781
Epoch: 2/10, step: 48879, training_loss: 2.39184
Epoch: 2/10, step: 48899, training_loss: 1.27991
Epoch: 2/10, step: 48919, training_loss: 1.36313
Epoch: 2/10, step: 48939, training_loss: 1.70426
Epoch: 2/10, step: 48959, training_loss: 1.37151
Epoch: 2/10, step: 48979, training_loss: 1.94358
Epoch: 2/10, step: 48999, training_loss: 1.10742
accuracy: 0.49, validation_loss: 1.3647102117538452, num_samples: 100
Epoch: 2/10, step: 49019, training_loss: 1.63940
Epoch: 2/10, step: 49039, training_loss: 1.08234
Epoch: 2/10, step: 49059, training_loss: 2.00506
Epoch: 2/10, step: 49079, training_loss: 1.95407
Epoch: 2/10, step: 49099, training_loss: 1.81459
Epoch: 2/10, step: 49119, training_loss: 1.83090
Epoch: 2/10, step: 49139, training_loss: 0.98462
Epoch: 2/10, step: 49159, training_loss: 1.42807
Epoch: 2/10, step: 49179, training_loss: 1.07972
Epoch: 2/10, step: 49199, training_loss: 1.51623
Epoch: 2/10, step: 49219, training_loss: 1.52740
Epoch: 2/10, step: 49239, training_loss: 1.41103
Epoch: 2/10, step: 49259, training_loss: 1.86021
Epoch: 2/10, step: 49279, training_loss: 1.64588
Epoch: 2/10, step: 49299, training_loss: 1.84538
Epoch: 2/10, step: 49319, training_loss: 1.15811
Epoch: 2/10, step: 49339, training_loss: 1.10468
Epoch: 2/10, step: 49359, training_loss: 1.45008
Epoch: 2/10, step: 49379, training_loss: 1.62902
Epoch: 2/10, step: 49399, training_loss: 1.33939
Epoch: 2/10, step: 49419, training_loss: 1.57218
Epoch: 2/10, step: 49439, training_loss: 1.53557
Epoch: 2/10, step: 49459, training_loss: 1.14388
Epoch: 2/10, step: 49479, training_loss: 1.28672
Epoch: 2/10, step: 49499, training_loss: 0.98592
Epoch: 2/10, step: 49519, training_loss: 1.36587
Epoch: 2/10, step: 49539, training_loss: 1.38442
Epoch: 2/10, step: 49559, training_loss: 1.14026
Epoch: 2/10, step: 49579, training_loss: 2.82584
Epoch: 2/10, step: 49599, training_loss: 1.58604
Epoch: 2/10, step: 49619, training_loss: 0.75930
Epoch: 2/10, step: 49639, training_loss: 0.81303
Epoch: 2/10, step: 49659, training_loss: 1.38356
Epoch: 2/10, step: 49679, training_loss: 1.56763
Epoch: 2/10, step: 49699, training_loss: 1.09537
Epoch: 2/10, step: 49719, training_loss: 1.61704
Epoch: 2/10, step: 49739, training_loss: 1.02814
Epoch: 2/10, step: 49759, training_loss: 1.56662
Epoch: 2/10, step: 49779, training_loss: 1.22758
Epoch: 2/10, step: 49799, training_loss: 1.12104
Epoch: 2/10, step: 49819, training_loss: 1.27572
Epoch: 2/10, step: 49839, training_loss: 1.57653
Epoch: 2/10, step: 49859, training_loss: 1.13318
Epoch: 2/10, step: 49879, training_loss: 1.46808
Epoch: 2/10, step: 49899, training_loss: 1.33361
Epoch: 2/10, step: 49919, training_loss: 1.17471
Epoch: 2/10, step: 49939, training_loss: 1.47744
Epoch: 2/10, step: 49959, training_loss: 1.29666
Epoch: 2/10, step: 49979, training_loss: 1.98702
Epoch: 2/10, step: 49999, training_loss: 0.61845
accuracy: 0.46, validation_loss: 1.5601307153701782, num_samples: 100
Epoch: 2/10, step: 50019, training_loss: 1.75070
Epoch: 2/10, step: 50039, training_loss: 1.10263
Epoch: 2/10, step: 50059, training_loss: 2.11893
Epoch: 2/10, step: 50079, training_loss: 1.35190
Epoch: 2/10, step: 50099, training_loss: 1.32233
Epoch: 2/10, step: 50119, training_loss: 1.61740
Epoch: 2/10, step: 50139, training_loss: 0.80782
Epoch: 2/10, step: 50159, training_loss: 1.75629
Epoch: 2/10, step: 50179, training_loss: 1.74116
Epoch: 2/10, step: 50199, training_loss: 1.58177
Epoch: 2/10, step: 50219, training_loss: 1.25901
Epoch: 2/10, step: 50239, training_loss: 1.16481
Epoch: 2/10, step: 50259, training_loss: 1.25359
Epoch: 2/10, step: 50279, training_loss: 1.82980
Epoch: 2/10, step: 50299, training_loss: 0.98766
Epoch: 2/10, step: 50319, training_loss: 0.82202
Epoch: 2/10, step: 50339, training_loss: 1.17450
Epoch: 2/10, step: 50359, training_loss: 1.68691
Epoch: 2/10, step: 50379, training_loss: 1.29930
Epoch: 2/10, step: 50399, training_loss: 1.16368
Epoch: 2/10, step: 50419, training_loss: 1.51934
Epoch: 2/10, step: 50439, training_loss: 1.05800
Epoch: 2/10, step: 50459, training_loss: 1.77617
Epoch: 2/10, step: 50479, training_loss: 0.98318
Epoch: 2/10, step: 50499, training_loss: 1.51573
Epoch: 2/10, step: 50519, training_loss: 1.13003
Epoch: 2/10, step: 50539, training_loss: 1.61572
Epoch: 2/10, step: 50559, training_loss: 1.29428
Epoch: 2/10, step: 50579, training_loss: 1.42256
Epoch: 2/10, step: 50599, training_loss: 1.55989
Epoch: 2/10, step: 50619, training_loss: 1.42484
Epoch: 2/10, step: 50639, training_loss: 1.83624
Epoch: 2/10, step: 50659, training_loss: 1.96200
Epoch: 2/10, step: 50679, training_loss: 1.45362
Epoch: 2/10, step: 50699, training_loss: 1.23725
Epoch: 2/10, step: 50719, training_loss: 1.75374
Epoch: 2/10, step: 50739, training_loss: 1.92169
Epoch: 2/10, step: 50759, training_loss: 1.07468
Epoch: 2/10, step: 50779, training_loss: 1.13812
Epoch: 2/10, step: 50799, training_loss: 1.31797
Epoch: 2/10, step: 50819, training_loss: 1.48123
Epoch: 2/10, step: 50839, training_loss: 1.55559
Epoch: 2/10, step: 50859, training_loss: 1.65424
Epoch: 2/10, step: 50879, training_loss: 1.54961
Epoch: 2/10, step: 50899, training_loss: 0.79303
Epoch: 2/10, step: 50919, training_loss: 1.47632
Epoch: 2/10, step: 50939, training_loss: 1.80773
Epoch: 2/10, step: 50959, training_loss: 1.26631
Epoch: 2/10, step: 50979, training_loss: 1.77201
Epoch: 2/10, step: 50999, training_loss: 1.16001
accuracy: 0.45, validation_loss: 1.5085645914077759, num_samples: 100
Epoch: 2/10, step: 51019, training_loss: 1.85825
Epoch: 2/10, step: 51039, training_loss: 2.07889
Epoch: 2/10, step: 51059, training_loss: 0.91865
Epoch: 2/10, step: 51079, training_loss: 0.90156
Epoch: 2/10, step: 51099, training_loss: 1.96490
Epoch: 2/10, step: 51119, training_loss: 1.64912
Epoch: 2/10, step: 51139, training_loss: 1.86316
Epoch: 2/10, step: 51159, training_loss: 1.11531
Epoch: 2/10, step: 51179, training_loss: 1.82476
Epoch: 2/10, step: 51199, training_loss: 1.32314
Epoch: 2/10, step: 51219, training_loss: 1.08062
Epoch: 2/10, step: 51239, training_loss: 1.13426
Epoch: 2/10, step: 51259, training_loss: 2.01446
Epoch: 2/10, step: 51279, training_loss: 1.39730
Epoch: 2/10, step: 51299, training_loss: 1.42287
Epoch: 2/10, step: 51319, training_loss: 1.13941
Epoch: 2/10, step: 51339, training_loss: 1.16394
Epoch: 2/10, step: 51359, training_loss: 0.92085
Epoch: 2/10, step: 51379, training_loss: 1.33308
Epoch: 2/10, step: 51399, training_loss: 1.98126
Epoch: 2/10, step: 51419, training_loss: 1.95640
Epoch: 2/10, step: 51439, training_loss: 2.05437
Epoch: 2/10, step: 51459, training_loss: 1.95047
Epoch: 2/10, step: 51479, training_loss: 1.10612
Epoch: 2/10, step: 51499, training_loss: 1.34848
Epoch: 2/10, step: 51519, training_loss: 1.39169
Epoch: 2/10, step: 51539, training_loss: 1.38695
Epoch: 2/10, step: 51559, training_loss: 0.73805
Epoch: 2/10, step: 51579, training_loss: 1.24268
Epoch: 2/10, step: 51599, training_loss: 1.14363
Epoch: 2/10, step: 51619, training_loss: 1.24946
Epoch: 2/10, step: 51639, training_loss: 1.07239
Epoch: 2/10, step: 51659, training_loss: 1.73945
Epoch: 2/10, step: 51679, training_loss: 1.73054
Epoch: 2/10, step: 51699, training_loss: 1.21282
Epoch: 2/10, step: 51719, training_loss: 1.28263
Epoch: 2/10, step: 51739, training_loss: 2.11149
Epoch: 2/10, step: 51759, training_loss: 1.26096
Epoch: 2/10, step: 51779, training_loss: 1.60635
Epoch: 2/10, step: 51799, training_loss: 1.51697
Epoch: 2/10, step: 51819, training_loss: 0.97298
Epoch: 2/10, step: 51839, training_loss: 0.98105
Epoch: 2/10, step: 51859, training_loss: 1.31827
Epoch: 2/10, step: 51879, training_loss: 1.43370
Epoch: 2/10, step: 51899, training_loss: 2.20287
Epoch: 2/10, step: 51919, training_loss: 1.18327
Epoch: 2/10, step: 51939, training_loss: 1.03092
Epoch: 2/10, step: 51959, training_loss: 1.01198
Epoch: 2/10, step: 51979, training_loss: 1.68916
Epoch: 2/10, step: 51999, training_loss: 1.00203
accuracy: 0.43, validation_loss: 1.748914361000061, num_samples: 100
Epoch: 2/10, step: 52019, training_loss: 1.95471
Epoch: 2/10, step: 52039, training_loss: 1.03861
Epoch: 2/10, step: 52059, training_loss: 1.73754
Epoch: 2/10, step: 52079, training_loss: 1.50522
Epoch: 2/10, step: 52099, training_loss: 2.32391
Epoch: 2/10, step: 52119, training_loss: 1.71198
Epoch: 2/10, step: 52139, training_loss: 1.61209
Epoch: 2/10, step: 52159, training_loss: 1.56803
Epoch: 2/10, step: 52179, training_loss: 0.97451
Epoch: 2/10, step: 52199, training_loss: 2.12679
Epoch: 2/10, step: 52219, training_loss: 1.09492
Epoch: 2/10, step: 52239, training_loss: 1.44111
Epoch: 2/10, step: 52259, training_loss: 2.42626
Epoch: 2/10, step: 52279, training_loss: 1.35125
Epoch: 2/10, step: 52299, training_loss: 1.20873
Epoch: 2/10, step: 52319, training_loss: 1.39591
Epoch: 2/10, step: 52339, training_loss: 1.47182
Epoch: 2/10, step: 52359, training_loss: 1.65538
Epoch: 2/10, step: 52379, training_loss: 1.47379
Epoch: 2/10, step: 52399, training_loss: 1.01560
Epoch: 2/10, step: 52419, training_loss: 1.88637
Epoch: 2/10, step: 52439, training_loss: 1.01744
Epoch: 2/10, step: 52459, training_loss: 1.33193
Epoch: 2/10, step: 52479, training_loss: 1.63048
Epoch: 2/10, step: 52499, training_loss: 1.02958
Epoch: 2/10, step: 52519, training_loss: 0.85143
Epoch: 2/10, step: 52539, training_loss: 2.28004
Epoch: 2/10, step: 52559, training_loss: 2.12633
Epoch: 2/10, step: 52579, training_loss: 1.05749
Epoch: 2/10, step: 52599, training_loss: 1.66113
Epoch: 2/10, step: 52619, training_loss: 1.48405
Epoch: 2/10, step: 52639, training_loss: 1.12800
Epoch: 2/10, step: 52659, training_loss: 1.10481
Epoch: 2/10, step: 52679, training_loss: 1.61339
Epoch: 2/10, step: 52699, training_loss: 1.34325
Epoch: 2/10, step: 52719, training_loss: 1.54431
Epoch: 2/10, step: 52739, training_loss: 1.43113
Epoch: 2/10, step: 52759, training_loss: 1.07043
Epoch: 2/10, step: 52779, training_loss: 1.42630
Epoch: 2/10, step: 52799, training_loss: 1.33865
Epoch: 2/10, step: 52819, training_loss: 1.07958
Epoch: 2/10, step: 52839, training_loss: 1.70618
Epoch: 2/10, step: 52859, training_loss: 1.24843
Epoch: 2/10, step: 52879, training_loss: 1.62332
Epoch: 2/10, step: 52899, training_loss: 1.41866
Epoch: 2/10, step: 52919, training_loss: 1.40343
Epoch: 2/10, step: 52939, training_loss: 1.79693
Epoch: 2/10, step: 52959, training_loss: 1.22351
Epoch: 2/10, step: 52979, training_loss: 1.20526
Epoch: 2/10, step: 52999, training_loss: 0.99959
accuracy: 0.49, validation_loss: 1.4535768032073975, num_samples: 100
Epoch: 2/10, step: 53019, training_loss: 1.41142
Epoch: 2/10, step: 53039, training_loss: 1.92553
Epoch: 2/10, step: 53059, training_loss: 1.55208
Epoch: 2/10, step: 53079, training_loss: 1.48705
Epoch: 2/10, step: 53099, training_loss: 1.82354
Epoch: 2/10, step: 53119, training_loss: 1.27663
Epoch: 2/10, step: 53139, training_loss: 1.31663
Epoch: 2/10, step: 53159, training_loss: 1.15990
Epoch: 2/10, step: 53179, training_loss: 1.60857
Epoch: 2/10, step: 53199, training_loss: 1.20897
Epoch: 2/10, step: 53219, training_loss: 1.30301
Epoch: 2/10, step: 53239, training_loss: 0.76557
Epoch: 2/10, step: 53259, training_loss: 1.45442
Epoch: 2/10, step: 53279, training_loss: 1.35719
Epoch: 2/10, step: 53299, training_loss: 1.60171
Epoch: 2/10, step: 53319, training_loss: 1.91375
Epoch: 2/10, step: 53339, training_loss: 1.57329
Epoch: 2/10, step: 53359, training_loss: 2.19973
Epoch: 2/10, step: 53379, training_loss: 1.95239
Epoch: 2/10, step: 53399, training_loss: 1.06898
Epoch: 2/10, step: 53419, training_loss: 1.40497
Epoch: 2/10, step: 53439, training_loss: 1.57138
Epoch: 2/10, step: 53459, training_loss: 1.25346
Epoch: 2/10, step: 53479, training_loss: 1.47860
Epoch: 2/10, step: 53499, training_loss: 0.82795
Epoch: 2/10, step: 53519, training_loss: 1.38855
Epoch: 2/10, step: 53539, training_loss: 1.34698
Epoch: 2/10, step: 53559, training_loss: 0.98810
Epoch: 2/10, step: 53579, training_loss: 1.55339
Epoch: 2/10, step: 53599, training_loss: 1.66343
Epoch: 2/10, step: 53619, training_loss: 1.71504
Epoch: 2/10, step: 53639, training_loss: 1.55618
Epoch: 2/10, step: 53659, training_loss: 1.34614
Epoch: 2/10, step: 53679, training_loss: 1.65416
Epoch: 2/10, step: 53699, training_loss: 1.41262
Epoch: 2/10, step: 53719, training_loss: 1.42991
Epoch: 2/10, step: 53739, training_loss: 2.05500
Epoch: 2/10, step: 53759, training_loss: 0.91035
Epoch: 2/10, step: 53779, training_loss: 0.91152
Epoch: 2/10, step: 53799, training_loss: 0.77662
Epoch: 2/10, step: 53819, training_loss: 1.58543
Epoch: 2/10, step: 53839, training_loss: 1.57728
Epoch: 2/10, step: 53859, training_loss: 1.75694
Epoch: 2/10, step: 53879, training_loss: 1.44990
Epoch: 2/10, step: 53899, training_loss: 2.02597
Epoch: 2/10, step: 53919, training_loss: 1.66303
Epoch: 2/10, step: 53939, training_loss: 1.00962
Epoch: 2/10, step: 53959, training_loss: 1.33606
Epoch: 2/10, step: 53979, training_loss: 1.21359
Epoch: 2/10, step: 53999, training_loss: 0.88708
accuracy: 0.46, validation_loss: 1.680553913116455, num_samples: 100
Epoch: 2/10, step: 54019, training_loss: 1.52711
Epoch: 2/10, step: 54039, training_loss: 1.23766
Epoch: 2/10, step: 54059, training_loss: 1.38774
Epoch: 2/10, step: 54079, training_loss: 1.23018
Epoch: 2/10, step: 54099, training_loss: 1.61304
Epoch: 2/10, step: 54119, training_loss: 1.21398
Epoch: 2/10, step: 54139, training_loss: 1.49153
Epoch: 2/10, step: 54159, training_loss: 2.00791
Epoch: 2/10, step: 54179, training_loss: 1.67261
Epoch: 2/10, step: 54199, training_loss: 1.73924
Epoch: 2/10, step: 54219, training_loss: 1.31744
Epoch: 2/10, step: 54239, training_loss: 1.85128
Epoch: 2/10, step: 54259, training_loss: 1.56080
Epoch: 2/10, step: 54279, training_loss: 0.82821
Epoch: 2/10, step: 54299, training_loss: 1.13350
Epoch: 2/10, step: 54319, training_loss: 1.23067
Epoch: 2/10, step: 54339, training_loss: 1.27863
Epoch: 2/10, step: 54359, training_loss: 1.97641
Epoch: 2/10, step: 54379, training_loss: 1.26583
Epoch: 2/10, step: 54399, training_loss: 1.19769
Epoch: 2/10, step: 54419, training_loss: 0.99649
Epoch: 2/10, step: 54439, training_loss: 1.00787
Epoch: 2/10, step: 54459, training_loss: 1.60721
Epoch: 2/10, step: 54479, training_loss: 1.55790
Epoch: 2/10, step: 54499, training_loss: 1.40113
Epoch: 2/10, step: 54519, training_loss: 1.93515
Epoch: 2/10, step: 54539, training_loss: 1.71359
Epoch: 2/10, step: 54559, training_loss: 1.33594
Epoch: 2/10, step: 54579, training_loss: 1.27825
Epoch: 2/10, step: 54599, training_loss: 1.19267
Epoch: 2/10, step: 54619, training_loss: 0.91789
Epoch: 2/10, step: 54639, training_loss: 1.42027
Epoch: 2/10, step: 54659, training_loss: 1.39499
Epoch: 2/10, step: 54679, training_loss: 1.47118
Epoch: 2/10, step: 54699, training_loss: 1.92833
Epoch: 2/10, step: 54719, training_loss: 1.51916
Epoch: 2/10, step: 54739, training_loss: 1.80044
Epoch: 2/10, step: 54759, training_loss: 1.88421
Epoch: 2/10, step: 54779, training_loss: 1.36984
Epoch: 2/10, step: 54799, training_loss: 1.02951
Epoch: 2/10, step: 54819, training_loss: 1.49557
Epoch: 2/10, step: 54839, training_loss: 1.78835
Epoch: 2/10, step: 54859, training_loss: 1.64428
Epoch: 2/10, step: 54879, training_loss: 1.13488
Epoch: 2/10, step: 54899, training_loss: 0.77312
Epoch: 2/10, step: 54919, training_loss: 1.55845
Epoch: 2/10, step: 54939, training_loss: 2.10395
Epoch: 2/10, step: 54959, training_loss: 0.96810
Epoch: 2/10, step: 54979, training_loss: 1.96863
Epoch: 2/10, step: 54999, training_loss: 1.41903
accuracy: 0.53, validation_loss: 1.3261322975158691, num_samples: 100
Epoch: 2/10, step: 55019, training_loss: 1.88086
Epoch: 2/10, step: 55039, training_loss: 1.98579
Epoch: 2/10, step: 55059, training_loss: 0.90004
Epoch: 2/10, step: 55079, training_loss: 1.25623
Epoch: 2/10, step: 55099, training_loss: 1.19043
Epoch: 2/10, step: 55119, training_loss: 0.82032
Epoch: 2/10, step: 55139, training_loss: 1.44272
Epoch: 2/10, step: 55159, training_loss: 2.35238
Epoch: 2/10, step: 55179, training_loss: 1.56052
Epoch: 2/10, step: 55199, training_loss: 0.88950
Epoch: 2/10, step: 55219, training_loss: 1.46323
Epoch: 2/10, step: 55239, training_loss: 1.25341
Epoch: 2/10, step: 55259, training_loss: 1.46484
Epoch: 2/10, step: 55279, training_loss: 1.66818
Epoch: 2/10, step: 55299, training_loss: 1.14445
Epoch: 2/10, step: 55319, training_loss: 1.54700
Epoch: 2/10, step: 55339, training_loss: 1.99380
Epoch: 2/10, step: 55359, training_loss: 1.18708
Epoch: 2/10, step: 55379, training_loss: 1.61245
Epoch: 2/10, step: 55399, training_loss: 1.56169
Epoch: 2/10, step: 55419, training_loss: 1.10171
Epoch: 2/10, step: 55439, training_loss: 1.46816
Epoch: 2/10, step: 55459, training_loss: 1.28430
Epoch: 2/10, step: 55479, training_loss: 1.23165
Epoch: 2/10, step: 55499, training_loss: 0.75953
Epoch: 2/10, step: 55519, training_loss: 1.28256
Epoch: 2/10, step: 55539, training_loss: 1.42181
Epoch: 2/10, step: 55559, training_loss: 1.61597
Epoch: 2/10, step: 55579, training_loss: 1.42844
Epoch: 2/10, step: 55599, training_loss: 1.10523
Epoch: 2/10, step: 55619, training_loss: 1.47708
Epoch: 2/10, step: 55639, training_loss: 1.55568
Epoch: 2/10, step: 55659, training_loss: 1.48088
Epoch: 2/10, step: 55679, training_loss: 1.17806
Epoch: 2/10, step: 55699, training_loss: 0.98803
Epoch: 2/10, step: 55719, training_loss: 0.78551
Epoch: 2/10, step: 55739, training_loss: 1.46496
Epoch: 2/10, step: 55759, training_loss: 2.03418
Epoch: 2/10, step: 55779, training_loss: 1.18072
Epoch: 2/10, step: 55799, training_loss: 1.26201
Epoch: 2/10, step: 55819, training_loss: 1.31650
Epoch: 2/10, step: 55839, training_loss: 1.27618
Epoch: 2/10, step: 55859, training_loss: 1.03718
Epoch: 2/10, step: 55879, training_loss: 2.17559
Epoch: 2/10, step: 55899, training_loss: 1.10472
Epoch: 2/10, step: 55919, training_loss: 1.32642
Epoch: 2/10, step: 55939, training_loss: 2.36534
Epoch: 2/10, step: 55959, training_loss: 1.72588
Epoch: 2/10, step: 55979, training_loss: 1.40878
Epoch: 2/10, step: 55999, training_loss: 1.18958
accuracy: 0.51, validation_loss: 1.2764217853546143, num_samples: 100
Epoch: 2/10, step: 56019, training_loss: 1.86955
Epoch: 2/10, step: 56039, training_loss: 1.71919
Epoch: 2/10, step: 56059, training_loss: 0.59513
Epoch: 2/10, step: 56079, training_loss: 1.24305
Epoch: 2/10, step: 56099, training_loss: 1.32250
Epoch: 2/10, step: 56119, training_loss: 1.52288
Epoch: 2/10, step: 56139, training_loss: 1.76116
Epoch: 2/10, step: 56159, training_loss: 1.58663
Epoch: 2/10, step: 56179, training_loss: 1.12954
Epoch: 2/10, step: 56199, training_loss: 1.54970
Epoch: 2/10, step: 56219, training_loss: 0.93914
Epoch: 2/10, step: 56239, training_loss: 1.53584
Epoch: 2/10, step: 56259, training_loss: 1.56035
Epoch: 2/10, step: 56279, training_loss: 1.46373
Epoch: 2/10, step: 56299, training_loss: 1.69381
Epoch: 2/10, step: 56319, training_loss: 1.65109
Epoch: 2/10, step: 56339, training_loss: 1.04022
Epoch: 2/10, step: 56359, training_loss: 1.33580
Epoch: 2/10, step: 56379, training_loss: 1.90852
Epoch: 2/10, step: 56399, training_loss: 0.85305
Epoch: 2/10, step: 56419, training_loss: 1.54512
Epoch: 2/10, step: 56439, training_loss: 1.50013
Epoch: 2/10, step: 56459, training_loss: 0.87920
Epoch: 2/10, step: 56479, training_loss: 1.16273
Epoch: 2/10, step: 56499, training_loss: 1.40707
Epoch: 2/10, step: 56519, training_loss: 1.14850
Epoch: 2/10, step: 56539, training_loss: 1.88224
Epoch: 2/10, step: 56559, training_loss: 1.58926
Epoch: 2/10, step: 56579, training_loss: 1.18772
Epoch: 2/10, step: 56599, training_loss: 1.35137
Epoch: 2/10, step: 56619, training_loss: 1.27609
Epoch: 2/10, step: 56639, training_loss: 1.67618
Epoch: 2/10, step: 56659, training_loss: 1.33063
Epoch: 2/10, step: 56679, training_loss: 1.80363
Epoch: 2/10, step: 56699, training_loss: 1.53063
Epoch: 2/10, step: 56719, training_loss: 1.49507
Epoch: 2/10, step: 56739, training_loss: 1.34228
Epoch: 2/10, step: 56759, training_loss: 0.95720
Epoch: 2/10, step: 56779, training_loss: 1.49444
Epoch: 2/10, step: 56799, training_loss: 2.06766
Epoch: 2/10, step: 56819, training_loss: 1.53193
Epoch: 2/10, step: 56839, training_loss: 1.58059
Epoch: 2/10, step: 56859, training_loss: 0.82980
Epoch: 2/10, step: 56879, training_loss: 1.73278
Epoch: 2/10, step: 56899, training_loss: 1.31801
Epoch: 2/10, step: 56919, training_loss: 1.99731
Epoch: 2/10, step: 56939, training_loss: 1.77845
Epoch: 2/10, step: 56959, training_loss: 1.20390
Epoch: 2/10, step: 56979, training_loss: 1.87597
Epoch: 2/10, step: 56999, training_loss: 1.18347
accuracy: 0.49, validation_loss: 1.3626487255096436, num_samples: 100
Epoch: 2/10, step: 57019, training_loss: 1.43250
Epoch: 2/10, step: 57039, training_loss: 1.54081
Epoch: 2/10, step: 57059, training_loss: 1.81753
Epoch: 2/10, step: 57079, training_loss: 1.39287
Epoch: 2/10, step: 57099, training_loss: 1.67759
Epoch: 2/10, step: 57119, training_loss: 1.81505
Epoch: 2/10, step: 57139, training_loss: 1.13760
Epoch: 2/10, step: 57159, training_loss: 1.06480
Epoch: 2/10, step: 57179, training_loss: 1.30883
Epoch: 2/10, step: 57199, training_loss: 1.11214
Epoch: 2/10, step: 57219, training_loss: 1.21500
Epoch: 2/10, step: 57239, training_loss: 1.50300
Epoch: 2/10, step: 57259, training_loss: 1.49604
Epoch: 2/10, step: 57279, training_loss: 1.99900
Epoch: 2/10, step: 57299, training_loss: 1.17678
Epoch: 2/10, step: 57319, training_loss: 1.57322
Epoch: 2/10, step: 57339, training_loss: 1.60013
Epoch: 2/10, step: 57359, training_loss: 0.85895
Epoch: 2/10, step: 57379, training_loss: 1.89018
Epoch: 2/10, step: 57399, training_loss: 0.69943
Epoch: 2/10, step: 57419, training_loss: 1.76334
Epoch: 2/10, step: 57439, training_loss: 1.59841
Epoch: 2/10, step: 57459, training_loss: 1.35988
Epoch: 2/10, step: 57479, training_loss: 2.05458
Epoch: 2/10, step: 57499, training_loss: 1.34023
Epoch: 2/10, step: 57519, training_loss: 0.92811
Epoch: 2/10, step: 57539, training_loss: 1.82515
Epoch: 2/10, step: 57559, training_loss: 1.28690
Epoch: 2/10, step: 57579, training_loss: 1.42281
Epoch: 2/10, step: 57599, training_loss: 1.88752
Epoch: 2/10, step: 57619, training_loss: 1.41019
Epoch: 2/10, step: 57639, training_loss: 0.96543
Epoch: 2/10, step: 57659, training_loss: 0.96753
Epoch: 2/10, step: 57679, training_loss: 1.04818
Epoch: 2/10, step: 57699, training_loss: 1.12593
Epoch: 2/10, step: 57719, training_loss: 1.72547
Epoch: 2/10, step: 57739, training_loss: 2.35829
Epoch: 2/10, step: 57759, training_loss: 1.20346
Epoch: 2/10, step: 57779, training_loss: 0.56340
Epoch: 2/10, step: 57799, training_loss: 1.24413
Epoch: 2/10, step: 57819, training_loss: 0.82148
Epoch: 2/10, step: 57839, training_loss: 1.73487
Epoch: 2/10, step: 57859, training_loss: 1.26513
Epoch: 2/10, step: 57879, training_loss: 1.76199
Epoch: 2/10, step: 57899, training_loss: 1.78479
Epoch: 2/10, step: 57919, training_loss: 0.80468
Epoch: 2/10, step: 57939, training_loss: 0.81161
Epoch: 2/10, step: 57959, training_loss: 1.34687
Epoch: 2/10, step: 57979, training_loss: 1.67831
Epoch: 2/10, step: 57999, training_loss: 1.06283
accuracy: 0.49, validation_loss: 1.3849033117294312, num_samples: 100
Epoch: 2/10, step: 58019, training_loss: 1.93358
Epoch: 2/10, step: 58039, training_loss: 1.10434
Epoch: 2/10, step: 58059, training_loss: 1.44849
Epoch: 2/10, step: 58079, training_loss: 1.24689
Epoch: 2/10, step: 58099, training_loss: 1.20099
Epoch: 2/10, step: 58119, training_loss: 1.22779
Epoch: 2/10, step: 58139, training_loss: 1.43978
Epoch: 2/10, step: 58159, training_loss: 0.88532
Epoch: 2/10, step: 58179, training_loss: 1.88489
Epoch: 2/10, step: 58199, training_loss: 1.28029
Epoch: 2/10, step: 58219, training_loss: 1.70257
Epoch: 2/10, step: 58239, training_loss: 1.42397
Epoch: 2/10, step: 58259, training_loss: 0.83395
Epoch: 2/10, step: 58279, training_loss: 0.60246
Epoch: 2/10, step: 58299, training_loss: 1.86567
Epoch: 2/10, step: 58319, training_loss: 1.66315
Epoch: 2/10, step: 58339, training_loss: 1.28434
Epoch: 2/10, step: 58359, training_loss: 1.32690
Epoch: 2/10, step: 58379, training_loss: 0.69965
Epoch: 2/10, step: 58399, training_loss: 1.35696
Epoch: 2/10, step: 58419, training_loss: 1.74256
Epoch: 2/10, step: 58439, training_loss: 1.38488
Epoch: 2/10, step: 58459, training_loss: 1.81515
Epoch: 2/10, step: 58479, training_loss: 0.92783
Epoch: 2/10, step: 58499, training_loss: 1.14747
Epoch: 2/10, step: 58519, training_loss: 1.71827
Epoch: 2/10, step: 58539, training_loss: 1.51147
Epoch: 2/10, step: 58559, training_loss: 1.71930
Epoch: 2/10, step: 58579, training_loss: 1.20342
Epoch: 2/10, step: 58599, training_loss: 1.83373
Epoch: 2/10, step: 58619, training_loss: 1.30104
Epoch: 2/10, step: 58639, training_loss: 1.49558
Epoch: 2/10, step: 58659, training_loss: 1.50530
Epoch: 2/10, step: 58679, training_loss: 1.64918
Epoch: 2/10, step: 58699, training_loss: 1.29584
Epoch: 2/10, step: 58719, training_loss: 1.18902
Epoch: 2/10, step: 58739, training_loss: 1.23365
Epoch: 2/10, step: 58759, training_loss: 1.16191
Epoch: 2/10, step: 58779, training_loss: 1.79511
Epoch: 2/10, step: 58799, training_loss: 1.41926
Epoch: 2/10, step: 58819, training_loss: 2.21824
Epoch: 2/10, step: 58839, training_loss: 1.12025
Epoch: 2/10, step: 58859, training_loss: 1.75341
Epoch: 2/10, step: 58879, training_loss: 1.48993
Epoch: 2/10, step: 58899, training_loss: 2.17746
Epoch: 2/10, step: 58919, training_loss: 2.01011
Epoch: 2/10, step: 58939, training_loss: 1.37096
Epoch: 2/10, step: 58959, training_loss: 0.80365
Epoch: 2/10, step: 58979, training_loss: 1.80826
Epoch: 2/10, step: 58999, training_loss: 1.44250
accuracy: 0.49, validation_loss: 1.4796470403671265, num_samples: 100
Epoch: 2/10, step: 59019, training_loss: 0.91654
Epoch: 2/10, step: 59039, training_loss: 1.77226
Epoch: 2/10, step: 59059, training_loss: 0.97925
Epoch: 2/10, step: 59079, training_loss: 1.48706
Epoch: 2/10, step: 59099, training_loss: 1.38036
Epoch: 2/10, step: 59119, training_loss: 1.41263
Epoch: 2/10, step: 59139, training_loss: 1.00491
Epoch: 2/10, step: 59159, training_loss: 1.47988
Epoch: 2/10, step: 59179, training_loss: 1.87905
Epoch: 2/10, step: 59199, training_loss: 1.10497
Epoch: 2/10, step: 59219, training_loss: 1.65126
Epoch: 2/10, step: 59239, training_loss: 1.35402
Epoch: 2/10, step: 59259, training_loss: 1.37790
Epoch: 2/10, step: 59279, training_loss: 1.35770
Epoch: 2/10, step: 59299, training_loss: 1.41723
Epoch: 2/10, step: 59319, training_loss: 0.88683
Epoch: 2/10, step: 59339, training_loss: 1.81186
Epoch: 2/10, step: 59359, training_loss: 1.44814
Epoch: 2/10, step: 59379, training_loss: 1.94963
Epoch: 2/10, step: 59399, training_loss: 1.44715
Epoch: 2/10, step: 59419, training_loss: 1.43171
Epoch: 2/10, step: 59439, training_loss: 0.97735
Epoch: 2/10, step: 59459, training_loss: 1.64704
Epoch: 2/10, step: 59479, training_loss: 1.00260
Epoch: 2/10, step: 59499, training_loss: 1.39887
Epoch: 2/10, step: 59519, training_loss: 1.66692
Epoch: 2/10, step: 59539, training_loss: 1.95243
Epoch: 2/10, step: 59559, training_loss: 1.57437
Epoch: 2/10, step: 59579, training_loss: 1.44762
Epoch: 2/10, step: 59599, training_loss: 1.22761
Epoch: 2/10, step: 59619, training_loss: 1.77134
Epoch: 2/10, step: 59639, training_loss: 0.95093
Epoch: 2/10, step: 59659, training_loss: 1.30156
Epoch: 2/10, step: 59679, training_loss: 1.89790
Epoch: 2/10, step: 59699, training_loss: 1.23071
Epoch: 2/10, step: 59719, training_loss: 2.11733
Epoch: 2/10, step: 59739, training_loss: 1.22562
Epoch: 2/10, step: 59759, training_loss: 1.16535
Epoch: 2/10, step: 59779, training_loss: 1.70899
Epoch: 2/10, step: 59799, training_loss: 1.30259
Epoch: 2/10, step: 59819, training_loss: 0.77811
Epoch: 2/10, step: 59839, training_loss: 0.93857
Epoch: 2/10, step: 59859, training_loss: 0.99149
Epoch: 2/10, step: 59879, training_loss: 1.15293
Epoch: 2/10, step: 59899, training_loss: 1.60759
Epoch: 2/10, step: 59919, training_loss: 0.82452
Epoch: 2/10, step: 59939, training_loss: 0.93592
Epoch: 2/10, step: 59959, training_loss: 1.22575
Epoch: 2/10, step: 59979, training_loss: 2.23549
Epoch: 2/10, step: 59999, training_loss: 1.89856
accuracy: 0.49, validation_loss: 1.4574412107467651, num_samples: 100
Epoch: 2/10, step: 60019, training_loss: 1.52909
Epoch: 2/10, step: 60039, training_loss: 1.75379
Epoch: 2/10, step: 60059, training_loss: 1.54473
Epoch: 2/10, step: 60079, training_loss: 1.87389
Epoch: 2/10, step: 60099, training_loss: 1.56327
Epoch: 2/10, step: 60119, training_loss: 1.61432
Epoch: 2/10, step: 60139, training_loss: 1.48544
Epoch: 2/10, step: 60159, training_loss: 2.23032
Epoch: 2/10, step: 60179, training_loss: 1.26422
Epoch: 2/10, step: 60199, training_loss: 1.41823
Epoch: 2/10, step: 60219, training_loss: 1.80935
Epoch: 2/10, step: 60239, training_loss: 1.21939
Epoch: 2/10, step: 60259, training_loss: 1.78720
Epoch: 2/10, step: 60279, training_loss: 1.69133
Epoch: 2/10, step: 60299, training_loss: 1.07033
Epoch: 2/10, step: 60319, training_loss: 1.10671
Epoch: 2/10, step: 60339, training_loss: 1.64234
Epoch: 2/10, step: 60359, training_loss: 1.03401
Epoch: 2/10, step: 60379, training_loss: 0.86107
Epoch: 2/10, step: 60399, training_loss: 1.13437
Epoch: 2/10, step: 60419, training_loss: 1.55720
Epoch: 2/10, step: 60439, training_loss: 1.67301
Epoch: 2/10, step: 60459, training_loss: 1.84778
Epoch: 2/10, step: 60479, training_loss: 1.84428
Epoch: 2/10, step: 60499, training_loss: 1.48235
Epoch: 2/10, step: 60519, training_loss: 1.49577
Epoch: 2/10, step: 60539, training_loss: 1.51189
Epoch: 2/10, step: 60559, training_loss: 0.63294
Epoch: 2/10, step: 60579, training_loss: 1.16196
Epoch: 2/10, step: 60599, training_loss: 1.58130
Epoch: 2/10, step: 60619, training_loss: 1.17590
Epoch: 2/10, step: 60639, training_loss: 1.36199
Epoch: 2/10, step: 60659, training_loss: 1.53231
Epoch: 2/10, step: 60679, training_loss: 1.13832
Epoch: 2/10, step: 60699, training_loss: 1.47931
Epoch: 2/10, step: 60719, training_loss: 1.68298
Epoch: 2/10, step: 60739, training_loss: 1.49450
Epoch: 2/10, step: 60759, training_loss: 0.84582
Epoch: 2/10, step: 60779, training_loss: 2.08352
Epoch: 2/10, step: 60799, training_loss: 1.00075
Epoch: 2/10, step: 60819, training_loss: 1.55332
Epoch: 2/10, step: 60839, training_loss: 1.37502
Epoch: 2/10, step: 60859, training_loss: 1.84596
Epoch: 2/10, step: 60879, training_loss: 0.61281
Epoch: 2/10, step: 60899, training_loss: 1.52833
Epoch: 2/10, step: 60919, training_loss: 1.24781
Epoch: 2/10, step: 60939, training_loss: 2.10352
Epoch: 2/10, step: 60959, training_loss: 1.50967
Epoch: 2/10, step: 60979, training_loss: 1.26735
Epoch: 2/10, step: 60999, training_loss: 0.96132
accuracy: 0.58, validation_loss: 1.171929955482483, num_samples: 100
Epoch: 2/10, step: 61019, training_loss: 0.93042
Epoch: 2/10, step: 61039, training_loss: 1.03526
Epoch: 2/10, step: 61059, training_loss: 1.48352
Epoch: 2/10, step: 61079, training_loss: 1.17037
Epoch: 2/10, step: 61099, training_loss: 1.01348
Epoch: 2/10, step: 61119, training_loss: 0.74050
Epoch: 2/10, step: 61139, training_loss: 0.91917
Epoch: 2/10, step: 61159, training_loss: 2.15444
Epoch: 2/10, step: 61179, training_loss: 1.03521
Epoch: 2/10, step: 61199, training_loss: 1.52174
Epoch: 2/10, step: 61219, training_loss: 1.54947
Epoch: 2/10, step: 61239, training_loss: 1.55114
Epoch: 2/10, step: 61259, training_loss: 1.39852
Epoch: 2/10, step: 61279, training_loss: 1.17013
Epoch: 2/10, step: 61299, training_loss: 1.49090
Epoch: 2/10, step: 61319, training_loss: 1.54674
Epoch: 2/10, step: 61339, training_loss: 2.00409
Epoch: 2/10, step: 61359, training_loss: 0.96320
Epoch: 2/10, step: 61379, training_loss: 1.23793
Epoch: 2/10, step: 61399, training_loss: 1.60444
Epoch: 2/10, step: 61419, training_loss: 1.56612
Epoch: 2/10, step: 61439, training_loss: 0.88669
Epoch: 2/10, step: 61459, training_loss: 1.59446
Epoch: 2/10, step: 61479, training_loss: 0.71334
Epoch: 2/10, step: 61499, training_loss: 2.04844
Epoch: 2/10, step: 61519, training_loss: 1.30121
Epoch: 2/10, step: 61539, training_loss: 0.78164
Epoch: 2/10, step: 61559, training_loss: 0.89589
Epoch: 2/10, step: 61579, training_loss: 1.00928
Epoch: 2/10, step: 61599, training_loss: 1.88398
Epoch: 2/10, step: 61619, training_loss: 2.27180
Epoch: 2/10, step: 61639, training_loss: 0.62034
Epoch: 2/10, step: 61659, training_loss: 1.56053
Epoch: 2/10, step: 61679, training_loss: 1.44428
Epoch: 2/10, step: 61699, training_loss: 1.37560
Epoch: 2/10, step: 61719, training_loss: 1.62524
Epoch: 2/10, step: 61739, training_loss: 1.80599
Epoch: 2/10, step: 61759, training_loss: 0.81464
Epoch: 2/10, step: 61779, training_loss: 1.44918
Epoch: 2/10, step: 61799, training_loss: 1.37037
Epoch: 2/10, step: 61819, training_loss: 1.39691
Epoch: 2/10, step: 61839, training_loss: 1.48822
Epoch: 2/10, step: 61859, training_loss: 1.31167
Epoch: 2/10, step: 61879, training_loss: 0.98746
Epoch: 2/10, step: 61899, training_loss: 1.26284
Epoch: 2/10, step: 61919, training_loss: 1.63732
Epoch: 2/10, step: 61939, training_loss: 1.52957
Epoch: 2/10, step: 61959, training_loss: 1.84852
Epoch: 2/10, step: 61979, training_loss: 1.55883
Epoch: 2/10, step: 61999, training_loss: 1.06240
accuracy: 0.5, validation_loss: 1.5096566677093506, num_samples: 100
Epoch: 2/10, step: 62019, training_loss: 1.18549
Epoch: 2/10, step: 62039, training_loss: 1.68944
Epoch: 2/10, step: 62059, training_loss: 1.68539
Epoch: 2/10, step: 62079, training_loss: 1.78301
Epoch: 2/10, step: 62099, training_loss: 1.24273
Epoch: 2/10, step: 62119, training_loss: 2.11815
Epoch: 2/10, step: 62139, training_loss: 1.85744
Epoch: 2/10, step: 62159, training_loss: 1.62815
Epoch: 2/10, step: 62179, training_loss: 0.92416
Epoch: 2/10, step: 62199, training_loss: 1.50908
Epoch: 2/10, step: 62219, training_loss: 1.27623
Epoch: 2/10, step: 62239, training_loss: 1.27509
Epoch: 2/10, step: 62259, training_loss: 1.94950
Epoch: 2/10, step: 62279, training_loss: 1.66018
Epoch: 2/10, step: 62299, training_loss: 1.23715
Epoch: 2/10, step: 62319, training_loss: 1.19393
Epoch: 2/10, step: 62339, training_loss: 1.47159
Epoch: 2/10, step: 62359, training_loss: 1.42708
Epoch: 2/10, step: 62379, training_loss: 1.59312
Epoch: 2/10, step: 62399, training_loss: 1.53969
Epoch: 2/10, step: 62419, training_loss: 0.97946
Epoch: 2/10, step: 62439, training_loss: 1.82803
Epoch: 2/10, step: 62459, training_loss: 0.69602
Epoch: 2/10, step: 62479, training_loss: 1.47112
Epoch: 2/10, step: 62499, training_loss: 1.48916
Epoch: 2/10, step: 62519, training_loss: 1.57291
Epoch: 2/10, step: 62539, training_loss: 1.64490
Epoch: 2/10, step: 62559, training_loss: 1.43046
Epoch: 2/10, step: 62579, training_loss: 1.89203
Epoch: 2/10, step: 62599, training_loss: 1.42479
Epoch: 2/10, step: 62619, training_loss: 1.41408
Epoch: 2/10, step: 62639, training_loss: 0.83206
Epoch: 2/10, step: 62659, training_loss: 0.94954
Epoch: 2/10, step: 62679, training_loss: 1.25831
Epoch: 2/10, step: 62699, training_loss: 1.49767
Epoch: 2/10, step: 62719, training_loss: 1.70541
Epoch: 2/10, step: 62739, training_loss: 1.44509
Epoch: 2/10, step: 62759, training_loss: 2.29404
Epoch: 2/10, step: 62779, training_loss: 1.46649
Epoch: 2/10, step: 62799, training_loss: 1.69217
Epoch: 2/10, step: 62819, training_loss: 1.69851
Epoch: 2/10, step: 62839, training_loss: 1.20390
Epoch: 2/10, step: 62859, training_loss: 1.58511
Epoch: 2/10, step: 62879, training_loss: 1.31436
Epoch: 2/10, step: 62899, training_loss: 1.39599
Epoch: 2/10, step: 62919, training_loss: 2.02487
Epoch: 2/10, step: 62939, training_loss: 1.54213
Epoch: 2/10, step: 62959, training_loss: 1.49337
Epoch: 2/10, step: 62979, training_loss: 2.15171
Epoch: 2/10, step: 62999, training_loss: 1.72081
accuracy: 0.58, validation_loss: 1.1283519268035889, num_samples: 100
Epoch: 2/10, step: 63019, training_loss: 0.84728
Epoch: 2/10, step: 63039, training_loss: 1.26785
Epoch: 2/10, step: 63059, training_loss: 1.54198
Epoch: 2/10, step: 63079, training_loss: 1.54923
Epoch: 2/10, step: 63099, training_loss: 1.69049
Epoch: 2/10, step: 63119, training_loss: 0.72209
Epoch: 2/10, step: 63139, training_loss: 1.36244
Epoch: 2/10, step: 63159, training_loss: 1.47617
Epoch: 2/10, step: 63179, training_loss: 1.84080
Epoch: 2/10, step: 63199, training_loss: 1.24202
Epoch: 2/10, step: 63219, training_loss: 1.65947
Epoch: 2/10, step: 63239, training_loss: 1.81293
Epoch: 2/10, step: 63259, training_loss: 1.52186
Epoch: 2/10, step: 63279, training_loss: 2.03820
Epoch: 2/10, step: 63299, training_loss: 1.69736
Epoch: 2/10, step: 63319, training_loss: 1.28740
Epoch: 2/10, step: 63339, training_loss: 1.15756
Epoch: 2/10, step: 63359, training_loss: 1.19700
Epoch: 2/10, step: 63379, training_loss: 1.30390
Epoch: 2/10, step: 63399, training_loss: 0.83847
Epoch: 2/10, step: 63419, training_loss: 1.49967
Epoch: 2/10, step: 63439, training_loss: 1.37263
Epoch: 2/10, step: 63459, training_loss: 1.56290
Epoch: 2/10, step: 63479, training_loss: 1.26221
Epoch: 2/10, step: 63499, training_loss: 1.39477
Epoch: 2/10, step: 63519, training_loss: 1.73435
Epoch: 2/10, step: 63539, training_loss: 1.85643
Epoch: 2/10, step: 63559, training_loss: 0.86730
Epoch: 2/10, step: 63579, training_loss: 1.66670
Epoch: 2/10, step: 63599, training_loss: 1.37236
Epoch: 2/10, step: 63619, training_loss: 1.67208
Epoch: 2/10, step: 63639, training_loss: 1.27043
Epoch: 2/10, step: 63659, training_loss: 1.55197
Epoch: 2/10, step: 63679, training_loss: 1.78415
Epoch: 2/10, step: 63699, training_loss: 2.40200
Epoch: 2/10, step: 63719, training_loss: 1.03063
Epoch: 2/10, step: 63739, training_loss: 1.47790
Epoch: 2/10, step: 63759, training_loss: 1.07483
Epoch: 2/10, step: 63779, training_loss: 1.63206
Epoch: 2/10, step: 63799, training_loss: 1.88958
Epoch: 2/10, step: 63819, training_loss: 2.21673
Epoch: 2/10, step: 63839, training_loss: 1.14258
Epoch: 2/10, step: 63859, training_loss: 1.81893
Epoch: 2/10, step: 63879, training_loss: 1.76682
Epoch: 2/10, step: 63899, training_loss: 1.19243
Epoch: 2/10, step: 63919, training_loss: 1.56709
Epoch: 2/10, step: 63939, training_loss: 1.34850
Epoch: 2/10, step: 63959, training_loss: 1.69596
Epoch: 2/10, step: 63979, training_loss: 1.55112
Epoch: 2/10, step: 63999, training_loss: 1.25891
accuracy: 0.47, validation_loss: 1.4723094701766968, num_samples: 100
Epoch: 2/10, step: 64019, training_loss: 1.49211
Epoch: 2/10, step: 64039, training_loss: 1.77258
Epoch: 2/10, step: 64059, training_loss: 1.47300
Epoch: 2/10, step: 64079, training_loss: 1.86328
Epoch: 2/10, step: 64099, training_loss: 1.44823
Epoch: 2/10, step: 64119, training_loss: 1.38558
Epoch: 2/10, step: 64139, training_loss: 0.95912
Epoch: 2/10, step: 64159, training_loss: 2.17031
Epoch: 2/10, step: 64179, training_loss: 1.79570
Epoch: 2/10, step: 64199, training_loss: 1.97889
Epoch: 2/10, step: 64219, training_loss: 1.43795
Epoch: 2/10, step: 64239, training_loss: 1.08387
Epoch: 2/10, step: 64259, training_loss: 1.16909
Epoch: 2/10, step: 64279, training_loss: 1.62659
Epoch: 2/10, step: 64299, training_loss: 1.04370
Epoch: 2/10, step: 64319, training_loss: 0.89132
Epoch: 2/10, step: 64339, training_loss: 2.09202
Epoch: 2/10, step: 64359, training_loss: 0.95866
Epoch: 2/10, step: 64379, training_loss: 1.47676
Epoch: 2/10, step: 64399, training_loss: 1.45105
Epoch: 2/10, step: 64419, training_loss: 1.18514
Epoch: 2/10, step: 64439, training_loss: 1.42105
Epoch: 2/10, step: 64459, training_loss: 1.04164
Epoch: 2/10, step: 64479, training_loss: 2.01531
Epoch: 2/10, step: 64499, training_loss: 0.92357
Epoch: 2/10, step: 64519, training_loss: 1.25703
Epoch: 2/10, step: 64539, training_loss: 1.04877
Epoch: 2/10, step: 64559, training_loss: 1.44807
Epoch: 2/10, step: 64579, training_loss: 1.41568
Epoch: 2/10, step: 64599, training_loss: 1.42811
Epoch: 2/10, step: 64619, training_loss: 1.20484
Epoch: 2/10, step: 64639, training_loss: 1.49008
Epoch: 2/10, step: 64659, training_loss: 1.59742
Epoch: 2/10, step: 64679, training_loss: 1.20233
Epoch: 2/10, step: 64699, training_loss: 1.40703
Epoch: 2/10, step: 64719, training_loss: 1.82625
Epoch: 2/10, step: 64739, training_loss: 0.77649
Epoch: 2/10, step: 64759, training_loss: 1.22597
Epoch: 2/10, step: 64779, training_loss: 1.67248
Epoch: 2/10, step: 64799, training_loss: 1.15276
Epoch: 2/10, step: 64819, training_loss: 1.77537
Epoch: 2/10, step: 64839, training_loss: 1.04081
Epoch: 2/10, step: 64859, training_loss: 1.35074
Epoch: 2/10, step: 64879, training_loss: 1.29782
Epoch: 2/10, step: 64899, training_loss: 1.23768
Epoch: 2/10, step: 64919, training_loss: 1.84999
Epoch: 2/10, step: 64939, training_loss: 1.53902
Epoch: 2/10, step: 64959, training_loss: 0.94618
Epoch: 2/10, step: 64979, training_loss: 1.76125
Epoch: 2/10, step: 64999, training_loss: 1.46380
accuracy: 0.53, validation_loss: 1.27970552444458, num_samples: 100
Epoch: 2/10, step: 65019, training_loss: 2.02658
Epoch: 2/10, step: 65039, training_loss: 1.83410
Epoch: 2/10, step: 65059, training_loss: 1.05090
Epoch: 2/10, step: 65079, training_loss: 1.63919
Epoch: 2/10, step: 65099, training_loss: 2.01469
Epoch: 2/10, step: 65119, training_loss: 1.26656
Epoch: 2/10, step: 65139, training_loss: 0.88349
Epoch: 2/10, step: 65159, training_loss: 1.07643
Epoch: 2/10, step: 65179, training_loss: 1.02327
Epoch: 2/10, step: 65199, training_loss: 1.38209
Epoch: 2/10, step: 65219, training_loss: 1.30998
Epoch: 2/10, step: 65239, training_loss: 1.64318
Epoch: 2/10, step: 65259, training_loss: 1.34747
Epoch: 2/10, step: 65279, training_loss: 1.80165
Epoch: 2/10, step: 65299, training_loss: 1.39814
Epoch: 2/10, step: 65319, training_loss: 2.38804
Epoch: 2/10, step: 65339, training_loss: 1.47281
Epoch: 2/10, step: 65359, training_loss: 2.20400
Epoch: 2/10, step: 65379, training_loss: 1.11559
Epoch: 2/10, step: 65399, training_loss: 1.86611
Epoch: 2/10, step: 65419, training_loss: 1.69213
Epoch: 2/10, step: 65439, training_loss: 1.51072
Epoch: 2/10, step: 65459, training_loss: 1.32633
Epoch: 2/10, step: 65479, training_loss: 1.75997
Epoch: 2/10, step: 65499, training_loss: 2.16605
Epoch: 2/10, step: 65519, training_loss: 0.90121
Epoch: 2/10, step: 65539, training_loss: 2.12557
Epoch: 2/10, step: 65559, training_loss: 1.72921
Epoch: 2/10, step: 65579, training_loss: 1.59499
Epoch: 2/10, step: 65599, training_loss: 1.13717
Epoch: 2/10, step: 65619, training_loss: 1.64752
Epoch: 2/10, step: 65639, training_loss: 2.07270
Epoch: 2/10, step: 65659, training_loss: 1.56047
Epoch: 2/10, step: 65679, training_loss: 1.12064
Epoch: 2/10, step: 65699, training_loss: 2.18166
Epoch: 2/10, step: 65719, training_loss: 1.42625
Epoch: 2/10, step: 65739, training_loss: 1.11914
Epoch: 2/10, step: 65759, training_loss: 2.03473
Epoch: 2/10, step: 65779, training_loss: 1.60702
Epoch: 2/10, step: 65799, training_loss: 1.49879
Epoch: 2/10, step: 65819, training_loss: 1.29872
Epoch: 2/10, step: 65839, training_loss: 1.47935
Epoch: 2/10, step: 65859, training_loss: 0.86980
Epoch: 2/10, step: 65879, training_loss: 1.74584
Epoch: 2/10, step: 65899, training_loss: 1.67305
Epoch: 2/10, step: 65919, training_loss: 1.23976
Epoch: 2/10, step: 65939, training_loss: 1.00882
Epoch: 2/10, step: 65959, training_loss: 1.37221
Epoch: 2/10, step: 65979, training_loss: 1.11278
Epoch: 2/10, step: 65999, training_loss: 0.91604
accuracy: 0.43, validation_loss: 1.6419143676757812, num_samples: 100
Epoch: 2/10, step: 66019, training_loss: 1.31333
Epoch: 2/10, step: 66039, training_loss: 1.42496
Epoch: 2/10, step: 66059, training_loss: 1.62669
Epoch: 2/10, step: 66079, training_loss: 1.49073
Epoch: 2/10, step: 66099, training_loss: 0.70815
Epoch: 2/10, step: 66119, training_loss: 1.31721
Epoch: 2/10, step: 66139, training_loss: 1.75230
Epoch: 2/10, step: 66159, training_loss: 1.68437
Epoch: 2/10, step: 66179, training_loss: 1.51741
Epoch: 2/10, step: 66199, training_loss: 1.16972
Epoch: 2/10, step: 66219, training_loss: 1.27491
Epoch: 2/10, step: 66239, training_loss: 1.37398
Epoch: 2/10, step: 66259, training_loss: 0.98106
Epoch: 2/10, step: 66279, training_loss: 0.81609
Epoch: 2/10, step: 66299, training_loss: 1.06599
Epoch: 2/10, step: 66319, training_loss: 1.30591
Epoch: 2/10, step: 66339, training_loss: 1.12169
Epoch: 2/10, step: 66359, training_loss: 1.25261
Epoch: 2/10, step: 66379, training_loss: 1.50977
Epoch: 2/10, step: 66399, training_loss: 1.13714
Epoch: 2/10, step: 66419, training_loss: 0.62365
Epoch: 2/10, step: 66439, training_loss: 2.03252
Epoch: 2/10, step: 66459, training_loss: 1.84948
Epoch: 2/10, step: 66479, training_loss: 1.29973
Epoch: 2/10, step: 66499, training_loss: 1.27926
Epoch: 2/10, step: 66519, training_loss: 1.61714
Epoch: 2/10, step: 66539, training_loss: 1.92489
Epoch: 2/10, step: 66559, training_loss: 1.39629
Epoch: 2/10, step: 66579, training_loss: 1.68356
Epoch: 2/10, step: 66599, training_loss: 1.25874
Epoch: 2/10, step: 66619, training_loss: 1.71202
Epoch: 2/10, step: 66639, training_loss: 1.00823
Epoch: 2/10, step: 66659, training_loss: 1.92359
Epoch: 2/10, step: 66679, training_loss: 1.60915
Epoch: 2/10, step: 66699, training_loss: 1.31648
Epoch: 2/10, step: 66719, training_loss: 1.06851
Epoch: 2/10, step: 66739, training_loss: 1.74353
Epoch: 2/10, step: 66759, training_loss: 1.72342
Epoch: 2/10, step: 66779, training_loss: 1.49845
Epoch: 2/10, step: 66799, training_loss: 1.69675
Epoch: 2/10, step: 66819, training_loss: 1.24748
Epoch: 2/10, step: 66839, training_loss: 1.38416
Epoch: 2/10, step: 66859, training_loss: 1.08291
Epoch: 2/10, step: 66879, training_loss: 1.29656
Epoch: 2/10, step: 66899, training_loss: 1.68351
Epoch: 2/10, step: 66919, training_loss: 0.63323
Epoch: 2/10, step: 66939, training_loss: 1.07171
Epoch: 2/10, step: 66959, training_loss: 1.41624
Epoch: 2/10, step: 66979, training_loss: 1.58388
Epoch: 2/10, step: 66999, training_loss: 1.37510
accuracy: 0.4, validation_loss: 1.6847054958343506, num_samples: 100
Epoch: 2/10, step: 67019, training_loss: 1.87449
Epoch: 2/10, step: 67039, training_loss: 1.12441
Epoch: 2/10, step: 67059, training_loss: 1.69179
Epoch: 2/10, step: 67079, training_loss: 2.14792
Epoch: 2/10, step: 67099, training_loss: 1.09156
Epoch: 2/10, step: 67119, training_loss: 1.53260
Epoch: 2/10, step: 67139, training_loss: 1.66501
Epoch: 2/10, step: 67159, training_loss: 1.35242
Epoch: 2/10, step: 67179, training_loss: 1.52885
Epoch: 2/10, step: 67199, training_loss: 1.57649
Epoch: 2/10, step: 67219, training_loss: 1.07206
Epoch: 2/10, step: 67239, training_loss: 0.76193
Epoch: 2/10, step: 67259, training_loss: 1.42044
Epoch: 2/10, step: 67279, training_loss: 0.72448
Epoch: 2/10, step: 67299, training_loss: 1.23458
Epoch: 2/10, step: 67319, training_loss: 1.20184
Epoch: 2/10, step: 67339, training_loss: 2.52223
Epoch: 2/10, step: 67359, training_loss: 2.06917
Epoch: 2/10, step: 67379, training_loss: 1.99669
Epoch: 2/10, step: 67399, training_loss: 1.15786
Epoch: 2/10, step: 67419, training_loss: 1.45659
Epoch: 2/10, step: 67439, training_loss: 1.45945
Epoch: 2/10, step: 67459, training_loss: 1.36309
Epoch: 2/10, step: 67479, training_loss: 0.88696
Epoch: 2/10, step: 67499, training_loss: 2.22155
Epoch: 2/10, step: 67519, training_loss: 1.85351
Epoch: 2/10, step: 67539, training_loss: 1.04711
Epoch: 2/10, step: 67559, training_loss: 1.23888
Epoch: 2/10, step: 67579, training_loss: 2.00877
Epoch: 2/10, step: 67599, training_loss: 1.34311
Epoch: 2/10, step: 67619, training_loss: 1.21865
Epoch: 2/10, step: 67639, training_loss: 0.84267
Epoch: 2/10, step: 67659, training_loss: 1.36501
Epoch: 2/10, step: 67679, training_loss: 1.70475
Epoch: 2/10, step: 67699, training_loss: 1.66881
Epoch: 2/10, step: 67719, training_loss: 1.27057
Epoch: 2/10, step: 67739, training_loss: 1.11790
Epoch: 2/10, step: 67759, training_loss: 1.19449
Epoch: 2/10, step: 67779, training_loss: 1.32875
Epoch: 2/10, step: 67799, training_loss: 1.53826
Epoch: 2/10, step: 67819, training_loss: 1.80541
Epoch: 2/10, step: 67839, training_loss: 1.40391
Epoch: 2/10, step: 67859, training_loss: 1.09869
Epoch: 2/10, step: 67879, training_loss: 1.54508
Epoch: 2/10, step: 67899, training_loss: 1.31435
Epoch: 2/10, step: 67919, training_loss: 1.47083
Epoch: 2/10, step: 67939, training_loss: 1.22359
Epoch: 2/10, step: 67959, training_loss: 0.98121
Epoch: 2/10, step: 67979, training_loss: 0.96434
Epoch: 2/10, step: 67999, training_loss: 1.91790
accuracy: 0.63, validation_loss: 1.0032025575637817, num_samples: 100
Epoch: 2/10, step: 68019, training_loss: 0.91046
Epoch: 2/10, step: 68039, training_loss: 1.32461
Epoch: 2/10, step: 68059, training_loss: 1.07069
Epoch: 2/10, step: 68079, training_loss: 2.25818
Epoch: 2/10, step: 68099, training_loss: 2.19456
Epoch: 2/10, step: 68119, training_loss: 0.73678
Epoch: 2/10, step: 68139, training_loss: 0.46346
Epoch: 2/10, step: 68159, training_loss: 1.06770
Epoch: 2/10, step: 68179, training_loss: 1.11470
Epoch: 2/10, step: 68199, training_loss: 1.03013
Epoch: 2/10, step: 68219, training_loss: 1.51486
Epoch: 2/10, step: 68239, training_loss: 1.48981
Epoch: 2/10, step: 68259, training_loss: 1.20954
Epoch: 2/10, step: 68279, training_loss: 1.12555
Epoch: 2/10, step: 68299, training_loss: 1.43666
Epoch: 2/10, step: 68319, training_loss: 1.46902
Epoch: 2/10, step: 68339, training_loss: 2.04501
Epoch: 2/10, step: 68359, training_loss: 1.69338
Epoch: 2/10, step: 68379, training_loss: 1.90424
Epoch: 2/10, step: 68399, training_loss: 0.91309
Epoch: 2/10, step: 68419, training_loss: 1.07061
Epoch: 2/10, step: 68439, training_loss: 1.84839
Epoch: 2/10, step: 68459, training_loss: 1.14110
Epoch: 2/10, step: 68479, training_loss: 1.60169
Epoch: 2/10, step: 68499, training_loss: 1.65531
Epoch: 2/10, step: 68519, training_loss: 1.82910
Epoch: 2/10, step: 68539, training_loss: 1.50704
Epoch: 2/10, step: 68559, training_loss: 1.77254
Epoch: 2/10, step: 68579, training_loss: 1.41921
Epoch: 2/10, step: 68599, training_loss: 1.64927
Epoch: 2/10, step: 68619, training_loss: 1.45344
Epoch: 2/10, step: 68639, training_loss: 0.67612
Epoch: 2/10, step: 68659, training_loss: 1.23714
Epoch: 2/10, step: 68679, training_loss: 1.12459
Epoch: 2/10, step: 68699, training_loss: 1.18997
Epoch: 2/10, step: 68719, training_loss: 1.07797
Epoch: 2/10, step: 68739, training_loss: 1.70430
Epoch: 2/10, step: 68759, training_loss: 1.09389
Epoch: 2/10, step: 68779, training_loss: 1.08909
Epoch: 2/10, step: 68799, training_loss: 1.40702
Epoch: 2/10, step: 68819, training_loss: 1.07952
Epoch: 2/10, step: 68839, training_loss: 1.03060
Epoch: 2/10, step: 68859, training_loss: 1.63520
Epoch: 2/10, step: 68879, training_loss: 1.82958
Epoch: 2/10, step: 68899, training_loss: 1.70953
Epoch: 2/10, step: 68919, training_loss: 0.82803
Epoch: 2/10, step: 68939, training_loss: 1.68591
Epoch: 2/10, step: 68959, training_loss: 1.17748
Epoch: 2/10, step: 68979, training_loss: 1.62470
Epoch: 2/10, step: 68999, training_loss: 1.21054
accuracy: 0.48, validation_loss: 1.321237325668335, num_samples: 100
Epoch: 2/10, step: 69019, training_loss: 1.63569
Epoch: 2/10, step: 69039, training_loss: 1.53641
Epoch: 2/10, step: 69059, training_loss: 2.35704
Epoch: 2/10, step: 69079, training_loss: 1.75010
Epoch: 2/10, step: 69099, training_loss: 1.05216
Epoch: 2/10, step: 69119, training_loss: 1.20640
Epoch: 2/10, step: 69139, training_loss: 1.25649
Epoch: 2/10, step: 69159, training_loss: 1.59079
Epoch: 2/10, step: 69179, training_loss: 1.17469
Epoch: 2/10, step: 69199, training_loss: 1.49097
Epoch: 2/10, step: 69219, training_loss: 1.80859
Epoch: 2/10, step: 69239, training_loss: 1.78212
Epoch: 2/10, step: 69259, training_loss: 0.93537
Epoch: 2/10, step: 69279, training_loss: 1.46612
Epoch: 2/10, step: 69299, training_loss: 1.15709
Epoch: 2/10, step: 69319, training_loss: 1.05676
Epoch: 2/10, step: 69339, training_loss: 1.53827
Epoch: 2/10, step: 69359, training_loss: 1.45791
Epoch: 2/10, step: 69379, training_loss: 1.19893
Epoch: 2/10, step: 69399, training_loss: 1.20684
Epoch: 2/10, step: 69419, training_loss: 1.69924
Epoch: 2/10, step: 69439, training_loss: 1.67603
Epoch: 2/10, step: 69459, training_loss: 1.38031
Epoch: 2/10, step: 69479, training_loss: 1.62028
Epoch: 2/10, step: 69499, training_loss: 1.23932
Epoch: 2/10, step: 69519, training_loss: 1.76885
Epoch: 2/10, step: 69539, training_loss: 1.53488
Epoch: 2/10, step: 69559, training_loss: 1.29414
Epoch: 2/10, step: 69579, training_loss: 1.16719
Epoch: 2/10, step: 69599, training_loss: 0.75935
Epoch: 2/10, step: 69619, training_loss: 2.00067
Epoch: 2/10, step: 69639, training_loss: 1.15552
Epoch: 2/10, step: 69659, training_loss: 1.67440
Epoch: 2/10, step: 69679, training_loss: 1.71541
Epoch: 2/10, step: 69699, training_loss: 1.04232
Epoch: 2/10, step: 69719, training_loss: 1.22565
Epoch: 2/10, step: 69739, training_loss: 1.46079
Epoch: 2/10, step: 69759, training_loss: 1.53788
Epoch: 2/10, step: 69779, training_loss: 1.65623
Epoch: 2/10, step: 69799, training_loss: 2.00236
Epoch: 2/10, step: 69819, training_loss: 1.62527
Epoch: 2/10, step: 69839, training_loss: 2.54883
Epoch: 2/10, step: 69859, training_loss: 1.61935
Epoch: 2/10, step: 69879, training_loss: 1.57440
Epoch: 2/10, step: 69899, training_loss: 1.40035
Epoch: 2/10, step: 69919, training_loss: 0.99632
Epoch: 2/10, step: 69939, training_loss: 0.99025
Epoch: 2/10, step: 69959, training_loss: 1.08488
Epoch: 2/10, step: 69979, training_loss: 1.13537
Epoch: 2/10, step: 69999, training_loss: 1.45641
accuracy: 0.56, validation_loss: 1.3849983215332031, num_samples: 100
Epoch: 2/10, step: 70019, training_loss: 1.71183
Epoch: 2/10, step: 70039, training_loss: 1.03470
Epoch: 2/10, step: 70059, training_loss: 0.76908
Epoch: 2/10, step: 70079, training_loss: 1.48920
Epoch: 2/10, step: 70099, training_loss: 1.63687
Epoch: 2/10, step: 70119, training_loss: 1.78375
Epoch: 2/10, step: 70139, training_loss: 1.46910
Epoch: 2/10, step: 70159, training_loss: 1.29001
Epoch: 2/10, step: 70179, training_loss: 1.30587
Epoch: 2/10, step: 70199, training_loss: 0.92595
Epoch: 2/10, step: 70219, training_loss: 1.25657
Epoch: 2/10, step: 70239, training_loss: 1.39305
Epoch: 2/10, step: 70259, training_loss: 1.61271
Epoch: 2/10, step: 70279, training_loss: 0.79441
Epoch: 2/10, step: 70299, training_loss: 1.54890
Epoch: 2/10, step: 70319, training_loss: 1.21962
Epoch: 2/10, step: 70339, training_loss: 1.33347
Epoch: 2/10, step: 70359, training_loss: 1.38826
Epoch: 2/10, step: 70379, training_loss: 1.85779
Epoch: 2/10, step: 70399, training_loss: 1.14580
Epoch: 2/10, step: 70419, training_loss: 1.81021
Epoch: 2/10, step: 70439, training_loss: 1.13145
Epoch: 2/10, step: 70459, training_loss: 0.89431
Epoch: 2/10, step: 70479, training_loss: 2.04118
Epoch: 2/10, step: 70499, training_loss: 1.02523
Epoch: 2/10, step: 70519, training_loss: 1.31038
Epoch: 2/10, step: 70539, training_loss: 1.16670
Epoch: 2/10, step: 70559, training_loss: 1.13211
Epoch: 2/10, step: 70579, training_loss: 1.43209
Epoch: 2/10, step: 70599, training_loss: 1.80934
Epoch: 2/10, step: 70619, training_loss: 1.23005
Epoch: 2/10, step: 70639, training_loss: 1.40358
Epoch: 2/10, step: 70659, training_loss: 1.10649
Epoch: 2/10, step: 70679, training_loss: 1.31405
Epoch: 2/10, step: 70699, training_loss: 1.44275
Epoch: 2/10, step: 70719, training_loss: 2.14693
Epoch: 2/10, step: 70739, training_loss: 1.28544
Epoch: 2/10, step: 70759, training_loss: 1.71121
Epoch: 2/10, step: 70779, training_loss: 1.32506
Epoch: 2/10, step: 70799, training_loss: 1.71738
Epoch: 2/10, step: 70819, training_loss: 1.50366
Epoch: 2/10, step: 70839, training_loss: 1.12016
Epoch: 2/10, step: 70859, training_loss: 1.36230
Epoch: 2/10, step: 70879, training_loss: 0.95495
Epoch: 2/10, step: 70899, training_loss: 1.51380
Epoch: 2/10, step: 70919, training_loss: 1.26892
Epoch: 2/10, step: 70939, training_loss: 1.43824
Epoch: 2/10, step: 70959, training_loss: 1.47037
Epoch: 2/10, step: 70979, training_loss: 0.96604
Epoch: 2/10, step: 70999, training_loss: 1.30528
accuracy: 0.55, validation_loss: 1.4263969659805298, num_samples: 100
Epoch: 2/10, step: 71019, training_loss: 1.01643
Epoch: 2/10, step: 71039, training_loss: 1.75394
Epoch: 2/10, step: 71059, training_loss: 2.59933
Epoch: 2/10, step: 71079, training_loss: 1.82782
Epoch: 2/10, step: 71099, training_loss: 2.03984
Epoch: 2/10, step: 71119, training_loss: 1.44014
Epoch: 2/10, step: 71139, training_loss: 1.12171
Epoch: 2/10, step: 71159, training_loss: 0.84426
Epoch: 2/10, step: 71179, training_loss: 1.60869
Epoch: 2/10, step: 71199, training_loss: 1.26609
Epoch: 2/10, step: 71219, training_loss: 1.53335
Epoch: 2/10, step: 71239, training_loss: 0.97202
Epoch: 2/10, step: 71259, training_loss: 1.51214
Epoch: 2/10, step: 71279, training_loss: 1.67338
Epoch: 2/10, step: 71299, training_loss: 2.08115
Epoch: 2/10, step: 71319, training_loss: 1.63691
Epoch: 2/10, step: 71339, training_loss: 1.20510
Epoch: 2/10, step: 71359, training_loss: 1.19737
Epoch: 2/10, step: 71379, training_loss: 1.76328
Epoch: 2/10, step: 71399, training_loss: 1.44865
Epoch: 2/10, step: 71419, training_loss: 1.19733
Epoch: 2/10, step: 71439, training_loss: 1.23581
Epoch: 2/10, step: 71459, training_loss: 1.35819
Epoch: 2/10, step: 71479, training_loss: 1.17288
Epoch: 2/10, step: 71499, training_loss: 2.02898
Epoch: 2/10, step: 71519, training_loss: 1.64631
Epoch: 2/10, step: 71539, training_loss: 0.97620
Epoch: 2/10, step: 71559, training_loss: 1.15943
Epoch: 2/10, step: 71579, training_loss: 1.51040
Epoch: 2/10, step: 71599, training_loss: 1.23817
Epoch: 2/10, step: 71619, training_loss: 1.35999
Epoch: 2/10, step: 71639, training_loss: 1.54961
Epoch: 2/10, step: 71659, training_loss: 1.30147
Epoch: 2/10, step: 71679, training_loss: 1.73856
Epoch: 2/10, step: 71699, training_loss: 1.14639
Epoch: 2/10, step: 71719, training_loss: 1.95165
Epoch: 2/10, step: 71739, training_loss: 1.72932
Epoch: 2/10, step: 71759, training_loss: 1.72649
Epoch: 2/10, step: 71779, training_loss: 1.72771
Epoch: 2/10, step: 71799, training_loss: 1.60013
Epoch: 2/10, step: 71819, training_loss: 1.32537
Epoch: 2/10, step: 71839, training_loss: 1.48977
Epoch: 2/10, step: 71859, training_loss: 1.85164
Epoch: 2/10, step: 71879, training_loss: 1.86218
Epoch: 2/10, step: 71899, training_loss: 1.12098
Epoch: 2/10, step: 71919, training_loss: 1.55154
Epoch: 2/10, step: 71939, training_loss: 1.17461
Epoch: 2/10, step: 71959, training_loss: 1.64875
Epoch: 2/10, step: 71979, training_loss: 1.36745
Epoch: 2/10, step: 71999, training_loss: 1.33829
accuracy: 0.46, validation_loss: 1.6245323419570923, num_samples: 100
Epoch: 2/10, step: 72019, training_loss: 1.29931
Epoch: 2/10, step: 72039, training_loss: 1.55747
Epoch: 2/10, step: 72059, training_loss: 1.00513
Epoch: 2/10, step: 72079, training_loss: 1.54119
Epoch: 2/10, step: 72099, training_loss: 1.91807
Epoch: 2/10, step: 72119, training_loss: 1.47564
Epoch: 2/10, step: 72139, training_loss: 2.08805
Epoch: 2/10, step: 72159, training_loss: 2.11552
Epoch: 2/10, step: 72179, training_loss: 1.86520
Epoch: 2/10, step: 72199, training_loss: 1.01116
Epoch: 2/10, step: 72219, training_loss: 1.33061
Epoch: 2/10, step: 72239, training_loss: 1.50911
Epoch: 2/10, step: 72259, training_loss: 1.64593
Epoch: 2/10, step: 72279, training_loss: 1.67824
Epoch: 2/10, step: 72299, training_loss: 1.13993
Epoch: 2/10, step: 72319, training_loss: 1.72736
Epoch: 2/10, step: 72339, training_loss: 1.12623
Epoch: 2/10, step: 72359, training_loss: 0.85087
Epoch: 2/10, step: 72379, training_loss: 1.78108
Epoch: 2/10, step: 72399, training_loss: 1.32415
Epoch: 2/10, step: 72419, training_loss: 1.82998
Epoch: 2/10, step: 72439, training_loss: 1.14491
Epoch: 2/10, step: 72459, training_loss: 1.35583
Epoch: 2/10, step: 72479, training_loss: 1.11538
Epoch: 2/10, step: 72499, training_loss: 1.15368
Epoch: 2/10, step: 72519, training_loss: 1.31292
Epoch: 2/10, step: 72539, training_loss: 1.67720
Epoch: 2/10, step: 72559, training_loss: 1.68948
Epoch: 2/10, step: 72579, training_loss: 1.48288
Epoch: 2/10, step: 72599, training_loss: 1.20623
Epoch: 2/10, step: 72619, training_loss: 1.58315
Epoch: 2/10, step: 72639, training_loss: 1.34595
Epoch: 2/10, step: 72659, training_loss: 1.50208
Epoch: 2/10, step: 72679, training_loss: 1.45186
Epoch: 2/10, step: 72699, training_loss: 1.48124
Epoch: 2/10, step: 72719, training_loss: 1.12982
Epoch: 2/10, step: 72739, training_loss: 1.70195
Epoch: 2/10, step: 72759, training_loss: 1.34319
Epoch: 2/10, step: 72779, training_loss: 1.99716
Epoch: 2/10, step: 72799, training_loss: 1.77654
Epoch: 2/10, step: 72819, training_loss: 1.42491
Epoch: 2/10, step: 72839, training_loss: 1.53770
Epoch: 2/10, step: 72859, training_loss: 1.50901
Epoch: 2/10, step: 72879, training_loss: 1.24217
Epoch: 2/10, step: 72899, training_loss: 1.09773
Epoch: 2/10, step: 72919, training_loss: 1.58759
Epoch: 2/10, step: 72939, training_loss: 1.52057
Epoch: 2/10, step: 72959, training_loss: 1.08686
Epoch: 2/10, step: 72979, training_loss: 1.19847
Epoch: 2/10, step: 72999, training_loss: 1.78562
accuracy: 0.46, validation_loss: 1.5212156772613525, num_samples: 100
Epoch: 2/10, step: 73019, training_loss: 1.39613
Epoch: 2/10, step: 73039, training_loss: 2.23925
Epoch: 2/10, step: 73059, training_loss: 1.31632
Epoch: 2/10, step: 73079, training_loss: 1.48882
Epoch: 2/10, step: 73099, training_loss: 1.77544
Epoch: 2/10, step: 73119, training_loss: 1.08289
Epoch: 2/10, step: 73139, training_loss: 1.56191
Epoch: 2/10, step: 73159, training_loss: 2.01395
Epoch: 2/10, step: 73179, training_loss: 1.48628
Epoch: 2/10, step: 73199, training_loss: 1.37942
Epoch: 2/10, step: 73219, training_loss: 1.49823
Epoch: 2/10, step: 73239, training_loss: 1.33486
Epoch: 2/10, step: 73259, training_loss: 1.25277
Epoch: 2/10, step: 73279, training_loss: 1.66487
Epoch: 2/10, step: 73299, training_loss: 0.93153
Epoch: 2/10, step: 73319, training_loss: 1.00531
Epoch: 2/10, step: 73339, training_loss: 1.53883
Epoch: 2/10, step: 73359, training_loss: 0.94914
Epoch: 2/10, step: 73379, training_loss: 1.27416
Epoch: 2/10, step: 73399, training_loss: 1.78440
Epoch: 2/10, step: 73419, training_loss: 1.72540
Epoch: 2/10, step: 73439, training_loss: 1.44530
Epoch: 2/10, step: 73459, training_loss: 0.51270
Epoch: 2/10, step: 73479, training_loss: 0.89464
Epoch: 2/10, step: 73499, training_loss: 1.57768
Epoch: 2/10, step: 73519, training_loss: 1.71855
Epoch: 2/10, step: 73539, training_loss: 1.27562
Epoch: 2/10, step: 73559, training_loss: 1.69988
Epoch: 2/10, step: 73579, training_loss: 0.94189
Epoch: 2/10, step: 73599, training_loss: 1.14398
Epoch: 2/10, step: 73619, training_loss: 1.06144
Epoch: 2/10, step: 73639, training_loss: 1.60838
Epoch: 2/10, step: 73659, training_loss: 1.68925
Epoch: 2/10, step: 73679, training_loss: 1.45620
Epoch: 2/10, step: 73699, training_loss: 1.69538
Epoch: 2/10, step: 73719, training_loss: 1.75914
Epoch: 2/10, step: 73739, training_loss: 1.79159
Epoch: 2/10, step: 73759, training_loss: 1.13083
Epoch: 2/10, step: 73779, training_loss: 1.78003
Epoch: 2/10, step: 73799, training_loss: 1.41267
Epoch: 2/10, step: 73819, training_loss: 0.94141
Epoch: 2/10, step: 73839, training_loss: 2.25915
Epoch: 2/10, step: 73859, training_loss: 1.49187
Epoch: 2/10, step: 73879, training_loss: 1.35037
Epoch: 2/10, step: 73899, training_loss: 1.09159
Epoch: 2/10, step: 73919, training_loss: 1.05277
Epoch: 2/10, step: 73939, training_loss: 0.61129
Epoch: 2/10, step: 73959, training_loss: 1.17041
Epoch: 2/10, step: 73979, training_loss: 1.52172
Epoch: 2/10, step: 73999, training_loss: 1.03352
accuracy: 0.43, validation_loss: 1.4530682563781738, num_samples: 100
Epoch: 2/10, step: 74019, training_loss: 1.67378
Epoch: 2/10, step: 74039, training_loss: 1.59723
Epoch: 2/10, step: 74059, training_loss: 1.35107
Epoch: 2/10, step: 74079, training_loss: 1.71324
Epoch: 2/10, step: 74099, training_loss: 1.96954
Epoch: 2/10, step: 74119, training_loss: 1.65810
Epoch: 2/10, step: 74139, training_loss: 0.88330
Epoch: 2/10, step: 74159, training_loss: 1.65161
Epoch: 2/10, step: 74179, training_loss: 1.60708
Epoch: 2/10, step: 74199, training_loss: 1.00981
Epoch: 2/10, step: 74219, training_loss: 1.48141
Epoch: 2/10, step: 74239, training_loss: 1.64602
Epoch: 2/10, step: 74259, training_loss: 1.46974
Epoch: 2/10, step: 74279, training_loss: 1.09660
Epoch: 2/10, step: 74299, training_loss: 1.08142
Epoch: 2/10, step: 74319, training_loss: 1.45957
Epoch: 2/10, step: 74339, training_loss: 1.31916
Epoch: 2/10, step: 74359, training_loss: 1.41277
Epoch: 2/10, step: 74379, training_loss: 1.13062
Epoch: 2/10, step: 74399, training_loss: 2.06526
Epoch: 2/10, step: 74419, training_loss: 1.81628
Epoch: 2/10, step: 74439, training_loss: 1.55455
Epoch: 2/10, step: 74459, training_loss: 1.29315
Epoch: 2/10, step: 74479, training_loss: 1.57444
Epoch: 2/10, step: 74499, training_loss: 1.33261
Epoch: 2/10, step: 74519, training_loss: 1.01878
Epoch: 2/10, step: 74539, training_loss: 1.27449
Epoch: 2/10, step: 74559, training_loss: 2.28927
Epoch: 2/10, step: 74579, training_loss: 1.48795
Epoch: 2/10, step: 74599, training_loss: 0.73657
Epoch: 2/10, step: 74619, training_loss: 1.54942
Epoch: 2/10, step: 74639, training_loss: 1.84827
Epoch: 2/10, step: 74659, training_loss: 0.82972
Epoch: 2/10, step: 74679, training_loss: 1.24792
Epoch: 2/10, step: 74699, training_loss: 1.46766
Epoch: 2/10, step: 74719, training_loss: 0.96139
Epoch: 2/10, step: 74739, training_loss: 1.26475
Epoch: 2/10, step: 74759, training_loss: 1.59357
Epoch: 2/10, step: 74779, training_loss: 1.18809
Epoch: 2/10, step: 74799, training_loss: 1.27946
Epoch: 2/10, step: 74819, training_loss: 1.47265
Epoch: 2/10, step: 74839, training_loss: 1.40355
Epoch: 2/10, step: 74859, training_loss: 0.85838
Epoch: 2/10, step: 74879, training_loss: 1.67335
Epoch: 2/10, step: 74899, training_loss: 1.55222
Epoch: 2/10, step: 74919, training_loss: 1.49288
Epoch: 2/10, step: 74939, training_loss: 1.44679
Epoch: 2/10, step: 74959, training_loss: 1.05439
Epoch: 2/10, step: 74979, training_loss: 2.06686
Epoch: 2/10, step: 74999, training_loss: 1.52603
accuracy: 0.47, validation_loss: 1.4195365905761719, num_samples: 100
Epoch: 2/10, step: 75019, training_loss: 1.67305
Epoch: 2/10, step: 75039, training_loss: 1.42339
Epoch: 2/10, step: 75059, training_loss: 1.18691
Epoch: 2/10, step: 75079, training_loss: 1.48446
Epoch: 2/10, step: 75099, training_loss: 1.63311
Epoch: 2/10, step: 75119, training_loss: 1.59868
Epoch: 2/10, step: 75139, training_loss: 1.45274
Epoch: 2/10, step: 75159, training_loss: 2.02325
Epoch: 2/10, step: 75179, training_loss: 1.28101
Epoch: 2/10, step: 75199, training_loss: 1.83690
Epoch: 2/10, step: 75219, training_loss: 1.87886
Epoch: 2/10, step: 75239, training_loss: 1.62109
Epoch: 2/10, step: 75259, training_loss: 1.55432
Epoch: 2/10, step: 75279, training_loss: 1.21794
Epoch: 2/10, step: 75299, training_loss: 1.19461
Epoch: 2/10, step: 75319, training_loss: 1.63536
Epoch: 2/10, step: 75339, training_loss: 1.68476
Epoch: 2/10, step: 75359, training_loss: 1.68721
Epoch: 2/10, step: 75379, training_loss: 1.88608
Epoch: 2/10, step: 75399, training_loss: 0.67656
Epoch: 2/10, step: 75419, training_loss: 1.24643
Epoch: 2/10, step: 75439, training_loss: 1.71848
Epoch: 2/10, step: 75459, training_loss: 1.39664
Epoch: 2/10, step: 75479, training_loss: 1.73322
Epoch: 2/10, step: 75499, training_loss: 1.01238
Epoch: 2/10, step: 75519, training_loss: 1.22009
Epoch: 2/10, step: 75539, training_loss: 1.28140
Epoch: 2/10, step: 75559, training_loss: 1.28221
Epoch: 2/10, step: 75579, training_loss: 1.36149
Epoch: 2/10, step: 75599, training_loss: 1.63312
Epoch: 2/10, step: 75619, training_loss: 1.45642
Epoch: 2/10, step: 75639, training_loss: 1.85816
Epoch: 2/10, step: 75659, training_loss: 1.21576
Epoch: 2/10, step: 75679, training_loss: 0.79710
Epoch: 2/10, step: 75699, training_loss: 1.19555
Epoch: 2/10, step: 75719, training_loss: 1.40977
Epoch: 2/10, step: 75739, training_loss: 1.62745
Epoch: 2/10, step: 75759, training_loss: 1.20987
Epoch: 2/10, step: 75779, training_loss: 0.92249
Epoch: 2/10, step: 75799, training_loss: 1.41800
Epoch: 2/10, step: 75819, training_loss: 1.52894
Epoch: 2/10, step: 75839, training_loss: 2.21542
Epoch: 2/10, step: 75859, training_loss: 1.18080
Epoch: 2/10, step: 75879, training_loss: 1.39764
Epoch: 2/10, step: 75899, training_loss: 1.21998
Epoch: 2/10, step: 75919, training_loss: 1.40101
Epoch: 2/10, step: 75939, training_loss: 1.48463
Epoch: 2/10, step: 75959, training_loss: 1.48501
Epoch: 2/10, step: 75979, training_loss: 1.21869
Epoch: 2/10, step: 75999, training_loss: 1.41767
accuracy: 0.43, validation_loss: 1.6458497047424316, num_samples: 100
Epoch: 2/10, step: 76019, training_loss: 1.51904
Epoch: 2/10, step: 76039, training_loss: 1.67866
Epoch: 2/10, step: 76059, training_loss: 1.26478
Epoch: 2/10, step: 76079, training_loss: 1.07021
Epoch: 2/10, step: 76099, training_loss: 1.14971
Epoch: 2/10, step: 76119, training_loss: 1.42303
Epoch: 2/10, step: 76139, training_loss: 0.75806
Epoch: 2/10, step: 76159, training_loss: 1.38727
Epoch: 2/10, step: 76179, training_loss: 2.14412
Epoch: 2/10, step: 76199, training_loss: 1.02303
Epoch: 2/10, step: 76219, training_loss: 2.06997
Epoch: 2/10, step: 76239, training_loss: 2.02423
Epoch: 2/10, step: 76259, training_loss: 1.64389
Epoch: 2/10, step: 76279, training_loss: 0.86624
Epoch: 2/10, step: 76299, training_loss: 0.99734
Epoch: 2/10, step: 76319, training_loss: 1.71817
Epoch: 2/10, step: 76339, training_loss: 1.38790
Epoch: 2/10, step: 76359, training_loss: 2.40222
Epoch: 2/10, step: 76379, training_loss: 1.69483
Epoch: 2/10, step: 76399, training_loss: 1.78693
Epoch: 2/10, step: 76419, training_loss: 1.21879
Epoch: 2/10, step: 76439, training_loss: 1.09979
Epoch: 2/10, step: 76459, training_loss: 1.33176
Epoch: 2/10, step: 76479, training_loss: 1.13766
Epoch: 2/10, step: 76499, training_loss: 1.86800
Epoch: 2/10, step: 76519, training_loss: 1.63141
Epoch: 2/10, step: 76539, training_loss: 0.69060
Epoch: 2/10, step: 76559, training_loss: 1.88969
Epoch: 2/10, step: 76579, training_loss: 1.22082
Epoch: 2/10, step: 76599, training_loss: 0.77587
Epoch: 2/10, step: 76619, training_loss: 0.88828
Epoch: 2/10, step: 76639, training_loss: 2.27473
Epoch: 2/10, step: 76659, training_loss: 1.66614
Epoch: 2/10, step: 76679, training_loss: 1.21628
Epoch: 2/10, step: 76699, training_loss: 0.46420
Epoch: 2/10, step: 76719, training_loss: 1.26902
Epoch: 2/10, step: 76739, training_loss: 1.64909
Epoch: 2/10, step: 76759, training_loss: 1.77043
Epoch: 2/10, step: 76779, training_loss: 0.85821
Epoch: 2/10, step: 76799, training_loss: 1.92285
Epoch: 2/10, step: 76819, training_loss: 1.08886
Epoch: 2/10, step: 76839, training_loss: 1.29809
Epoch: 2/10, step: 76859, training_loss: 1.45237
Epoch: 2/10, step: 76879, training_loss: 1.99436
Epoch: 2/10, step: 76899, training_loss: 1.30773
Epoch: 2/10, step: 76919, training_loss: 2.22787
Epoch: 2/10, step: 76939, training_loss: 1.25014
Epoch: 2/10, step: 76959, training_loss: 1.43202
Epoch: 2/10, step: 76979, training_loss: 1.81968
Epoch: 2/10, step: 76999, training_loss: 0.84433
accuracy: 0.49, validation_loss: 1.5851777791976929, num_samples: 100
Epoch: 2/10, step: 77019, training_loss: 2.33453
Epoch: 2/10, step: 77039, training_loss: 1.27529
Epoch: 2/10, step: 77059, training_loss: 1.59395
Epoch: 2/10, step: 77079, training_loss: 0.77861
Epoch: 2/10, step: 77099, training_loss: 0.75059
Epoch: 2/10, step: 77119, training_loss: 2.26756
Epoch: 2/10, step: 77139, training_loss: 1.67519
Epoch: 2/10, step: 77159, training_loss: 1.66485
Epoch: 2/10, step: 77179, training_loss: 2.07439
Epoch: 2/10, step: 77199, training_loss: 2.08685
Epoch: 2/10, step: 77219, training_loss: 2.31367
Epoch: 2/10, step: 77239, training_loss: 1.33423
Epoch: 2/10, step: 77259, training_loss: 1.18590
Epoch: 2/10, step: 77279, training_loss: 0.80702
Epoch: 2/10, step: 77299, training_loss: 1.18332
Epoch: 2/10, step: 77319, training_loss: 1.20339
Epoch: 2/10, step: 77339, training_loss: 1.60871
Epoch: 2/10, step: 77359, training_loss: 2.12241
Epoch: 2/10, step: 77379, training_loss: 1.56965
Epoch: 2/10, step: 77399, training_loss: 0.92891
Epoch: 2/10, step: 77419, training_loss: 1.83264
Epoch: 2/10, step: 77439, training_loss: 1.26468
Epoch: 2/10, step: 77459, training_loss: 1.36517
Epoch: 2/10, step: 77479, training_loss: 1.56085
Epoch: 2/10, step: 77499, training_loss: 1.70564
Epoch: 2/10, step: 77519, training_loss: 1.18837
Epoch: 2/10, step: 77539, training_loss: 1.30157
Epoch: 2/10, step: 77559, training_loss: 1.02673
Epoch: 2/10, step: 77579, training_loss: 1.53444
Epoch: 2/10, step: 77599, training_loss: 1.62230
Epoch: 2/10, step: 77619, training_loss: 1.54101
Epoch: 2/10, step: 77639, training_loss: 1.10898
Epoch: 2/10, step: 77659, training_loss: 1.70788
Epoch: 2/10, step: 77679, training_loss: 0.78145
Epoch: 2/10, step: 77699, training_loss: 1.52849
Epoch: 2/10, step: 77719, training_loss: 1.80790
Epoch: 2/10, step: 77739, training_loss: 2.21561
Epoch: 2/10, step: 77759, training_loss: 1.80138
Epoch: 2/10, step: 77779, training_loss: 1.88917
Epoch: 2/10, step: 77799, training_loss: 1.17214
Epoch: 2/10, step: 77819, training_loss: 1.02767
Epoch: 2/10, step: 77839, training_loss: 1.52893
Epoch: 2/10, step: 77859, training_loss: 1.34355
Epoch: 2/10, step: 77879, training_loss: 1.18251
Epoch: 2/10, step: 77899, training_loss: 1.22417
Epoch: 2/10, step: 77919, training_loss: 1.52566
Epoch: 2/10, step: 77939, training_loss: 2.22400
Epoch: 2/10, step: 77959, training_loss: 1.28797
Epoch: 2/10, step: 77979, training_loss: 1.92608
Epoch: 2/10, step: 77999, training_loss: 1.37270
accuracy: 0.41, validation_loss: 1.664534091949463, num_samples: 100
Epoch: 2/10, step: 78019, training_loss: 1.23470
Epoch: 2/10, step: 78039, training_loss: 0.94316
Epoch: 2/10, step: 78059, training_loss: 1.02364
Epoch: 2/10, step: 78079, training_loss: 1.90189
Epoch: 2/10, step: 78099, training_loss: 1.76771
Epoch: 2/10, step: 78119, training_loss: 1.89823
Epoch: 2/10, step: 78139, training_loss: 1.75628
Epoch: 2/10, step: 78159, training_loss: 0.98644
Epoch: 2/10, step: 78179, training_loss: 0.93520
Epoch: 2/10, step: 78199, training_loss: 2.44615
Epoch: 2/10, step: 78219, training_loss: 1.32726
Epoch: 2/10, step: 78239, training_loss: 1.27823
Epoch: 2/10, step: 78259, training_loss: 1.15908
Epoch: 2/10, step: 78279, training_loss: 1.18343
Epoch: 2/10, step: 78299, training_loss: 1.31404
Epoch: 2/10, step: 78319, training_loss: 2.10126
Epoch: 2/10, step: 78339, training_loss: 1.60452
Epoch: 2/10, step: 78359, training_loss: 1.33357
Epoch: 2/10, step: 78379, training_loss: 1.48974
Epoch: 2/10, step: 78399, training_loss: 1.61878
Epoch: 2/10, step: 78419, training_loss: 1.45748
Epoch: 2/10, step: 78439, training_loss: 1.34000
Epoch: 2/10, step: 78459, training_loss: 1.42495
Epoch: 2/10, step: 78479, training_loss: 1.19391
Epoch: 2/10, step: 78499, training_loss: 1.24153
Epoch: 2/10, step: 78519, training_loss: 1.73638
Epoch: 2/10, step: 78539, training_loss: 1.65000
Epoch: 2/10, step: 78559, training_loss: 1.28289
Epoch: 2/10, step: 78579, training_loss: 1.56519
Epoch: 2/10, step: 78599, training_loss: 1.82388
Epoch: 2/10, step: 78619, training_loss: 1.75958
Epoch: 2/10, step: 78639, training_loss: 0.72436
Epoch: 2/10, step: 78659, training_loss: 1.76977
Epoch: 2/10, step: 78679, training_loss: 1.56074
Epoch: 2/10, step: 78699, training_loss: 1.79882
Epoch: 2/10, step: 78719, training_loss: 1.65564
Epoch: 2/10, step: 78739, training_loss: 1.60303
Epoch: 2/10, step: 78759, training_loss: 1.60850
Epoch: 2/10, step: 78779, training_loss: 1.40293
Epoch: 2/10, step: 78799, training_loss: 1.81364
Epoch: 2/10, step: 78819, training_loss: 1.46355
Epoch: 2/10, step: 78839, training_loss: 1.54867
Epoch: 2/10, step: 78859, training_loss: 1.53459
Epoch: 2/10, step: 78879, training_loss: 1.73471
Epoch: 2/10, step: 78899, training_loss: 1.21371
Epoch: 2/10, step: 78919, training_loss: 1.86538
Epoch: 2/10, step: 78939, training_loss: 1.47767
Epoch: 2/10, step: 78959, training_loss: 1.18498
Epoch: 2/10, step: 78979, training_loss: 1.45927
Epoch: 2/10, step: 78999, training_loss: 0.74263
accuracy: 0.58, validation_loss: 1.3292551040649414, num_samples: 100
Epoch: 2/10, step: 79019, training_loss: 1.64329
Epoch: 2/10, step: 79039, training_loss: 2.23345
Epoch: 2/10, step: 79059, training_loss: 1.87524
Epoch: 2/10, step: 79079, training_loss: 1.13165
Epoch: 2/10, step: 79099, training_loss: 1.41547
Epoch: 2/10, step: 79119, training_loss: 0.98628
Epoch: 2/10, step: 79139, training_loss: 1.49738
Epoch: 2/10, step: 79159, training_loss: 2.58823
Epoch: 2/10, step: 79179, training_loss: 1.47416
Epoch: 2/10, step: 79199, training_loss: 1.94267
Epoch: 2/10, step: 79219, training_loss: 1.16944
Epoch: 2/10, step: 79239, training_loss: 1.25466
Epoch: 2/10, step: 79259, training_loss: 1.29135
Epoch: 2/10, step: 79279, training_loss: 1.11937
Epoch: 2/10, step: 79299, training_loss: 1.98228
Epoch: 2/10, step: 79319, training_loss: 1.32144
Epoch: 2/10, step: 79339, training_loss: 1.68608
Epoch: 2/10, step: 79359, training_loss: 1.40110
Epoch: 2/10, step: 79379, training_loss: 0.48988
Epoch: 2/10, step: 79399, training_loss: 1.36478
Epoch: 2/10, step: 79419, training_loss: 1.29663
Epoch: 2/10, step: 79439, training_loss: 1.96477
Epoch: 2/10, step: 79459, training_loss: 1.10624
Epoch: 2/10, step: 79479, training_loss: 1.42312
Epoch: 2/10, step: 79499, training_loss: 1.56971
Epoch: 2/10, step: 79519, training_loss: 1.09828
Epoch: 2/10, step: 79539, training_loss: 0.85828
Epoch: 2/10, step: 79559, training_loss: 1.51687
Epoch: 2/10, step: 79579, training_loss: 1.88281
Epoch: 2/10, step: 79599, training_loss: 1.13018
Epoch: 2/10, step: 79619, training_loss: 1.69961
Epoch: 2/10, step: 79639, training_loss: 1.16718
Epoch: 2/10, step: 79659, training_loss: 1.74646
Epoch: 2/10, step: 79679, training_loss: 1.34358
Epoch: 2/10, step: 79699, training_loss: 1.64204
Epoch: 2/10, step: 79719, training_loss: 1.20574
Epoch: 2/10, step: 79739, training_loss: 1.13540
Epoch: 2/10, step: 79759, training_loss: 1.11352
Epoch: 2/10, step: 79779, training_loss: 1.55689
Epoch: 2/10, step: 79799, training_loss: 1.59853
Epoch: 2/10, step: 79819, training_loss: 1.78593
Epoch: 2/10, step: 79839, training_loss: 1.41979
Epoch: 2/10, step: 79859, training_loss: 1.33367
Epoch: 2/10, step: 79879, training_loss: 1.33364
Epoch: 2/10, step: 79899, training_loss: 1.24914
Epoch: 2/10, step: 79919, training_loss: 1.32846
Epoch: 2/10, step: 79939, training_loss: 2.37506
Epoch: 2/10, step: 79959, training_loss: 1.73823
Epoch: 2/10, step: 79979, training_loss: 1.54190
Epoch: 2/10, step: 79999, training_loss: 1.54210
accuracy: 0.51, validation_loss: 1.5143176317214966, num_samples: 100
Epoch: 2/10, step: 80019, training_loss: 2.11032
Epoch: 2/10, step: 80039, training_loss: 0.77549
Epoch: 2/10, step: 80059, training_loss: 0.92549
Epoch: 2/10, step: 80079, training_loss: 1.24503
Epoch: 2/10, step: 80099, training_loss: 1.58489
Epoch: 2/10, step: 80119, training_loss: 1.71122
Epoch: 2/10, step: 80139, training_loss: 1.75680
Epoch: 2/10, step: 80159, training_loss: 1.40598
Epoch: 2/10, step: 80179, training_loss: 1.43634
Epoch: 2/10, step: 80199, training_loss: 1.41125
Epoch: 2/10, step: 80219, training_loss: 1.25683
Epoch: 2/10, step: 80239, training_loss: 1.37718
Epoch: 2/10, step: 80259, training_loss: 1.17925
Epoch: 2/10, step: 80279, training_loss: 1.86168
Epoch: 2/10, step: 80299, training_loss: 1.49068
Epoch: 2/10, step: 80319, training_loss: 1.65699
Epoch: 2/10, step: 80339, training_loss: 1.15123
Epoch: 2/10, step: 80359, training_loss: 1.19530
Epoch: 2/10, step: 80379, training_loss: 1.77585
Epoch: 2/10, step: 80399, training_loss: 1.36682
Epoch: 2/10, step: 80419, training_loss: 1.54843
Epoch: 2/10, step: 80439, training_loss: 1.00411
Epoch: 2/10, step: 80459, training_loss: 0.83614
Epoch: 2/10, step: 80479, training_loss: 1.68236
Epoch: 2/10, step: 80499, training_loss: 1.31187
Epoch: 2/10, step: 80519, training_loss: 1.83611
Epoch: 2/10, step: 80539, training_loss: 1.39941
Epoch: 2/10, step: 80559, training_loss: 1.37191
Epoch: 2/10, step: 80579, training_loss: 1.73721
Epoch: 2/10, step: 80599, training_loss: 1.46053
Epoch: 2/10, step: 80619, training_loss: 1.20054
Epoch: 2/10, step: 80639, training_loss: 1.65112
Epoch: 2/10, step: 80659, training_loss: 1.57783
Epoch: 2/10, step: 80679, training_loss: 1.67083
Epoch: 2/10, step: 80699, training_loss: 1.18883
Epoch: 2/10, step: 80719, training_loss: 1.20544
Epoch: 2/10, step: 80739, training_loss: 1.30869
Epoch: 2/10, step: 80759, training_loss: 1.68474
Epoch: 2/10, step: 80779, training_loss: 1.41348
Epoch: 2/10, step: 80799, training_loss: 1.71092
Epoch: 2/10, step: 80819, training_loss: 1.29742
Epoch: 2/10, step: 80839, training_loss: 0.97383
Epoch: 2/10, step: 80859, training_loss: 1.93634
Epoch: 2/10, step: 80879, training_loss: 1.27740
Epoch: 2/10, step: 80899, training_loss: 1.71594
Epoch: 2/10, step: 80919, training_loss: 1.40486
Epoch: 2/10, step: 80939, training_loss: 2.20321
Epoch: 2/10, step: 80959, training_loss: 1.56063
Epoch: 2/10, step: 80979, training_loss: 1.32625
Epoch: 2/10, step: 80999, training_loss: 1.32324
accuracy: 0.49, validation_loss: 1.3553467988967896, num_samples: 100
Epoch: 2/10, step: 81019, training_loss: 1.30951
Epoch: 2/10, step: 81039, training_loss: 1.95020
Epoch: 2/10, step: 81059, training_loss: 1.28514
Epoch: 2/10, step: 81079, training_loss: 1.61808
Epoch: 2/10, step: 81099, training_loss: 0.73783
Epoch: 2/10, step: 81119, training_loss: 1.46074
Epoch: 2/10, step: 81139, training_loss: 1.18242
Epoch: 2/10, step: 81159, training_loss: 1.20431
Epoch: 2/10, step: 81179, training_loss: 3.22529
Epoch: 2/10, step: 81199, training_loss: 0.75680
Epoch: 2/10, step: 81219, training_loss: 1.31563
Epoch: 2/10, step: 81239, training_loss: 1.58689
Epoch: 2/10, step: 81259, training_loss: 1.13224
Epoch: 2/10, step: 81279, training_loss: 1.61553
Epoch: 2/10, step: 81299, training_loss: 1.47418
Epoch: 2/10, step: 81319, training_loss: 1.81992
Epoch: 2/10, step: 81339, training_loss: 1.24504
Epoch: 2/10, step: 81359, training_loss: 1.54478
Epoch: 2/10, step: 81379, training_loss: 1.01617
Epoch: 2/10, step: 81399, training_loss: 0.83031
Epoch: 2/10, step: 81419, training_loss: 1.46594
Epoch: 2/10, step: 81439, training_loss: 1.33502
Epoch: 2/10, step: 81459, training_loss: 1.71230
Epoch: 2/10, step: 81479, training_loss: 0.62827
Epoch: 2/10, step: 81499, training_loss: 1.39422
Epoch: 2/10, step: 81519, training_loss: 1.69871
Epoch: 2/10, step: 81539, training_loss: 1.79439
Epoch: 2/10, step: 81559, training_loss: 1.37314
Epoch: 2/10, step: 81579, training_loss: 0.84220
Epoch: 2/10, step: 81599, training_loss: 0.89993
Epoch: 2/10, step: 81619, training_loss: 1.31080
Epoch: 2/10, step: 81639, training_loss: 1.10699
Epoch: 2/10, step: 81659, training_loss: 1.19418
Epoch: 2/10, step: 81679, training_loss: 1.04466
Epoch: 2/10, step: 81699, training_loss: 0.97334
Epoch: 2/10, step: 81719, training_loss: 1.51815
Epoch: 2/10, step: 81739, training_loss: 1.19587
Epoch: 2/10, step: 81759, training_loss: 1.02453
Epoch: 2/10, step: 81779, training_loss: 1.10960
Epoch: 2/10, step: 81799, training_loss: 1.34501
Epoch: 2/10, step: 81819, training_loss: 1.92846
Epoch: 2/10, step: 81839, training_loss: 1.33173
Epoch: 2/10, step: 81859, training_loss: 1.14778
Epoch: 2/10, step: 81879, training_loss: 1.13001
Epoch: 2/10, step: 81899, training_loss: 1.16214
Epoch: 2/10, step: 81919, training_loss: 1.77836
Epoch: 2/10, step: 81939, training_loss: 1.99527
Epoch: 2/10, step: 81959, training_loss: 1.32615
Epoch: 2/10, step: 81979, training_loss: 1.39560
Epoch: 2/10, step: 81999, training_loss: 1.07164
accuracy: 0.46, validation_loss: 1.6271358728408813, num_samples: 100
Epoch: 2/10, step: 82019, training_loss: 1.31658
Epoch: 2/10, step: 82039, training_loss: 1.10628
Epoch: 2/10, step: 82059, training_loss: 1.25085
Epoch: 2/10, step: 82079, training_loss: 1.56504
Epoch: 2/10, step: 82099, training_loss: 0.51101
Epoch: 2/10, step: 82119, training_loss: 2.09977
Epoch: 2/10, step: 82139, training_loss: 1.24171
Epoch: 2/10, step: 82159, training_loss: 1.80203
Epoch: 2/10, step: 82179, training_loss: 1.22550
Epoch: 2/10, step: 82199, training_loss: 1.75823
Epoch: 2/10, step: 82219, training_loss: 1.42220
Epoch: 2/10, step: 82239, training_loss: 1.34963
Epoch: 2/10, step: 82259, training_loss: 2.11517
Epoch: 2/10, step: 82279, training_loss: 1.35091
Epoch: 2/10, step: 82299, training_loss: 1.51858
Epoch: 2/10, step: 82319, training_loss: 1.83111
Epoch: 2/10, step: 82339, training_loss: 1.79707
Epoch: 2/10, step: 82359, training_loss: 1.20731
Epoch: 2/10, step: 82379, training_loss: 1.27943
Epoch: 2/10, step: 82399, training_loss: 2.36947
Epoch: 2/10, step: 82419, training_loss: 1.59865
Epoch: 2/10, step: 82439, training_loss: 0.86740
Epoch: 2/10, step: 82459, training_loss: 1.06300
Epoch: 2/10, step: 82479, training_loss: 2.08104
Epoch: 2/10, step: 82499, training_loss: 1.70490
Epoch: 2/10, step: 82519, training_loss: 1.69564
Epoch: 2/10, step: 82539, training_loss: 1.26939
Epoch: 2/10, step: 82559, training_loss: 1.23316
Epoch: 2/10, step: 82579, training_loss: 1.28693
Epoch: 2/10, step: 82599, training_loss: 1.09252
Epoch: 2/10, step: 82619, training_loss: 1.42770
Epoch: 2/10, step: 82639, training_loss: 1.33358
Epoch: 2/10, step: 82659, training_loss: 0.98340
Epoch: 2/10, step: 82679, training_loss: 1.73097
Epoch: 2/10, step: 82699, training_loss: 1.28006
Epoch: 2/10, step: 82719, training_loss: 0.82283
Epoch: 2/10, step: 82739, training_loss: 1.55582
Epoch: 2/10, step: 82759, training_loss: 1.52570
Epoch: 2/10, step: 82779, training_loss: 1.11879
Epoch: 2/10, step: 82799, training_loss: 1.23556
Epoch: 2/10, step: 82819, training_loss: 1.61343
Epoch: 2/10, step: 82839, training_loss: 1.61514
Epoch: 2/10, step: 82859, training_loss: 0.91478
Epoch: 2/10, step: 82879, training_loss: 1.10412
Epoch: 2/10, step: 82899, training_loss: 1.76503
Epoch: 2/10, step: 82919, training_loss: 0.96545
Epoch: 2/10, step: 82939, training_loss: 1.81026
Epoch: 2/10, step: 82959, training_loss: 1.36894
Epoch: 2/10, step: 82979, training_loss: 1.25493
Epoch: 2/10, step: 82999, training_loss: 1.35702
accuracy: 0.49, validation_loss: 1.6007416248321533, num_samples: 100
Epoch: 2/10, step: 83019, training_loss: 1.08222
Epoch: 2/10, step: 83039, training_loss: 1.86460
Epoch: 2/10, step: 83059, training_loss: 1.43056
Epoch: 2/10, step: 83079, training_loss: 1.67994
Epoch: 2/10, step: 83099, training_loss: 1.75639
Epoch: 2/10, step: 83119, training_loss: 1.67788
Epoch: 2/10, step: 83139, training_loss: 1.30461
Epoch: 2/10, step: 83159, training_loss: 1.50588
Epoch: 2/10, step: 83179, training_loss: 1.48057
Epoch: 2/10, step: 83199, training_loss: 1.25314
Epoch: 2/10, step: 83219, training_loss: 1.18574
Epoch: 2/10, step: 83239, training_loss: 0.83272
Epoch: 2/10, step: 83259, training_loss: 1.61483
Epoch: 2/10, step: 83279, training_loss: 1.76387
Epoch: 2/10, step: 83299, training_loss: 1.59414
Epoch: 2/10, step: 83319, training_loss: 1.20494
Epoch: 2/10, step: 83339, training_loss: 1.59910
Epoch: 2/10, step: 83359, training_loss: 1.46115
Epoch: 2/10, step: 83379, training_loss: 1.57645
Epoch: 2/10, step: 83399, training_loss: 1.19964
Epoch: 2/10, step: 83419, training_loss: 1.08225
Epoch: 2/10, step: 83439, training_loss: 1.89618
Epoch: 2/10, step: 83459, training_loss: 0.79529
Epoch: 2/10, step: 83479, training_loss: 1.75961
Epoch: 2/10, step: 83499, training_loss: 1.84817
Epoch: 2/10, step: 83519, training_loss: 1.78581
Epoch: 2/10, step: 83539, training_loss: 1.05164
Epoch: 2/10, step: 83559, training_loss: 1.45538
Epoch: 2/10, step: 83579, training_loss: 1.81300
Epoch: 2/10, step: 83599, training_loss: 1.22043
Epoch: 2/10, step: 83619, training_loss: 0.98745
Epoch: 2/10, step: 83639, training_loss: 1.25462
Epoch: 2/10, step: 83659, training_loss: 1.77532
Epoch: 2/10, step: 83679, training_loss: 1.17637
Epoch: 2/10, step: 83699, training_loss: 0.95664
Epoch: 2/10, step: 83719, training_loss: 0.87006
Epoch: 2/10, step: 83739, training_loss: 1.03521
Epoch: 2/10, step: 83759, training_loss: 1.40418
Epoch: 2/10, step: 83779, training_loss: 1.47316
Epoch: 2/10, step: 83799, training_loss: 1.23710
Epoch: 2/10, step: 83819, training_loss: 1.11661
Epoch: 2/10, step: 83839, training_loss: 1.11633
Epoch: 2/10, step: 83859, training_loss: 1.27069
Epoch: 2/10, step: 83879, training_loss: 1.96768
Epoch: 2/10, step: 83899, training_loss: 0.79054
Epoch: 2/10, step: 83919, training_loss: 1.94923
Epoch: 2/10, step: 83939, training_loss: 2.67431
Epoch: 2/10, step: 83959, training_loss: 1.15889
Epoch: 2/10, step: 83979, training_loss: 1.62433
Epoch: 2/10, step: 83999, training_loss: 1.50690
accuracy: 0.49, validation_loss: 1.3105168342590332, num_samples: 100
Epoch: 2/10, step: 84019, training_loss: 1.64112
Epoch: 2/10, step: 84039, training_loss: 2.21854
Epoch: 2/10, step: 84059, training_loss: 1.53342
Epoch: 2/10, step: 84079, training_loss: 1.43678
Epoch: 2/10, step: 84099, training_loss: 1.58542
Epoch: 2/10, step: 84119, training_loss: 1.48175
Epoch: 2/10, step: 84139, training_loss: 1.38991
Epoch: 2/10, step: 84159, training_loss: 2.16123
Epoch: 2/10, step: 84179, training_loss: 1.21773
Epoch: 2/10, step: 84199, training_loss: 1.79358
Epoch: 2/10, step: 84219, training_loss: 1.39740
Epoch: 2/10, step: 84239, training_loss: 1.20905
Epoch: 2/10, step: 84259, training_loss: 1.53496
Epoch: 2/10, step: 84279, training_loss: 1.77217
Epoch: 2/10, step: 84299, training_loss: 1.17113
Epoch: 2/10, step: 84319, training_loss: 1.69521
Epoch: 2/10, step: 84339, training_loss: 1.71077
Epoch: 2/10, step: 84359, training_loss: 1.50987
Epoch: 2/10, step: 84379, training_loss: 1.05793
Epoch: 2/10, step: 84399, training_loss: 1.44075
Epoch: 2/10, step: 84419, training_loss: 0.93537
Epoch: 2/10, step: 84439, training_loss: 0.64023
Epoch: 2/10, step: 84459, training_loss: 1.09630
Epoch: 2/10, step: 84479, training_loss: 2.02436
Epoch: 2/10, step: 84499, training_loss: 1.31412
Epoch: 2/10, step: 84519, training_loss: 0.99673
Epoch: 2/10, step: 84539, training_loss: 0.98705
Epoch: 2/10, step: 84559, training_loss: 1.72012
Epoch: 2/10, step: 84579, training_loss: 2.30392
Epoch: 2/10, step: 84599, training_loss: 1.50431
Epoch: 2/10, step: 84619, training_loss: 1.19041
Epoch: 2/10, step: 84639, training_loss: 2.13580
Epoch: 2/10, step: 84659, training_loss: 1.28079
Epoch: 2/10, step: 84679, training_loss: 1.28456
Epoch: 2/10, step: 84699, training_loss: 1.03204
Epoch: 2/10, step: 84719, training_loss: 1.42489
Epoch: 2/10, step: 84739, training_loss: 1.06731
Epoch: 2/10, step: 84759, training_loss: 1.24897
Epoch: 2/10, step: 84779, training_loss: 1.35698
Epoch: 2/10, step: 84799, training_loss: 1.19102
Epoch: 2/10, step: 84819, training_loss: 1.13087
Epoch: 2/10, step: 84839, training_loss: 2.18376
Epoch: 2/10, step: 84859, training_loss: 2.06855
Epoch: 2/10, step: 84879, training_loss: 1.22823
Epoch: 2/10, step: 84899, training_loss: 1.51807
Epoch: 2/10, step: 84919, training_loss: 1.15530
Epoch: 2/10, step: 84939, training_loss: 1.14250
Epoch: 2/10, step: 84959, training_loss: 1.19659
Epoch: 2/10, step: 84979, training_loss: 1.29110
Epoch: 2/10, step: 84999, training_loss: 1.62017
accuracy: 0.53, validation_loss: 1.4361451864242554, num_samples: 100
Epoch: 2/10, step: 85019, training_loss: 1.33988
Epoch: 2/10, step: 85039, training_loss: 1.39872
Epoch: 2/10, step: 85059, training_loss: 1.56101
Epoch: 2/10, step: 85079, training_loss: 2.22639
Epoch: 2/10, step: 85099, training_loss: 1.66855
Epoch: 2/10, step: 85119, training_loss: 2.06876
Epoch: 2/10, step: 85139, training_loss: 1.09732
Epoch: 2/10, step: 85159, training_loss: 1.30358
Epoch: 2/10, step: 85179, training_loss: 1.65258
Epoch: 2/10, step: 85199, training_loss: 1.14630
Epoch: 2/10, step: 85219, training_loss: 1.31935
Epoch: 2/10, step: 85239, training_loss: 1.46891
Epoch: 2/10, step: 85259, training_loss: 1.28188
Epoch: 2/10, step: 85279, training_loss: 1.65827
Epoch: 2/10, step: 85299, training_loss: 1.60366
Epoch: 2/10, step: 85319, training_loss: 1.92528
Epoch: 2/10, step: 85339, training_loss: 1.26952
Epoch: 2/10, step: 85359, training_loss: 1.36742
Epoch: 2/10, step: 85379, training_loss: 1.13861
Epoch: 2/10, step: 85399, training_loss: 1.35995
Epoch: 2/10, step: 85419, training_loss: 1.74807
Epoch: 2/10, step: 85439, training_loss: 1.54284
Epoch: 2/10, step: 85459, training_loss: 1.96820
Epoch: 2/10, step: 85479, training_loss: 2.49243
Epoch: 2/10, step: 85499, training_loss: 1.30133
Epoch: 2/10, step: 85519, training_loss: 1.92168
Epoch: 2/10, step: 85539, training_loss: 2.09840
Epoch: 2/10, step: 85559, training_loss: 0.91555
Epoch: 2/10, step: 85579, training_loss: 1.74963
Epoch: 2/10, step: 85599, training_loss: 1.48140
Epoch: 2/10, step: 85619, training_loss: 1.80184
Epoch: 2/10, step: 85639, training_loss: 1.80457
Epoch: 2/10, step: 85659, training_loss: 1.29091
Epoch: 2/10, step: 85679, training_loss: 1.58855
Epoch: 2/10, step: 85699, training_loss: 1.28653
Epoch: 2/10, step: 85719, training_loss: 1.49320
Epoch: 2/10, step: 85739, training_loss: 1.33792
Epoch: 2/10, step: 85759, training_loss: 1.11758
Epoch: 2/10, step: 85779, training_loss: 1.89855
Epoch: 2/10, step: 85799, training_loss: 1.75986
Epoch: 2/10, step: 85819, training_loss: 1.43675
Epoch: 2/10, step: 85839, training_loss: 1.36608
Epoch: 2/10, step: 85859, training_loss: 1.45104
Epoch: 2/10, step: 85879, training_loss: 0.94920
Epoch: 2/10, step: 85899, training_loss: 1.75571
Epoch: 2/10, step: 85919, training_loss: 1.39523
Epoch: 2/10, step: 85939, training_loss: 1.12880
Epoch: 2/10, step: 85959, training_loss: 1.24028
Epoch: 2/10, step: 85979, training_loss: 1.57678
Epoch: 2/10, step: 85999, training_loss: 1.64014
accuracy: 0.48, validation_loss: 1.6165831089019775, num_samples: 100
Epoch: 2/10, step: 86019, training_loss: 0.91749
Epoch: 2/10, step: 86039, training_loss: 1.44200
Epoch: 2/10, step: 86059, training_loss: 1.62670
Epoch: 2/10, step: 86079, training_loss: 1.67082
Epoch: 2/10, step: 86099, training_loss: 1.61204
Epoch: 2/10, step: 86119, training_loss: 1.40483
Epoch: 2/10, step: 86139, training_loss: 1.47887
Epoch: 2/10, step: 86159, training_loss: 1.67602
Epoch: 2/10, step: 86179, training_loss: 1.34524
Epoch: 2/10, step: 86199, training_loss: 0.97110
Epoch: 2/10, step: 86219, training_loss: 1.97889
Epoch: 2/10, step: 86239, training_loss: 1.69993
Epoch: 2/10, step: 86259, training_loss: 1.34418
Epoch: 2/10, step: 86279, training_loss: 1.37528
Epoch: 2/10, step: 86299, training_loss: 1.88308
Epoch: 2/10, step: 86319, training_loss: 1.20583
Epoch: 2/10, step: 86339, training_loss: 1.64355
Epoch: 2/10, step: 86359, training_loss: 1.49842
Epoch: 2/10, step: 86379, training_loss: 0.77910
Epoch: 2/10, step: 86399, training_loss: 1.49878
Epoch: 2/10, step: 86419, training_loss: 1.11255
Epoch: 2/10, step: 86439, training_loss: 2.30078
Epoch: 2/10, step: 86459, training_loss: 1.26162
Epoch: 2/10, step: 86479, training_loss: 0.91799
Epoch: 2/10, step: 86499, training_loss: 1.76800
Epoch: 2/10, step: 86519, training_loss: 1.17846
Epoch: 2/10, step: 86539, training_loss: 0.65975
Epoch: 2/10, step: 86559, training_loss: 1.07251
Epoch: 2/10, step: 86579, training_loss: 1.96402
Epoch: 2/10, step: 86599, training_loss: 1.12649
Epoch: 2/10, step: 86619, training_loss: 1.12046
Epoch: 2/10, step: 86639, training_loss: 1.34782
Epoch: 2/10, step: 86659, training_loss: 1.86605
Epoch: 2/10, step: 86679, training_loss: 1.52983
Epoch: 2/10, step: 86699, training_loss: 1.46242
Epoch: 2/10, step: 86719, training_loss: 1.86157
Epoch: 2/10, step: 86739, training_loss: 1.07083
Epoch: 2/10, step: 86759, training_loss: 1.68540
Epoch: 2/10, step: 86779, training_loss: 1.43258
Epoch: 2/10, step: 86799, training_loss: 1.20480
Epoch: 2/10, step: 86819, training_loss: 1.34787
Epoch: 2/10, step: 86839, training_loss: 1.38954
Epoch: 2/10, step: 86859, training_loss: 1.29894
Epoch: 2/10, step: 86879, training_loss: 1.36330
Epoch: 2/10, step: 86899, training_loss: 1.27203
Epoch: 2/10, step: 86919, training_loss: 1.40243
Epoch: 2/10, step: 86939, training_loss: 1.66136
Epoch: 2/10, step: 86959, training_loss: 1.55346
Epoch: 2/10, step: 86979, training_loss: 2.11958
Epoch: 2/10, step: 86999, training_loss: 1.42570
accuracy: 0.42, validation_loss: 1.4111233949661255, num_samples: 100
Epoch: 2/10, step: 87019, training_loss: 1.34556
Epoch: 2/10, step: 87039, training_loss: 0.97995
Epoch: 2/10, step: 87059, training_loss: 1.74636
Epoch: 2/10, step: 87079, training_loss: 1.23988
Epoch: 2/10, step: 87099, training_loss: 1.66278
Epoch: 2/10, step: 87119, training_loss: 1.73017
Epoch: 2/10, step: 87139, training_loss: 1.30114
Epoch: 2/10, step: 87159, training_loss: 0.82361
Epoch: 2/10, step: 87179, training_loss: 1.72014
Epoch: 2/10, step: 87199, training_loss: 1.00402
Epoch: 2/10, step: 87219, training_loss: 1.53372
Epoch: 2/10, step: 87239, training_loss: 1.40981
Epoch: 2/10, step: 87259, training_loss: 1.82903
Epoch: 2/10, step: 87279, training_loss: 1.49158
Epoch: 2/10, step: 87299, training_loss: 1.23082
Epoch: 2/10, step: 87319, training_loss: 1.16481
Epoch: 2/10, step: 87339, training_loss: 1.19406
Epoch: 2/10, step: 87359, training_loss: 1.27034
Epoch: 2/10, step: 87379, training_loss: 1.32831
Epoch: 2/10, step: 87399, training_loss: 1.36804
Epoch: 2/10, step: 87419, training_loss: 1.23667
Epoch: 2/10, step: 87439, training_loss: 2.22957
Epoch: 2/10, step: 87459, training_loss: 0.71762
Epoch: 2/10, step: 87479, training_loss: 1.02107
Epoch: 2/10, step: 87499, training_loss: 1.94447
Epoch: 2/10, step: 87519, training_loss: 1.23332
Epoch: 2/10, step: 87539, training_loss: 1.63193
Epoch: 2/10, step: 87559, training_loss: 1.46674
Epoch: 2/10, step: 87579, training_loss: 1.35227
Epoch: 2/10, step: 87599, training_loss: 1.63969
Epoch: 2/10, step: 87619, training_loss: 1.50214
Epoch: 2/10, step: 87639, training_loss: 1.74551
Epoch: 2/10, step: 87659, training_loss: 1.34584
Epoch: 2/10, step: 87679, training_loss: 0.80061
Epoch: 2/10, step: 87699, training_loss: 1.46656
Epoch: 2/10, step: 87719, training_loss: 0.97441
Epoch: 2/10, step: 87739, training_loss: 1.41579
Epoch: 2/10, step: 87759, training_loss: 1.83642
Epoch: 2/10, step: 87779, training_loss: 1.16452
Epoch: 2/10, step: 87799, training_loss: 2.05994
Epoch: 2/10, step: 87819, training_loss: 1.06166
Epoch: 2/10, step: 87839, training_loss: 2.03398
Epoch: 2/10, step: 87859, training_loss: 1.20613
Epoch: 2/10, step: 87879, training_loss: 1.05728
Epoch: 2/10, step: 87899, training_loss: 1.26442
Epoch: 2/10, step: 87919, training_loss: 1.37611
Epoch: 2/10, step: 87939, training_loss: 1.69280
Epoch: 2/10, step: 87959, training_loss: 1.06784
Epoch: 2/10, step: 87979, training_loss: 1.38267
Epoch: 2/10, step: 87999, training_loss: 1.45180
accuracy: 0.58, validation_loss: 1.1276777982711792, num_samples: 100
Epoch: 2/10, step: 88019, training_loss: 0.73416
Epoch: 2/10, step: 88039, training_loss: 1.21664
Epoch: 2/10, step: 88059, training_loss: 1.06715
Epoch: 2/10, step: 88079, training_loss: 1.55660
Epoch: 2/10, step: 88099, training_loss: 1.03292
Epoch: 2/10, step: 88119, training_loss: 1.61424
Epoch: 2/10, step: 88139, training_loss: 1.62609
Epoch: 2/10, step: 88159, training_loss: 1.20219
Epoch: 2/10, step: 88179, training_loss: 2.03933
Epoch: 2/10, step: 88199, training_loss: 1.16343
Epoch: 2/10, step: 88219, training_loss: 1.44236
Epoch: 2/10, step: 88239, training_loss: 1.75674
Epoch: 2/10, step: 88259, training_loss: 1.43220
Epoch: 2/10, step: 88279, training_loss: 1.07182
Epoch: 2/10, step: 88299, training_loss: 1.73448
Epoch: 2/10, step: 88319, training_loss: 1.23587
Epoch: 2/10, step: 88339, training_loss: 1.82789
Epoch: 2/10, step: 88359, training_loss: 1.42041
Epoch: 2/10, step: 88379, training_loss: 1.18099
Epoch: 2/10, step: 88399, training_loss: 1.56475
Epoch: 2/10, step: 88419, training_loss: 1.03755
Epoch: 2/10, step: 88439, training_loss: 1.06548
Epoch: 2/10, step: 88459, training_loss: 1.47914
Epoch: 2/10, step: 88479, training_loss: 1.80124
Epoch: 2/10, step: 88499, training_loss: 1.01002
Epoch: 2/10, step: 88519, training_loss: 1.37417
Epoch: 2/10, step: 88539, training_loss: 1.35548
Epoch: 2/10, step: 88559, training_loss: 2.16549
Epoch: 2/10, step: 88579, training_loss: 1.20698
Epoch: 2/10, step: 88599, training_loss: 1.24142
Epoch: 2/10, step: 88619, training_loss: 1.13057
Epoch: 2/10, step: 88639, training_loss: 0.78183
Epoch: 2/10, step: 88659, training_loss: 1.67744
Epoch: 2/10, step: 88679, training_loss: 1.06124
Epoch: 2/10, step: 88699, training_loss: 1.98998
Epoch: 2/10, step: 88719, training_loss: 1.82297
Epoch: 2/10, step: 88739, training_loss: 1.60668
Epoch: 2/10, step: 88759, training_loss: 1.13128
Epoch: 2/10, step: 88779, training_loss: 0.92338
Epoch: 2/10, step: 88799, training_loss: 1.23064
Epoch: 2/10, step: 88819, training_loss: 1.67514
Epoch: 2/10, step: 88839, training_loss: 0.94810
Epoch: 2/10, step: 88859, training_loss: 1.40661
Epoch: 2/10, step: 88879, training_loss: 1.77181
Epoch: 2/10, step: 88899, training_loss: 0.76526
Epoch: 2/10, step: 88919, training_loss: 1.47913
Epoch: 2/10, step: 88939, training_loss: 1.19914
Epoch: 2/10, step: 88959, training_loss: 1.50445
Epoch: 2/10, step: 88979, training_loss: 1.24805
Epoch: 2/10, step: 88999, training_loss: 1.85759
accuracy: 0.52, validation_loss: 1.389094352722168, num_samples: 100
Epoch: 2/10, step: 89019, training_loss: 1.14802
Epoch: 2/10, step: 89039, training_loss: 1.35621
Epoch: 2/10, step: 89059, training_loss: 2.12989
Epoch: 2/10, step: 89079, training_loss: 1.24295
Epoch: 2/10, step: 89099, training_loss: 1.73771
Epoch: 2/10, step: 89119, training_loss: 1.34131
Epoch: 2/10, step: 89139, training_loss: 1.05257
Epoch: 2/10, step: 89159, training_loss: 1.22683
Epoch: 2/10, step: 89179, training_loss: 1.64536
Epoch: 2/10, step: 89199, training_loss: 1.39291
Epoch: 2/10, step: 89219, training_loss: 1.04217
Epoch: 2/10, step: 89239, training_loss: 1.68317
Epoch: 2/10, step: 89259, training_loss: 1.60867
Epoch: 2/10, step: 89279, training_loss: 1.13729
Epoch: 2/10, step: 89299, training_loss: 1.65735
Epoch: 2/10, step: 89319, training_loss: 1.57801
Epoch: 2/10, step: 89339, training_loss: 1.20034
Epoch: 2/10, step: 89359, training_loss: 1.73157
Epoch: 2/10, step: 89379, training_loss: 1.49919
Epoch: 2/10, step: 89399, training_loss: 1.24702
Epoch: 2/10, step: 89419, training_loss: 1.65623
Epoch: 2/10, step: 89439, training_loss: 1.76657
Epoch: 2/10, step: 89459, training_loss: 1.54632
Epoch: 2/10, step: 89479, training_loss: 1.47742
Epoch: 2/10, step: 89499, training_loss: 0.89019
Epoch: 2/10, step: 89519, training_loss: 1.71918
Epoch: 2/10, step: 89539, training_loss: 0.97867
Epoch: 2/10, step: 89559, training_loss: 1.18840
Epoch: 2/10, step: 89579, training_loss: 1.84791
Epoch: 2/10, step: 89599, training_loss: 0.98592
Epoch: 2/10, step: 89619, training_loss: 1.50882
Epoch: 2/10, step: 89639, training_loss: 1.09228
Epoch: 2/10, step: 89659, training_loss: 1.67612
Epoch: 2/10, step: 89679, training_loss: 2.27271
Epoch: 2/10, step: 89699, training_loss: 1.53891
Epoch: 2/10, step: 89719, training_loss: 1.22575
Epoch: 2/10, step: 89739, training_loss: 1.28291
Epoch: 2/10, step: 89759, training_loss: 1.24923
Epoch: 2/10, step: 89779, training_loss: 1.52233
Epoch: 2/10, step: 89799, training_loss: 1.53903
Epoch: 2/10, step: 89819, training_loss: 0.75786
Epoch: 2/10, step: 89839, training_loss: 1.30521
Epoch: 2/10, step: 89859, training_loss: 0.94937
Epoch: 2/10, step: 89879, training_loss: 1.37323
Epoch: 2/10, step: 89899, training_loss: 1.59466
Epoch: 2/10, step: 89919, training_loss: 0.83919
Epoch: 2/10, step: 89939, training_loss: 1.99857
Epoch: 2/10, step: 89959, training_loss: 1.59336
Epoch: 2/10, step: 89979, training_loss: 1.19172
Epoch: 2/10, step: 89999, training_loss: 1.17213
accuracy: 0.51, validation_loss: 1.2933610677719116, num_samples: 100
Epoch: 2/10, step: 90019, training_loss: 1.05879
Epoch: 2/10, step: 90039, training_loss: 1.12250
Epoch: 2/10, step: 90059, training_loss: 0.61416
Epoch: 2/10, step: 90079, training_loss: 0.85041
Epoch: 2/10, step: 90099, training_loss: 2.07444
Epoch: 2/10, step: 90119, training_loss: 1.03798
Epoch: 2/10, step: 90139, training_loss: 1.69542
Epoch: 2/10, step: 90159, training_loss: 1.26219
Epoch: 2/10, step: 90179, training_loss: 1.54090
Epoch: 2/10, step: 90199, training_loss: 1.51824
Epoch: 2/10, step: 90219, training_loss: 1.00471
Epoch: 2/10, step: 90239, training_loss: 0.77946
Epoch: 2/10, step: 90259, training_loss: 0.85714
Epoch: 2/10, step: 90279, training_loss: 1.37583
Epoch: 2/10, step: 90299, training_loss: 1.37317
Epoch: 2/10, step: 90319, training_loss: 1.77123
Epoch: 2/10, step: 90339, training_loss: 1.28797
Epoch: 2/10, step: 90359, training_loss: 1.62137
Epoch: 2/10, step: 90379, training_loss: 1.15254
Epoch: 2/10, step: 90399, training_loss: 1.15871
Epoch: 2/10, step: 90419, training_loss: 2.06894
Epoch: 2/10, step: 90439, training_loss: 1.43720
Epoch: 2/10, step: 90459, training_loss: 1.79289
Epoch: 2/10, step: 90479, training_loss: 1.54220
Epoch: 2/10, step: 90499, training_loss: 1.39759
Epoch: 2/10, step: 90519, training_loss: 1.43504
Epoch: 2/10, step: 90539, training_loss: 1.68752
Epoch: 2/10, step: 90559, training_loss: 1.06336
Epoch: 2/10, step: 90579, training_loss: 1.87691
Epoch: 2/10, step: 90599, training_loss: 1.69086
Epoch: 2/10, step: 90619, training_loss: 1.79860
Epoch: 2/10, step: 90639, training_loss: 1.25019
Epoch: 2/10, step: 90659, training_loss: 1.38476
Epoch: 2/10, step: 90679, training_loss: 0.84136
Epoch: 2/10, step: 90699, training_loss: 1.81228
Epoch: 2/10, step: 90719, training_loss: 0.68651
Epoch: 2/10, step: 90739, training_loss: 1.94246
Epoch: 2/10, step: 90759, training_loss: 1.89566
Epoch: 2/10, step: 90779, training_loss: 1.65105
Epoch: 2/10, step: 90799, training_loss: 1.21024
Epoch: 2/10, step: 90819, training_loss: 1.48223
Epoch: 2/10, step: 90839, training_loss: 1.83848
Epoch: 2/10, step: 90859, training_loss: 1.45162
Epoch: 2/10, step: 90879, training_loss: 1.95661
Epoch: 2/10, step: 90899, training_loss: 1.34307
Epoch: 2/10, step: 90919, training_loss: 0.96977
Epoch: 2/10, step: 90939, training_loss: 0.91224
Epoch: 2/10, step: 90959, training_loss: 1.25161
Epoch: 2/10, step: 90979, training_loss: 1.51773
Epoch: 2/10, step: 90999, training_loss: 1.37489
accuracy: 0.4, validation_loss: 1.5058038234710693, num_samples: 100
Epoch: 2/10, step: 91019, training_loss: 1.13017
Epoch: 2/10, step: 91039, training_loss: 1.53622
Epoch: 2/10, step: 91059, training_loss: 1.87848
Epoch: 2/10, step: 91079, training_loss: 1.61846
Epoch: 2/10, step: 91099, training_loss: 1.65071
Epoch: 2/10, step: 91119, training_loss: 1.71786
Epoch: 2/10, step: 91139, training_loss: 1.22437
Epoch: 2/10, step: 91159, training_loss: 1.40701
Epoch: 2/10, step: 91179, training_loss: 1.40641
Epoch: 2/10, step: 91199, training_loss: 1.14165
Epoch: 2/10, step: 91219, training_loss: 0.90878
Epoch: 2/10, step: 91239, training_loss: 1.01787
Epoch: 2/10, step: 91259, training_loss: 1.50518
Epoch: 2/10, step: 91279, training_loss: 1.43491
Epoch: 2/10, step: 91299, training_loss: 1.35156
Epoch: 2/10, step: 91319, training_loss: 1.13422
Epoch: 2/10, step: 91339, training_loss: 2.10865
Epoch: 2/10, step: 91359, training_loss: 1.72126
Epoch: 2/10, step: 91379, training_loss: 1.66226
Epoch: 2/10, step: 91399, training_loss: 0.70795
Epoch: 2/10, step: 91419, training_loss: 0.76495
Epoch: 2/10, step: 91439, training_loss: 1.54243
Epoch: 2/10, step: 91459, training_loss: 1.84568
Epoch: 2/10, step: 91479, training_loss: 1.25734
Epoch: 2/10, step: 91499, training_loss: 1.10040
Epoch: 2/10, step: 91519, training_loss: 1.47684
Epoch: 2/10, step: 91539, training_loss: 1.97721
Epoch: 2/10, step: 91559, training_loss: 1.98563
Epoch: 2/10, step: 91579, training_loss: 0.93703
Epoch: 2/10, step: 91599, training_loss: 1.22896
Epoch: 2/10, step: 91619, training_loss: 1.31629
Epoch: 2/10, step: 91639, training_loss: 1.34931
Epoch: 2/10, step: 91659, training_loss: 1.37127
Epoch: 2/10, step: 91679, training_loss: 2.10843
Epoch: 2/10, step: 91699, training_loss: 1.36994
Epoch: 2/10, step: 91719, training_loss: 1.35690
Epoch: 2/10, step: 91739, training_loss: 1.37595
Epoch: 2/10, step: 91759, training_loss: 0.84291
Epoch: 2/10, step: 91779, training_loss: 1.64916
Epoch: 2/10, step: 91799, training_loss: 1.54731
Epoch: 2/10, step: 91819, training_loss: 1.57002
Epoch: 2/10, step: 91839, training_loss: 1.95483
Epoch: 2/10, step: 91859, training_loss: 1.25812
Epoch: 2/10, step: 91879, training_loss: 0.88491
Epoch: 2/10, step: 91899, training_loss: 2.02378
Epoch: 2/10, step: 91919, training_loss: 0.93145
Epoch: 2/10, step: 91939, training_loss: 1.61016
Epoch: 2/10, step: 91959, training_loss: 2.14348
Epoch: 2/10, step: 91979, training_loss: 0.95778
Epoch: 2/10, step: 91999, training_loss: 1.47775
accuracy: 0.47, validation_loss: 1.3654162883758545, num_samples: 100
Epoch: 2/10, step: 92019, training_loss: 0.84136
Epoch: 2/10, step: 92039, training_loss: 1.51743
Epoch: 2/10, step: 92059, training_loss: 2.21733
Epoch: 2/10, step: 92079, training_loss: 0.86284
Epoch: 2/10, step: 92099, training_loss: 1.04847
Epoch: 2/10, step: 92119, training_loss: 1.38119
Epoch: 2/10, step: 92139, training_loss: 1.67406
Epoch: 2/10, step: 92159, training_loss: 1.62510
Epoch: 2/10, step: 92179, training_loss: 1.67411
Epoch: 2/10, step: 92199, training_loss: 1.28788
Epoch: 2/10, step: 92219, training_loss: 1.62287
Epoch: 2/10, step: 92239, training_loss: 1.06179
Epoch: 2/10, step: 92259, training_loss: 1.27537
Epoch: 2/10, step: 92279, training_loss: 0.99636
Epoch: 2/10, step: 92299, training_loss: 1.07508
Epoch: 2/10, step: 92319, training_loss: 1.38864
Epoch: 2/10, step: 92339, training_loss: 1.28142
Epoch: 2/10, step: 92359, training_loss: 1.52459
Epoch: 2/10, step: 92379, training_loss: 1.39685
Epoch: 2/10, step: 92399, training_loss: 1.15596
Epoch: 2/10, step: 92419, training_loss: 1.50798
Epoch: 2/10, step: 92439, training_loss: 1.73787
Epoch: 2/10, step: 92459, training_loss: 1.79610
Epoch: 2/10, step: 92479, training_loss: 1.30767
Epoch: 2/10, step: 92499, training_loss: 1.40653
Epoch: 2/10, step: 92519, training_loss: 1.27505
Epoch: 2/10, step: 92539, training_loss: 1.97377
Epoch: 2/10, step: 92559, training_loss: 1.59147
Epoch: 2/10, step: 92579, training_loss: 1.46901
Epoch: 2/10, step: 92599, training_loss: 1.53800
Epoch: 2/10, step: 92619, training_loss: 1.36704
Epoch: 2/10, step: 92639, training_loss: 1.55132
Epoch: 2/10, step: 92659, training_loss: 0.97920
Epoch: 2/10, step: 92679, training_loss: 1.44638
Epoch: 2/10, step: 92699, training_loss: 1.69064
Epoch: 2/10, step: 92719, training_loss: 1.70106
Epoch: 2/10, step: 92739, training_loss: 1.69283
Epoch: 2/10, step: 92759, training_loss: 1.48106
Epoch: 2/10, step: 92779, training_loss: 1.31755
Epoch: 2/10, step: 92799, training_loss: 1.38246
Epoch: 2/10, step: 92819, training_loss: 1.18822
Epoch: 2/10, step: 92839, training_loss: 1.82857
Epoch: 2/10, step: 92859, training_loss: 1.66094
Epoch: 2/10, step: 92879, training_loss: 1.96490
Epoch: 2/10, step: 92899, training_loss: 1.54175
Epoch: 2/10, step: 92919, training_loss: 1.24381
Epoch: 2/10, step: 92939, training_loss: 1.07109
Epoch: 2/10, step: 92959, training_loss: 1.56313
Epoch: 2/10, step: 92979, training_loss: 1.64154
Epoch: 2/10, step: 92999, training_loss: 1.32040
accuracy: 0.48, validation_loss: 1.3199882507324219, num_samples: 100
Epoch: 2/10, step: 93019, training_loss: 0.84587
Epoch: 2/10, step: 93039, training_loss: 0.98847
Epoch: 2/10, step: 93059, training_loss: 1.47892
Epoch: 2/10, step: 93079, training_loss: 1.13288
Epoch: 2/10, step: 93099, training_loss: 0.38652
Epoch: 2/10, step: 93119, training_loss: 1.92531
Epoch: 2/10, step: 93139, training_loss: 0.93967
Epoch: 2/10, step: 93159, training_loss: 1.70386
Epoch: 2/10, step: 93179, training_loss: 1.85414
Epoch: 2/10, step: 93199, training_loss: 1.30303
Epoch: 2/10, step: 93219, training_loss: 1.56582
Epoch: 2/10, step: 93239, training_loss: 1.06484
Epoch: 2/10, step: 93259, training_loss: 1.40828
Epoch: 2/10, step: 93279, training_loss: 1.05347
Epoch: 2/10, step: 93299, training_loss: 1.55542
Epoch: 2/10, step: 93319, training_loss: 2.05029
Epoch: 2/10, step: 93339, training_loss: 2.18352
Epoch: 2/10, step: 93359, training_loss: 2.13311
Epoch: 2/10, step: 93379, training_loss: 1.27119
Epoch: 2/10, step: 93399, training_loss: 1.34963
Epoch: 2/10, step: 93419, training_loss: 1.05732
Epoch: 2/10, step: 93439, training_loss: 1.72829
Epoch: 2/10, step: 93459, training_loss: 1.29723
Epoch: 2/10, step: 93479, training_loss: 0.92280
Epoch: 2/10, step: 93499, training_loss: 1.62555
Epoch: 2/10, step: 93519, training_loss: 1.51923
Epoch: 2/10, step: 93539, training_loss: 1.46308
Epoch: 2/10, step: 93559, training_loss: 1.93246
Epoch: 2/10, step: 93579, training_loss: 1.06669
Epoch: 2/10, step: 93599, training_loss: 1.50993
Epoch: 2/10, step: 93619, training_loss: 0.88240
Epoch: 2/10, step: 93639, training_loss: 1.21411
Epoch: 2/10, step: 93659, training_loss: 1.42492
Epoch: 2/10, step: 93679, training_loss: 0.89261
Epoch: 2/10, step: 93699, training_loss: 2.07114
Epoch: 2/10, step: 93719, training_loss: 1.44583
Epoch: 2/10, step: 93739, training_loss: 1.55787
Epoch: 2/10, step: 93759, training_loss: 1.48060
Epoch: 2/10, step: 93779, training_loss: 1.84473
Epoch: 2/10, step: 93799, training_loss: 1.41345
Epoch: 2/10, step: 93819, training_loss: 1.98580
Epoch: 2/10, step: 93839, training_loss: 1.14643
Epoch: 2/10, step: 93859, training_loss: 1.58862
Epoch: 2/10, step: 93879, training_loss: 1.66567
Epoch: 2/10, step: 93899, training_loss: 2.03165
Epoch: 2/10, step: 93919, training_loss: 0.98660
Epoch: 2/10, step: 93939, training_loss: 2.61326
Epoch: 2/10, step: 93959, training_loss: 1.26341
Epoch: 2/10, step: 93979, training_loss: 1.18973
Epoch: 2/10, step: 93999, training_loss: 1.78650
accuracy: 0.52, validation_loss: 1.2231498956680298, num_samples: 100
Epoch: 2/10, step: 94019, training_loss: 1.59121
Epoch: 2/10, step: 94039, training_loss: 1.73685
Epoch: 2/10, step: 94059, training_loss: 1.23531
Epoch: 2/10, step: 94079, training_loss: 1.60214
Epoch: 2/10, step: 94099, training_loss: 1.58732
Epoch: 2/10, step: 94119, training_loss: 1.57460
Epoch: 2/10, step: 94139, training_loss: 1.69507
Epoch: 2/10, step: 94159, training_loss: 1.88724
Epoch: 2/10, step: 94179, training_loss: 1.46565
Epoch: 2/10, step: 94199, training_loss: 1.25860
Epoch: 2/10, step: 94219, training_loss: 1.25378
Epoch: 2/10, step: 94239, training_loss: 1.51798
Epoch: 2/10, step: 94259, training_loss: 1.99814
Epoch: 2/10, step: 94279, training_loss: 1.66285
Epoch: 2/10, step: 94299, training_loss: 1.25123
Epoch: 2/10, step: 94319, training_loss: 1.25010
Epoch: 2/10, step: 94339, training_loss: 1.83723
Epoch: 2/10, step: 94359, training_loss: 1.82916
Epoch: 2/10, step: 94379, training_loss: 1.34008
Epoch: 2/10, step: 94399, training_loss: 1.33864
Epoch: 2/10, step: 94419, training_loss: 0.76993
Epoch: 2/10, step: 94439, training_loss: 1.64438
Epoch: 2/10, step: 94459, training_loss: 1.15611
Epoch: 2/10, step: 94479, training_loss: 1.32433
Epoch: 2/10, step: 94499, training_loss: 0.93324
Epoch: 2/10, step: 94519, training_loss: 1.00952
Epoch: 2/10, step: 94539, training_loss: 1.49033
Epoch: 2/10, step: 94559, training_loss: 1.31746
Epoch: 2/10, step: 94579, training_loss: 0.81029
Epoch: 2/10, step: 94599, training_loss: 1.68090
Epoch: 2/10, step: 94619, training_loss: 1.60072
Epoch: 2/10, step: 94639, training_loss: 1.99466
Epoch: 2/10, step: 94659, training_loss: 1.45495
Epoch: 2/10, step: 94679, training_loss: 2.08224
Epoch: 2/10, step: 94699, training_loss: 1.32342
Epoch: 2/10, step: 94719, training_loss: 1.83790
Epoch: 2/10, step: 94739, training_loss: 1.11308
Epoch: 2/10, step: 94759, training_loss: 1.55686
Epoch: 2/10, step: 94779, training_loss: 1.19168
Epoch: 2/10, step: 94799, training_loss: 1.26442
Epoch: 2/10, step: 94819, training_loss: 1.08735
Epoch: 2/10, step: 94839, training_loss: 1.15048
Epoch: 2/10, step: 94859, training_loss: 1.36087
Epoch: 2/10, step: 94879, training_loss: 1.53719
Epoch: 2/10, step: 94899, training_loss: 1.86730
Epoch: 2/10, step: 94919, training_loss: 1.97786
Epoch: 2/10, step: 94939, training_loss: 1.55015
Epoch: 2/10, step: 94959, training_loss: 1.93496
Epoch: 2/10, step: 94979, training_loss: 1.72163
Epoch: 2/10, step: 94999, training_loss: 1.41293
accuracy: 0.54, validation_loss: 1.1895911693572998, num_samples: 100
Epoch: 2/10, step: 95019, training_loss: 1.89266
Epoch: 2/10, step: 95039, training_loss: 1.99454
Epoch: 2/10, step: 95059, training_loss: 0.94714
Epoch: 2/10, step: 95079, training_loss: 1.19175
Epoch: 2/10, step: 95099, training_loss: 1.36306
Epoch: 2/10, step: 95119, training_loss: 1.32622
Epoch: 2/10, step: 95139, training_loss: 1.79147
Epoch: 2/10, step: 95159, training_loss: 1.37210
Epoch: 2/10, step: 95179, training_loss: 1.23211
Epoch: 2/10, step: 95199, training_loss: 1.33807
Epoch: 2/10, step: 95219, training_loss: 1.58788
Epoch: 2/10, step: 95239, training_loss: 1.01234
Epoch: 2/10, step: 95259, training_loss: 0.89423
Epoch: 2/10, step: 95279, training_loss: 1.19915
Epoch: 2/10, step: 95299, training_loss: 1.42374
Epoch: 2/10, step: 95319, training_loss: 1.33195
Epoch: 2/10, step: 95339, training_loss: 0.89476
Epoch: 2/10, step: 95359, training_loss: 1.46451
Epoch: 2/10, step: 95379, training_loss: 1.02076
Epoch: 2/10, step: 95399, training_loss: 1.73899
Epoch: 2/10, step: 95419, training_loss: 1.88159
Epoch: 2/10, step: 95439, training_loss: 1.50274
Epoch: 2/10, step: 95459, training_loss: 1.48724
Epoch: 2/10, step: 95479, training_loss: 1.40232
Epoch: 2/10, step: 95499, training_loss: 2.00067
Epoch: 2/10, step: 95519, training_loss: 1.37261
Epoch: 2/10, step: 95539, training_loss: 1.57108
Epoch: 2/10, step: 95559, training_loss: 1.38906
Epoch: 2/10, step: 95579, training_loss: 1.00410
Epoch: 2/10, step: 95599, training_loss: 1.57821
Epoch: 2/10, step: 95619, training_loss: 1.40312
Epoch: 2/10, step: 95639, training_loss: 1.53270
Epoch: 2/10, step: 95659, training_loss: 1.72751
Epoch: 2/10, step: 95679, training_loss: 1.52061
Epoch: 2/10, step: 95699, training_loss: 1.07322
Epoch: 2/10, step: 95719, training_loss: 1.74622
Epoch: 2/10, step: 95739, training_loss: 1.30751
Epoch: 2/10, step: 95759, training_loss: 1.33262
Epoch: 2/10, step: 95779, training_loss: 1.61538
Epoch: 2/10, step: 95799, training_loss: 0.57434
Epoch: 2/10, step: 95819, training_loss: 1.80452
Epoch: 2/10, step: 95839, training_loss: 1.33993
Epoch: 2/10, step: 95859, training_loss: 1.77446
Epoch: 2/10, step: 95879, training_loss: 1.44780
Epoch: 2/10, step: 95899, training_loss: 2.32378
Epoch: 2/10, step: 95919, training_loss: 1.37790
Epoch: 2/10, step: 95939, training_loss: 1.24882
Epoch: 2/10, step: 95959, training_loss: 1.16897
Epoch: 2/10, step: 95979, training_loss: 1.11012
Epoch: 2/10, step: 95999, training_loss: 1.32208
accuracy: 0.46, validation_loss: 1.460375189781189, num_samples: 100
Epoch: 2/10, step: 96019, training_loss: 1.73343
Epoch: 2/10, step: 96039, training_loss: 1.34164
Epoch: 2/10, step: 96059, training_loss: 2.23060
Epoch: 2/10, step: 96079, training_loss: 0.84675
Epoch: 2/10, step: 96099, training_loss: 1.10339
Epoch: 2/10, step: 96119, training_loss: 1.55991
Epoch: 2/10, step: 96139, training_loss: 1.32955
Epoch: 2/10, step: 96159, training_loss: 1.47902
Epoch: 2/10, step: 96179, training_loss: 1.76040
Epoch: 2/10, step: 96199, training_loss: 1.13336
Epoch: 2/10, step: 96219, training_loss: 1.83982
Epoch: 2/10, step: 96239, training_loss: 1.55401
Epoch: 2/10, step: 96259, training_loss: 1.92904
Epoch: 2/10, step: 96279, training_loss: 1.60065
Epoch: 2/10, step: 96299, training_loss: 1.85617
Epoch: 2/10, step: 96319, training_loss: 1.01496
Epoch: 2/10, step: 96339, training_loss: 0.89259
Epoch: 2/10, step: 96359, training_loss: 1.50486
Epoch: 2/10, step: 96379, training_loss: 1.62200
Epoch: 2/10, step: 96399, training_loss: 1.61267
Epoch: 2/10, step: 96419, training_loss: 1.05489
Epoch: 2/10, step: 96439, training_loss: 1.07104
Epoch: 2/10, step: 96459, training_loss: 1.30629
Epoch: 2/10, step: 96479, training_loss: 1.58051
Epoch: 2/10, step: 96499, training_loss: 1.81597
Epoch: 2/10, step: 96519, training_loss: 1.57207
Epoch: 2/10, step: 96539, training_loss: 1.27204
Epoch: 2/10, step: 96559, training_loss: 1.51163
Epoch: 2/10, step: 96579, training_loss: 1.79712
Epoch: 2/10, step: 96599, training_loss: 1.17461
Epoch: 2/10, step: 96619, training_loss: 1.23035
Epoch: 2/10, step: 96639, training_loss: 1.62016
Epoch: 2/10, step: 96659, training_loss: 1.13180
Epoch: 2/10, step: 96679, training_loss: 1.94672
Epoch: 2/10, step: 96699, training_loss: 1.85898
Epoch: 2/10, step: 96719, training_loss: 1.85626
Epoch: 2/10, step: 96739, training_loss: 1.51045
Epoch: 2/10, step: 96759, training_loss: 1.25068
Epoch: 2/10, step: 96779, training_loss: 1.00116
Epoch: 2/10, step: 96799, training_loss: 1.38296
Epoch: 2/10, step: 96819, training_loss: 1.72118
Epoch: 2/10, step: 96839, training_loss: 1.56046
Epoch: 2/10, step: 96859, training_loss: 1.91714
Epoch: 2/10, step: 96879, training_loss: 0.95357
Epoch: 2/10, step: 96899, training_loss: 1.76745
Epoch: 2/10, step: 96919, training_loss: 1.56125
Epoch: 2/10, step: 96939, training_loss: 1.11852
Epoch: 2/10, step: 96959, training_loss: 1.07836
Epoch: 2/10, step: 96979, training_loss: 1.91272
Epoch: 2/10, step: 96999, training_loss: 1.54226
accuracy: 0.49, validation_loss: 1.4744133949279785, num_samples: 100
Epoch: 2/10, step: 97019, training_loss: 0.86658
Epoch: 2/10, step: 97039, training_loss: 1.18395
Epoch: 2/10, step: 97059, training_loss: 1.06498
Epoch: 2/10, step: 97079, training_loss: 1.05632
Epoch: 2/10, step: 97099, training_loss: 1.27777
Epoch: 2/10, step: 97119, training_loss: 1.44187
Epoch: 2/10, step: 97139, training_loss: 1.31288
Epoch: 2/10, step: 97159, training_loss: 1.80631
Epoch: 2/10, step: 97179, training_loss: 1.56868
Epoch: 2/10, step: 97199, training_loss: 1.65390
Epoch: 2/10, step: 97219, training_loss: 1.39078
Epoch: 2/10, step: 97239, training_loss: 0.88545
Epoch: 2/10, step: 97259, training_loss: 1.84084
Epoch: 2/10, step: 97279, training_loss: 1.11598
Epoch: 2/10, step: 97299, training_loss: 1.38111
Epoch: 2/10, step: 97319, training_loss: 1.94476
Epoch: 2/10, step: 97339, training_loss: 1.24380
Epoch: 2/10, step: 97359, training_loss: 0.70472
Epoch: 2/10, step: 97379, training_loss: 1.17578
Epoch: 2/10, step: 97399, training_loss: 1.50924
Epoch: 2/10, step: 97419, training_loss: 1.41256
Epoch: 2/10, step: 97439, training_loss: 0.88498
Epoch: 2/10, step: 97459, training_loss: 1.50349
Epoch: 2/10, step: 97479, training_loss: 0.73754
Epoch: 2/10, step: 97499, training_loss: 1.60383
Epoch: 2/10, step: 97519, training_loss: 1.18028
Epoch: 2/10, step: 97539, training_loss: 1.76904
Epoch: 2/10, step: 97559, training_loss: 1.67709
Epoch: 2/10, step: 97579, training_loss: 1.20715
Epoch: 2/10, step: 97599, training_loss: 1.12474
Epoch: 2/10, step: 97619, training_loss: 1.96272
Epoch: 2/10, step: 97639, training_loss: 0.89040
Epoch: 2/10, step: 97659, training_loss: 1.60227
Epoch: 2/10, step: 97679, training_loss: 0.95874
Epoch: 2/10, step: 97699, training_loss: 1.96394
Epoch: 2/10, step: 97719, training_loss: 1.06958
Epoch: 2/10, step: 97739, training_loss: 1.26411
Epoch: 2/10, step: 97759, training_loss: 1.82992
Epoch: 2/10, step: 97779, training_loss: 2.09544
Epoch: 2/10, step: 97799, training_loss: 0.94203
Epoch: 2/10, step: 97819, training_loss: 1.89875
Epoch: 2/10, step: 97839, training_loss: 1.25409
Epoch: 2/10, step: 97859, training_loss: 1.98879
Epoch: 2/10, step: 97879, training_loss: 1.61078
Epoch: 2/10, step: 97899, training_loss: 1.52948
Epoch: 2/10, step: 97919, training_loss: 1.40324
Epoch: 2/10, step: 97939, training_loss: 1.34705
Epoch: 2/10, step: 97959, training_loss: 1.16440
Epoch: 2/10, step: 97979, training_loss: 1.23251
Epoch: 2/10, step: 97999, training_loss: 1.46631
accuracy: 0.56, validation_loss: 1.3835159540176392, num_samples: 100
Epoch: 2/10, step: 98019, training_loss: 1.82718
Epoch: 2/10, step: 98039, training_loss: 1.13359
Epoch: 2/10, step: 98059, training_loss: 1.42530
Epoch: 2/10, step: 98079, training_loss: 1.04394
Epoch: 2/10, step: 98099, training_loss: 1.22904
Epoch: 2/10, step: 98119, training_loss: 2.04506
Epoch: 2/10, step: 98139, training_loss: 1.05556
Epoch: 2/10, step: 98159, training_loss: 0.98806
Epoch: 2/10, step: 98179, training_loss: 1.12642
Epoch: 2/10, step: 98199, training_loss: 1.34179
Epoch: 2/10, step: 98219, training_loss: 1.58634
Epoch: 2/10, step: 98239, training_loss: 1.84517
Epoch: 2/10, step: 98259, training_loss: 1.42175
Epoch: 2/10, step: 98279, training_loss: 1.60020
Epoch: 2/10, step: 98299, training_loss: 1.93986
Epoch: 2/10, step: 98319, training_loss: 1.33112
Epoch: 2/10, step: 98339, training_loss: 1.32243
Epoch: 2/10, step: 98359, training_loss: 1.65096
Epoch: 2/10, step: 98379, training_loss: 1.76126
Epoch: 2/10, step: 98399, training_loss: 1.61966
Epoch: 2/10, step: 98419, training_loss: 1.51587
Epoch: 2/10, step: 98439, training_loss: 0.98913
Epoch: 2/10, step: 98459, training_loss: 1.38959
Epoch: 2/10, step: 98479, training_loss: 1.27836
Epoch: 2/10, step: 98499, training_loss: 1.28738
Epoch: 2/10, step: 98519, training_loss: 1.38487
Epoch: 2/10, step: 98539, training_loss: 0.72446
Epoch: 2/10, step: 98559, training_loss: 1.33140
Epoch: 2/10, step: 98579, training_loss: 1.33394
Epoch: 2/10, step: 98599, training_loss: 1.30266
Epoch: 2/10, step: 98619, training_loss: 0.97061
Epoch: 2/10, step: 98639, training_loss: 1.40352
Epoch: 2/10, step: 98659, training_loss: 1.09204
Epoch: 2/10, step: 98679, training_loss: 1.63024
Epoch: 2/10, step: 98699, training_loss: 1.42341
Epoch: 2/10, step: 98719, training_loss: 1.21072
Epoch: 2/10, step: 98739, training_loss: 0.95556
Epoch: 2/10, step: 98759, training_loss: 1.93354
Epoch: 2/10, step: 98779, training_loss: 1.40707
Epoch: 2/10, step: 98799, training_loss: 1.76762
Epoch: 2/10, step: 98819, training_loss: 1.46605
Epoch: 2/10, step: 98839, training_loss: 1.12353
Epoch: 2/10, step: 98859, training_loss: 2.02949
Epoch: 2/10, step: 98879, training_loss: 1.33718
Epoch: 2/10, step: 98899, training_loss: 1.64227
Epoch: 2/10, step: 98919, training_loss: 0.87486
Epoch: 2/10, step: 98939, training_loss: 0.94689
Epoch: 2/10, step: 98959, training_loss: 1.76294
Epoch: 2/10, step: 98979, training_loss: 1.68225
Epoch: 2/10, step: 98999, training_loss: 1.87681
accuracy: 0.51, validation_loss: 1.657983422279358, num_samples: 100
Epoch: 2/10, step: 99019, training_loss: 1.39570
Epoch: 2/10, step: 99039, training_loss: 0.72166
Epoch: 2/10, step: 99059, training_loss: 1.32313
Epoch: 2/10, step: 99079, training_loss: 2.28974
Epoch: 2/10, step: 99099, training_loss: 0.90586
Epoch: 2/10, step: 99119, training_loss: 2.10405
Epoch: 2/10, step: 99139, training_loss: 1.51221
Epoch: 2/10, step: 99159, training_loss: 1.43402
Epoch: 2/10, step: 99179, training_loss: 1.24060
Epoch: 2/10, step: 99199, training_loss: 2.53114
Epoch: 2/10, step: 99219, training_loss: 1.15181
Epoch: 2/10, step: 99239, training_loss: 1.52990
Epoch: 2/10, step: 99259, training_loss: 1.19663
Epoch: 2/10, step: 99279, training_loss: 1.68005
Epoch: 2/10, step: 99299, training_loss: 1.22896
Epoch: 2/10, step: 99319, training_loss: 2.11540
Epoch: 2/10, step: 99339, training_loss: 1.65590
Epoch: 2/10, step: 99359, training_loss: 1.21052
Epoch: 2/10, step: 99379, training_loss: 1.60641
Epoch: 2/10, step: 99399, training_loss: 1.08460
Epoch: 2/10, step: 99419, training_loss: 1.92112
Epoch: 2/10, step: 99439, training_loss: 1.60788
Epoch: 2/10, step: 99459, training_loss: 1.81454
Epoch: 2/10, step: 99479, training_loss: 2.01581
Epoch: 2/10, step: 99499, training_loss: 2.18106
Epoch: 2/10, step: 99519, training_loss: 1.18467
Epoch: 2/10, step: 99539, training_loss: 1.25414
Epoch: 2/10, step: 99559, training_loss: 1.25222
Epoch: 2/10, step: 99579, training_loss: 1.36006
Epoch: 2/10, step: 99599, training_loss: 0.91593
Epoch: 2/10, step: 99619, training_loss: 1.66989
Epoch: 2/10, step: 99639, training_loss: 1.51298
Epoch: 2/10, step: 99659, training_loss: 1.76006
Epoch: 2/10, step: 99679, training_loss: 1.24033
Epoch: 2/10, step: 99699, training_loss: 1.63937
Epoch: 2/10, step: 99719, training_loss: 1.35066
Epoch: 2/10, step: 99739, training_loss: 1.62747
Epoch: 2/10, step: 99759, training_loss: 1.49523
Epoch: 2/10, step: 99779, training_loss: 1.31664
Epoch: 2/10, step: 99799, training_loss: 0.98314
Epoch: 2/10, step: 99819, training_loss: 1.12121
Epoch: 2/10, step: 99839, training_loss: 1.16811
Epoch: 2/10, step: 99859, training_loss: 1.50107
Epoch: 2/10, step: 99879, training_loss: 0.97613
Epoch: 2/10, step: 99899, training_loss: 1.31322
Epoch: 2/10, step: 99919, training_loss: 1.17101
Epoch: 2/10, step: 99939, training_loss: 1.11325
Epoch: 2/10, step: 99959, training_loss: 1.95647
Epoch: 2/10, step: 99979, training_loss: 1.99726
Epoch: 2/10, step: 99999, training_loss: 1.41752
accuracy: 0.45, validation_loss: 1.4679090976715088, num_samples: 100
Epoch: 2/10, step: 100019, training_loss: 1.02416
Epoch: 2/10, step: 100039, training_loss: 1.66720
Epoch: 2/10, step: 100059, training_loss: 1.83821
Epoch: 2/10, step: 100079, training_loss: 1.39024
Epoch: 2/10, step: 100099, training_loss: 1.56701
Epoch: 2/10, step: 100119, training_loss: 0.75718
Epoch: 2/10, step: 100139, training_loss: 1.23683
Epoch: 2/10, step: 100159, training_loss: 1.04965
Epoch: 2/10, step: 100179, training_loss: 0.69394
Epoch: 2/10, step: 100199, training_loss: 0.83358
Epoch: 2/10, step: 100219, training_loss: 0.69862
Epoch: 2/10, step: 100239, training_loss: 1.25449
Epoch: 2/10, step: 100259, training_loss: 1.84188
Epoch: 2/10, step: 100279, training_loss: 1.78203
Epoch: 2/10, step: 100299, training_loss: 1.17673
Epoch: 2/10, step: 100319, training_loss: 1.11303
Epoch: 2/10, step: 100339, training_loss: 1.14713
Epoch: 2/10, step: 100359, training_loss: 0.82200
Epoch: 2/10, step: 100379, training_loss: 2.30514
Epoch: 2/10, step: 100399, training_loss: 1.33676
Epoch: 2/10, step: 100419, training_loss: 1.92899
Epoch: 2/10, step: 100439, training_loss: 1.39628
Epoch: 2/10, step: 100459, training_loss: 1.11645
Epoch: 2/10, step: 100479, training_loss: 1.06753
Epoch: 2/10, step: 100499, training_loss: 1.53293
Epoch: 2/10, step: 100519, training_loss: 0.66505
Epoch: 2/10, step: 100539, training_loss: 1.10305
Epoch: 2/10, step: 100559, training_loss: 1.35678
Epoch: 2/10, step: 100579, training_loss: 1.46915
Epoch: 2/10, step: 100599, training_loss: 1.46795
Epoch: 2/10, step: 100619, training_loss: 1.31984
Epoch: 2/10, step: 100639, training_loss: 1.83311
Epoch: 2/10, step: 100659, training_loss: 0.84924
Epoch: 2/10, step: 100679, training_loss: 0.74699
Epoch: 2/10, step: 100699, training_loss: 1.37129
Epoch: 2/10, step: 100719, training_loss: 1.30314
Epoch: 2/10, step: 100739, training_loss: 1.95999
Epoch: 2/10, step: 100759, training_loss: 1.21923
Epoch: 2/10, step: 100779, training_loss: 1.91857
Epoch: 2/10, step: 100799, training_loss: 1.35017
Epoch: 2/10, step: 100819, training_loss: 1.33339
Epoch: 2/10, step: 100839, training_loss: 1.54554
Epoch: 2/10, step: 100859, training_loss: 1.07265
Epoch: 2/10, step: 100879, training_loss: 1.09187
Epoch: 2/10, step: 100899, training_loss: 1.95709
Epoch: 2/10, step: 100919, training_loss: 1.29325
Epoch: 2/10, step: 100939, training_loss: 1.69557
Epoch: 2/10, step: 100959, training_loss: 0.85762
Epoch: 2/10, step: 100979, training_loss: 1.57437
Epoch: 2/10, step: 100999, training_loss: 1.38313
accuracy: 0.55, validation_loss: 1.2310664653778076, num_samples: 100
Epoch: 2/10, step: 101019, training_loss: 1.82227
Epoch: 2/10, step: 101039, training_loss: 1.36516
Epoch: 2/10, step: 101059, training_loss: 1.17133
Epoch: 2/10, step: 101079, training_loss: 1.89184
Epoch: 2/10, step: 101099, training_loss: 1.21562
Epoch: 2/10, step: 101119, training_loss: 1.03988
Epoch: 2/10, step: 101139, training_loss: 1.49678
Epoch: 2/10, step: 101159, training_loss: 2.02046
Epoch: 2/10, step: 101179, training_loss: 1.49540
Epoch: 2/10, step: 101199, training_loss: 1.30239
Epoch: 2/10, step: 101219, training_loss: 1.14393
Epoch: 2/10, step: 101239, training_loss: 1.45553
Epoch: 2/10, step: 101259, training_loss: 0.85206
Epoch: 2/10, step: 101279, training_loss: 1.22867
Epoch: 2/10, step: 101299, training_loss: 1.36950
Epoch: 2/10, step: 101319, training_loss: 1.55308
Epoch: 2/10, step: 101339, training_loss: 2.20703
Epoch: 2/10, step: 101359, training_loss: 1.85880
Epoch: 2/10, step: 101379, training_loss: 1.86256
Epoch: 2/10, step: 101399, training_loss: 1.41999
Epoch: 2/10, step: 101419, training_loss: 1.53103
Epoch: 2/10, step: 101439, training_loss: 1.17053
Epoch: 2/10, step: 101459, training_loss: 1.03384
Epoch: 2/10, step: 101479, training_loss: 1.88412
Epoch: 2/10, step: 101499, training_loss: 0.95280
Epoch: 2/10, step: 101519, training_loss: 1.64299
Epoch: 2/10, step: 101539, training_loss: 1.25301
Epoch: 2/10, step: 101559, training_loss: 1.35018
Epoch: 2/10, step: 101579, training_loss: 1.37393
Epoch: 2/10, step: 101599, training_loss: 1.34773
Epoch: 2/10, step: 101619, training_loss: 1.30534
Epoch: 2/10, step: 101639, training_loss: 1.42257
Epoch: 2/10, step: 101659, training_loss: 1.04054
Epoch: 2/10, step: 101679, training_loss: 1.33423
Epoch: 2/10, step: 101699, training_loss: 1.60909
Epoch: 2/10, step: 101719, training_loss: 1.50561
Epoch: 2/10, step: 101739, training_loss: 1.32590
Epoch: 2/10, step: 101759, training_loss: 1.85261
Epoch: 2/10, step: 101779, training_loss: 0.85520
Epoch: 2/10, step: 101799, training_loss: 1.24066
Epoch: 2/10, step: 101819, training_loss: 1.73956
Epoch: 2/10, step: 101839, training_loss: 1.19731
Epoch: 2/10, step: 101859, training_loss: 1.82873
Epoch: 2/10, step: 101879, training_loss: 1.38684
Epoch: 2/10, step: 101899, training_loss: 1.48332
Epoch: 2/10, step: 101919, training_loss: 1.63601
Epoch: 2/10, step: 101939, training_loss: 1.19529
Epoch: 2/10, step: 101959, training_loss: 1.62139
Epoch: 2/10, step: 101979, training_loss: 1.55793
Epoch: 2/10, step: 101999, training_loss: 1.10725
accuracy: 0.44, validation_loss: 1.5464739799499512, num_samples: 100
Epoch: 2/10, step: 102019, training_loss: 1.05888
Epoch: 2/10, step: 102039, training_loss: 1.10757
Epoch: 2/10, step: 102059, training_loss: 1.15963
Epoch: 2/10, step: 102079, training_loss: 0.82967
Epoch: 2/10, step: 102099, training_loss: 1.60691
Epoch: 2/10, step: 102119, training_loss: 1.70446
Epoch: 2/10, step: 102139, training_loss: 1.26487
Epoch: 2/10, step: 102159, training_loss: 0.75848
Epoch: 2/10, step: 102179, training_loss: 1.88292
Epoch: 2/10, step: 102199, training_loss: 1.24165
Epoch: 2/10, step: 102219, training_loss: 1.09641
Epoch: 2/10, step: 102239, training_loss: 1.08502
Epoch: 2/10, step: 102259, training_loss: 1.17410
Epoch: 2/10, step: 102279, training_loss: 1.10132
Epoch: 2/10, step: 102299, training_loss: 1.81111
Epoch: 2/10, step: 102319, training_loss: 1.35527
Epoch: 2/10, step: 102339, training_loss: 1.46041
Epoch: 2/10, step: 102359, training_loss: 1.57340
Epoch: 2/10, step: 102379, training_loss: 1.38916
Epoch: 2/10, step: 102399, training_loss: 1.68672
Epoch: 2/10, step: 102419, training_loss: 0.68404
Epoch: 2/10, step: 102439, training_loss: 1.87119
Epoch: 2/10, step: 102459, training_loss: 1.54098
Epoch: 2/10, step: 102479, training_loss: 1.33579
Epoch: 2/10, step: 102499, training_loss: 1.48851
Epoch: 2/10, step: 102519, training_loss: 1.25286
Epoch: 2/10, step: 102539, training_loss: 1.29169
Epoch: 2/10, step: 102559, training_loss: 2.39730
Epoch: 2/10, step: 102579, training_loss: 1.19450
Epoch: 2/10, step: 102599, training_loss: 0.87806
Epoch: 2/10, step: 102619, training_loss: 2.41104
Epoch: 2/10, step: 102639, training_loss: 0.95286
Epoch: 3/10, step: 19, training_loss: 0.64258
Epoch: 3/10, step: 39, training_loss: 1.39375
Epoch: 3/10, step: 59, training_loss: 1.18830
Epoch: 3/10, step: 79, training_loss: 1.72966
Epoch: 3/10, step: 99, training_loss: 1.82367
Epoch: 3/10, step: 119, training_loss: 1.18122
Epoch: 3/10, step: 139, training_loss: 1.33342
Epoch: 3/10, step: 159, training_loss: 1.46307
Epoch: 3/10, step: 179, training_loss: 1.01315
Epoch: 3/10, step: 199, training_loss: 1.73895
Epoch: 3/10, step: 219, training_loss: 0.80826
Epoch: 3/10, step: 239, training_loss: 1.24280
Epoch: 3/10, step: 259, training_loss: 1.13107
Epoch: 3/10, step: 279, training_loss: 1.69170
Epoch: 3/10, step: 299, training_loss: 1.60749
Epoch: 3/10, step: 319, training_loss: 1.73971
Epoch: 3/10, step: 339, training_loss: 0.93668
Epoch: 3/10, step: 359, training_loss: 1.48097
Epoch: 3/10, step: 379, training_loss: 1.00351
Epoch: 3/10, step: 399, training_loss: 1.97711
Epoch: 3/10, step: 419, training_loss: 1.74829
Epoch: 3/10, step: 439, training_loss: 1.42443
Epoch: 3/10, step: 459, training_loss: 2.02164
Epoch: 3/10, step: 479, training_loss: 1.16852
Epoch: 3/10, step: 499, training_loss: 1.72932
Epoch: 3/10, step: 519, training_loss: 0.92501
Epoch: 3/10, step: 539, training_loss: 1.72023
Epoch: 3/10, step: 559, training_loss: 0.91171
Epoch: 3/10, step: 579, training_loss: 1.58658
Epoch: 3/10, step: 599, training_loss: 1.53953
Epoch: 3/10, step: 619, training_loss: 1.36768
Epoch: 3/10, step: 639, training_loss: 1.36215
Epoch: 3/10, step: 659, training_loss: 1.37467
Epoch: 3/10, step: 679, training_loss: 1.53734
Epoch: 3/10, step: 699, training_loss: 0.86813
Epoch: 3/10, step: 719, training_loss: 1.41590
Epoch: 3/10, step: 739, training_loss: 1.48631
Epoch: 3/10, step: 759, training_loss: 1.01242
Epoch: 3/10, step: 779, training_loss: 1.50645
Epoch: 3/10, step: 799, training_loss: 1.86559
Epoch: 3/10, step: 819, training_loss: 1.38467
Epoch: 3/10, step: 839, training_loss: 1.36219
Epoch: 3/10, step: 859, training_loss: 1.85905
Epoch: 3/10, step: 879, training_loss: 1.52777
Epoch: 3/10, step: 899, training_loss: 1.57552
Epoch: 3/10, step: 919, training_loss: 2.11728
Epoch: 3/10, step: 939, training_loss: 1.21952
Epoch: 3/10, step: 959, training_loss: 1.37587
Epoch: 3/10, step: 979, training_loss: 1.67970
Epoch: 3/10, step: 999, training_loss: 1.46122
accuracy: 0.51, validation_loss: 1.50571608543396, num_samples: 100
Epoch: 3/10, step: 1019, training_loss: 1.94915
Epoch: 3/10, step: 1039, training_loss: 1.09937
Epoch: 3/10, step: 1059, training_loss: 1.18383
Epoch: 3/10, step: 1079, training_loss: 1.70269
Epoch: 3/10, step: 1099, training_loss: 1.55900
Epoch: 3/10, step: 1119, training_loss: 1.18484
Epoch: 3/10, step: 1139, training_loss: 1.26085
Epoch: 3/10, step: 1159, training_loss: 1.30119
Epoch: 3/10, step: 1179, training_loss: 0.94151
Epoch: 3/10, step: 1199, training_loss: 1.23247
Epoch: 3/10, step: 1219, training_loss: 1.05833
Epoch: 3/10, step: 1239, training_loss: 1.70505
Epoch: 3/10, step: 1259, training_loss: 1.25638
Epoch: 3/10, step: 1279, training_loss: 1.35995
Epoch: 3/10, step: 1299, training_loss: 1.62377
Epoch: 3/10, step: 1319, training_loss: 1.31847
Epoch: 3/10, step: 1339, training_loss: 1.27395
Epoch: 3/10, step: 1359, training_loss: 0.84769
Epoch: 3/10, step: 1379, training_loss: 1.13514
Epoch: 3/10, step: 1399, training_loss: 1.66763
Epoch: 3/10, step: 1419, training_loss: 1.42828
Epoch: 3/10, step: 1439, training_loss: 1.71793
Epoch: 3/10, step: 1459, training_loss: 2.10247
Epoch: 3/10, step: 1479, training_loss: 1.57167
Epoch: 3/10, step: 1499, training_loss: 0.80461
Epoch: 3/10, step: 1519, training_loss: 1.49799
Epoch: 3/10, step: 1539, training_loss: 1.59087
Epoch: 3/10, step: 1559, training_loss: 1.16818
Epoch: 3/10, step: 1579, training_loss: 1.34435
Epoch: 3/10, step: 1599, training_loss: 1.02652
Epoch: 3/10, step: 1619, training_loss: 1.69163
Epoch: 3/10, step: 1639, training_loss: 1.70730
Epoch: 3/10, step: 1659, training_loss: 1.84745
Epoch: 3/10, step: 1679, training_loss: 1.87968
Epoch: 3/10, step: 1699, training_loss: 2.30371
Epoch: 3/10, step: 1719, training_loss: 1.72032
Epoch: 3/10, step: 1739, training_loss: 1.18532
Epoch: 3/10, step: 1759, training_loss: 1.41751
Epoch: 3/10, step: 1779, training_loss: 0.99509
Epoch: 3/10, step: 1799, training_loss: 0.98719
Epoch: 3/10, step: 1819, training_loss: 1.55949
Epoch: 3/10, step: 1839, training_loss: 1.74200
Epoch: 3/10, step: 1859, training_loss: 1.56880
Epoch: 3/10, step: 1879, training_loss: 1.97161
Epoch: 3/10, step: 1899, training_loss: 1.08116
Epoch: 3/10, step: 1919, training_loss: 1.66000
Epoch: 3/10, step: 1939, training_loss: 1.46743
Epoch: 3/10, step: 1959, training_loss: 1.75887
Epoch: 3/10, step: 1979, training_loss: 0.64583
Epoch: 3/10, step: 1999, training_loss: 1.45855
accuracy: 0.5, validation_loss: 1.3229477405548096, num_samples: 100
Epoch: 3/10, step: 2019, training_loss: 0.71518
Epoch: 3/10, step: 2039, training_loss: 1.20831
Epoch: 3/10, step: 2059, training_loss: 1.30440
Epoch: 3/10, step: 2079, training_loss: 1.06764
Epoch: 3/10, step: 2099, training_loss: 1.02410
Epoch: 3/10, step: 2119, training_loss: 1.83576
Epoch: 3/10, step: 2139, training_loss: 1.23377
Epoch: 3/10, step: 2159, training_loss: 1.30729
Epoch: 3/10, step: 2179, training_loss: 1.46754
Epoch: 3/10, step: 2199, training_loss: 1.37704
Epoch: 3/10, step: 2219, training_loss: 1.63691
Epoch: 3/10, step: 2239, training_loss: 1.64361
Epoch: 3/10, step: 2259, training_loss: 1.76495
Epoch: 3/10, step: 2279, training_loss: 1.22916
Epoch: 3/10, step: 2299, training_loss: 1.18603
Epoch: 3/10, step: 2319, training_loss: 1.46353
Epoch: 3/10, step: 2339, training_loss: 1.91564
Epoch: 3/10, step: 2359, training_loss: 1.53304
Epoch: 3/10, step: 2379, training_loss: 1.83063
Epoch: 3/10, step: 2399, training_loss: 0.80930
Epoch: 3/10, step: 2419, training_loss: 1.09083
Epoch: 3/10, step: 2439, training_loss: 0.97561
Epoch: 3/10, step: 2459, training_loss: 1.46310
Epoch: 3/10, step: 2479, training_loss: 2.08099
Epoch: 3/10, step: 2499, training_loss: 1.59271
Epoch: 3/10, step: 2519, training_loss: 1.85483
Epoch: 3/10, step: 2539, training_loss: 1.07331
Epoch: 3/10, step: 2559, training_loss: 2.18914
Epoch: 3/10, step: 2579, training_loss: 0.91840
Epoch: 3/10, step: 2599, training_loss: 1.50880
Epoch: 3/10, step: 2619, training_loss: 1.93980
Epoch: 3/10, step: 2639, training_loss: 1.33338
Epoch: 3/10, step: 2659, training_loss: 1.86998
Epoch: 3/10, step: 2679, training_loss: 1.59613
Epoch: 3/10, step: 2699, training_loss: 1.23178
Epoch: 3/10, step: 2719, training_loss: 1.22081
Epoch: 3/10, step: 2739, training_loss: 1.73057
Epoch: 3/10, step: 2759, training_loss: 1.97481
Epoch: 3/10, step: 2779, training_loss: 1.33669
Epoch: 3/10, step: 2799, training_loss: 1.65159
Epoch: 3/10, step: 2819, training_loss: 2.33329
Epoch: 3/10, step: 2839, training_loss: 1.88180
Epoch: 3/10, step: 2859, training_loss: 1.31473
Epoch: 3/10, step: 2879, training_loss: 1.20030
Epoch: 3/10, step: 2899, training_loss: 1.52445
Epoch: 3/10, step: 2919, training_loss: 1.48324
Epoch: 3/10, step: 2939, training_loss: 2.04003
Epoch: 3/10, step: 2959, training_loss: 1.62670
Epoch: 3/10, step: 2979, training_loss: 1.52521
Epoch: 3/10, step: 2999, training_loss: 1.32056
accuracy: 0.52, validation_loss: 1.3344109058380127, num_samples: 100
Epoch: 3/10, step: 3019, training_loss: 2.24904
Epoch: 3/10, step: 3039, training_loss: 1.87535
Epoch: 3/10, step: 3059, training_loss: 1.46566
Epoch: 3/10, step: 3079, training_loss: 1.43194
Epoch: 3/10, step: 3099, training_loss: 1.60184
Epoch: 3/10, step: 3119, training_loss: 0.97389
Epoch: 3/10, step: 3139, training_loss: 1.28030
Epoch: 3/10, step: 3159, training_loss: 1.23545
Epoch: 3/10, step: 3179, training_loss: 1.20662
Epoch: 3/10, step: 3199, training_loss: 1.46356
Epoch: 3/10, step: 3219, training_loss: 1.79586
Epoch: 3/10, step: 3239, training_loss: 1.33335
Epoch: 3/10, step: 3259, training_loss: 2.23070
Epoch: 3/10, step: 3279, training_loss: 1.61683
Epoch: 3/10, step: 3299, training_loss: 0.94901
Epoch: 3/10, step: 3319, training_loss: 1.74215
Epoch: 3/10, step: 3339, training_loss: 1.16273
Epoch: 3/10, step: 3359, training_loss: 0.86801
Epoch: 3/10, step: 3379, training_loss: 1.49613
Epoch: 3/10, step: 3399, training_loss: 1.18650
Epoch: 3/10, step: 3419, training_loss: 1.17763
Epoch: 3/10, step: 3439, training_loss: 1.32543
Epoch: 3/10, step: 3459, training_loss: 1.48693
Epoch: 3/10, step: 3479, training_loss: 1.60862
Epoch: 3/10, step: 3499, training_loss: 1.64743
Epoch: 3/10, step: 3519, training_loss: 1.22781
Epoch: 3/10, step: 3539, training_loss: 1.09668
Epoch: 3/10, step: 3559, training_loss: 1.57889
Epoch: 3/10, step: 3579, training_loss: 1.89682
Epoch: 3/10, step: 3599, training_loss: 1.53450
Epoch: 3/10, step: 3619, training_loss: 1.51997
Epoch: 3/10, step: 3639, training_loss: 1.22261
Epoch: 3/10, step: 3659, training_loss: 1.75284
Epoch: 3/10, step: 3679, training_loss: 1.55148
Epoch: 3/10, step: 3699, training_loss: 0.89424
Epoch: 3/10, step: 3719, training_loss: 1.97719
Epoch: 3/10, step: 3739, training_loss: 1.61401
Epoch: 3/10, step: 3759, training_loss: 1.62355
Epoch: 3/10, step: 3779, training_loss: 1.81100
Epoch: 3/10, step: 3799, training_loss: 1.81158
Epoch: 3/10, step: 3819, training_loss: 1.12126
Epoch: 3/10, step: 3839, training_loss: 1.82199
Epoch: 3/10, step: 3859, training_loss: 1.40015
Epoch: 3/10, step: 3879, training_loss: 1.35691
Epoch: 3/10, step: 3899, training_loss: 1.44743
Epoch: 3/10, step: 3919, training_loss: 1.17516
Epoch: 3/10, step: 3939, training_loss: 1.26265
Epoch: 3/10, step: 3959, training_loss: 1.42359
Epoch: 3/10, step: 3979, training_loss: 1.23599
Epoch: 3/10, step: 3999, training_loss: 0.73681
accuracy: 0.45, validation_loss: 1.4856693744659424, num_samples: 100
Epoch: 3/10, step: 4019, training_loss: 0.80171
Epoch: 3/10, step: 4039, training_loss: 1.10497
Epoch: 3/10, step: 4059, training_loss: 1.27289
Epoch: 3/10, step: 4079, training_loss: 1.77048
Epoch: 3/10, step: 4099, training_loss: 1.34515
Epoch: 3/10, step: 4119, training_loss: 0.95718
Epoch: 3/10, step: 4139, training_loss: 1.29234
Epoch: 3/10, step: 4159, training_loss: 1.03649
Epoch: 3/10, step: 4179, training_loss: 1.63918
Epoch: 3/10, step: 4199, training_loss: 1.54601
Epoch: 3/10, step: 4219, training_loss: 1.09352
Epoch: 3/10, step: 4239, training_loss: 1.21826
Epoch: 3/10, step: 4259, training_loss: 1.33441
Epoch: 3/10, step: 4279, training_loss: 1.29010
Epoch: 3/10, step: 4299, training_loss: 1.92921
Epoch: 3/10, step: 4319, training_loss: 1.26723
Epoch: 3/10, step: 4339, training_loss: 1.16830
Epoch: 3/10, step: 4359, training_loss: 1.49249
Epoch: 3/10, step: 4379, training_loss: 1.19687
Epoch: 3/10, step: 4399, training_loss: 1.20575
Epoch: 3/10, step: 4419, training_loss: 1.33809
Epoch: 3/10, step: 4439, training_loss: 1.86306
Epoch: 3/10, step: 4459, training_loss: 1.30378
Epoch: 3/10, step: 4479, training_loss: 1.17290
Epoch: 3/10, step: 4499, training_loss: 1.18602
Epoch: 3/10, step: 4519, training_loss: 1.41009
Epoch: 3/10, step: 4539, training_loss: 2.05841
Epoch: 3/10, step: 4559, training_loss: 1.38691
Epoch: 3/10, step: 4579, training_loss: 1.43103
Epoch: 3/10, step: 4599, training_loss: 1.10936
Epoch: 3/10, step: 4619, training_loss: 1.38250
Epoch: 3/10, step: 4639, training_loss: 1.45550
Epoch: 3/10, step: 4659, training_loss: 1.16360
Epoch: 3/10, step: 4679, training_loss: 0.88299
Epoch: 3/10, step: 4699, training_loss: 1.31009
Epoch: 3/10, step: 4719, training_loss: 1.36485
Epoch: 3/10, step: 4739, training_loss: 1.45250
Epoch: 3/10, step: 4759, training_loss: 1.08031
Epoch: 3/10, step: 4779, training_loss: 1.88145
Epoch: 3/10, step: 4799, training_loss: 1.17420
Epoch: 3/10, step: 4819, training_loss: 1.02189
Epoch: 3/10, step: 4839, training_loss: 0.91239
Epoch: 3/10, step: 4859, training_loss: 1.26551
Epoch: 3/10, step: 4879, training_loss: 1.30890
Epoch: 3/10, step: 4899, training_loss: 1.83327
Epoch: 3/10, step: 4919, training_loss: 1.87343
Epoch: 3/10, step: 4939, training_loss: 1.54834
Epoch: 3/10, step: 4959, training_loss: 1.53599
Epoch: 3/10, step: 4979, training_loss: 0.78825
Epoch: 3/10, step: 4999, training_loss: 2.23282
accuracy: 0.53, validation_loss: 1.3105592727661133, num_samples: 100
Epoch: 3/10, step: 5019, training_loss: 1.28356
Epoch: 3/10, step: 5039, training_loss: 1.45566
Epoch: 3/10, step: 5059, training_loss: 1.70292
Epoch: 3/10, step: 5079, training_loss: 1.83256
Epoch: 3/10, step: 5099, training_loss: 1.45489
Epoch: 3/10, step: 5119, training_loss: 1.36154
Epoch: 3/10, step: 5139, training_loss: 2.15901
Epoch: 3/10, step: 5159, training_loss: 1.15273
Epoch: 3/10, step: 5179, training_loss: 0.77310
Epoch: 3/10, step: 5199, training_loss: 0.87817
Epoch: 3/10, step: 5219, training_loss: 1.42500
Epoch: 3/10, step: 5239, training_loss: 1.47539
Epoch: 3/10, step: 5259, training_loss: 1.55532
Epoch: 3/10, step: 5279, training_loss: 1.45615
Epoch: 3/10, step: 5299, training_loss: 1.29667
Epoch: 3/10, step: 5319, training_loss: 1.81522
Epoch: 3/10, step: 5339, training_loss: 1.61295
Epoch: 3/10, step: 5359, training_loss: 1.63435
Epoch: 3/10, step: 5379, training_loss: 1.53386
Epoch: 3/10, step: 5399, training_loss: 1.12634
Epoch: 3/10, step: 5419, training_loss: 1.42844
Epoch: 3/10, step: 5439, training_loss: 1.47168
Epoch: 3/10, step: 5459, training_loss: 1.41664
Epoch: 3/10, step: 5479, training_loss: 1.60057
Epoch: 3/10, step: 5499, training_loss: 1.58223
Epoch: 3/10, step: 5519, training_loss: 1.42305
Epoch: 3/10, step: 5539, training_loss: 2.04720
Epoch: 3/10, step: 5559, training_loss: 1.55324
Epoch: 3/10, step: 5579, training_loss: 1.34616
Epoch: 3/10, step: 5599, training_loss: 0.88294
Epoch: 3/10, step: 5619, training_loss: 1.39109
Epoch: 3/10, step: 5639, training_loss: 0.69523
Epoch: 3/10, step: 5659, training_loss: 1.41030
Epoch: 3/10, step: 5679, training_loss: 1.63445
Epoch: 3/10, step: 5699, training_loss: 1.10284
Epoch: 3/10, step: 5719, training_loss: 2.16856
Epoch: 3/10, step: 5739, training_loss: 1.28526
Epoch: 3/10, step: 5759, training_loss: 1.36799
Epoch: 3/10, step: 5779, training_loss: 1.58209
Epoch: 3/10, step: 5799, training_loss: 1.08267
Epoch: 3/10, step: 5819, training_loss: 1.55532
Epoch: 3/10, step: 5839, training_loss: 2.06161
Epoch: 3/10, step: 5859, training_loss: 1.90073
Epoch: 3/10, step: 5879, training_loss: 0.98582
Epoch: 3/10, step: 5899, training_loss: 1.57778
Epoch: 3/10, step: 5919, training_loss: 1.43304
Epoch: 3/10, step: 5939, training_loss: 1.42166
Epoch: 3/10, step: 5959, training_loss: 1.29872
Epoch: 3/10, step: 5979, training_loss: 1.98260
Epoch: 3/10, step: 5999, training_loss: 1.38574
accuracy: 0.52, validation_loss: 1.4418761730194092, num_samples: 100
Epoch: 3/10, step: 6019, training_loss: 1.99054
Epoch: 3/10, step: 6039, training_loss: 1.33927
Epoch: 3/10, step: 6059, training_loss: 1.43809
Epoch: 3/10, step: 6079, training_loss: 0.93584
Epoch: 3/10, step: 6099, training_loss: 1.04890
Epoch: 3/10, step: 6119, training_loss: 1.36383
Epoch: 3/10, step: 6139, training_loss: 1.23682
Epoch: 3/10, step: 6159, training_loss: 1.47792
Epoch: 3/10, step: 6179, training_loss: 1.46022
Epoch: 3/10, step: 6199, training_loss: 1.72809
Epoch: 3/10, step: 6219, training_loss: 1.26524
Epoch: 3/10, step: 6239, training_loss: 0.91377
Epoch: 3/10, step: 6259, training_loss: 1.50612
Epoch: 3/10, step: 6279, training_loss: 1.08780
Epoch: 3/10, step: 6299, training_loss: 1.24761
Epoch: 3/10, step: 6319, training_loss: 1.61093
Epoch: 3/10, step: 6339, training_loss: 0.97529
Epoch: 3/10, step: 6359, training_loss: 1.65060
Epoch: 3/10, step: 6379, training_loss: 1.99905
Epoch: 3/10, step: 6399, training_loss: 1.47789
Epoch: 3/10, step: 6419, training_loss: 1.07020
Epoch: 3/10, step: 6439, training_loss: 1.42475
Epoch: 3/10, step: 6459, training_loss: 2.06950
Epoch: 3/10, step: 6479, training_loss: 1.26750
Epoch: 3/10, step: 6499, training_loss: 1.22741
Epoch: 3/10, step: 6519, training_loss: 1.86708
Epoch: 3/10, step: 6539, training_loss: 1.03225
Epoch: 3/10, step: 6559, training_loss: 1.49420
Epoch: 3/10, step: 6579, training_loss: 0.91932
Epoch: 3/10, step: 6599, training_loss: 1.40690
Epoch: 3/10, step: 6619, training_loss: 1.62138
Epoch: 3/10, step: 6639, training_loss: 2.01722
Epoch: 3/10, step: 6659, training_loss: 0.80110
Epoch: 3/10, step: 6679, training_loss: 0.89016
Epoch: 3/10, step: 6699, training_loss: 1.12828
Epoch: 3/10, step: 6719, training_loss: 1.00312
Epoch: 3/10, step: 6739, training_loss: 1.42347
Epoch: 3/10, step: 6759, training_loss: 1.05729
Epoch: 3/10, step: 6779, training_loss: 1.43141
Epoch: 3/10, step: 6799, training_loss: 1.27072
Epoch: 3/10, step: 6819, training_loss: 1.55482
Epoch: 3/10, step: 6839, training_loss: 1.00848
Epoch: 3/10, step: 6859, training_loss: 1.13995
Epoch: 3/10, step: 6879, training_loss: 1.10373
Epoch: 3/10, step: 6899, training_loss: 0.98915
Epoch: 3/10, step: 6919, training_loss: 1.84919
Epoch: 3/10, step: 6939, training_loss: 1.37799
Epoch: 3/10, step: 6959, training_loss: 1.55403
Epoch: 3/10, step: 6979, training_loss: 1.11645
Epoch: 3/10, step: 6999, training_loss: 0.78916
accuracy: 0.49, validation_loss: 1.382422685623169, num_samples: 100
Epoch: 3/10, step: 7019, training_loss: 1.45018
Epoch: 3/10, step: 7039, training_loss: 1.71307
Epoch: 3/10, step: 7059, training_loss: 1.49334
Epoch: 3/10, step: 7079, training_loss: 1.88131
Epoch: 3/10, step: 7099, training_loss: 1.05573
Epoch: 3/10, step: 7119, training_loss: 1.14069
Epoch: 3/10, step: 7139, training_loss: 1.43767
Epoch: 3/10, step: 7159, training_loss: 0.84533
Epoch: 3/10, step: 7179, training_loss: 1.16344
Epoch: 3/10, step: 7199, training_loss: 1.51253
Epoch: 3/10, step: 7219, training_loss: 1.31924
Epoch: 3/10, step: 7239, training_loss: 2.17025
Epoch: 3/10, step: 7259, training_loss: 2.16514
Epoch: 3/10, step: 7279, training_loss: 1.75814
Epoch: 3/10, step: 7299, training_loss: 2.12570
Epoch: 3/10, step: 7319, training_loss: 1.54306
Epoch: 3/10, step: 7339, training_loss: 1.54004
Epoch: 3/10, step: 7359, training_loss: 1.55248
Epoch: 3/10, step: 7379, training_loss: 1.48490
Epoch: 3/10, step: 7399, training_loss: 1.11772
Epoch: 3/10, step: 7419, training_loss: 0.87456
Epoch: 3/10, step: 7439, training_loss: 2.00036
Epoch: 3/10, step: 7459, training_loss: 1.32159
Epoch: 3/10, step: 7479, training_loss: 1.14393
Epoch: 3/10, step: 7499, training_loss: 1.14184
Epoch: 3/10, step: 7519, training_loss: 1.86883
Epoch: 3/10, step: 7539, training_loss: 1.17114
Epoch: 3/10, step: 7559, training_loss: 1.36899
Epoch: 3/10, step: 7579, training_loss: 0.96294
Epoch: 3/10, step: 7599, training_loss: 1.72307
Epoch: 3/10, step: 7619, training_loss: 1.86124
Epoch: 3/10, step: 7639, training_loss: 1.47788
Epoch: 3/10, step: 7659, training_loss: 0.64233
Epoch: 3/10, step: 7679, training_loss: 1.26782
Epoch: 3/10, step: 7699, training_loss: 1.84473
Epoch: 3/10, step: 7719, training_loss: 1.56831
Epoch: 3/10, step: 7739, training_loss: 1.71814
Epoch: 3/10, step: 7759, training_loss: 1.39493
Epoch: 3/10, step: 7779, training_loss: 1.58437
Epoch: 3/10, step: 7799, training_loss: 1.60650
Epoch: 3/10, step: 7819, training_loss: 1.25451
Epoch: 3/10, step: 7839, training_loss: 1.88982
Epoch: 3/10, step: 7859, training_loss: 1.67186
Epoch: 3/10, step: 7879, training_loss: 1.15244
Epoch: 3/10, step: 7899, training_loss: 1.14029
Epoch: 3/10, step: 7919, training_loss: 1.45429
Epoch: 3/10, step: 7939, training_loss: 1.45937
Epoch: 3/10, step: 7959, training_loss: 1.91224
Epoch: 3/10, step: 7979, training_loss: 1.05018
Epoch: 3/10, step: 7999, training_loss: 1.68838
accuracy: 0.52, validation_loss: 1.5135290622711182, num_samples: 100
Epoch: 3/10, step: 8019, training_loss: 1.31026
Epoch: 3/10, step: 8039, training_loss: 1.23918
Epoch: 3/10, step: 8059, training_loss: 0.99054
Epoch: 3/10, step: 8079, training_loss: 1.08199
Epoch: 3/10, step: 8099, training_loss: 2.02341
Epoch: 3/10, step: 8119, training_loss: 1.59642
Epoch: 3/10, step: 8139, training_loss: 2.01781
Epoch: 3/10, step: 8159, training_loss: 1.82240
Epoch: 3/10, step: 8179, training_loss: 1.90652
Epoch: 3/10, step: 8199, training_loss: 1.15469
Epoch: 3/10, step: 8219, training_loss: 1.48359
Epoch: 3/10, step: 8239, training_loss: 2.09842
Epoch: 3/10, step: 8259, training_loss: 2.03750
Epoch: 3/10, step: 8279, training_loss: 0.97442
Epoch: 3/10, step: 8299, training_loss: 1.81319
Epoch: 3/10, step: 8319, training_loss: 1.52904
Epoch: 3/10, step: 8339, training_loss: 1.57139
Epoch: 3/10, step: 8359, training_loss: 2.22094
Epoch: 3/10, step: 8379, training_loss: 1.32661
Epoch: 3/10, step: 8399, training_loss: 1.01211
Epoch: 3/10, step: 8419, training_loss: 1.42680
Epoch: 3/10, step: 8439, training_loss: 2.20665
Epoch: 3/10, step: 8459, training_loss: 0.85613
Epoch: 3/10, step: 8479, training_loss: 1.46123
Epoch: 3/10, step: 8499, training_loss: 1.57445
Epoch: 3/10, step: 8519, training_loss: 1.46092
Epoch: 3/10, step: 8539, training_loss: 1.30627
Epoch: 3/10, step: 8559, training_loss: 1.46123
Epoch: 3/10, step: 8579, training_loss: 1.04618
Epoch: 3/10, step: 8599, training_loss: 1.20578
Epoch: 3/10, step: 8619, training_loss: 1.36248
Epoch: 3/10, step: 8639, training_loss: 1.34373
Epoch: 3/10, step: 8659, training_loss: 0.89655
Epoch: 3/10, step: 8679, training_loss: 1.05422
Epoch: 3/10, step: 8699, training_loss: 1.20580
Epoch: 3/10, step: 8719, training_loss: 1.62251
Epoch: 3/10, step: 8739, training_loss: 1.51982
Epoch: 3/10, step: 8759, training_loss: 1.35593
Epoch: 3/10, step: 8779, training_loss: 1.35121
Epoch: 3/10, step: 8799, training_loss: 1.57246
Epoch: 3/10, step: 8819, training_loss: 1.23612
Epoch: 3/10, step: 8839, training_loss: 1.56797
Epoch: 3/10, step: 8859, training_loss: 1.21236
Epoch: 3/10, step: 8879, training_loss: 1.59105
Epoch: 3/10, step: 8899, training_loss: 1.46023
Epoch: 3/10, step: 8919, training_loss: 1.24628
Epoch: 3/10, step: 8939, training_loss: 1.76950
Epoch: 3/10, step: 8959, training_loss: 1.66959
Epoch: 3/10, step: 8979, training_loss: 1.30421
Epoch: 3/10, step: 8999, training_loss: 1.40432
accuracy: 0.51, validation_loss: 1.473800778388977, num_samples: 100
Epoch: 3/10, step: 9019, training_loss: 1.25040
Epoch: 3/10, step: 9039, training_loss: 1.07889
Epoch: 3/10, step: 9059, training_loss: 1.61493
Epoch: 3/10, step: 9079, training_loss: 1.30152
Epoch: 3/10, step: 9099, training_loss: 1.64794
Epoch: 3/10, step: 9119, training_loss: 1.75142
Epoch: 3/10, step: 9139, training_loss: 1.22626
Epoch: 3/10, step: 9159, training_loss: 0.82131
Epoch: 3/10, step: 9179, training_loss: 1.25286
Epoch: 3/10, step: 9199, training_loss: 1.18280
Epoch: 3/10, step: 9219, training_loss: 1.22431
Epoch: 3/10, step: 9239, training_loss: 1.64129
Epoch: 3/10, step: 9259, training_loss: 1.08982
Epoch: 3/10, step: 9279, training_loss: 1.10977
Epoch: 3/10, step: 9299, training_loss: 1.63127
Epoch: 3/10, step: 9319, training_loss: 1.73957
Epoch: 3/10, step: 9339, training_loss: 1.51819
Epoch: 3/10, step: 9359, training_loss: 1.49849
Epoch: 3/10, step: 9379, training_loss: 2.05986
Epoch: 3/10, step: 9399, training_loss: 0.99860
Epoch: 3/10, step: 9419, training_loss: 1.85631
Epoch: 3/10, step: 9439, training_loss: 1.36297
Epoch: 3/10, step: 9459, training_loss: 1.25610
Epoch: 3/10, step: 9479, training_loss: 1.92876
Epoch: 3/10, step: 9499, training_loss: 1.75102
Epoch: 3/10, step: 9519, training_loss: 1.54053
Epoch: 3/10, step: 9539, training_loss: 1.59487
Epoch: 3/10, step: 9559, training_loss: 1.59392
Epoch: 3/10, step: 9579, training_loss: 1.67044
Epoch: 3/10, step: 9599, training_loss: 1.62004
Epoch: 3/10, step: 9619, training_loss: 1.27312
Epoch: 3/10, step: 9639, training_loss: 1.22600
Epoch: 3/10, step: 9659, training_loss: 1.18460
Epoch: 3/10, step: 9679, training_loss: 0.78023
Epoch: 3/10, step: 9699, training_loss: 1.10726
Epoch: 3/10, step: 9719, training_loss: 1.18808
Epoch: 3/10, step: 9739, training_loss: 1.59353
Epoch: 3/10, step: 9759, training_loss: 1.51276
Epoch: 3/10, step: 9779, training_loss: 1.39640
Epoch: 3/10, step: 9799, training_loss: 1.32591
Epoch: 3/10, step: 9819, training_loss: 1.70488
Epoch: 3/10, step: 9839, training_loss: 1.35951
Epoch: 3/10, step: 9859, training_loss: 1.70937
Epoch: 3/10, step: 9879, training_loss: 1.18621
Epoch: 3/10, step: 9899, training_loss: 1.18136
Epoch: 3/10, step: 9919, training_loss: 1.29562
Epoch: 3/10, step: 9939, training_loss: 1.56017
Epoch: 3/10, step: 9959, training_loss: 1.09777
Epoch: 3/10, step: 9979, training_loss: 0.88426
Epoch: 3/10, step: 9999, training_loss: 1.09262
accuracy: 0.43, validation_loss: 1.4997869729995728, num_samples: 100
Epoch: 3/10, step: 10019, training_loss: 0.65174
Epoch: 3/10, step: 10039, training_loss: 1.38270
Epoch: 3/10, step: 10059, training_loss: 1.01671
Epoch: 3/10, step: 10079, training_loss: 1.24773
Epoch: 3/10, step: 10099, training_loss: 1.61929
Epoch: 3/10, step: 10119, training_loss: 1.25997
Epoch: 3/10, step: 10139, training_loss: 1.33338
Epoch: 3/10, step: 10159, training_loss: 1.49916
Epoch: 3/10, step: 10179, training_loss: 1.66337
Epoch: 3/10, step: 10199, training_loss: 1.53763
Epoch: 3/10, step: 10219, training_loss: 1.30627
Epoch: 3/10, step: 10239, training_loss: 1.11458
Epoch: 3/10, step: 10259, training_loss: 1.47644
Epoch: 3/10, step: 10279, training_loss: 0.99926
Epoch: 3/10, step: 10299, training_loss: 1.28436
Epoch: 3/10, step: 10319, training_loss: 1.43194
Epoch: 3/10, step: 10339, training_loss: 1.25189
Epoch: 3/10, step: 10359, training_loss: 1.08354
Epoch: 3/10, step: 10379, training_loss: 1.42424
Epoch: 3/10, step: 10399, training_loss: 1.30744
Epoch: 3/10, step: 10419, training_loss: 1.04375
Epoch: 3/10, step: 10439, training_loss: 1.35396
Epoch: 3/10, step: 10459, training_loss: 1.90234
Epoch: 3/10, step: 10479, training_loss: 1.21957
Epoch: 3/10, step: 10499, training_loss: 1.40937
Epoch: 3/10, step: 10519, training_loss: 1.63826
Epoch: 3/10, step: 10539, training_loss: 1.27358
Epoch: 3/10, step: 10559, training_loss: 1.19085
Epoch: 3/10, step: 10579, training_loss: 1.21092
Epoch: 3/10, step: 10599, training_loss: 0.99870
Epoch: 3/10, step: 10619, training_loss: 1.25479
Epoch: 3/10, step: 10639, training_loss: 2.04780
Epoch: 3/10, step: 10659, training_loss: 1.30673
Epoch: 3/10, step: 10679, training_loss: 1.45929
Epoch: 3/10, step: 10699, training_loss: 1.52514
Epoch: 3/10, step: 10719, training_loss: 1.95009
Epoch: 3/10, step: 10739, training_loss: 1.52847
Epoch: 3/10, step: 10759, training_loss: 2.17703
Epoch: 3/10, step: 10779, training_loss: 1.45596
Epoch: 3/10, step: 10799, training_loss: 1.74320
Epoch: 3/10, step: 10819, training_loss: 1.75918
Epoch: 3/10, step: 10839, training_loss: 1.45984
Epoch: 3/10, step: 10859, training_loss: 1.11431
Epoch: 3/10, step: 10879, training_loss: 1.47827
Epoch: 3/10, step: 10899, training_loss: 1.62010
Epoch: 3/10, step: 10919, training_loss: 1.61446
Epoch: 3/10, step: 10939, training_loss: 2.06985
Epoch: 3/10, step: 10959, training_loss: 1.48061
Epoch: 3/10, step: 10979, training_loss: 1.32953
Epoch: 3/10, step: 10999, training_loss: 1.44431
accuracy: 0.51, validation_loss: 1.2551366090774536, num_samples: 100
Epoch: 3/10, step: 11019, training_loss: 0.87341
Epoch: 3/10, step: 11039, training_loss: 1.42373
Epoch: 3/10, step: 11059, training_loss: 0.99301
Epoch: 3/10, step: 11079, training_loss: 1.76052
Epoch: 3/10, step: 11099, training_loss: 1.53337
Epoch: 3/10, step: 11119, training_loss: 1.37427
Epoch: 3/10, step: 11139, training_loss: 1.58651
Epoch: 3/10, step: 11159, training_loss: 1.32638
Epoch: 3/10, step: 11179, training_loss: 1.27643
Epoch: 3/10, step: 11199, training_loss: 1.33746
Epoch: 3/10, step: 11219, training_loss: 1.33544
Epoch: 3/10, step: 11239, training_loss: 1.78188
Epoch: 3/10, step: 11259, training_loss: 1.29657
Epoch: 3/10, step: 11279, training_loss: 1.37629
Epoch: 3/10, step: 11299, training_loss: 1.56885
Epoch: 3/10, step: 11319, training_loss: 1.76211
Epoch: 3/10, step: 11339, training_loss: 1.85026
Epoch: 3/10, step: 11359, training_loss: 1.04115
Epoch: 3/10, step: 11379, training_loss: 2.07706
Epoch: 3/10, step: 11399, training_loss: 0.72595
Epoch: 3/10, step: 11419, training_loss: 1.05021
Epoch: 3/10, step: 11439, training_loss: 1.59573
Epoch: 3/10, step: 11459, training_loss: 1.40326
Epoch: 3/10, step: 11479, training_loss: 1.56420
Epoch: 3/10, step: 11499, training_loss: 1.62595
Epoch: 3/10, step: 11519, training_loss: 1.34269
Epoch: 3/10, step: 11539, training_loss: 1.51233
Epoch: 3/10, step: 11559, training_loss: 1.14518
Epoch: 3/10, step: 11579, training_loss: 1.61607
Epoch: 3/10, step: 11599, training_loss: 1.97847
Epoch: 3/10, step: 11619, training_loss: 1.56746
Epoch: 3/10, step: 11639, training_loss: 2.63324
Epoch: 3/10, step: 11659, training_loss: 0.83340
Epoch: 3/10, step: 11679, training_loss: 1.09235
Epoch: 3/10, step: 11699, training_loss: 1.48266
Epoch: 3/10, step: 11719, training_loss: 1.42545
Epoch: 3/10, step: 11739, training_loss: 1.49149
Epoch: 3/10, step: 11759, training_loss: 1.21189
Epoch: 3/10, step: 11779, training_loss: 1.56296
Epoch: 3/10, step: 11799, training_loss: 1.46144
Epoch: 3/10, step: 11819, training_loss: 0.80365
Epoch: 3/10, step: 11839, training_loss: 1.27294
Epoch: 3/10, step: 11859, training_loss: 1.43827
Epoch: 3/10, step: 11879, training_loss: 2.12517
Epoch: 3/10, step: 11899, training_loss: 0.62420
Epoch: 3/10, step: 11919, training_loss: 0.92200
Epoch: 3/10, step: 11939, training_loss: 1.16011
Epoch: 3/10, step: 11959, training_loss: 1.34035
Epoch: 3/10, step: 11979, training_loss: 1.31421
Epoch: 3/10, step: 11999, training_loss: 0.73839
accuracy: 0.46, validation_loss: 1.5916595458984375, num_samples: 100
Epoch: 3/10, step: 12019, training_loss: 1.81681
Epoch: 3/10, step: 12039, training_loss: 1.09284
Epoch: 3/10, step: 12059, training_loss: 0.95155
Epoch: 3/10, step: 12079, training_loss: 1.22330
Epoch: 3/10, step: 12099, training_loss: 2.05640
Epoch: 3/10, step: 12119, training_loss: 1.49328
Epoch: 3/10, step: 12139, training_loss: 1.70599
Epoch: 3/10, step: 12159, training_loss: 1.34439
Epoch: 3/10, step: 12179, training_loss: 1.11196
Epoch: 3/10, step: 12199, training_loss: 1.81745
Epoch: 3/10, step: 12219, training_loss: 0.70970
Epoch: 3/10, step: 12239, training_loss: 1.38475
Epoch: 3/10, step: 12259, training_loss: 1.36132
Epoch: 3/10, step: 12279, training_loss: 1.22969
Epoch: 3/10, step: 12299, training_loss: 1.36364
Epoch: 3/10, step: 12319, training_loss: 1.74452
Epoch: 3/10, step: 12339, training_loss: 2.31175
Epoch: 3/10, step: 12359, training_loss: 1.16454
Epoch: 3/10, step: 12379, training_loss: 1.60207
Epoch: 3/10, step: 12399, training_loss: 1.69275
Epoch: 3/10, step: 12419, training_loss: 1.54458
Epoch: 3/10, step: 12439, training_loss: 1.69242
Epoch: 3/10, step: 12459, training_loss: 1.76073
Epoch: 3/10, step: 12479, training_loss: 1.63129
Epoch: 3/10, step: 12499, training_loss: 1.59075
Epoch: 3/10, step: 12519, training_loss: 0.94449
Epoch: 3/10, step: 12539, training_loss: 1.51161
Epoch: 3/10, step: 12559, training_loss: 1.44805
Epoch: 3/10, step: 12579, training_loss: 1.50825
Epoch: 3/10, step: 12599, training_loss: 1.30710
Epoch: 3/10, step: 12619, training_loss: 1.43447
Epoch: 3/10, step: 12639, training_loss: 1.25716
Epoch: 3/10, step: 12659, training_loss: 1.90804
Epoch: 3/10, step: 12679, training_loss: 1.25645
Epoch: 3/10, step: 12699, training_loss: 1.64239
Epoch: 3/10, step: 12719, training_loss: 0.73331
Epoch: 3/10, step: 12739, training_loss: 1.59617
Epoch: 3/10, step: 12759, training_loss: 1.99242
Epoch: 3/10, step: 12779, training_loss: 1.56093
Epoch: 3/10, step: 12799, training_loss: 0.88122
Epoch: 3/10, step: 12819, training_loss: 1.58787
Epoch: 3/10, step: 12839, training_loss: 1.72196
Epoch: 3/10, step: 12859, training_loss: 1.91676
Epoch: 3/10, step: 12879, training_loss: 1.37806
Epoch: 3/10, step: 12899, training_loss: 1.66509
Epoch: 3/10, step: 12919, training_loss: 1.58899
Epoch: 3/10, step: 12939, training_loss: 2.17894
Epoch: 3/10, step: 12959, training_loss: 1.48219
Epoch: 3/10, step: 12979, training_loss: 1.74025
Epoch: 3/10, step: 12999, training_loss: 1.45423
accuracy: 0.49, validation_loss: 1.3923121690750122, num_samples: 100
Epoch: 3/10, step: 13019, training_loss: 1.53350
Epoch: 3/10, step: 13039, training_loss: 1.37171
Epoch: 3/10, step: 13059, training_loss: 1.65885
Epoch: 3/10, step: 13079, training_loss: 1.40979
Epoch: 3/10, step: 13099, training_loss: 1.78197
Epoch: 3/10, step: 13119, training_loss: 1.36391
Epoch: 3/10, step: 13139, training_loss: 2.17144
Epoch: 3/10, step: 13159, training_loss: 1.85206
Epoch: 3/10, step: 13179, training_loss: 1.23579
Epoch: 3/10, step: 13199, training_loss: 1.03242
Epoch: 3/10, step: 13219, training_loss: 1.62084
Epoch: 3/10, step: 13239, training_loss: 0.75895
Epoch: 3/10, step: 13259, training_loss: 1.26324
Epoch: 3/10, step: 13279, training_loss: 1.54277
Epoch: 3/10, step: 13299, training_loss: 1.79700
Epoch: 3/10, step: 13319, training_loss: 1.55304
Epoch: 3/10, step: 13339, training_loss: 1.22112
Epoch: 3/10, step: 13359, training_loss: 1.37391
Epoch: 3/10, step: 13379, training_loss: 0.95147
Epoch: 3/10, step: 13399, training_loss: 1.72817
Epoch: 3/10, step: 13419, training_loss: 1.24361
Epoch: 3/10, step: 13439, training_loss: 1.52015
Epoch: 3/10, step: 13459, training_loss: 0.67011
Epoch: 3/10, step: 13479, training_loss: 1.76511
Epoch: 3/10, step: 13499, training_loss: 1.64965
Epoch: 3/10, step: 13519, training_loss: 1.45905
Epoch: 3/10, step: 13539, training_loss: 1.01030
Epoch: 3/10, step: 13559, training_loss: 1.83668
Epoch: 3/10, step: 13579, training_loss: 1.07257
Epoch: 3/10, step: 13599, training_loss: 1.48821
Epoch: 3/10, step: 13619, training_loss: 1.03525
Epoch: 3/10, step: 13639, training_loss: 1.33717
Epoch: 3/10, step: 13659, training_loss: 1.32694
Epoch: 3/10, step: 13679, training_loss: 1.70957
Epoch: 3/10, step: 13699, training_loss: 1.38198
Epoch: 3/10, step: 13719, training_loss: 0.95337
Epoch: 3/10, step: 13739, training_loss: 1.03856
Epoch: 3/10, step: 13759, training_loss: 1.36011
Epoch: 3/10, step: 13779, training_loss: 1.70405
Epoch: 3/10, step: 13799, training_loss: 1.80372
Epoch: 3/10, step: 13819, training_loss: 1.91953
Epoch: 3/10, step: 13839, training_loss: 1.32295
Epoch: 3/10, step: 13859, training_loss: 0.92101
Epoch: 3/10, step: 13879, training_loss: 1.39227
Epoch: 3/10, step: 13899, training_loss: 1.30759
Epoch: 3/10, step: 13919, training_loss: 1.61363
Epoch: 3/10, step: 13939, training_loss: 1.91050
Epoch: 3/10, step: 13959, training_loss: 1.15244
Epoch: 3/10, step: 13979, training_loss: 1.62863
Epoch: 3/10, step: 13999, training_loss: 1.46770
accuracy: 0.47, validation_loss: 1.6121925115585327, num_samples: 100
Epoch: 3/10, step: 14019, training_loss: 2.18182
Epoch: 3/10, step: 14039, training_loss: 2.06331
Epoch: 3/10, step: 14059, training_loss: 1.30159
Epoch: 3/10, step: 14079, training_loss: 2.02741
Epoch: 3/10, step: 14099, training_loss: 1.07677
Epoch: 3/10, step: 14119, training_loss: 1.39523
Epoch: 3/10, step: 14139, training_loss: 1.31751
Epoch: 3/10, step: 14159, training_loss: 1.69541
Epoch: 3/10, step: 14179, training_loss: 1.37208
Epoch: 3/10, step: 14199, training_loss: 1.28319
Epoch: 3/10, step: 14219, training_loss: 0.84885
Epoch: 3/10, step: 14239, training_loss: 1.62745
Epoch: 3/10, step: 14259, training_loss: 1.56006
Epoch: 3/10, step: 14279, training_loss: 1.54614
Epoch: 3/10, step: 14299, training_loss: 1.98832
Epoch: 3/10, step: 14319, training_loss: 1.10993
Epoch: 3/10, step: 14339, training_loss: 1.07206
Epoch: 3/10, step: 14359, training_loss: 1.55720
Epoch: 3/10, step: 14379, training_loss: 1.26811
Epoch: 3/10, step: 14399, training_loss: 1.31907
Epoch: 3/10, step: 14419, training_loss: 2.52559
Epoch: 3/10, step: 14439, training_loss: 1.83419
Epoch: 3/10, step: 14459, training_loss: 0.85468
Epoch: 3/10, step: 14479, training_loss: 1.66914
Epoch: 3/10, step: 14499, training_loss: 1.11595
Epoch: 3/10, step: 14519, training_loss: 1.38385
Epoch: 3/10, step: 14539, training_loss: 1.37372
Epoch: 3/10, step: 14559, training_loss: 1.35194
Epoch: 3/10, step: 14579, training_loss: 1.03528
Epoch: 3/10, step: 14599, training_loss: 1.89698
Epoch: 3/10, step: 14619, training_loss: 1.42391
Epoch: 3/10, step: 14639, training_loss: 1.30927
Epoch: 3/10, step: 14659, training_loss: 1.09372
Epoch: 3/10, step: 14679, training_loss: 1.59914
Epoch: 3/10, step: 14699, training_loss: 1.96303
Epoch: 3/10, step: 14719, training_loss: 1.17554
Epoch: 3/10, step: 14739, training_loss: 1.71090
Epoch: 3/10, step: 14759, training_loss: 1.13865
Epoch: 3/10, step: 14779, training_loss: 1.55388
Epoch: 3/10, step: 14799, training_loss: 1.46349
Epoch: 3/10, step: 14819, training_loss: 1.38560
Epoch: 3/10, step: 14839, training_loss: 1.85366
Epoch: 3/10, step: 14859, training_loss: 0.96380
Epoch: 3/10, step: 14879, training_loss: 1.88204
Epoch: 3/10, step: 14899, training_loss: 1.45674
Epoch: 3/10, step: 14919, training_loss: 1.16729
Epoch: 3/10, step: 14939, training_loss: 1.68266
Epoch: 3/10, step: 14959, training_loss: 1.10230
Epoch: 3/10, step: 14979, training_loss: 1.13293
Epoch: 3/10, step: 14999, training_loss: 0.76811
accuracy: 0.56, validation_loss: 1.367496132850647, num_samples: 100
Epoch: 3/10, step: 15019, training_loss: 1.25473
Epoch: 3/10, step: 15039, training_loss: 1.25855
Epoch: 3/10, step: 15059, training_loss: 1.60607
Epoch: 3/10, step: 15079, training_loss: 0.99222
Epoch: 3/10, step: 15099, training_loss: 1.09348
Epoch: 3/10, step: 15119, training_loss: 1.26851
Epoch: 3/10, step: 15139, training_loss: 1.44245
Epoch: 3/10, step: 15159, training_loss: 1.93276
Epoch: 3/10, step: 15179, training_loss: 1.62908
Epoch: 3/10, step: 15199, training_loss: 0.42040
Epoch: 3/10, step: 15219, training_loss: 1.33834
Epoch: 3/10, step: 15239, training_loss: 1.18013
Epoch: 3/10, step: 15259, training_loss: 1.41716
Epoch: 3/10, step: 15279, training_loss: 0.84027
Epoch: 3/10, step: 15299, training_loss: 1.52447
Epoch: 3/10, step: 15319, training_loss: 1.18001
Epoch: 3/10, step: 15339, training_loss: 1.27271
Epoch: 3/10, step: 15359, training_loss: 0.95035
Epoch: 3/10, step: 15379, training_loss: 1.74129
Epoch: 3/10, step: 15399, training_loss: 1.27447
Epoch: 3/10, step: 15419, training_loss: 1.39398
Epoch: 3/10, step: 15439, training_loss: 1.78278
Epoch: 3/10, step: 15459, training_loss: 1.67970
Epoch: 3/10, step: 15479, training_loss: 1.08103
Epoch: 3/10, step: 15499, training_loss: 1.47866
Epoch: 3/10, step: 15519, training_loss: 1.75770
Epoch: 3/10, step: 15539, training_loss: 1.48448
Epoch: 3/10, step: 15559, training_loss: 0.77835
Epoch: 3/10, step: 15579, training_loss: 1.16290
Epoch: 3/10, step: 15599, training_loss: 1.36532
Epoch: 3/10, step: 15619, training_loss: 1.40040
Epoch: 3/10, step: 15639, training_loss: 2.23631
Epoch: 3/10, step: 15659, training_loss: 1.26222
Epoch: 3/10, step: 15679, training_loss: 1.72168
Epoch: 3/10, step: 15699, training_loss: 1.62515
Epoch: 3/10, step: 15719, training_loss: 1.91033
Epoch: 3/10, step: 15739, training_loss: 1.55312
Epoch: 3/10, step: 15759, training_loss: 1.74806
Epoch: 3/10, step: 15779, training_loss: 1.06439
Epoch: 3/10, step: 15799, training_loss: 1.56712
Epoch: 3/10, step: 15819, training_loss: 1.17384
Epoch: 3/10, step: 15839, training_loss: 0.69994
Epoch: 3/10, step: 15859, training_loss: 1.74726
Epoch: 3/10, step: 15879, training_loss: 0.42023
Epoch: 3/10, step: 15899, training_loss: 1.54017
Epoch: 3/10, step: 15919, training_loss: 1.27313
Epoch: 3/10, step: 15939, training_loss: 2.17101
Epoch: 3/10, step: 15959, training_loss: 0.72921
Epoch: 3/10, step: 15979, training_loss: 1.43277
Epoch: 3/10, step: 15999, training_loss: 1.46656
accuracy: 0.5, validation_loss: 1.4879658222198486, num_samples: 100
Epoch: 3/10, step: 16019, training_loss: 1.18179
Epoch: 3/10, step: 16039, training_loss: 0.78446
Epoch: 3/10, step: 16059, training_loss: 1.20933
Epoch: 3/10, step: 16079, training_loss: 1.47780
Epoch: 3/10, step: 16099, training_loss: 1.68184
Epoch: 3/10, step: 16119, training_loss: 1.79291
Epoch: 3/10, step: 16139, training_loss: 1.57763
Epoch: 3/10, step: 16159, training_loss: 0.98429
Epoch: 3/10, step: 16179, training_loss: 1.50561
Epoch: 3/10, step: 16199, training_loss: 0.82493
Epoch: 3/10, step: 16219, training_loss: 2.43765
Epoch: 3/10, step: 16239, training_loss: 1.18063
Epoch: 3/10, step: 16259, training_loss: 1.68121
Epoch: 3/10, step: 16279, training_loss: 1.31208
Epoch: 3/10, step: 16299, training_loss: 0.84568
Epoch: 3/10, step: 16319, training_loss: 1.37201
Epoch: 3/10, step: 16339, training_loss: 1.48567
Epoch: 3/10, step: 16359, training_loss: 2.12826
Epoch: 3/10, step: 16379, training_loss: 0.86035
Epoch: 3/10, step: 16399, training_loss: 1.48661
Epoch: 3/10, step: 16419, training_loss: 1.48682
Epoch: 3/10, step: 16439, training_loss: 0.90319
Epoch: 3/10, step: 16459, training_loss: 1.04077
Epoch: 3/10, step: 16479, training_loss: 2.03300
Epoch: 3/10, step: 16499, training_loss: 1.05186
Epoch: 3/10, step: 16519, training_loss: 1.19002
Epoch: 3/10, step: 16539, training_loss: 2.06181
Epoch: 3/10, step: 16559, training_loss: 1.17537
Epoch: 3/10, step: 16579, training_loss: 1.68937
Epoch: 3/10, step: 16599, training_loss: 1.58858
Epoch: 3/10, step: 16619, training_loss: 1.29514
Epoch: 3/10, step: 16639, training_loss: 1.12276
Epoch: 3/10, step: 16659, training_loss: 1.40172
Epoch: 3/10, step: 16679, training_loss: 1.45319
Epoch: 3/10, step: 16699, training_loss: 1.46688
Epoch: 3/10, step: 16719, training_loss: 1.08219
Epoch: 3/10, step: 16739, training_loss: 1.54972
Epoch: 3/10, step: 16759, training_loss: 1.30304
Epoch: 3/10, step: 16779, training_loss: 0.99329
Epoch: 3/10, step: 16799, training_loss: 1.75988
Epoch: 3/10, step: 16819, training_loss: 1.26245
Epoch: 3/10, step: 16839, training_loss: 1.39600
Epoch: 3/10, step: 16859, training_loss: 1.22601
Epoch: 3/10, step: 16879, training_loss: 1.24760
Epoch: 3/10, step: 16899, training_loss: 1.64122
Epoch: 3/10, step: 16919, training_loss: 1.28918
Epoch: 3/10, step: 16939, training_loss: 1.87368
Epoch: 3/10, step: 16959, training_loss: 1.34211
Epoch: 3/10, step: 16979, training_loss: 0.89554
Epoch: 3/10, step: 16999, training_loss: 1.70453
accuracy: 0.5, validation_loss: 1.4149378538131714, num_samples: 100
Epoch: 3/10, step: 17019, training_loss: 1.56699
Epoch: 3/10, step: 17039, training_loss: 1.20668
Epoch: 3/10, step: 17059, training_loss: 1.31385
Epoch: 3/10, step: 17079, training_loss: 1.38796
Epoch: 3/10, step: 17099, training_loss: 1.40434
Epoch: 3/10, step: 17119, training_loss: 1.04172
Epoch: 3/10, step: 17139, training_loss: 1.83190
Epoch: 3/10, step: 17159, training_loss: 1.34512
Epoch: 3/10, step: 17179, training_loss: 1.29159
Epoch: 3/10, step: 17199, training_loss: 1.37645
Epoch: 3/10, step: 17219, training_loss: 1.70746
Epoch: 3/10, step: 17239, training_loss: 1.58960
Epoch: 3/10, step: 17259, training_loss: 1.09541
Epoch: 3/10, step: 17279, training_loss: 1.45726
Epoch: 3/10, step: 17299, training_loss: 2.01813
Epoch: 3/10, step: 17319, training_loss: 1.46205
Epoch: 3/10, step: 17339, training_loss: 1.30083
Epoch: 3/10, step: 17359, training_loss: 1.66739
Epoch: 3/10, step: 17379, training_loss: 0.97349
Epoch: 3/10, step: 17399, training_loss: 1.18704
Epoch: 3/10, step: 17419, training_loss: 1.59583
Epoch: 3/10, step: 17439, training_loss: 1.88075
Epoch: 3/10, step: 17459, training_loss: 1.09406
Epoch: 3/10, step: 17479, training_loss: 1.62325
Epoch: 3/10, step: 17499, training_loss: 1.26194
Epoch: 3/10, step: 17519, training_loss: 1.10139
Epoch: 3/10, step: 17539, training_loss: 1.24272
Epoch: 3/10, step: 17559, training_loss: 1.38493
Epoch: 3/10, step: 17579, training_loss: 1.27165
Epoch: 3/10, step: 17599, training_loss: 1.42710
Epoch: 3/10, step: 17619, training_loss: 1.71973
Epoch: 3/10, step: 17639, training_loss: 1.65908
Epoch: 3/10, step: 17659, training_loss: 1.35113
Epoch: 3/10, step: 17679, training_loss: 0.68377
Epoch: 3/10, step: 17699, training_loss: 1.90131
Epoch: 3/10, step: 17719, training_loss: 1.17173
Epoch: 3/10, step: 17739, training_loss: 1.95445
Epoch: 3/10, step: 17759, training_loss: 0.93459
Epoch: 3/10, step: 17779, training_loss: 1.01260
Epoch: 3/10, step: 17799, training_loss: 1.78976
Epoch: 3/10, step: 17819, training_loss: 1.32924
Epoch: 3/10, step: 17839, training_loss: 0.67379
Epoch: 3/10, step: 17859, training_loss: 2.17573
Epoch: 3/10, step: 17879, training_loss: 1.51589
Epoch: 3/10, step: 17899, training_loss: 1.58289
Epoch: 3/10, step: 17919, training_loss: 0.48759
Epoch: 3/10, step: 17939, training_loss: 1.64964
Epoch: 3/10, step: 17959, training_loss: 1.76599
Epoch: 3/10, step: 17979, training_loss: 1.41096
Epoch: 3/10, step: 17999, training_loss: 1.74332
accuracy: 0.48, validation_loss: 1.4876292943954468, num_samples: 100
Epoch: 3/10, step: 18019, training_loss: 1.36403
Epoch: 3/10, step: 18039, training_loss: 1.93340
Epoch: 3/10, step: 18059, training_loss: 1.21351
Epoch: 3/10, step: 18079, training_loss: 1.63295
Epoch: 3/10, step: 18099, training_loss: 1.37803
Epoch: 3/10, step: 18119, training_loss: 1.68814
Epoch: 3/10, step: 18139, training_loss: 1.35127
Epoch: 3/10, step: 18159, training_loss: 1.68757
Epoch: 3/10, step: 18179, training_loss: 1.22918
Epoch: 3/10, step: 18199, training_loss: 1.07020
Epoch: 3/10, step: 18219, training_loss: 1.07282
Epoch: 3/10, step: 18239, training_loss: 1.61537
Epoch: 3/10, step: 18259, training_loss: 0.81256
Epoch: 3/10, step: 18279, training_loss: 1.59731
Epoch: 3/10, step: 18299, training_loss: 1.45150
Epoch: 3/10, step: 18319, training_loss: 0.71557
Epoch: 3/10, step: 18339, training_loss: 1.35152
Epoch: 3/10, step: 18359, training_loss: 1.34824
Epoch: 3/10, step: 18379, training_loss: 2.03460
Epoch: 3/10, step: 18399, training_loss: 1.31871
Epoch: 3/10, step: 18419, training_loss: 1.79182
Epoch: 3/10, step: 18439, training_loss: 1.07964
Epoch: 3/10, step: 18459, training_loss: 0.88377
Epoch: 3/10, step: 18479, training_loss: 1.07795
Epoch: 3/10, step: 18499, training_loss: 1.69511
Epoch: 3/10, step: 18519, training_loss: 0.89119
Epoch: 3/10, step: 18539, training_loss: 1.21403
Epoch: 3/10, step: 18559, training_loss: 1.20075
Epoch: 3/10, step: 18579, training_loss: 1.88726
Epoch: 3/10, step: 18599, training_loss: 0.97250
Epoch: 3/10, step: 18619, training_loss: 1.40511
Epoch: 3/10, step: 18639, training_loss: 1.11200
Epoch: 3/10, step: 18659, training_loss: 0.97504
Epoch: 3/10, step: 18679, training_loss: 0.93990
Epoch: 3/10, step: 18699, training_loss: 1.82692
Epoch: 3/10, step: 18719, training_loss: 1.48468
Epoch: 3/10, step: 18739, training_loss: 1.46411
Epoch: 3/10, step: 18759, training_loss: 1.34781
Epoch: 3/10, step: 18779, training_loss: 1.67247
Epoch: 3/10, step: 18799, training_loss: 1.04545
Epoch: 3/10, step: 18819, training_loss: 1.09712
Epoch: 3/10, step: 18839, training_loss: 1.53739
Epoch: 3/10, step: 18859, training_loss: 1.15695
Epoch: 3/10, step: 18879, training_loss: 1.42543
Epoch: 3/10, step: 18899, training_loss: 0.96798
Epoch: 3/10, step: 18919, training_loss: 1.30818
Epoch: 3/10, step: 18939, training_loss: 1.54817
Epoch: 3/10, step: 18959, training_loss: 2.17900
Epoch: 3/10, step: 18979, training_loss: 2.21156
Epoch: 3/10, step: 18999, training_loss: 1.70657
accuracy: 0.49, validation_loss: 1.6454561948776245, num_samples: 100
Epoch: 3/10, step: 19019, training_loss: 1.30131
Epoch: 3/10, step: 19039, training_loss: 1.23874
Epoch: 3/10, step: 19059, training_loss: 1.13786
Epoch: 3/10, step: 19079, training_loss: 0.95321
Epoch: 3/10, step: 19099, training_loss: 1.29227
Epoch: 3/10, step: 19119, training_loss: 1.53112
Epoch: 3/10, step: 19139, training_loss: 1.67169
Epoch: 3/10, step: 19159, training_loss: 0.99335
Epoch: 3/10, step: 19179, training_loss: 1.07036
Epoch: 3/10, step: 19199, training_loss: 1.62288
Epoch: 3/10, step: 19219, training_loss: 0.92187
Epoch: 3/10, step: 19239, training_loss: 2.12516
Epoch: 3/10, step: 19259, training_loss: 1.23892
Epoch: 3/10, step: 19279, training_loss: 1.11592
Epoch: 3/10, step: 19299, training_loss: 1.38015
Epoch: 3/10, step: 19319, training_loss: 1.11322
Epoch: 3/10, step: 19339, training_loss: 1.04361
Epoch: 3/10, step: 19359, training_loss: 1.51844
Epoch: 3/10, step: 19379, training_loss: 2.03401
Epoch: 3/10, step: 19399, training_loss: 1.42128
Epoch: 3/10, step: 19419, training_loss: 1.63710
Epoch: 3/10, step: 19439, training_loss: 1.75660
Epoch: 3/10, step: 19459, training_loss: 1.50698
Epoch: 3/10, step: 19479, training_loss: 0.80434
Epoch: 3/10, step: 19499, training_loss: 1.47362
Epoch: 3/10, step: 19519, training_loss: 1.50460
Epoch: 3/10, step: 19539, training_loss: 1.69868
Epoch: 3/10, step: 19559, training_loss: 1.29183
Epoch: 3/10, step: 19579, training_loss: 1.30307
Epoch: 3/10, step: 19599, training_loss: 1.31361
Epoch: 3/10, step: 19619, training_loss: 1.01698
Epoch: 3/10, step: 19639, training_loss: 1.36354
Epoch: 3/10, step: 19659, training_loss: 1.50100
Epoch: 3/10, step: 19679, training_loss: 1.94848
Epoch: 3/10, step: 19699, training_loss: 1.62384
Epoch: 3/10, step: 19719, training_loss: 1.39719
Epoch: 3/10, step: 19739, training_loss: 1.75395
Epoch: 3/10, step: 19759, training_loss: 1.71904
Epoch: 3/10, step: 19779, training_loss: 0.98954
Epoch: 3/10, step: 19799, training_loss: 1.93051
Epoch: 3/10, step: 19819, training_loss: 1.67150
Epoch: 3/10, step: 19839, training_loss: 1.08498
Epoch: 3/10, step: 19859, training_loss: 1.84534
Epoch: 3/10, step: 19879, training_loss: 1.42181
Epoch: 3/10, step: 19899, training_loss: 1.10283
Epoch: 3/10, step: 19919, training_loss: 1.02421
Epoch: 3/10, step: 19939, training_loss: 1.54276
Epoch: 3/10, step: 19959, training_loss: 1.51834
Epoch: 3/10, step: 19979, training_loss: 1.47490
Epoch: 3/10, step: 19999, training_loss: 1.11310
accuracy: 0.51, validation_loss: 1.4757832288742065, num_samples: 100
Epoch: 3/10, step: 20019, training_loss: 1.29591
Epoch: 3/10, step: 20039, training_loss: 1.19597
Epoch: 3/10, step: 20059, training_loss: 0.85366
Epoch: 3/10, step: 20079, training_loss: 1.77896
Epoch: 3/10, step: 20099, training_loss: 1.48418
Epoch: 3/10, step: 20119, training_loss: 1.50106
Epoch: 3/10, step: 20139, training_loss: 1.41658
Epoch: 3/10, step: 20159, training_loss: 1.40399
Epoch: 3/10, step: 20179, training_loss: 1.39861
Epoch: 3/10, step: 20199, training_loss: 1.37013
Epoch: 3/10, step: 20219, training_loss: 1.51748
Epoch: 3/10, step: 20239, training_loss: 0.93819
Epoch: 3/10, step: 20259, training_loss: 1.61911
Epoch: 3/10, step: 20279, training_loss: 1.48442
Epoch: 3/10, step: 20299, training_loss: 1.40690
Epoch: 3/10, step: 20319, training_loss: 1.41553
Epoch: 3/10, step: 20339, training_loss: 1.34698
Epoch: 3/10, step: 20359, training_loss: 1.70757
Epoch: 3/10, step: 20379, training_loss: 1.74748
Epoch: 3/10, step: 20399, training_loss: 2.00411
Epoch: 3/10, step: 20419, training_loss: 1.13736
Epoch: 3/10, step: 20439, training_loss: 1.48698
Epoch: 3/10, step: 20459, training_loss: 1.48328
Epoch: 3/10, step: 20479, training_loss: 2.16476
Epoch: 3/10, step: 20499, training_loss: 1.61404
Epoch: 3/10, step: 20519, training_loss: 1.42164
Epoch: 3/10, step: 20539, training_loss: 0.93585
Epoch: 3/10, step: 20559, training_loss: 1.28077
Epoch: 3/10, step: 20579, training_loss: 0.98746
Epoch: 3/10, step: 20599, training_loss: 1.32659
Epoch: 3/10, step: 20619, training_loss: 0.97396
Epoch: 3/10, step: 20639, training_loss: 1.48873
Epoch: 3/10, step: 20659, training_loss: 0.98412
Epoch: 3/10, step: 20679, training_loss: 1.23566
Epoch: 3/10, step: 20699, training_loss: 1.52511
Epoch: 3/10, step: 20719, training_loss: 1.33243
Epoch: 3/10, step: 20739, training_loss: 1.62661
Epoch: 3/10, step: 20759, training_loss: 1.26481
Epoch: 3/10, step: 20779, training_loss: 1.43857
Epoch: 3/10, step: 20799, training_loss: 1.62435
Epoch: 3/10, step: 20819, training_loss: 1.54543
Epoch: 3/10, step: 20839, training_loss: 1.38860
Epoch: 3/10, step: 20859, training_loss: 1.56358
Epoch: 3/10, step: 20879, training_loss: 1.86099
Epoch: 3/10, step: 20899, training_loss: 1.45497
Epoch: 3/10, step: 20919, training_loss: 1.37319
Epoch: 3/10, step: 20939, training_loss: 1.00596
Epoch: 3/10, step: 20959, training_loss: 1.48514
Epoch: 3/10, step: 20979, training_loss: 1.09967
Epoch: 3/10, step: 20999, training_loss: 1.61556
accuracy: 0.51, validation_loss: 1.267154335975647, num_samples: 100
Epoch: 3/10, step: 21019, training_loss: 1.55697
Epoch: 3/10, step: 21039, training_loss: 1.09510
Epoch: 3/10, step: 21059, training_loss: 0.97319
Epoch: 3/10, step: 21079, training_loss: 1.59894
Epoch: 3/10, step: 21099, training_loss: 1.15367
Epoch: 3/10, step: 21119, training_loss: 1.26824
Epoch: 3/10, step: 21139, training_loss: 2.05858
Epoch: 3/10, step: 21159, training_loss: 1.17841
Epoch: 3/10, step: 21179, training_loss: 1.05756
Epoch: 3/10, step: 21199, training_loss: 1.77897
Epoch: 3/10, step: 21219, training_loss: 1.27907
Epoch: 3/10, step: 21239, training_loss: 1.43784
Epoch: 3/10, step: 21259, training_loss: 2.02105
Epoch: 3/10, step: 21279, training_loss: 1.21030
Epoch: 3/10, step: 21299, training_loss: 1.32046
Epoch: 3/10, step: 21319, training_loss: 1.45862
Epoch: 3/10, step: 21339, training_loss: 1.27548
Epoch: 3/10, step: 21359, training_loss: 1.90648
Epoch: 3/10, step: 21379, training_loss: 1.23359
Epoch: 3/10, step: 21399, training_loss: 1.26290
Epoch: 3/10, step: 21419, training_loss: 0.66796
Epoch: 3/10, step: 21439, training_loss: 1.44538
Epoch: 3/10, step: 21459, training_loss: 1.14969
Epoch: 3/10, step: 21479, training_loss: 1.57571
Epoch: 3/10, step: 21499, training_loss: 1.55098
Epoch: 3/10, step: 21519, training_loss: 1.26191
Epoch: 3/10, step: 21539, training_loss: 1.64679
Epoch: 3/10, step: 21559, training_loss: 0.88320
Epoch: 3/10, step: 21579, training_loss: 1.51276
Epoch: 3/10, step: 21599, training_loss: 1.45603
Epoch: 3/10, step: 21619, training_loss: 1.79522
Epoch: 3/10, step: 21639, training_loss: 0.91908
Epoch: 3/10, step: 21659, training_loss: 1.26270
Epoch: 3/10, step: 21679, training_loss: 1.09400
Epoch: 3/10, step: 21699, training_loss: 1.62110
Epoch: 3/10, step: 21719, training_loss: 2.02105
Epoch: 3/10, step: 21739, training_loss: 1.81731
Epoch: 3/10, step: 21759, training_loss: 1.22677
Epoch: 3/10, step: 21779, training_loss: 1.43397
Epoch: 3/10, step: 21799, training_loss: 2.08992
Epoch: 3/10, step: 21819, training_loss: 1.06648
Epoch: 3/10, step: 21839, training_loss: 0.78336
Epoch: 3/10, step: 21859, training_loss: 1.82152
Epoch: 3/10, step: 21879, training_loss: 1.83505
Epoch: 3/10, step: 21899, training_loss: 1.01510
Epoch: 3/10, step: 21919, training_loss: 1.51294
Epoch: 3/10, step: 21939, training_loss: 1.05211
Epoch: 3/10, step: 21959, training_loss: 1.32527
Epoch: 3/10, step: 21979, training_loss: 1.23922
Epoch: 3/10, step: 21999, training_loss: 1.04454
accuracy: 0.56, validation_loss: 1.266524314880371, num_samples: 100
Epoch: 3/10, step: 22019, training_loss: 0.91824
Epoch: 3/10, step: 22039, training_loss: 1.08499
Epoch: 3/10, step: 22059, training_loss: 1.18264
Epoch: 3/10, step: 22079, training_loss: 1.58939
Epoch: 3/10, step: 22099, training_loss: 1.80530
Epoch: 3/10, step: 22119, training_loss: 1.48080
Epoch: 3/10, step: 22139, training_loss: 1.43181
Epoch: 3/10, step: 22159, training_loss: 2.00817
Epoch: 3/10, step: 22179, training_loss: 1.17940
Epoch: 3/10, step: 22199, training_loss: 1.17307
Epoch: 3/10, step: 22219, training_loss: 1.67670
Epoch: 3/10, step: 22239, training_loss: 1.79304
Epoch: 3/10, step: 22259, training_loss: 1.61603
Epoch: 3/10, step: 22279, training_loss: 1.11638
Epoch: 3/10, step: 22299, training_loss: 1.66001
Epoch: 3/10, step: 22319, training_loss: 1.50178
Epoch: 3/10, step: 22339, training_loss: 1.05674
Epoch: 3/10, step: 22359, training_loss: 0.91382
Epoch: 3/10, step: 22379, training_loss: 1.64627
Epoch: 3/10, step: 22399, training_loss: 1.19379
Epoch: 3/10, step: 22419, training_loss: 0.86352
Epoch: 3/10, step: 22439, training_loss: 1.53612
Epoch: 3/10, step: 22459, training_loss: 1.36681
Epoch: 3/10, step: 22479, training_loss: 0.98641
Epoch: 3/10, step: 22499, training_loss: 1.28988
Epoch: 3/10, step: 22519, training_loss: 1.26944
Epoch: 3/10, step: 22539, training_loss: 1.74358
Epoch: 3/10, step: 22559, training_loss: 1.43535
Epoch: 3/10, step: 22579, training_loss: 1.40803
Epoch: 3/10, step: 22599, training_loss: 0.73891
Epoch: 3/10, step: 22619, training_loss: 1.78020
Epoch: 3/10, step: 22639, training_loss: 1.68521
Epoch: 3/10, step: 22659, training_loss: 1.10855
Epoch: 3/10, step: 22679, training_loss: 0.98265
Epoch: 3/10, step: 22699, training_loss: 1.54243
Epoch: 3/10, step: 22719, training_loss: 1.92978
Epoch: 3/10, step: 22739, training_loss: 1.47588
Epoch: 3/10, step: 22759, training_loss: 2.52488
Epoch: 3/10, step: 22779, training_loss: 1.00295
Epoch: 3/10, step: 22799, training_loss: 1.14423
Epoch: 3/10, step: 22819, training_loss: 1.94950
Epoch: 3/10, step: 22839, training_loss: 1.04207
Epoch: 3/10, step: 22859, training_loss: 1.02264
Epoch: 3/10, step: 22879, training_loss: 2.20078
Epoch: 3/10, step: 22899, training_loss: 1.49208
Epoch: 3/10, step: 22919, training_loss: 1.76097
Epoch: 3/10, step: 22939, training_loss: 1.97250
Epoch: 3/10, step: 22959, training_loss: 0.84006
Epoch: 3/10, step: 22979, training_loss: 1.44778
Epoch: 3/10, step: 22999, training_loss: 1.05798
accuracy: 0.52, validation_loss: 1.3646609783172607, num_samples: 100
Epoch: 3/10, step: 23019, training_loss: 2.13768
Epoch: 3/10, step: 23039, training_loss: 1.44686
Epoch: 3/10, step: 23059, training_loss: 1.49319
Epoch: 3/10, step: 23079, training_loss: 1.96088
Epoch: 3/10, step: 23099, training_loss: 1.27758
Epoch: 3/10, step: 23119, training_loss: 1.57878
Epoch: 3/10, step: 23139, training_loss: 1.35085
Epoch: 3/10, step: 23159, training_loss: 1.83462
Epoch: 3/10, step: 23179, training_loss: 1.14684
Epoch: 3/10, step: 23199, training_loss: 1.83950
Epoch: 3/10, step: 23219, training_loss: 1.62230
Epoch: 3/10, step: 23239, training_loss: 1.66279
Epoch: 3/10, step: 23259, training_loss: 1.36848
Epoch: 3/10, step: 23279, training_loss: 0.96503
Epoch: 3/10, step: 23299, training_loss: 1.35421
Epoch: 3/10, step: 23319, training_loss: 1.40271
Epoch: 3/10, step: 23339, training_loss: 1.47722
Epoch: 3/10, step: 23359, training_loss: 1.63182
Epoch: 3/10, step: 23379, training_loss: 1.06988
Epoch: 3/10, step: 23399, training_loss: 0.96869
Epoch: 3/10, step: 23419, training_loss: 1.21505
Epoch: 3/10, step: 23439, training_loss: 1.66360
Epoch: 3/10, step: 23459, training_loss: 1.39885
Epoch: 3/10, step: 23479, training_loss: 1.46896
Epoch: 3/10, step: 23499, training_loss: 1.62402
Epoch: 3/10, step: 23519, training_loss: 1.96487
Epoch: 3/10, step: 23539, training_loss: 2.11470
Epoch: 3/10, step: 23559, training_loss: 2.03354
Epoch: 3/10, step: 23579, training_loss: 1.20554
Epoch: 3/10, step: 23599, training_loss: 1.07174
Epoch: 3/10, step: 23619, training_loss: 0.78166
Epoch: 3/10, step: 23639, training_loss: 2.06576
Epoch: 3/10, step: 23659, training_loss: 1.59711
Epoch: 3/10, step: 23679, training_loss: 1.39928
Epoch: 3/10, step: 23699, training_loss: 1.14882
Epoch: 3/10, step: 23719, training_loss: 1.54729
Epoch: 3/10, step: 23739, training_loss: 0.86531
Epoch: 3/10, step: 23759, training_loss: 1.54365
Epoch: 3/10, step: 23779, training_loss: 0.77858
Epoch: 3/10, step: 23799, training_loss: 1.75330
Epoch: 3/10, step: 23819, training_loss: 1.37753
Epoch: 3/10, step: 23839, training_loss: 1.59442
Epoch: 3/10, step: 23859, training_loss: 1.61258
Epoch: 3/10, step: 23879, training_loss: 1.58631
Epoch: 3/10, step: 23899, training_loss: 1.29859
Epoch: 3/10, step: 23919, training_loss: 1.01783
Epoch: 3/10, step: 23939, training_loss: 1.36862
Epoch: 3/10, step: 23959, training_loss: 1.30588
Epoch: 3/10, step: 23979, training_loss: 1.02303
Epoch: 3/10, step: 23999, training_loss: 1.74983
accuracy: 0.43, validation_loss: 1.4920778274536133, num_samples: 100
Epoch: 3/10, step: 24019, training_loss: 1.65338
Epoch: 3/10, step: 24039, training_loss: 2.24332
Epoch: 3/10, step: 24059, training_loss: 2.01861
Epoch: 3/10, step: 24079, training_loss: 1.13676
Epoch: 3/10, step: 24099, training_loss: 1.50264
Epoch: 3/10, step: 24119, training_loss: 1.51383
Epoch: 3/10, step: 24139, training_loss: 1.67127
Epoch: 3/10, step: 24159, training_loss: 1.39793
Epoch: 3/10, step: 24179, training_loss: 1.14422
Epoch: 3/10, step: 24199, training_loss: 1.59590
Epoch: 3/10, step: 24219, training_loss: 1.24990
Epoch: 3/10, step: 24239, training_loss: 1.53380
Epoch: 3/10, step: 24259, training_loss: 1.56091
Epoch: 3/10, step: 24279, training_loss: 1.40658
Epoch: 3/10, step: 24299, training_loss: 1.39610
Epoch: 3/10, step: 24319, training_loss: 0.89738
Epoch: 3/10, step: 24339, training_loss: 1.70090
Epoch: 3/10, step: 24359, training_loss: 1.10936
Epoch: 3/10, step: 24379, training_loss: 1.28375
Epoch: 3/10, step: 24399, training_loss: 1.22405
Epoch: 3/10, step: 24419, training_loss: 1.20868
Epoch: 3/10, step: 24439, training_loss: 0.81196
Epoch: 3/10, step: 24459, training_loss: 1.02523
Epoch: 3/10, step: 24479, training_loss: 1.25707
Epoch: 3/10, step: 24499, training_loss: 1.67165
Epoch: 3/10, step: 24519, training_loss: 0.99995
Epoch: 3/10, step: 24539, training_loss: 1.87881
Epoch: 3/10, step: 24559, training_loss: 1.19960
Epoch: 3/10, step: 24579, training_loss: 1.68240
Epoch: 3/10, step: 24599, training_loss: 1.04082
Epoch: 3/10, step: 24619, training_loss: 1.88111
Epoch: 3/10, step: 24639, training_loss: 0.89911
Epoch: 3/10, step: 24659, training_loss: 1.24215
Epoch: 3/10, step: 24679, training_loss: 1.69006
Epoch: 3/10, step: 24699, training_loss: 1.00303
Epoch: 3/10, step: 24719, training_loss: 1.68823
Epoch: 3/10, step: 24739, training_loss: 1.36972
Epoch: 3/10, step: 24759, training_loss: 1.53900
Epoch: 3/10, step: 24779, training_loss: 1.54317
Epoch: 3/10, step: 24799, training_loss: 1.18509
Epoch: 3/10, step: 24819, training_loss: 1.55745
Epoch: 3/10, step: 24839, training_loss: 1.26979
Epoch: 3/10, step: 24859, training_loss: 1.35325
Epoch: 3/10, step: 24879, training_loss: 1.47289
Epoch: 3/10, step: 24899, training_loss: 1.79448
Epoch: 3/10, step: 24919, training_loss: 1.37251
Epoch: 3/10, step: 24939, training_loss: 1.14439
Epoch: 3/10, step: 24959, training_loss: 2.20506
Epoch: 3/10, step: 24979, training_loss: 1.46920
Epoch: 3/10, step: 24999, training_loss: 1.06948
accuracy: 0.37, validation_loss: 1.7596156597137451, num_samples: 100
Epoch: 3/10, step: 25019, training_loss: 0.80167
Epoch: 3/10, step: 25039, training_loss: 1.68302
Epoch: 3/10, step: 25059, training_loss: 1.48541
Epoch: 3/10, step: 25079, training_loss: 2.14155
Epoch: 3/10, step: 25099, training_loss: 1.93686
Epoch: 3/10, step: 25119, training_loss: 1.44775
Epoch: 3/10, step: 25139, training_loss: 1.37490
Epoch: 3/10, step: 25159, training_loss: 1.11140
Epoch: 3/10, step: 25179, training_loss: 1.18579
Epoch: 3/10, step: 25199, training_loss: 1.08881
Epoch: 3/10, step: 25219, training_loss: 1.62214
Epoch: 3/10, step: 25239, training_loss: 1.19921
Epoch: 3/10, step: 25259, training_loss: 0.96160
Epoch: 3/10, step: 25279, training_loss: 0.92950
Epoch: 3/10, step: 25299, training_loss: 0.88847
Epoch: 3/10, step: 25319, training_loss: 1.72216
Epoch: 3/10, step: 25339, training_loss: 1.36282
Epoch: 3/10, step: 25359, training_loss: 1.55020
Epoch: 3/10, step: 25379, training_loss: 1.83322
Epoch: 3/10, step: 25399, training_loss: 1.70275
Epoch: 3/10, step: 25419, training_loss: 1.41116
Epoch: 3/10, step: 25439, training_loss: 1.34084
Epoch: 3/10, step: 25459, training_loss: 2.50879
Epoch: 3/10, step: 25479, training_loss: 2.08872
Epoch: 3/10, step: 25499, training_loss: 1.58113
Epoch: 3/10, step: 25519, training_loss: 1.57013
Epoch: 3/10, step: 25539, training_loss: 1.62274
Epoch: 3/10, step: 25559, training_loss: 1.62304
Epoch: 3/10, step: 25579, training_loss: 1.67526
Epoch: 3/10, step: 25599, training_loss: 1.46424
Epoch: 3/10, step: 25619, training_loss: 1.06692
Epoch: 3/10, step: 25639, training_loss: 1.17930
Epoch: 3/10, step: 25659, training_loss: 1.37926
Epoch: 3/10, step: 25679, training_loss: 1.51212
Epoch: 3/10, step: 25699, training_loss: 1.54143
Epoch: 3/10, step: 25719, training_loss: 1.21507
Epoch: 3/10, step: 25739, training_loss: 1.25435
Epoch: 3/10, step: 25759, training_loss: 1.12498
Epoch: 3/10, step: 25779, training_loss: 1.33139
Epoch: 3/10, step: 25799, training_loss: 1.62010
Epoch: 3/10, step: 25819, training_loss: 1.25324
Epoch: 3/10, step: 25839, training_loss: 1.40087
Epoch: 3/10, step: 25859, training_loss: 1.56419
Epoch: 3/10, step: 25879, training_loss: 1.15809
Epoch: 3/10, step: 25899, training_loss: 1.74888
Epoch: 3/10, step: 25919, training_loss: 0.97892
Epoch: 3/10, step: 25939, training_loss: 1.27862
Epoch: 3/10, step: 25959, training_loss: 1.33309
Epoch: 3/10, step: 25979, training_loss: 1.57784
Epoch: 3/10, step: 25999, training_loss: 1.65670
accuracy: 0.54, validation_loss: 1.3823928833007812, num_samples: 100
Epoch: 3/10, step: 26019, training_loss: 1.10452
Epoch: 3/10, step: 26039, training_loss: 1.33313
Epoch: 3/10, step: 26059, training_loss: 1.99186
Epoch: 3/10, step: 26079, training_loss: 0.62832
Epoch: 3/10, step: 26099, training_loss: 1.48779
Epoch: 3/10, step: 26119, training_loss: 2.06594
Epoch: 3/10, step: 26139, training_loss: 0.63201
Epoch: 3/10, step: 26159, training_loss: 1.96886
Epoch: 3/10, step: 26179, training_loss: 1.97160
Epoch: 3/10, step: 26199, training_loss: 1.56091
Epoch: 3/10, step: 26219, training_loss: 1.53803
Epoch: 3/10, step: 26239, training_loss: 1.45686
Epoch: 3/10, step: 26259, training_loss: 1.76380
Epoch: 3/10, step: 26279, training_loss: 1.37717
Epoch: 3/10, step: 26299, training_loss: 1.11956
Epoch: 3/10, step: 26319, training_loss: 0.99578
Epoch: 3/10, step: 26339, training_loss: 1.37033
Epoch: 3/10, step: 26359, training_loss: 1.38654
Epoch: 3/10, step: 26379, training_loss: 1.33035
Epoch: 3/10, step: 26399, training_loss: 1.31246
Epoch: 3/10, step: 26419, training_loss: 1.27986
Epoch: 3/10, step: 26439, training_loss: 1.85376
Epoch: 3/10, step: 26459, training_loss: 1.21458
Epoch: 3/10, step: 26479, training_loss: 1.98495
Epoch: 3/10, step: 26499, training_loss: 1.55445
Epoch: 3/10, step: 26519, training_loss: 1.66268
Epoch: 3/10, step: 26539, training_loss: 1.44299
Epoch: 3/10, step: 26559, training_loss: 1.41312
Epoch: 3/10, step: 26579, training_loss: 1.35521
Epoch: 3/10, step: 26599, training_loss: 0.85359
Epoch: 3/10, step: 26619, training_loss: 2.28360
Epoch: 3/10, step: 26639, training_loss: 1.53337
Epoch: 3/10, step: 26659, training_loss: 1.82462
Epoch: 3/10, step: 26679, training_loss: 1.84081
Epoch: 3/10, step: 26699, training_loss: 2.07492
Epoch: 3/10, step: 26719, training_loss: 1.43637
Epoch: 3/10, step: 26739, training_loss: 0.75204
Epoch: 3/10, step: 26759, training_loss: 1.63483
Epoch: 3/10, step: 26779, training_loss: 0.79454
Epoch: 3/10, step: 26799, training_loss: 1.38724
Epoch: 3/10, step: 26819, training_loss: 1.13383
Epoch: 3/10, step: 26839, training_loss: 1.81833
Epoch: 3/10, step: 26859, training_loss: 1.37465
Epoch: 3/10, step: 26879, training_loss: 1.41206
Epoch: 3/10, step: 26899, training_loss: 1.97624
Epoch: 3/10, step: 26919, training_loss: 1.27700
Epoch: 3/10, step: 26939, training_loss: 1.00806
Epoch: 3/10, step: 26959, training_loss: 1.66205
Epoch: 3/10, step: 26979, training_loss: 1.48685
Epoch: 3/10, step: 26999, training_loss: 0.99475
accuracy: 0.52, validation_loss: 1.2246315479278564, num_samples: 100
Epoch: 3/10, step: 27019, training_loss: 1.28028
Epoch: 3/10, step: 27039, training_loss: 1.34945
Epoch: 3/10, step: 27059, training_loss: 1.29976
Epoch: 3/10, step: 27079, training_loss: 1.41284
Epoch: 3/10, step: 27099, training_loss: 1.66215
Epoch: 3/10, step: 27119, training_loss: 1.49210
Epoch: 3/10, step: 27139, training_loss: 1.77582
Epoch: 3/10, step: 27159, training_loss: 1.61586
Epoch: 3/10, step: 27179, training_loss: 0.94193
Epoch: 3/10, step: 27199, training_loss: 1.70977
Epoch: 3/10, step: 27219, training_loss: 0.79275
Epoch: 3/10, step: 27239, training_loss: 2.65388
Epoch: 3/10, step: 27259, training_loss: 1.19344
Epoch: 3/10, step: 27279, training_loss: 1.58476
Epoch: 3/10, step: 27299, training_loss: 1.38920
Epoch: 3/10, step: 27319, training_loss: 2.01621
Epoch: 3/10, step: 27339, training_loss: 1.49192
Epoch: 3/10, step: 27359, training_loss: 1.38633
Epoch: 3/10, step: 27379, training_loss: 1.07243
Epoch: 3/10, step: 27399, training_loss: 2.62478
Epoch: 3/10, step: 27419, training_loss: 1.02539
Epoch: 3/10, step: 27439, training_loss: 1.59028
Epoch: 3/10, step: 27459, training_loss: 1.20957
Epoch: 3/10, step: 27479, training_loss: 2.23042
Epoch: 3/10, step: 27499, training_loss: 2.05068
Epoch: 3/10, step: 27519, training_loss: 1.46541
Epoch: 3/10, step: 27539, training_loss: 2.30768
Epoch: 3/10, step: 27559, training_loss: 1.25041
Epoch: 3/10, step: 27579, training_loss: 0.78827
Epoch: 3/10, step: 27599, training_loss: 0.74855
Epoch: 3/10, step: 27619, training_loss: 1.13398
Epoch: 3/10, step: 27639, training_loss: 1.51447
Epoch: 3/10, step: 27659, training_loss: 1.14525
Epoch: 3/10, step: 27679, training_loss: 1.00773
Epoch: 3/10, step: 27699, training_loss: 1.50554
Epoch: 3/10, step: 27719, training_loss: 1.15973
Epoch: 3/10, step: 27739, training_loss: 1.50108
Epoch: 3/10, step: 27759, training_loss: 1.21136
Epoch: 3/10, step: 27779, training_loss: 1.15601
Epoch: 3/10, step: 27799, training_loss: 1.39873
Epoch: 3/10, step: 27819, training_loss: 1.33896
Epoch: 3/10, step: 27839, training_loss: 1.36567
Epoch: 3/10, step: 27859, training_loss: 1.60488
Epoch: 3/10, step: 27879, training_loss: 1.72298
Epoch: 3/10, step: 27899, training_loss: 1.02022
Epoch: 3/10, step: 27919, training_loss: 0.96362
Epoch: 3/10, step: 27939, training_loss: 2.31812
Epoch: 3/10, step: 27959, training_loss: 1.06251
Epoch: 3/10, step: 27979, training_loss: 1.93715
Epoch: 3/10, step: 27999, training_loss: 2.17151
accuracy: 0.49, validation_loss: 1.520565152168274, num_samples: 100
Epoch: 3/10, step: 28019, training_loss: 1.09721
Epoch: 3/10, step: 28039, training_loss: 1.37012
Epoch: 3/10, step: 28059, training_loss: 2.42697
Epoch: 3/10, step: 28079, training_loss: 1.55951
Epoch: 3/10, step: 28099, training_loss: 1.51513
Epoch: 3/10, step: 28119, training_loss: 1.54357
Epoch: 3/10, step: 28139, training_loss: 0.98998
Epoch: 3/10, step: 28159, training_loss: 2.20936
Epoch: 3/10, step: 28179, training_loss: 1.32980
Epoch: 3/10, step: 28199, training_loss: 2.37081
Epoch: 3/10, step: 28219, training_loss: 2.00328
Epoch: 3/10, step: 28239, training_loss: 1.17241
Epoch: 3/10, step: 28259, training_loss: 0.98778
Epoch: 3/10, step: 28279, training_loss: 1.31680
Epoch: 3/10, step: 28299, training_loss: 1.38957
Epoch: 3/10, step: 28319, training_loss: 1.16756
Epoch: 3/10, step: 28339, training_loss: 1.14097
Epoch: 3/10, step: 28359, training_loss: 1.67067
Epoch: 3/10, step: 28379, training_loss: 1.30292
Epoch: 3/10, step: 28399, training_loss: 1.86523
Epoch: 3/10, step: 28419, training_loss: 0.77130
Epoch: 3/10, step: 28439, training_loss: 1.65956
Epoch: 3/10, step: 28459, training_loss: 1.42520
Epoch: 3/10, step: 28479, training_loss: 1.37862
Epoch: 3/10, step: 28499, training_loss: 1.79955
Epoch: 3/10, step: 28519, training_loss: 0.84223
Epoch: 3/10, step: 28539, training_loss: 1.60584
Epoch: 3/10, step: 28559, training_loss: 1.44040
Epoch: 3/10, step: 28579, training_loss: 1.61352
Epoch: 3/10, step: 28599, training_loss: 1.09916
Epoch: 3/10, step: 28619, training_loss: 1.21943
Epoch: 3/10, step: 28639, training_loss: 2.35792
Epoch: 3/10, step: 28659, training_loss: 1.95011
Epoch: 3/10, step: 28679, training_loss: 1.46682
Epoch: 3/10, step: 28699, training_loss: 1.11986
Epoch: 3/10, step: 28719, training_loss: 1.74648
Epoch: 3/10, step: 28739, training_loss: 1.07737
Epoch: 3/10, step: 28759, training_loss: 1.11398
Epoch: 3/10, step: 28779, training_loss: 1.23426
Epoch: 3/10, step: 28799, training_loss: 0.80828
Epoch: 3/10, step: 28819, training_loss: 1.33786
Epoch: 3/10, step: 28839, training_loss: 1.29163
Epoch: 3/10, step: 28859, training_loss: 1.80627
Epoch: 3/10, step: 28879, training_loss: 1.52416
Epoch: 3/10, step: 28899, training_loss: 1.64405
Epoch: 3/10, step: 28919, training_loss: 1.07699
Epoch: 3/10, step: 28939, training_loss: 1.01202
Epoch: 3/10, step: 28959, training_loss: 1.57592
Epoch: 3/10, step: 28979, training_loss: 1.63725
Epoch: 3/10, step: 28999, training_loss: 1.17194
accuracy: 0.45, validation_loss: 1.5178223848342896, num_samples: 100
Epoch: 3/10, step: 29019, training_loss: 1.15532
Epoch: 3/10, step: 29039, training_loss: 1.77033
Epoch: 3/10, step: 29059, training_loss: 1.67264
Epoch: 3/10, step: 29079, training_loss: 0.92624
Epoch: 3/10, step: 29099, training_loss: 1.21760
Epoch: 3/10, step: 29119, training_loss: 1.39095
Epoch: 3/10, step: 29139, training_loss: 1.12265
Epoch: 3/10, step: 29159, training_loss: 0.83499
Epoch: 3/10, step: 29179, training_loss: 1.66783
Epoch: 3/10, step: 29199, training_loss: 1.21126
Epoch: 3/10, step: 29219, training_loss: 1.40738
Epoch: 3/10, step: 29239, training_loss: 1.98789
Epoch: 3/10, step: 29259, training_loss: 1.52322
Epoch: 3/10, step: 29279, training_loss: 1.15213
Epoch: 3/10, step: 29299, training_loss: 2.16931
Epoch: 3/10, step: 29319, training_loss: 1.41597
Epoch: 3/10, step: 29339, training_loss: 1.69238
Epoch: 3/10, step: 29359, training_loss: 1.06385
Epoch: 3/10, step: 29379, training_loss: 2.01396
Epoch: 3/10, step: 29399, training_loss: 0.91942
Epoch: 3/10, step: 29419, training_loss: 2.01828
Epoch: 3/10, step: 29439, training_loss: 0.91476
Epoch: 3/10, step: 29459, training_loss: 1.47547
Epoch: 3/10, step: 29479, training_loss: 1.86633
Epoch: 3/10, step: 29499, training_loss: 1.28696
Epoch: 3/10, step: 29519, training_loss: 0.84625
Epoch: 3/10, step: 29539, training_loss: 0.67811
Epoch: 3/10, step: 29559, training_loss: 0.87390
Epoch: 3/10, step: 29579, training_loss: 1.92455
Epoch: 3/10, step: 29599, training_loss: 1.53941
Epoch: 3/10, step: 29619, training_loss: 1.44872
Epoch: 3/10, step: 29639, training_loss: 1.31955
Epoch: 3/10, step: 29659, training_loss: 1.66415
Epoch: 3/10, step: 29679, training_loss: 1.49191
Epoch: 3/10, step: 29699, training_loss: 1.21478
Epoch: 3/10, step: 29719, training_loss: 1.32422
Epoch: 3/10, step: 29739, training_loss: 1.73054
Epoch: 3/10, step: 29759, training_loss: 1.52187
Epoch: 3/10, step: 29779, training_loss: 1.09895
Epoch: 3/10, step: 29799, training_loss: 1.31775
Epoch: 3/10, step: 29819, training_loss: 0.95870
Epoch: 3/10, step: 29839, training_loss: 1.78144
Epoch: 3/10, step: 29859, training_loss: 1.33229
Epoch: 3/10, step: 29879, training_loss: 1.77484
Epoch: 3/10, step: 29899, training_loss: 1.28919
Epoch: 3/10, step: 29919, training_loss: 1.34665
Epoch: 3/10, step: 29939, training_loss: 1.16621
Epoch: 3/10, step: 29959, training_loss: 1.40056
Epoch: 3/10, step: 29979, training_loss: 1.97160
Epoch: 3/10, step: 29999, training_loss: 0.87083
accuracy: 0.48, validation_loss: 1.5461312532424927, num_samples: 100
Epoch: 3/10, step: 30019, training_loss: 0.79208
Epoch: 3/10, step: 30039, training_loss: 1.31121
Epoch: 3/10, step: 30059, training_loss: 1.50422
Epoch: 3/10, step: 30079, training_loss: 1.63123
Epoch: 3/10, step: 30099, training_loss: 1.04941
Epoch: 3/10, step: 30119, training_loss: 1.32253
Epoch: 3/10, step: 30139, training_loss: 0.99846
Epoch: 3/10, step: 30159, training_loss: 1.27255
Epoch: 3/10, step: 30179, training_loss: 1.29365
Epoch: 3/10, step: 30199, training_loss: 1.09767
Epoch: 3/10, step: 30219, training_loss: 1.37739
Epoch: 3/10, step: 30239, training_loss: 0.71942
Epoch: 3/10, step: 30259, training_loss: 1.64663
Epoch: 3/10, step: 30279, training_loss: 1.49418
Epoch: 3/10, step: 30299, training_loss: 1.55388
Epoch: 3/10, step: 30319, training_loss: 1.18593
Epoch: 3/10, step: 30339, training_loss: 1.46328
Epoch: 3/10, step: 30359, training_loss: 1.42962
Epoch: 3/10, step: 30379, training_loss: 2.06649
Epoch: 3/10, step: 30399, training_loss: 1.58182
Epoch: 3/10, step: 30419, training_loss: 2.34780
Epoch: 3/10, step: 30439, training_loss: 1.49293
Epoch: 3/10, step: 30459, training_loss: 1.91206
Epoch: 3/10, step: 30479, training_loss: 1.73850
Epoch: 3/10, step: 30499, training_loss: 1.05167
Epoch: 3/10, step: 30519, training_loss: 1.05810
Epoch: 3/10, step: 30539, training_loss: 1.18497
Epoch: 3/10, step: 30559, training_loss: 1.39170
Epoch: 3/10, step: 30579, training_loss: 1.79793
Epoch: 3/10, step: 30599, training_loss: 1.02531
Epoch: 3/10, step: 30619, training_loss: 1.51820
Epoch: 3/10, step: 30639, training_loss: 1.30691
Epoch: 3/10, step: 30659, training_loss: 1.80719
Epoch: 3/10, step: 30679, training_loss: 1.57168
Epoch: 3/10, step: 30699, training_loss: 1.12969
Epoch: 3/10, step: 30719, training_loss: 1.33162
Epoch: 3/10, step: 30739, training_loss: 2.21284
Epoch: 3/10, step: 30759, training_loss: 1.58115
Epoch: 3/10, step: 30779, training_loss: 1.07529
Epoch: 3/10, step: 30799, training_loss: 0.72422
Epoch: 3/10, step: 30819, training_loss: 1.30403
Epoch: 3/10, step: 30839, training_loss: 1.10982
Epoch: 3/10, step: 30859, training_loss: 1.18647
Epoch: 3/10, step: 30879, training_loss: 0.99861
Epoch: 3/10, step: 30899, training_loss: 1.19867
Epoch: 3/10, step: 30919, training_loss: 1.39084
Epoch: 3/10, step: 30939, training_loss: 1.55676
Epoch: 3/10, step: 30959, training_loss: 1.19062
Epoch: 3/10, step: 30979, training_loss: 1.98230
Epoch: 3/10, step: 30999, training_loss: 1.19035
accuracy: 0.47, validation_loss: 1.3491566181182861, num_samples: 100
Epoch: 3/10, step: 31019, training_loss: 1.40317
Epoch: 3/10, step: 31039, training_loss: 0.95230
Epoch: 3/10, step: 31059, training_loss: 0.90311
Epoch: 3/10, step: 31079, training_loss: 1.73037
Epoch: 3/10, step: 31099, training_loss: 2.13559
Epoch: 3/10, step: 31119, training_loss: 2.49394
Epoch: 3/10, step: 31139, training_loss: 1.19579
Epoch: 3/10, step: 31159, training_loss: 1.63908
Epoch: 3/10, step: 31179, training_loss: 1.51182
Epoch: 3/10, step: 31199, training_loss: 1.61959
Epoch: 3/10, step: 31219, training_loss: 1.59498
Epoch: 3/10, step: 31239, training_loss: 1.97713
Epoch: 3/10, step: 31259, training_loss: 1.49232
Epoch: 3/10, step: 31279, training_loss: 1.14821
Epoch: 3/10, step: 31299, training_loss: 0.64430
Epoch: 3/10, step: 31319, training_loss: 1.46779
Epoch: 3/10, step: 31339, training_loss: 1.76558
Epoch: 3/10, step: 31359, training_loss: 1.55647
Epoch: 3/10, step: 31379, training_loss: 1.62929
Epoch: 3/10, step: 31399, training_loss: 1.65108
Epoch: 3/10, step: 31419, training_loss: 1.72549
Epoch: 3/10, step: 31439, training_loss: 0.74034
Epoch: 3/10, step: 31459, training_loss: 1.24569
Epoch: 3/10, step: 31479, training_loss: 1.56149
Epoch: 3/10, step: 31499, training_loss: 1.59146
Epoch: 3/10, step: 31519, training_loss: 1.01730
Epoch: 3/10, step: 31539, training_loss: 1.42335
Epoch: 3/10, step: 31559, training_loss: 1.40305
Epoch: 3/10, step: 31579, training_loss: 1.81093
Epoch: 3/10, step: 31599, training_loss: 1.59582
Epoch: 3/10, step: 31619, training_loss: 1.06497
Epoch: 3/10, step: 31639, training_loss: 1.27384
Epoch: 3/10, step: 31659, training_loss: 0.98331
Epoch: 3/10, step: 31679, training_loss: 1.96837
Epoch: 3/10, step: 31699, training_loss: 1.08429
Epoch: 3/10, step: 31719, training_loss: 1.24675
Epoch: 3/10, step: 31739, training_loss: 1.31724
Epoch: 3/10, step: 31759, training_loss: 0.85821
Epoch: 3/10, step: 31779, training_loss: 1.42384
Epoch: 3/10, step: 31799, training_loss: 1.30729
Epoch: 3/10, step: 31819, training_loss: 1.15564
Epoch: 3/10, step: 31839, training_loss: 1.27505
Epoch: 3/10, step: 31859, training_loss: 1.43174
Epoch: 3/10, step: 31879, training_loss: 1.19146
Epoch: 3/10, step: 31899, training_loss: 1.32235
Epoch: 3/10, step: 31919, training_loss: 1.38670
Epoch: 3/10, step: 31939, training_loss: 1.82548
Epoch: 3/10, step: 31959, training_loss: 1.40419
Epoch: 3/10, step: 31979, training_loss: 0.95023
Epoch: 3/10, step: 31999, training_loss: 1.67051
accuracy: 0.43, validation_loss: 1.5311638116836548, num_samples: 100
Epoch: 3/10, step: 32019, training_loss: 1.47349
Epoch: 3/10, step: 32039, training_loss: 0.99539
Epoch: 3/10, step: 32059, training_loss: 1.71830
Epoch: 3/10, step: 32079, training_loss: 1.83390
Epoch: 3/10, step: 32099, training_loss: 1.27380
Epoch: 3/10, step: 32119, training_loss: 1.57701
Epoch: 3/10, step: 32139, training_loss: 1.13466
Epoch: 3/10, step: 32159, training_loss: 1.79002
Epoch: 3/10, step: 32179, training_loss: 1.63153
Epoch: 3/10, step: 32199, training_loss: 1.71006
Epoch: 3/10, step: 32219, training_loss: 1.34418
Epoch: 3/10, step: 32239, training_loss: 1.72992
Epoch: 3/10, step: 32259, training_loss: 1.39977
Epoch: 3/10, step: 32279, training_loss: 2.08782
Epoch: 3/10, step: 32299, training_loss: 1.73199
Epoch: 3/10, step: 32319, training_loss: 1.52157
Epoch: 3/10, step: 32339, training_loss: 1.56402
Epoch: 3/10, step: 32359, training_loss: 1.16806
Epoch: 3/10, step: 32379, training_loss: 1.28263
Epoch: 3/10, step: 32399, training_loss: 1.04633
Epoch: 3/10, step: 32419, training_loss: 2.05335
Epoch: 3/10, step: 32439, training_loss: 1.12403
Epoch: 3/10, step: 32459, training_loss: 1.25169
Epoch: 3/10, step: 32479, training_loss: 1.06711
Epoch: 3/10, step: 32499, training_loss: 1.22305
Epoch: 3/10, step: 32519, training_loss: 1.12157
Epoch: 3/10, step: 32539, training_loss: 1.07282
Epoch: 3/10, step: 32559, training_loss: 1.37214
Epoch: 3/10, step: 32579, training_loss: 1.63029
Epoch: 3/10, step: 32599, training_loss: 1.11007
Epoch: 3/10, step: 32619, training_loss: 1.25663
Epoch: 3/10, step: 32639, training_loss: 0.98625
Epoch: 3/10, step: 32659, training_loss: 1.00689
Epoch: 3/10, step: 32679, training_loss: 0.60797
Epoch: 3/10, step: 32699, training_loss: 0.90166
Epoch: 3/10, step: 32719, training_loss: 1.32301
Epoch: 3/10, step: 32739, training_loss: 1.25566
Epoch: 3/10, step: 32759, training_loss: 1.56592
Epoch: 3/10, step: 32779, training_loss: 1.44196
Epoch: 3/10, step: 32799, training_loss: 1.20993
Epoch: 3/10, step: 32819, training_loss: 1.09786
Epoch: 3/10, step: 32839, training_loss: 1.58445
Epoch: 3/10, step: 32859, training_loss: 1.73557
Epoch: 3/10, step: 32879, training_loss: 1.20230
Epoch: 3/10, step: 32899, training_loss: 1.54072
Epoch: 3/10, step: 32919, training_loss: 1.62829
Epoch: 3/10, step: 32939, training_loss: 2.13106
Epoch: 3/10, step: 32959, training_loss: 1.67300
Epoch: 3/10, step: 32979, training_loss: 1.30698
Epoch: 3/10, step: 32999, training_loss: 1.73504
accuracy: 0.41, validation_loss: 1.4520469903945923, num_samples: 100
Epoch: 3/10, step: 33019, training_loss: 1.82302
Epoch: 3/10, step: 33039, training_loss: 1.19333
Epoch: 3/10, step: 33059, training_loss: 1.11779
Epoch: 3/10, step: 33079, training_loss: 0.93504
Epoch: 3/10, step: 33099, training_loss: 1.42202
Epoch: 3/10, step: 33119, training_loss: 1.83176
Epoch: 3/10, step: 33139, training_loss: 1.48766
Epoch: 3/10, step: 33159, training_loss: 1.62584
Epoch: 3/10, step: 33179, training_loss: 1.11946
Epoch: 3/10, step: 33199, training_loss: 0.86635
Epoch: 3/10, step: 33219, training_loss: 1.02388
Epoch: 3/10, step: 33239, training_loss: 1.04791
Epoch: 3/10, step: 33259, training_loss: 1.11360
Epoch: 3/10, step: 33279, training_loss: 1.15083
Epoch: 3/10, step: 33299, training_loss: 1.08171
Epoch: 3/10, step: 33319, training_loss: 1.99620
Epoch: 3/10, step: 33339, training_loss: 1.41351
Epoch: 3/10, step: 33359, training_loss: 1.45556
Epoch: 3/10, step: 33379, training_loss: 1.60266
Epoch: 3/10, step: 33399, training_loss: 1.15079
Epoch: 3/10, step: 33419, training_loss: 1.65351
Epoch: 3/10, step: 33439, training_loss: 1.41100
Epoch: 3/10, step: 33459, training_loss: 1.60254
Epoch: 3/10, step: 33479, training_loss: 1.72432
Epoch: 3/10, step: 33499, training_loss: 1.42288
Epoch: 3/10, step: 33519, training_loss: 1.47703
Epoch: 3/10, step: 33539, training_loss: 1.42766
Epoch: 3/10, step: 33559, training_loss: 1.46892
Epoch: 3/10, step: 33579, training_loss: 2.16192
Epoch: 3/10, step: 33599, training_loss: 1.46304
Epoch: 3/10, step: 33619, training_loss: 1.33172
Epoch: 3/10, step: 33639, training_loss: 1.57392
Epoch: 3/10, step: 33659, training_loss: 1.81770
Epoch: 3/10, step: 33679, training_loss: 1.21244
Epoch: 3/10, step: 33699, training_loss: 0.91298
Epoch: 3/10, step: 33719, training_loss: 1.25748
Epoch: 3/10, step: 33739, training_loss: 1.27822
Epoch: 3/10, step: 33759, training_loss: 1.80046
Epoch: 3/10, step: 33779, training_loss: 1.61811
Epoch: 3/10, step: 33799, training_loss: 1.01693
Epoch: 3/10, step: 33819, training_loss: 1.11653
Epoch: 3/10, step: 33839, training_loss: 1.55161
Epoch: 3/10, step: 33859, training_loss: 1.33046
Epoch: 3/10, step: 33879, training_loss: 1.80449
Epoch: 3/10, step: 33899, training_loss: 1.42649
Epoch: 3/10, step: 33919, training_loss: 1.71889
Epoch: 3/10, step: 33939, training_loss: 1.57388
Epoch: 3/10, step: 33959, training_loss: 1.48846
Epoch: 3/10, step: 33979, training_loss: 1.16378
Epoch: 3/10, step: 33999, training_loss: 1.16046
accuracy: 0.53, validation_loss: 1.3350329399108887, num_samples: 100
Epoch: 3/10, step: 34019, training_loss: 1.38924
Epoch: 3/10, step: 34039, training_loss: 1.12654
Epoch: 3/10, step: 34059, training_loss: 2.07053
Epoch: 3/10, step: 34079, training_loss: 1.32961
Epoch: 3/10, step: 34099, training_loss: 1.96980
Epoch: 3/10, step: 34119, training_loss: 0.88339
Epoch: 3/10, step: 34139, training_loss: 1.89737
Epoch: 3/10, step: 34159, training_loss: 1.73061
Epoch: 3/10, step: 34179, training_loss: 1.06949
Epoch: 3/10, step: 34199, training_loss: 1.54143
Epoch: 3/10, step: 34219, training_loss: 1.16364
Epoch: 3/10, step: 34239, training_loss: 1.24414
Epoch: 3/10, step: 34259, training_loss: 1.25278
Epoch: 3/10, step: 34279, training_loss: 1.07671
Epoch: 3/10, step: 34299, training_loss: 1.65920
Epoch: 3/10, step: 34319, training_loss: 1.25554
Epoch: 3/10, step: 34339, training_loss: 1.43910
Epoch: 3/10, step: 34359, training_loss: 1.14678
Epoch: 3/10, step: 34379, training_loss: 1.90505
Epoch: 3/10, step: 34399, training_loss: 2.27515
Epoch: 3/10, step: 34419, training_loss: 1.04570
Epoch: 3/10, step: 34439, training_loss: 1.37211
Epoch: 3/10, step: 34459, training_loss: 1.68047
Epoch: 3/10, step: 34479, training_loss: 1.65492
Epoch: 3/10, step: 34499, training_loss: 1.44655
Epoch: 3/10, step: 34519, training_loss: 0.97894
Epoch: 3/10, step: 34539, training_loss: 1.49591
Epoch: 3/10, step: 34559, training_loss: 1.04463
Epoch: 3/10, step: 34579, training_loss: 0.78377
Epoch: 3/10, step: 34599, training_loss: 2.40550
Epoch: 3/10, step: 34619, training_loss: 1.36674
Epoch: 3/10, step: 34639, training_loss: 1.73012
Epoch: 3/10, step: 34659, training_loss: 1.28972
Epoch: 3/10, step: 34679, training_loss: 1.85517
Epoch: 3/10, step: 34699, training_loss: 1.62119
Epoch: 3/10, step: 34719, training_loss: 1.18369
Epoch: 3/10, step: 34739, training_loss: 1.58254
Epoch: 3/10, step: 34759, training_loss: 1.92547
Epoch: 3/10, step: 34779, training_loss: 1.42334
Epoch: 3/10, step: 34799, training_loss: 2.07188
Epoch: 3/10, step: 34819, training_loss: 1.04165
Epoch: 3/10, step: 34839, training_loss: 1.90824
Epoch: 3/10, step: 34859, training_loss: 1.09865
Epoch: 3/10, step: 34879, training_loss: 1.45491
Epoch: 3/10, step: 34899, training_loss: 1.68155
Epoch: 3/10, step: 34919, training_loss: 1.80371
Epoch: 3/10, step: 34939, training_loss: 1.70630
Epoch: 3/10, step: 34959, training_loss: 1.35745
Epoch: 3/10, step: 34979, training_loss: 1.40556
Epoch: 3/10, step: 34999, training_loss: 1.53560
accuracy: 0.43, validation_loss: 1.592299461364746, num_samples: 100
Epoch: 3/10, step: 35019, training_loss: 1.36029
Epoch: 3/10, step: 35039, training_loss: 0.87551
Epoch: 3/10, step: 35059, training_loss: 1.78390
Epoch: 3/10, step: 35079, training_loss: 1.53232
Epoch: 3/10, step: 35099, training_loss: 1.40279
Epoch: 3/10, step: 35119, training_loss: 1.42745
Epoch: 3/10, step: 35139, training_loss: 1.22285
Epoch: 3/10, step: 35159, training_loss: 0.95373
Epoch: 3/10, step: 35179, training_loss: 1.25971
Epoch: 3/10, step: 35199, training_loss: 0.73002
Epoch: 3/10, step: 35219, training_loss: 2.04468
Epoch: 3/10, step: 35239, training_loss: 1.57491
Epoch: 3/10, step: 35259, training_loss: 1.03339
Epoch: 3/10, step: 35279, training_loss: 1.38277
Epoch: 3/10, step: 35299, training_loss: 1.81560
Epoch: 3/10, step: 35319, training_loss: 1.44528
Epoch: 3/10, step: 35339, training_loss: 1.59083
Epoch: 3/10, step: 35359, training_loss: 1.70460
Epoch: 3/10, step: 35379, training_loss: 1.31668
Epoch: 3/10, step: 35399, training_loss: 0.69649
Epoch: 3/10, step: 35419, training_loss: 1.06139
Epoch: 3/10, step: 35439, training_loss: 0.80783
Epoch: 3/10, step: 35459, training_loss: 2.07598
Epoch: 3/10, step: 35479, training_loss: 1.31695
Epoch: 3/10, step: 35499, training_loss: 1.79422
Epoch: 3/10, step: 35519, training_loss: 1.97145
Epoch: 3/10, step: 35539, training_loss: 1.22268
Epoch: 3/10, step: 35559, training_loss: 1.87917
Epoch: 3/10, step: 35579, training_loss: 1.89604
Epoch: 3/10, step: 35599, training_loss: 1.46222
Epoch: 3/10, step: 35619, training_loss: 0.97903
Epoch: 3/10, step: 35639, training_loss: 1.48432
Epoch: 3/10, step: 35659, training_loss: 1.50784
Epoch: 3/10, step: 35679, training_loss: 0.97533
Epoch: 3/10, step: 35699, training_loss: 1.59102
Epoch: 3/10, step: 35719, training_loss: 1.35423
Epoch: 3/10, step: 35739, training_loss: 1.65196
Epoch: 3/10, step: 35759, training_loss: 1.91982
Epoch: 3/10, step: 35779, training_loss: 1.53545
Epoch: 3/10, step: 35799, training_loss: 1.35331
Epoch: 3/10, step: 35819, training_loss: 1.87658
Epoch: 3/10, step: 35839, training_loss: 0.64173
Epoch: 3/10, step: 35859, training_loss: 1.52514
Epoch: 3/10, step: 35879, training_loss: 1.61612
Epoch: 3/10, step: 35899, training_loss: 1.56741
Epoch: 3/10, step: 35919, training_loss: 1.57955
Epoch: 3/10, step: 35939, training_loss: 2.52801
Epoch: 3/10, step: 35959, training_loss: 1.37548
Epoch: 3/10, step: 35979, training_loss: 1.53185
Epoch: 3/10, step: 35999, training_loss: 1.20054
accuracy: 0.4, validation_loss: 1.5512127876281738, num_samples: 100
Epoch: 3/10, step: 36019, training_loss: 1.50471
Epoch: 3/10, step: 36039, training_loss: 0.97715
Epoch: 3/10, step: 36059, training_loss: 1.79757
Epoch: 3/10, step: 36079, training_loss: 1.34957
Epoch: 3/10, step: 36099, training_loss: 1.70948
Epoch: 3/10, step: 36119, training_loss: 1.63968
Epoch: 3/10, step: 36139, training_loss: 1.69337
Epoch: 3/10, step: 36159, training_loss: 1.55002
Epoch: 3/10, step: 36179, training_loss: 1.55983
Epoch: 3/10, step: 36199, training_loss: 0.90157
Epoch: 3/10, step: 36219, training_loss: 1.11992
Epoch: 3/10, step: 36239, training_loss: 1.00003
Epoch: 3/10, step: 36259, training_loss: 1.86365
Epoch: 3/10, step: 36279, training_loss: 1.24833
Epoch: 3/10, step: 36299, training_loss: 1.01870
Epoch: 3/10, step: 36319, training_loss: 1.30468
Epoch: 3/10, step: 36339, training_loss: 1.14736
Epoch: 3/10, step: 36359, training_loss: 1.46571
Epoch: 3/10, step: 36379, training_loss: 1.44892
Epoch: 3/10, step: 36399, training_loss: 0.99146
Epoch: 3/10, step: 36419, training_loss: 1.80369
Epoch: 3/10, step: 36439, training_loss: 1.44511
Epoch: 3/10, step: 36459, training_loss: 1.21211
Epoch: 3/10, step: 36479, training_loss: 1.51151
Epoch: 3/10, step: 36499, training_loss: 1.73715
Epoch: 3/10, step: 36519, training_loss: 1.40629
Epoch: 3/10, step: 36539, training_loss: 1.50392
Epoch: 3/10, step: 36559, training_loss: 1.85799
Epoch: 3/10, step: 36579, training_loss: 1.90608
Epoch: 3/10, step: 36599, training_loss: 0.94974
Epoch: 3/10, step: 36619, training_loss: 1.59814
Epoch: 3/10, step: 36639, training_loss: 1.58934
Epoch: 3/10, step: 36659, training_loss: 1.41321
Epoch: 3/10, step: 36679, training_loss: 1.46104
Epoch: 3/10, step: 36699, training_loss: 1.14954
Epoch: 3/10, step: 36719, training_loss: 1.51359
Epoch: 3/10, step: 36739, training_loss: 1.61220
Epoch: 3/10, step: 36759, training_loss: 2.04122
Epoch: 3/10, step: 36779, training_loss: 1.32602
Epoch: 3/10, step: 36799, training_loss: 0.91687
Epoch: 3/10, step: 36819, training_loss: 0.92542
Epoch: 3/10, step: 36839, training_loss: 1.76968
Epoch: 3/10, step: 36859, training_loss: 2.13191
Epoch: 3/10, step: 36879, training_loss: 1.57777
Epoch: 3/10, step: 36899, training_loss: 1.52048
Epoch: 3/10, step: 36919, training_loss: 1.76910
Epoch: 3/10, step: 36939, training_loss: 1.43415
Epoch: 3/10, step: 36959, training_loss: 2.18611
Epoch: 3/10, step: 36979, training_loss: 1.65740
Epoch: 3/10, step: 36999, training_loss: 2.05343
accuracy: 0.54, validation_loss: 1.3316460847854614, num_samples: 100
Epoch: 3/10, step: 37019, training_loss: 1.76488
Epoch: 3/10, step: 37039, training_loss: 1.56187
Epoch: 3/10, step: 37059, training_loss: 1.22782
Epoch: 3/10, step: 37079, training_loss: 1.81710
Epoch: 3/10, step: 37099, training_loss: 0.91983
Epoch: 3/10, step: 37119, training_loss: 1.46183
Epoch: 3/10, step: 37139, training_loss: 0.97779
Epoch: 3/10, step: 37159, training_loss: 1.00789
Epoch: 3/10, step: 37179, training_loss: 0.99380
Epoch: 3/10, step: 37199, training_loss: 1.77048
Epoch: 3/10, step: 37219, training_loss: 2.01333
Epoch: 3/10, step: 37239, training_loss: 1.53192
Epoch: 3/10, step: 37259, training_loss: 1.63417
Epoch: 3/10, step: 37279, training_loss: 1.66251
Epoch: 3/10, step: 37299, training_loss: 1.66809
Epoch: 3/10, step: 37319, training_loss: 1.60427
Epoch: 3/10, step: 37339, training_loss: 1.80616
Epoch: 3/10, step: 37359, training_loss: 1.00056
Epoch: 3/10, step: 37379, training_loss: 2.01231
Epoch: 3/10, step: 37399, training_loss: 1.28862
Epoch: 3/10, step: 37419, training_loss: 1.82693
Epoch: 3/10, step: 37439, training_loss: 1.37376
Epoch: 3/10, step: 37459, training_loss: 1.89472
Epoch: 3/10, step: 37479, training_loss: 1.20730
Epoch: 3/10, step: 37499, training_loss: 1.01821
Epoch: 3/10, step: 37519, training_loss: 1.59595
Epoch: 3/10, step: 37539, training_loss: 1.72901
Epoch: 3/10, step: 37559, training_loss: 1.01329
Epoch: 3/10, step: 37579, training_loss: 1.45700
Epoch: 3/10, step: 37599, training_loss: 1.36975
Epoch: 3/10, step: 37619, training_loss: 0.93120
Epoch: 3/10, step: 37639, training_loss: 2.09217
Epoch: 3/10, step: 37659, training_loss: 1.67681
Epoch: 3/10, step: 37679, training_loss: 1.34031
Epoch: 3/10, step: 37699, training_loss: 1.07014
Epoch: 3/10, step: 37719, training_loss: 1.75669
Epoch: 3/10, step: 37739, training_loss: 1.16743
Epoch: 3/10, step: 37759, training_loss: 1.84337
Epoch: 3/10, step: 37779, training_loss: 0.80930
Epoch: 3/10, step: 37799, training_loss: 1.44309
Epoch: 3/10, step: 37819, training_loss: 1.66036
Epoch: 3/10, step: 37839, training_loss: 1.15617
Epoch: 3/10, step: 37859, training_loss: 1.53705
Epoch: 3/10, step: 37879, training_loss: 1.91126
Epoch: 3/10, step: 37899, training_loss: 1.51410
Epoch: 3/10, step: 37919, training_loss: 0.92462
Epoch: 3/10, step: 37939, training_loss: 1.55565
Epoch: 3/10, step: 37959, training_loss: 1.74641
Epoch: 3/10, step: 37979, training_loss: 1.07862
Epoch: 3/10, step: 37999, training_loss: 1.40846
accuracy: 0.48, validation_loss: 1.4390536546707153, num_samples: 100
Epoch: 3/10, step: 38019, training_loss: 1.29844
Epoch: 3/10, step: 38039, training_loss: 1.23370
Epoch: 3/10, step: 38059, training_loss: 1.54055
Epoch: 3/10, step: 38079, training_loss: 1.15672
Epoch: 3/10, step: 38099, training_loss: 1.57805
Epoch: 3/10, step: 38119, training_loss: 1.40038
Epoch: 3/10, step: 38139, training_loss: 1.44976
Epoch: 3/10, step: 38159, training_loss: 1.11295
Epoch: 3/10, step: 38179, training_loss: 1.49358
Epoch: 3/10, step: 38199, training_loss: 1.47587
Epoch: 3/10, step: 38219, training_loss: 0.91426
Epoch: 3/10, step: 38239, training_loss: 0.99753
Epoch: 3/10, step: 38259, training_loss: 1.29234
Epoch: 3/10, step: 38279, training_loss: 1.80461
Epoch: 3/10, step: 38299, training_loss: 1.17874
Epoch: 3/10, step: 38319, training_loss: 2.03062
Epoch: 3/10, step: 38339, training_loss: 1.46935
Epoch: 3/10, step: 38359, training_loss: 1.82978
Epoch: 3/10, step: 38379, training_loss: 1.59412
Epoch: 3/10, step: 38399, training_loss: 1.53163
Epoch: 3/10, step: 38419, training_loss: 1.32440
Epoch: 3/10, step: 38439, training_loss: 1.29549
Epoch: 3/10, step: 38459, training_loss: 1.21941
Epoch: 3/10, step: 38479, training_loss: 1.39013
Epoch: 3/10, step: 38499, training_loss: 1.51304
Epoch: 3/10, step: 38519, training_loss: 1.29022
Epoch: 3/10, step: 38539, training_loss: 1.26318
Epoch: 3/10, step: 38559, training_loss: 1.16100
Epoch: 3/10, step: 38579, training_loss: 1.87157
Epoch: 3/10, step: 38599, training_loss: 1.43702
Epoch: 3/10, step: 38619, training_loss: 1.10127
Epoch: 3/10, step: 38639, training_loss: 1.93074
Epoch: 3/10, step: 38659, training_loss: 1.72228
Epoch: 3/10, step: 38679, training_loss: 0.87204
Epoch: 3/10, step: 38699, training_loss: 1.51153
Epoch: 3/10, step: 38719, training_loss: 1.34398
Epoch: 3/10, step: 38739, training_loss: 1.53157
Epoch: 3/10, step: 38759, training_loss: 1.23340
Epoch: 3/10, step: 38779, training_loss: 1.39116
Epoch: 3/10, step: 38799, training_loss: 1.87357
Epoch: 3/10, step: 38819, training_loss: 1.13516
Epoch: 3/10, step: 38839, training_loss: 2.30461
Epoch: 3/10, step: 38859, training_loss: 1.37319
Epoch: 3/10, step: 38879, training_loss: 1.49799
Epoch: 3/10, step: 38899, training_loss: 1.57100
Epoch: 3/10, step: 38919, training_loss: 1.39179
Epoch: 3/10, step: 38939, training_loss: 1.15737
Epoch: 3/10, step: 38959, training_loss: 1.43522
Epoch: 3/10, step: 38979, training_loss: 1.64628
Epoch: 3/10, step: 38999, training_loss: 1.88373
accuracy: 0.46, validation_loss: 1.4193387031555176, num_samples: 100
Epoch: 3/10, step: 39019, training_loss: 1.51806
Epoch: 3/10, step: 39039, training_loss: 1.93016
Epoch: 3/10, step: 39059, training_loss: 1.73252
Epoch: 3/10, step: 39079, training_loss: 1.33662
Epoch: 3/10, step: 39099, training_loss: 1.42669
Epoch: 3/10, step: 39119, training_loss: 1.51153
Epoch: 3/10, step: 39139, training_loss: 1.81990
Epoch: 3/10, step: 39159, training_loss: 0.98358
Epoch: 3/10, step: 39179, training_loss: 1.05174
Epoch: 3/10, step: 39199, training_loss: 0.90422
Epoch: 3/10, step: 39219, training_loss: 1.41969
Epoch: 3/10, step: 39239, training_loss: 1.81779
Epoch: 3/10, step: 39259, training_loss: 2.17578
Epoch: 3/10, step: 39279, training_loss: 1.05148
Epoch: 3/10, step: 39299, training_loss: 1.68372
Epoch: 3/10, step: 39319, training_loss: 1.05198
Epoch: 3/10, step: 39339, training_loss: 1.62287
Epoch: 3/10, step: 39359, training_loss: 1.96174
Epoch: 3/10, step: 39379, training_loss: 1.78155
Epoch: 3/10, step: 39399, training_loss: 1.64000
Epoch: 3/10, step: 39419, training_loss: 1.10117
Epoch: 3/10, step: 39439, training_loss: 1.39508
Epoch: 3/10, step: 39459, training_loss: 0.87163
Epoch: 3/10, step: 39479, training_loss: 1.00918
Epoch: 3/10, step: 39499, training_loss: 1.49155
Epoch: 3/10, step: 39519, training_loss: 0.99618
Epoch: 3/10, step: 39539, training_loss: 1.82400
Epoch: 3/10, step: 39559, training_loss: 0.96035
Epoch: 3/10, step: 39579, training_loss: 0.88137
Epoch: 3/10, step: 39599, training_loss: 1.43389
Epoch: 3/10, step: 39619, training_loss: 1.22974
Epoch: 3/10, step: 39639, training_loss: 1.39690
Epoch: 3/10, step: 39659, training_loss: 1.14444
Epoch: 3/10, step: 39679, training_loss: 1.63482
Epoch: 3/10, step: 39699, training_loss: 1.06744
Epoch: 3/10, step: 39719, training_loss: 1.49907
Epoch: 3/10, step: 39739, training_loss: 1.58590
Epoch: 3/10, step: 39759, training_loss: 1.01402
Epoch: 3/10, step: 39779, training_loss: 1.33039
Epoch: 3/10, step: 39799, training_loss: 1.60951
Epoch: 3/10, step: 39819, training_loss: 1.87173
Epoch: 3/10, step: 39839, training_loss: 2.15419
Epoch: 3/10, step: 39859, training_loss: 1.05961
Epoch: 3/10, step: 39879, training_loss: 0.82566
Epoch: 3/10, step: 39899, training_loss: 1.60306
Epoch: 3/10, step: 39919, training_loss: 1.13512
Epoch: 3/10, step: 39939, training_loss: 1.66567
Epoch: 3/10, step: 39959, training_loss: 1.64973
Epoch: 3/10, step: 39979, training_loss: 1.09741
Epoch: 3/10, step: 39999, training_loss: 1.03230
accuracy: 0.54, validation_loss: 1.3014377355575562, num_samples: 100
Epoch: 3/10, step: 40019, training_loss: 2.43629
Epoch: 3/10, step: 40039, training_loss: 1.68480
Epoch: 3/10, step: 40059, training_loss: 1.44246
Epoch: 3/10, step: 40079, training_loss: 1.75097
Epoch: 3/10, step: 40099, training_loss: 1.20809
Epoch: 3/10, step: 40119, training_loss: 1.45841
Epoch: 3/10, step: 40139, training_loss: 1.09924
Epoch: 3/10, step: 40159, training_loss: 1.98118
Epoch: 3/10, step: 40179, training_loss: 1.32592
Epoch: 3/10, step: 40199, training_loss: 1.36118
Epoch: 3/10, step: 40219, training_loss: 1.43807
Epoch: 3/10, step: 40239, training_loss: 1.55454
Epoch: 3/10, step: 40259, training_loss: 1.39961
Epoch: 3/10, step: 40279, training_loss: 1.88391
Epoch: 3/10, step: 40299, training_loss: 1.56870
Epoch: 3/10, step: 40319, training_loss: 1.18336
Epoch: 3/10, step: 40339, training_loss: 1.25222
Epoch: 3/10, step: 40359, training_loss: 1.43210
Epoch: 3/10, step: 40379, training_loss: 1.58098
Epoch: 3/10, step: 40399, training_loss: 0.86741
Epoch: 3/10, step: 40419, training_loss: 1.14619
Epoch: 3/10, step: 40439, training_loss: 1.60403
Epoch: 3/10, step: 40459, training_loss: 0.94218
Epoch: 3/10, step: 40479, training_loss: 0.97479
Epoch: 3/10, step: 40499, training_loss: 0.79022
Epoch: 3/10, step: 40519, training_loss: 1.13579
Epoch: 3/10, step: 40539, training_loss: 0.85080
Epoch: 3/10, step: 40559, training_loss: 1.73150
Epoch: 3/10, step: 40579, training_loss: 2.04333
Epoch: 3/10, step: 40599, training_loss: 1.33136
Epoch: 3/10, step: 40619, training_loss: 1.49399
Epoch: 3/10, step: 40639, training_loss: 0.84394
Epoch: 3/10, step: 40659, training_loss: 1.45560
Epoch: 3/10, step: 40679, training_loss: 1.36455
Epoch: 3/10, step: 40699, training_loss: 1.26047
Epoch: 3/10, step: 40719, training_loss: 1.71546
Epoch: 3/10, step: 40739, training_loss: 1.25731
Epoch: 3/10, step: 40759, training_loss: 1.57061
Epoch: 3/10, step: 40779, training_loss: 1.26701
Epoch: 3/10, step: 40799, training_loss: 1.51940
Epoch: 3/10, step: 40819, training_loss: 1.89143
Epoch: 3/10, step: 40839, training_loss: 1.45330
Epoch: 3/10, step: 40859, training_loss: 1.55349
Epoch: 3/10, step: 40879, training_loss: 1.39735
Epoch: 3/10, step: 40899, training_loss: 0.90810
Epoch: 3/10, step: 40919, training_loss: 1.23452
Epoch: 3/10, step: 40939, training_loss: 1.45663
Epoch: 3/10, step: 40959, training_loss: 1.57620
Epoch: 3/10, step: 40979, training_loss: 0.98686
Epoch: 3/10, step: 40999, training_loss: 1.07872
accuracy: 0.5, validation_loss: 1.3374431133270264, num_samples: 100
Epoch: 3/10, step: 41019, training_loss: 1.45980
Epoch: 3/10, step: 41039, training_loss: 1.74310
Epoch: 3/10, step: 41059, training_loss: 1.81152
Epoch: 3/10, step: 41079, training_loss: 1.14141
Epoch: 3/10, step: 41099, training_loss: 1.14909
Epoch: 3/10, step: 41119, training_loss: 1.52036
Epoch: 3/10, step: 41139, training_loss: 0.82333
Epoch: 3/10, step: 41159, training_loss: 1.29790
Epoch: 3/10, step: 41179, training_loss: 2.04385
Epoch: 3/10, step: 41199, training_loss: 1.37454
Epoch: 3/10, step: 41219, training_loss: 0.89037
Epoch: 3/10, step: 41239, training_loss: 1.51141
Epoch: 3/10, step: 41259, training_loss: 1.13873
Epoch: 3/10, step: 41279, training_loss: 1.00532
Epoch: 3/10, step: 41299, training_loss: 1.51411
Epoch: 3/10, step: 41319, training_loss: 1.53136
Epoch: 3/10, step: 41339, training_loss: 1.49588
Epoch: 3/10, step: 41359, training_loss: 1.32824
Epoch: 3/10, step: 41379, training_loss: 1.45770
Epoch: 3/10, step: 41399, training_loss: 0.90013
Epoch: 3/10, step: 41419, training_loss: 0.93953
Epoch: 3/10, step: 41439, training_loss: 1.00673
Epoch: 3/10, step: 41459, training_loss: 0.75449
Epoch: 3/10, step: 41479, training_loss: 1.82659
Epoch: 3/10, step: 41499, training_loss: 0.69937
Epoch: 3/10, step: 41519, training_loss: 1.12975
Epoch: 3/10, step: 41539, training_loss: 1.53143
Epoch: 3/10, step: 41559, training_loss: 1.46930
Epoch: 3/10, step: 41579, training_loss: 1.61581
Epoch: 3/10, step: 41599, training_loss: 0.95636
Epoch: 3/10, step: 41619, training_loss: 1.44519
Epoch: 3/10, step: 41639, training_loss: 1.41930
Epoch: 3/10, step: 41659, training_loss: 0.96481
Epoch: 3/10, step: 41679, training_loss: 0.96570
Epoch: 3/10, step: 41699, training_loss: 1.31021
Epoch: 3/10, step: 41719, training_loss: 1.52023
Epoch: 3/10, step: 41739, training_loss: 1.74215
Epoch: 3/10, step: 41759, training_loss: 1.48595
Epoch: 3/10, step: 41779, training_loss: 1.59935
Epoch: 3/10, step: 41799, training_loss: 1.80505
Epoch: 3/10, step: 41819, training_loss: 1.37998
Epoch: 3/10, step: 41839, training_loss: 2.10728
Epoch: 3/10, step: 41859, training_loss: 0.98405
Epoch: 3/10, step: 41879, training_loss: 2.24707
Epoch: 3/10, step: 41899, training_loss: 1.48719
Epoch: 3/10, step: 41919, training_loss: 1.14959
Epoch: 3/10, step: 41939, training_loss: 1.93084
Epoch: 3/10, step: 41959, training_loss: 0.78004
Epoch: 3/10, step: 41979, training_loss: 0.91293
Epoch: 3/10, step: 41999, training_loss: 1.29380
accuracy: 0.53, validation_loss: 1.3890869617462158, num_samples: 100
Epoch: 3/10, step: 42019, training_loss: 2.09592
Epoch: 3/10, step: 42039, training_loss: 1.31905
Epoch: 3/10, step: 42059, training_loss: 1.39877
Epoch: 3/10, step: 42079, training_loss: 1.21900
Epoch: 3/10, step: 42099, training_loss: 1.58398
Epoch: 3/10, step: 42119, training_loss: 1.27234
Epoch: 3/10, step: 42139, training_loss: 1.05899
Epoch: 3/10, step: 42159, training_loss: 1.38218
Epoch: 3/10, step: 42179, training_loss: 1.14172
Epoch: 3/10, step: 42199, training_loss: 1.63800
Epoch: 3/10, step: 42219, training_loss: 1.59921
Epoch: 3/10, step: 42239, training_loss: 2.10779
Epoch: 3/10, step: 42259, training_loss: 1.98148
Epoch: 3/10, step: 42279, training_loss: 2.24815
Epoch: 3/10, step: 42299, training_loss: 1.36563
Epoch: 3/10, step: 42319, training_loss: 1.50982
Epoch: 3/10, step: 42339, training_loss: 2.06028
Epoch: 3/10, step: 42359, training_loss: 1.29420
Epoch: 3/10, step: 42379, training_loss: 1.10298
Epoch: 3/10, step: 42399, training_loss: 1.86009
Epoch: 3/10, step: 42419, training_loss: 1.46057
Epoch: 3/10, step: 42439, training_loss: 1.28046
Epoch: 3/10, step: 42459, training_loss: 1.31622
Epoch: 3/10, step: 42479, training_loss: 1.03115
Epoch: 3/10, step: 42499, training_loss: 0.96081
Epoch: 3/10, step: 42519, training_loss: 1.10244
Epoch: 3/10, step: 42539, training_loss: 1.33313
Epoch: 3/10, step: 42559, training_loss: 1.16766
Epoch: 3/10, step: 42579, training_loss: 1.81368
Epoch: 3/10, step: 42599, training_loss: 1.61690
Epoch: 3/10, step: 42619, training_loss: 1.21049
Epoch: 3/10, step: 42639, training_loss: 1.53958
Epoch: 3/10, step: 42659, training_loss: 1.88711
Epoch: 3/10, step: 42679, training_loss: 1.23704
Epoch: 3/10, step: 42699, training_loss: 1.76795
Epoch: 3/10, step: 42719, training_loss: 0.93712
Epoch: 3/10, step: 42739, training_loss: 1.89304
Epoch: 3/10, step: 42759, training_loss: 1.23731
Epoch: 3/10, step: 42779, training_loss: 0.82336
Epoch: 3/10, step: 42799, training_loss: 1.21840
Epoch: 3/10, step: 42819, training_loss: 1.43746
Epoch: 3/10, step: 42839, training_loss: 1.19700
Epoch: 3/10, step: 42859, training_loss: 1.18709
Epoch: 3/10, step: 42879, training_loss: 1.31617
Epoch: 3/10, step: 42899, training_loss: 0.74472
Epoch: 3/10, step: 42919, training_loss: 1.58076
Epoch: 3/10, step: 42939, training_loss: 1.34940
Epoch: 3/10, step: 42959, training_loss: 1.61767
Epoch: 3/10, step: 42979, training_loss: 1.97899
Epoch: 3/10, step: 42999, training_loss: 0.66589
accuracy: 0.51, validation_loss: 1.53691828250885, num_samples: 100
Epoch: 3/10, step: 43019, training_loss: 1.31838
Epoch: 3/10, step: 43039, training_loss: 1.33837
Epoch: 3/10, step: 43059, training_loss: 1.54106
Epoch: 3/10, step: 43079, training_loss: 0.87186
Epoch: 3/10, step: 43099, training_loss: 1.26852
Epoch: 3/10, step: 43119, training_loss: 1.38809
Epoch: 3/10, step: 43139, training_loss: 1.37467
Epoch: 3/10, step: 43159, training_loss: 0.93082
Epoch: 3/10, step: 43179, training_loss: 1.72375
Epoch: 3/10, step: 43199, training_loss: 1.50388
Epoch: 3/10, step: 43219, training_loss: 1.50959
Epoch: 3/10, step: 43239, training_loss: 2.38363
Epoch: 3/10, step: 43259, training_loss: 1.32987
Epoch: 3/10, step: 43279, training_loss: 2.03798
Epoch: 3/10, step: 43299, training_loss: 1.16971
Epoch: 3/10, step: 43319, training_loss: 1.07977
Epoch: 3/10, step: 43339, training_loss: 1.74044
Epoch: 3/10, step: 43359, training_loss: 1.24082
Epoch: 3/10, step: 43379, training_loss: 2.09438
Epoch: 3/10, step: 43399, training_loss: 1.21478
Epoch: 3/10, step: 43419, training_loss: 1.29795
Epoch: 3/10, step: 43439, training_loss: 2.00348
Epoch: 3/10, step: 43459, training_loss: 1.26818
Epoch: 3/10, step: 43479, training_loss: 1.54811
Epoch: 3/10, step: 43499, training_loss: 2.06447
Epoch: 3/10, step: 43519, training_loss: 1.57029
Epoch: 3/10, step: 43539, training_loss: 1.59704
Epoch: 3/10, step: 43559, training_loss: 1.11299
Epoch: 3/10, step: 43579, training_loss: 1.39787
Epoch: 3/10, step: 43599, training_loss: 1.45959
Epoch: 3/10, step: 43619, training_loss: 2.04166
Epoch: 3/10, step: 43639, training_loss: 0.88143
Epoch: 3/10, step: 43659, training_loss: 1.38653
Epoch: 3/10, step: 43679, training_loss: 1.50388
Epoch: 3/10, step: 43699, training_loss: 1.37349
Epoch: 3/10, step: 43719, training_loss: 1.10687
Epoch: 3/10, step: 43739, training_loss: 1.29082
Epoch: 3/10, step: 43759, training_loss: 1.71031
Epoch: 3/10, step: 43779, training_loss: 1.11945
Epoch: 3/10, step: 43799, training_loss: 0.59072
Epoch: 3/10, step: 43819, training_loss: 1.62437
Epoch: 3/10, step: 43839, training_loss: 2.21581
Epoch: 3/10, step: 43859, training_loss: 1.03231
Epoch: 3/10, step: 43879, training_loss: 1.23430
Epoch: 3/10, step: 43899, training_loss: 1.07878
Epoch: 3/10, step: 43919, training_loss: 1.29282
Epoch: 3/10, step: 43939, training_loss: 1.61062
Epoch: 3/10, step: 43959, training_loss: 1.62229
Epoch: 3/10, step: 43979, training_loss: 1.66316
Epoch: 3/10, step: 43999, training_loss: 0.99350
accuracy: 0.43, validation_loss: 1.6858221292495728, num_samples: 100
Epoch: 3/10, step: 44019, training_loss: 1.37925
Epoch: 3/10, step: 44039, training_loss: 1.73550
Epoch: 3/10, step: 44059, training_loss: 1.53673
Epoch: 3/10, step: 44079, training_loss: 1.88395
Epoch: 3/10, step: 44099, training_loss: 1.52826
Epoch: 3/10, step: 44119, training_loss: 0.70661
Epoch: 3/10, step: 44139, training_loss: 1.44279
Epoch: 3/10, step: 44159, training_loss: 1.35608
Epoch: 3/10, step: 44179, training_loss: 1.87183
Epoch: 3/10, step: 44199, training_loss: 0.79194
Epoch: 3/10, step: 44219, training_loss: 1.83219
Epoch: 3/10, step: 44239, training_loss: 0.94984
Epoch: 3/10, step: 44259, training_loss: 1.54488
Epoch: 3/10, step: 44279, training_loss: 1.10373
Epoch: 3/10, step: 44299, training_loss: 1.70542
Epoch: 3/10, step: 44319, training_loss: 1.37432
Epoch: 3/10, step: 44339, training_loss: 1.50768
Epoch: 3/10, step: 44359, training_loss: 1.53711
Epoch: 3/10, step: 44379, training_loss: 1.60278
Epoch: 3/10, step: 44399, training_loss: 1.40270
Epoch: 3/10, step: 44419, training_loss: 1.20557
Epoch: 3/10, step: 44439, training_loss: 1.74767
Epoch: 3/10, step: 44459, training_loss: 2.04392
Epoch: 3/10, step: 44479, training_loss: 1.60829
Epoch: 3/10, step: 44499, training_loss: 1.00894
Epoch: 3/10, step: 44519, training_loss: 2.01024
Epoch: 3/10, step: 44539, training_loss: 1.69879
Epoch: 3/10, step: 44559, training_loss: 1.56572
Epoch: 3/10, step: 44579, training_loss: 1.86084
Epoch: 3/10, step: 44599, training_loss: 1.51217
Epoch: 3/10, step: 44619, training_loss: 0.96808
Epoch: 3/10, step: 44639, training_loss: 1.63694
Epoch: 3/10, step: 44659, training_loss: 1.71655
Epoch: 3/10, step: 44679, training_loss: 1.34370
Epoch: 3/10, step: 44699, training_loss: 1.02158
Epoch: 3/10, step: 44719, training_loss: 1.47084
Epoch: 3/10, step: 44739, training_loss: 1.08866
Epoch: 3/10, step: 44759, training_loss: 1.10538
Epoch: 3/10, step: 44779, training_loss: 1.18128
Epoch: 3/10, step: 44799, training_loss: 1.43446
Epoch: 3/10, step: 44819, training_loss: 1.14587
Epoch: 3/10, step: 44839, training_loss: 1.97098
Epoch: 3/10, step: 44859, training_loss: 1.34672
Epoch: 3/10, step: 44879, training_loss: 1.65269
Epoch: 3/10, step: 44899, training_loss: 1.45042
Epoch: 3/10, step: 44919, training_loss: 1.37363
Epoch: 3/10, step: 44939, training_loss: 1.25709
Epoch: 3/10, step: 44959, training_loss: 1.83589
Epoch: 3/10, step: 44979, training_loss: 1.28543
Epoch: 3/10, step: 44999, training_loss: 1.26276
accuracy: 0.46, validation_loss: 1.4341998100280762, num_samples: 100
Epoch: 3/10, step: 45019, training_loss: 1.34868
Epoch: 3/10, step: 45039, training_loss: 2.29872
Epoch: 3/10, step: 45059, training_loss: 1.67627
Epoch: 3/10, step: 45079, training_loss: 1.36076
Epoch: 3/10, step: 45099, training_loss: 1.06391
Epoch: 3/10, step: 45119, training_loss: 1.68430
Epoch: 3/10, step: 45139, training_loss: 1.44389
Epoch: 3/10, step: 45159, training_loss: 1.65020
Epoch: 3/10, step: 45179, training_loss: 0.83205
Epoch: 3/10, step: 45199, training_loss: 1.26930
Epoch: 3/10, step: 45219, training_loss: 1.11085
Epoch: 3/10, step: 45239, training_loss: 1.41099
Epoch: 3/10, step: 45259, training_loss: 1.99353
Epoch: 3/10, step: 45279, training_loss: 1.62647
Epoch: 3/10, step: 45299, training_loss: 1.23963
Epoch: 3/10, step: 45319, training_loss: 0.95844
Epoch: 3/10, step: 45339, training_loss: 1.12142
Epoch: 3/10, step: 45359, training_loss: 1.17249
Epoch: 3/10, step: 45379, training_loss: 1.01899
Epoch: 3/10, step: 45399, training_loss: 0.97712
Epoch: 3/10, step: 45419, training_loss: 0.96572
Epoch: 3/10, step: 45439, training_loss: 1.45379
Epoch: 3/10, step: 45459, training_loss: 1.31200
Epoch: 3/10, step: 45479, training_loss: 2.40076
Epoch: 3/10, step: 45499, training_loss: 1.57305
Epoch: 3/10, step: 45519, training_loss: 1.14247
Epoch: 3/10, step: 45539, training_loss: 1.17028
Epoch: 3/10, step: 45559, training_loss: 1.98396
Epoch: 3/10, step: 45579, training_loss: 1.48386
Epoch: 3/10, step: 45599, training_loss: 1.63364
Epoch: 3/10, step: 45619, training_loss: 1.71076
Epoch: 3/10, step: 45639, training_loss: 1.72836
Epoch: 3/10, step: 45659, training_loss: 1.45220
Epoch: 3/10, step: 45679, training_loss: 1.71133
Epoch: 3/10, step: 45699, training_loss: 1.09245
Epoch: 3/10, step: 45719, training_loss: 1.20579
Epoch: 3/10, step: 45739, training_loss: 1.15108
Epoch: 3/10, step: 45759, training_loss: 1.52118
Epoch: 3/10, step: 45779, training_loss: 1.79931
Epoch: 3/10, step: 45799, training_loss: 1.88956
Epoch: 3/10, step: 45819, training_loss: 1.62373
Epoch: 3/10, step: 45839, training_loss: 1.69347
Epoch: 3/10, step: 45859, training_loss: 1.42260
Epoch: 3/10, step: 45879, training_loss: 0.62783
Epoch: 3/10, step: 45899, training_loss: 1.25248
Epoch: 3/10, step: 45919, training_loss: 0.74715
Epoch: 3/10, step: 45939, training_loss: 1.98490
Epoch: 3/10, step: 45959, training_loss: 1.02843
Epoch: 3/10, step: 45979, training_loss: 2.27216
Epoch: 3/10, step: 45999, training_loss: 1.32121
accuracy: 0.53, validation_loss: 1.3471788167953491, num_samples: 100
Epoch: 3/10, step: 46019, training_loss: 1.29526
Epoch: 3/10, step: 46039, training_loss: 0.89423
Epoch: 3/10, step: 46059, training_loss: 1.32390
Epoch: 3/10, step: 46079, training_loss: 1.69292
Epoch: 3/10, step: 46099, training_loss: 1.43760
Epoch: 3/10, step: 46119, training_loss: 1.22504
Epoch: 3/10, step: 46139, training_loss: 1.07595
Epoch: 3/10, step: 46159, training_loss: 2.01829
Epoch: 3/10, step: 46179, training_loss: 1.20085
Epoch: 3/10, step: 46199, training_loss: 1.35099
Epoch: 3/10, step: 46219, training_loss: 1.10162
Epoch: 3/10, step: 46239, training_loss: 1.35996
Epoch: 3/10, step: 46259, training_loss: 1.12322
Epoch: 3/10, step: 46279, training_loss: 2.17110
Epoch: 3/10, step: 46299, training_loss: 1.91745
Epoch: 3/10, step: 46319, training_loss: 1.37023
Epoch: 3/10, step: 46339, training_loss: 1.32201
Epoch: 3/10, step: 46359, training_loss: 1.03087
Epoch: 3/10, step: 46379, training_loss: 1.33537
Epoch: 3/10, step: 46399, training_loss: 1.54168
Epoch: 3/10, step: 46419, training_loss: 1.14852
Epoch: 3/10, step: 46439, training_loss: 1.30354
Epoch: 3/10, step: 46459, training_loss: 0.75758
Epoch: 3/10, step: 46479, training_loss: 1.18365
Epoch: 3/10, step: 46499, training_loss: 1.68457
Epoch: 3/10, step: 46519, training_loss: 1.59827
Epoch: 3/10, step: 46539, training_loss: 2.31163
Epoch: 3/10, step: 46559, training_loss: 1.69256
Epoch: 3/10, step: 46579, training_loss: 1.14467
Epoch: 3/10, step: 46599, training_loss: 1.45910
Epoch: 3/10, step: 46619, training_loss: 1.25816
Epoch: 3/10, step: 46639, training_loss: 1.39507
Epoch: 3/10, step: 46659, training_loss: 1.08131
Epoch: 3/10, step: 46679, training_loss: 0.83151
Epoch: 3/10, step: 46699, training_loss: 1.74426
Epoch: 3/10, step: 46719, training_loss: 1.17493
Epoch: 3/10, step: 46739, training_loss: 1.40917
Epoch: 3/10, step: 46759, training_loss: 0.89405
Epoch: 3/10, step: 46779, training_loss: 1.52347
Epoch: 3/10, step: 46799, training_loss: 1.14993
Epoch: 3/10, step: 46819, training_loss: 1.27387
Epoch: 3/10, step: 46839, training_loss: 1.64814
Epoch: 3/10, step: 46859, training_loss: 1.79289
Epoch: 3/10, step: 46879, training_loss: 0.90534
Epoch: 3/10, step: 46899, training_loss: 1.21317
Epoch: 3/10, step: 46919, training_loss: 1.59042
Epoch: 3/10, step: 46939, training_loss: 1.86575
Epoch: 3/10, step: 46959, training_loss: 1.49487
Epoch: 3/10, step: 46979, training_loss: 1.46782
Epoch: 3/10, step: 46999, training_loss: 1.25925
accuracy: 0.47, validation_loss: 1.4589169025421143, num_samples: 100
Epoch: 3/10, step: 47019, training_loss: 1.51165
Epoch: 3/10, step: 47039, training_loss: 1.08712
Epoch: 3/10, step: 47059, training_loss: 1.38182
Epoch: 3/10, step: 47079, training_loss: 1.68280
Epoch: 3/10, step: 47099, training_loss: 1.18843
Epoch: 3/10, step: 47119, training_loss: 1.45520
Epoch: 3/10, step: 47139, training_loss: 1.30125
Epoch: 3/10, step: 47159, training_loss: 1.40544
Epoch: 3/10, step: 47179, training_loss: 1.34071
Epoch: 3/10, step: 47199, training_loss: 1.47152
Epoch: 3/10, step: 47219, training_loss: 1.06412
Epoch: 3/10, step: 47239, training_loss: 1.59518
Epoch: 3/10, step: 47259, training_loss: 2.26042
Epoch: 3/10, step: 47279, training_loss: 1.85359
Epoch: 3/10, step: 47299, training_loss: 1.37147
Epoch: 3/10, step: 47319, training_loss: 1.57212
Epoch: 3/10, step: 47339, training_loss: 1.57877
Epoch: 3/10, step: 47359, training_loss: 1.50345
Epoch: 3/10, step: 47379, training_loss: 1.71123
Epoch: 3/10, step: 47399, training_loss: 1.48656
Epoch: 3/10, step: 47419, training_loss: 1.73336
Epoch: 3/10, step: 47439, training_loss: 0.98984
Epoch: 3/10, step: 47459, training_loss: 1.15229
Epoch: 3/10, step: 47479, training_loss: 1.33094
Epoch: 3/10, step: 47499, training_loss: 1.47484
Epoch: 3/10, step: 47519, training_loss: 0.90235
Epoch: 3/10, step: 47539, training_loss: 0.92574
Epoch: 3/10, step: 47559, training_loss: 0.68394
Epoch: 3/10, step: 47579, training_loss: 1.13261
Epoch: 3/10, step: 47599, training_loss: 1.68761
Epoch: 3/10, step: 47619, training_loss: 1.57685
Epoch: 3/10, step: 47639, training_loss: 2.25180
Epoch: 3/10, step: 47659, training_loss: 2.28797
Epoch: 3/10, step: 47679, training_loss: 1.32275
Epoch: 3/10, step: 47699, training_loss: 1.20301
Epoch: 3/10, step: 47719, training_loss: 1.18606
Epoch: 3/10, step: 47739, training_loss: 0.80612
Epoch: 3/10, step: 47759, training_loss: 1.28472
Epoch: 3/10, step: 47779, training_loss: 1.04977
Epoch: 3/10, step: 47799, training_loss: 1.20640
Epoch: 3/10, step: 47819, training_loss: 1.37475
Epoch: 3/10, step: 47839, training_loss: 1.26022
Epoch: 3/10, step: 47859, training_loss: 1.04023
Epoch: 3/10, step: 47879, training_loss: 1.99892
Epoch: 3/10, step: 47899, training_loss: 1.43572
Epoch: 3/10, step: 47919, training_loss: 1.15067
Epoch: 3/10, step: 47939, training_loss: 1.60876
Epoch: 3/10, step: 47959, training_loss: 1.43695
Epoch: 3/10, step: 47979, training_loss: 1.51869
Epoch: 3/10, step: 47999, training_loss: 1.24335
accuracy: 0.48, validation_loss: 1.3326693773269653, num_samples: 100
Epoch: 3/10, step: 48019, training_loss: 1.40398
Epoch: 3/10, step: 48039, training_loss: 1.16734
Epoch: 3/10, step: 48059, training_loss: 1.25348
Epoch: 3/10, step: 48079, training_loss: 1.49125
Epoch: 3/10, step: 48099, training_loss: 2.14120
Epoch: 3/10, step: 48119, training_loss: 1.18034
Epoch: 3/10, step: 48139, training_loss: 1.45286
Epoch: 3/10, step: 48159, training_loss: 1.72928
Epoch: 3/10, step: 48179, training_loss: 2.34778
Epoch: 3/10, step: 48199, training_loss: 1.67201
Epoch: 3/10, step: 48219, training_loss: 2.17872
Epoch: 3/10, step: 48239, training_loss: 1.45413
Epoch: 3/10, step: 48259, training_loss: 0.72914
Epoch: 3/10, step: 48279, training_loss: 1.20644
Epoch: 3/10, step: 48299, training_loss: 1.14701
Epoch: 3/10, step: 48319, training_loss: 1.41076
Epoch: 3/10, step: 48339, training_loss: 1.53393
Epoch: 3/10, step: 48359, training_loss: 1.39582
Epoch: 3/10, step: 48379, training_loss: 0.92932
Epoch: 3/10, step: 48399, training_loss: 1.25364
Epoch: 3/10, step: 48419, training_loss: 0.92447
Epoch: 3/10, step: 48439, training_loss: 0.55569
Epoch: 3/10, step: 48459, training_loss: 1.07750
Epoch: 3/10, step: 48479, training_loss: 1.28963
Epoch: 3/10, step: 48499, training_loss: 2.79813
Epoch: 3/10, step: 48519, training_loss: 1.70721
Epoch: 3/10, step: 48539, training_loss: 1.24376
Epoch: 3/10, step: 48559, training_loss: 2.30092
Epoch: 3/10, step: 48579, training_loss: 1.45579
Epoch: 3/10, step: 48599, training_loss: 1.48345
Epoch: 3/10, step: 48619, training_loss: 1.13276
Epoch: 3/10, step: 48639, training_loss: 1.65953
Epoch: 3/10, step: 48659, training_loss: 1.97180
Epoch: 3/10, step: 48679, training_loss: 1.61761
Epoch: 3/10, step: 48699, training_loss: 1.17111
Epoch: 3/10, step: 48719, training_loss: 1.23186
Epoch: 3/10, step: 48739, training_loss: 1.62837
Epoch: 3/10, step: 48759, training_loss: 1.99253
Epoch: 3/10, step: 48779, training_loss: 2.12302
Epoch: 3/10, step: 48799, training_loss: 1.79243
Epoch: 3/10, step: 48819, training_loss: 1.50234
Epoch: 3/10, step: 48839, training_loss: 1.49170
Epoch: 3/10, step: 48859, training_loss: 1.21131
Epoch: 3/10, step: 48879, training_loss: 2.36226
Epoch: 3/10, step: 48899, training_loss: 1.30760
Epoch: 3/10, step: 48919, training_loss: 1.41554
Epoch: 3/10, step: 48939, training_loss: 1.72178
Epoch: 3/10, step: 48959, training_loss: 1.36431
Epoch: 3/10, step: 48979, training_loss: 1.93702
Epoch: 3/10, step: 48999, training_loss: 1.12303
accuracy: 0.5, validation_loss: 1.5479397773742676, num_samples: 100
Epoch: 3/10, step: 49019, training_loss: 1.62067
Epoch: 3/10, step: 49039, training_loss: 1.13844
Epoch: 3/10, step: 49059, training_loss: 2.02224
Epoch: 3/10, step: 49079, training_loss: 1.92270
Epoch: 3/10, step: 49099, training_loss: 1.73358
Epoch: 3/10, step: 49119, training_loss: 1.83902
Epoch: 3/10, step: 49139, training_loss: 0.98175
Epoch: 3/10, step: 49159, training_loss: 1.38704
Epoch: 3/10, step: 49179, training_loss: 1.00044
Epoch: 3/10, step: 49199, training_loss: 1.54093
Epoch: 3/10, step: 49219, training_loss: 1.49474
Epoch: 3/10, step: 49239, training_loss: 1.41787
Epoch: 3/10, step: 49259, training_loss: 1.81642
Epoch: 3/10, step: 49279, training_loss: 1.66272
Epoch: 3/10, step: 49299, training_loss: 1.86152
Epoch: 3/10, step: 49319, training_loss: 1.10704
Epoch: 3/10, step: 49339, training_loss: 1.09535
Epoch: 3/10, step: 49359, training_loss: 1.45506
Epoch: 3/10, step: 49379, training_loss: 1.64417
Epoch: 3/10, step: 49399, training_loss: 1.31423
Epoch: 3/10, step: 49419, training_loss: 1.54804
Epoch: 3/10, step: 49439, training_loss: 1.55123
Epoch: 3/10, step: 49459, training_loss: 1.13540
Epoch: 3/10, step: 49479, training_loss: 1.26894
Epoch: 3/10, step: 49499, training_loss: 0.96150
Epoch: 3/10, step: 49519, training_loss: 1.35921
Epoch: 3/10, step: 49539, training_loss: 1.40487
Epoch: 3/10, step: 49559, training_loss: 1.09131
Epoch: 3/10, step: 49579, training_loss: 2.81524
Epoch: 3/10, step: 49599, training_loss: 1.58313
Epoch: 3/10, step: 49619, training_loss: 0.74674
Epoch: 3/10, step: 49639, training_loss: 0.80450
Epoch: 3/10, step: 49659, training_loss: 1.41521
Epoch: 3/10, step: 49679, training_loss: 1.59410
Epoch: 3/10, step: 49699, training_loss: 1.08150
Epoch: 3/10, step: 49719, training_loss: 1.54966
Epoch: 3/10, step: 49739, training_loss: 1.00590
Epoch: 3/10, step: 49759, training_loss: 1.60768
Epoch: 3/10, step: 49779, training_loss: 1.23169
Epoch: 3/10, step: 49799, training_loss: 1.11438
Epoch: 3/10, step: 49819, training_loss: 1.20528
Epoch: 3/10, step: 49839, training_loss: 1.52394
Epoch: 3/10, step: 49859, training_loss: 1.10246
Epoch: 3/10, step: 49879, training_loss: 1.47838
Epoch: 3/10, step: 49899, training_loss: 1.35262
Epoch: 3/10, step: 49919, training_loss: 1.12425
Epoch: 3/10, step: 49939, training_loss: 1.51880
Epoch: 3/10, step: 49959, training_loss: 1.22729
Epoch: 3/10, step: 49979, training_loss: 1.94155
Epoch: 3/10, step: 49999, training_loss: 0.60910
accuracy: 0.47, validation_loss: 1.5200331211090088, num_samples: 100
Epoch: 3/10, step: 50019, training_loss: 1.71268
Epoch: 3/10, step: 50039, training_loss: 1.08515
Epoch: 3/10, step: 50059, training_loss: 2.09964
Epoch: 3/10, step: 50079, training_loss: 1.32157
Epoch: 3/10, step: 50099, training_loss: 1.33452
Epoch: 3/10, step: 50119, training_loss: 1.60671
Epoch: 3/10, step: 50139, training_loss: 0.80570
Epoch: 3/10, step: 50159, training_loss: 1.72634
Epoch: 3/10, step: 50179, training_loss: 1.75412
Epoch: 3/10, step: 50199, training_loss: 1.59187
Epoch: 3/10, step: 50219, training_loss: 1.27577
Epoch: 3/10, step: 50239, training_loss: 1.17723
Epoch: 3/10, step: 50259, training_loss: 1.19895
Epoch: 3/10, step: 50279, training_loss: 1.82144
Epoch: 3/10, step: 50299, training_loss: 0.94585
Epoch: 3/10, step: 50319, training_loss: 0.75094
Epoch: 3/10, step: 50339, training_loss: 1.18147
Epoch: 3/10, step: 50359, training_loss: 1.66609
Epoch: 3/10, step: 50379, training_loss: 1.27867
Epoch: 3/10, step: 50399, training_loss: 1.16312
Epoch: 3/10, step: 50419, training_loss: 1.49981
Epoch: 3/10, step: 50439, training_loss: 1.07451
Epoch: 3/10, step: 50459, training_loss: 1.76432
Epoch: 3/10, step: 50479, training_loss: 0.92929
Epoch: 3/10, step: 50499, training_loss: 1.49413
Epoch: 3/10, step: 50519, training_loss: 1.13171
Epoch: 3/10, step: 50539, training_loss: 1.56181
Epoch: 3/10, step: 50559, training_loss: 1.23632
Epoch: 3/10, step: 50579, training_loss: 1.35039
Epoch: 3/10, step: 50599, training_loss: 1.51987
Epoch: 3/10, step: 50619, training_loss: 1.42687
Epoch: 3/10, step: 50639, training_loss: 1.75875
Epoch: 3/10, step: 50659, training_loss: 1.94017
Epoch: 3/10, step: 50679, training_loss: 1.45284
Epoch: 3/10, step: 50699, training_loss: 1.17899
Epoch: 3/10, step: 50719, training_loss: 1.73224
Epoch: 3/10, step: 50739, training_loss: 1.90711
Epoch: 3/10, step: 50759, training_loss: 1.02273
Epoch: 3/10, step: 50779, training_loss: 1.10307
Epoch: 3/10, step: 50799, training_loss: 1.33227
Epoch: 3/10, step: 50819, training_loss: 1.42942
Epoch: 3/10, step: 50839, training_loss: 1.57440
Epoch: 3/10, step: 50859, training_loss: 1.66853
Epoch: 3/10, step: 50879, training_loss: 1.55152
Epoch: 3/10, step: 50899, training_loss: 0.77360
Epoch: 3/10, step: 50919, training_loss: 1.41600
Epoch: 3/10, step: 50939, training_loss: 1.76662
Epoch: 3/10, step: 50959, training_loss: 1.27837
Epoch: 3/10, step: 50979, training_loss: 1.75376
Epoch: 3/10, step: 50999, training_loss: 1.18014
accuracy: 0.49, validation_loss: 1.4436378479003906, num_samples: 100
Epoch: 3/10, step: 51019, training_loss: 1.84730
Epoch: 3/10, step: 51039, training_loss: 2.06800
Epoch: 3/10, step: 51059, training_loss: 0.96372
Epoch: 3/10, step: 51079, training_loss: 0.88205
Epoch: 3/10, step: 51099, training_loss: 1.93427
Epoch: 3/10, step: 51119, training_loss: 1.63329
Epoch: 3/10, step: 51139, training_loss: 1.85811
Epoch: 3/10, step: 51159, training_loss: 1.08949
Epoch: 3/10, step: 51179, training_loss: 1.80425
Epoch: 3/10, step: 51199, training_loss: 1.32474
Epoch: 3/10, step: 51219, training_loss: 1.05931
Epoch: 3/10, step: 51239, training_loss: 1.15649
Epoch: 3/10, step: 51259, training_loss: 2.02414
Epoch: 3/10, step: 51279, training_loss: 1.39586
Epoch: 3/10, step: 51299, training_loss: 1.46960
Epoch: 3/10, step: 51319, training_loss: 1.08103
Epoch: 3/10, step: 51339, training_loss: 1.16009
Epoch: 3/10, step: 51359, training_loss: 0.89610
Epoch: 3/10, step: 51379, training_loss: 1.33684
Epoch: 3/10, step: 51399, training_loss: 1.93924
Epoch: 3/10, step: 51419, training_loss: 1.93332
Epoch: 3/10, step: 51439, training_loss: 2.07172
Epoch: 3/10, step: 51459, training_loss: 1.93241
Epoch: 3/10, step: 51479, training_loss: 1.07666
Epoch: 3/10, step: 51499, training_loss: 1.31200
Epoch: 3/10, step: 51519, training_loss: 1.37662
Epoch: 3/10, step: 51539, training_loss: 1.40992
Epoch: 3/10, step: 51559, training_loss: 0.73384
Epoch: 3/10, step: 51579, training_loss: 1.23843
Epoch: 3/10, step: 51599, training_loss: 1.10956
Epoch: 3/10, step: 51619, training_loss: 1.25283
Epoch: 3/10, step: 51639, training_loss: 1.01116
Epoch: 3/10, step: 51659, training_loss: 1.67189
Epoch: 3/10, step: 51679, training_loss: 1.68075
Epoch: 3/10, step: 51699, training_loss: 1.23089
Epoch: 3/10, step: 51719, training_loss: 1.29942
Epoch: 3/10, step: 51739, training_loss: 2.05225
Epoch: 3/10, step: 51759, training_loss: 1.26521
Epoch: 3/10, step: 51779, training_loss: 1.58487
Epoch: 3/10, step: 51799, training_loss: 1.46040
Epoch: 3/10, step: 51819, training_loss: 0.98786
Epoch: 3/10, step: 51839, training_loss: 0.99155
Epoch: 3/10, step: 51859, training_loss: 1.33948
Epoch: 3/10, step: 51879, training_loss: 1.46983
Epoch: 3/10, step: 51899, training_loss: 2.19124
Epoch: 3/10, step: 51919, training_loss: 1.16854
Epoch: 3/10, step: 51939, training_loss: 0.98121
Epoch: 3/10, step: 51959, training_loss: 0.98999
Epoch: 3/10, step: 51979, training_loss: 1.71717
Epoch: 3/10, step: 51999, training_loss: 0.98448
accuracy: 0.46, validation_loss: 1.473726511001587, num_samples: 100
Epoch: 3/10, step: 52019, training_loss: 1.98049
Epoch: 3/10, step: 52039, training_loss: 1.02957
Epoch: 3/10, step: 52059, training_loss: 1.66681
Epoch: 3/10, step: 52079, training_loss: 1.42807
Epoch: 3/10, step: 52099, training_loss: 2.36835
Epoch: 3/10, step: 52119, training_loss: 1.69037
Epoch: 3/10, step: 52139, training_loss: 1.61247
Epoch: 3/10, step: 52159, training_loss: 1.53747
Epoch: 3/10, step: 52179, training_loss: 0.96627
Epoch: 3/10, step: 52199, training_loss: 2.13265
Epoch: 3/10, step: 52219, training_loss: 1.08484
Epoch: 3/10, step: 52239, training_loss: 1.41089
Epoch: 3/10, step: 52259, training_loss: 2.41779
Epoch: 3/10, step: 52279, training_loss: 1.31557
Epoch: 3/10, step: 52299, training_loss: 1.14873
Epoch: 3/10, step: 52319, training_loss: 1.34195
Epoch: 3/10, step: 52339, training_loss: 1.46099
Epoch: 3/10, step: 52359, training_loss: 1.66109
Epoch: 3/10, step: 52379, training_loss: 1.43703
Epoch: 3/10, step: 52399, training_loss: 1.02066
Epoch: 3/10, step: 52419, training_loss: 1.87657
Epoch: 3/10, step: 52439, training_loss: 1.02332
Epoch: 3/10, step: 52459, training_loss: 1.35245
Epoch: 3/10, step: 52479, training_loss: 1.67069
Epoch: 3/10, step: 52499, training_loss: 0.96596
Epoch: 3/10, step: 52519, training_loss: 0.85211
Epoch: 3/10, step: 52539, training_loss: 2.24679
Epoch: 3/10, step: 52559, training_loss: 2.08576
Epoch: 3/10, step: 52579, training_loss: 1.04517
Epoch: 3/10, step: 52599, training_loss: 1.66113
Epoch: 3/10, step: 52619, training_loss: 1.46434
Epoch: 3/10, step: 52639, training_loss: 1.12740
Epoch: 3/10, step: 52659, training_loss: 1.11495
Epoch: 3/10, step: 52679, training_loss: 1.55734
Epoch: 3/10, step: 52699, training_loss: 1.32080
Epoch: 3/10, step: 52719, training_loss: 1.48701
Epoch: 3/10, step: 52739, training_loss: 1.39548
Epoch: 3/10, step: 52759, training_loss: 1.07670
Epoch: 3/10, step: 52779, training_loss: 1.39299
Epoch: 3/10, step: 52799, training_loss: 1.37191
Epoch: 3/10, step: 52819, training_loss: 1.04986
Epoch: 3/10, step: 52839, training_loss: 1.67690
Epoch: 3/10, step: 52859, training_loss: 1.24623
Epoch: 3/10, step: 52879, training_loss: 1.59990
Epoch: 3/10, step: 52899, training_loss: 1.39214
Epoch: 3/10, step: 52919, training_loss: 1.44713
Epoch: 3/10, step: 52939, training_loss: 1.80417
Epoch: 3/10, step: 52959, training_loss: 1.24421
Epoch: 3/10, step: 52979, training_loss: 1.21902
Epoch: 3/10, step: 52999, training_loss: 0.97735
accuracy: 0.49, validation_loss: 1.4456510543823242, num_samples: 100
Epoch: 3/10, step: 53019, training_loss: 1.39159
Epoch: 3/10, step: 53039, training_loss: 1.93914
Epoch: 3/10, step: 53059, training_loss: 1.49827
Epoch: 3/10, step: 53079, training_loss: 1.46212
Epoch: 3/10, step: 53099, training_loss: 1.84262
Epoch: 3/10, step: 53119, training_loss: 1.23832
Epoch: 3/10, step: 53139, training_loss: 1.29084
Epoch: 3/10, step: 53159, training_loss: 1.17014
Epoch: 3/10, step: 53179, training_loss: 1.59747
Epoch: 3/10, step: 53199, training_loss: 1.20511
Epoch: 3/10, step: 53219, training_loss: 1.23230
Epoch: 3/10, step: 53239, training_loss: 0.73227
Epoch: 3/10, step: 53259, training_loss: 1.44504
Epoch: 3/10, step: 53279, training_loss: 1.30854
Epoch: 3/10, step: 53299, training_loss: 1.58149
Epoch: 3/10, step: 53319, training_loss: 1.86579
Epoch: 3/10, step: 53339, training_loss: 1.53205
Epoch: 3/10, step: 53359, training_loss: 2.11464
Epoch: 3/10, step: 53379, training_loss: 1.99061
Epoch: 3/10, step: 53399, training_loss: 1.03780
Epoch: 3/10, step: 53419, training_loss: 1.39082
Epoch: 3/10, step: 53439, training_loss: 1.57913
Epoch: 3/10, step: 53459, training_loss: 1.21207
Epoch: 3/10, step: 53479, training_loss: 1.46992
Epoch: 3/10, step: 53499, training_loss: 0.83840
Epoch: 3/10, step: 53519, training_loss: 1.35349
Epoch: 3/10, step: 53539, training_loss: 1.32180
Epoch: 3/10, step: 53559, training_loss: 0.96313
Epoch: 3/10, step: 53579, training_loss: 1.49056
Epoch: 3/10, step: 53599, training_loss: 1.66524
Epoch: 3/10, step: 53619, training_loss: 1.70642
Epoch: 3/10, step: 53639, training_loss: 1.51937
Epoch: 3/10, step: 53659, training_loss: 1.31343
Epoch: 3/10, step: 53679, training_loss: 1.61384
Epoch: 3/10, step: 53699, training_loss: 1.38106
Epoch: 3/10, step: 53719, training_loss: 1.41874
Epoch: 3/10, step: 53739, training_loss: 2.07969
Epoch: 3/10, step: 53759, training_loss: 0.89079
Epoch: 3/10, step: 53779, training_loss: 0.92490
Epoch: 3/10, step: 53799, training_loss: 0.76637
Epoch: 3/10, step: 53819, training_loss: 1.53997
Epoch: 3/10, step: 53839, training_loss: 1.57739
Epoch: 3/10, step: 53859, training_loss: 1.68632
Epoch: 3/10, step: 53879, training_loss: 1.45300
Epoch: 3/10, step: 53899, training_loss: 2.00953
Epoch: 3/10, step: 53919, training_loss: 1.66633
Epoch: 3/10, step: 53939, training_loss: 1.00394
Epoch: 3/10, step: 53959, training_loss: 1.31496
Epoch: 3/10, step: 53979, training_loss: 1.17556
Epoch: 3/10, step: 53999, training_loss: 0.90736
accuracy: 0.48, validation_loss: 1.3401710987091064, num_samples: 100
Epoch: 3/10, step: 54019, training_loss: 1.55301
Epoch: 3/10, step: 54039, training_loss: 1.22192
Epoch: 3/10, step: 54059, training_loss: 1.40160
Epoch: 3/10, step: 54079, training_loss: 1.24796
Epoch: 3/10, step: 54099, training_loss: 1.61477
Epoch: 3/10, step: 54119, training_loss: 1.17037
Epoch: 3/10, step: 54139, training_loss: 1.59043
Epoch: 3/10, step: 54159, training_loss: 1.94706
Epoch: 3/10, step: 54179, training_loss: 1.69426
Epoch: 3/10, step: 54199, training_loss: 1.70212
Epoch: 3/10, step: 54219, training_loss: 1.29795
Epoch: 3/10, step: 54239, training_loss: 1.82614
Epoch: 3/10, step: 54259, training_loss: 1.58413
Epoch: 3/10, step: 54279, training_loss: 0.78361
Epoch: 3/10, step: 54299, training_loss: 1.11450
Epoch: 3/10, step: 54319, training_loss: 1.28445
Epoch: 3/10, step: 54339, training_loss: 1.29562
Epoch: 3/10, step: 54359, training_loss: 1.98701
Epoch: 3/10, step: 54379, training_loss: 1.22245
Epoch: 3/10, step: 54399, training_loss: 1.19823
Epoch: 3/10, step: 54419, training_loss: 1.06085
Epoch: 3/10, step: 54439, training_loss: 0.96602
Epoch: 3/10, step: 54459, training_loss: 1.61494
Epoch: 3/10, step: 54479, training_loss: 1.49985
Epoch: 3/10, step: 54499, training_loss: 1.34853
Epoch: 3/10, step: 54519, training_loss: 1.97623
Epoch: 3/10, step: 54539, training_loss: 1.76055
Epoch: 3/10, step: 54559, training_loss: 1.35263
Epoch: 3/10, step: 54579, training_loss: 1.32487
Epoch: 3/10, step: 54599, training_loss: 1.16065
Epoch: 3/10, step: 54619, training_loss: 0.90112
Epoch: 3/10, step: 54639, training_loss: 1.36885
Epoch: 3/10, step: 54659, training_loss: 1.37730
Epoch: 3/10, step: 54679, training_loss: 1.48810
Epoch: 3/10, step: 54699, training_loss: 1.87281
Epoch: 3/10, step: 54719, training_loss: 1.46775
Epoch: 3/10, step: 54739, training_loss: 1.81297
Epoch: 3/10, step: 54759, training_loss: 1.89010
Epoch: 3/10, step: 54779, training_loss: 1.33172
Epoch: 3/10, step: 54799, training_loss: 0.98654
Epoch: 3/10, step: 54819, training_loss: 1.47032
Epoch: 3/10, step: 54839, training_loss: 1.80080
Epoch: 3/10, step: 54859, training_loss: 1.61831
Epoch: 3/10, step: 54879, training_loss: 1.06342
Epoch: 3/10, step: 54899, training_loss: 0.76778
Epoch: 3/10, step: 54919, training_loss: 1.55308
Epoch: 3/10, step: 54939, training_loss: 2.08637
Epoch: 3/10, step: 54959, training_loss: 0.96567
Epoch: 3/10, step: 54979, training_loss: 1.95555
Epoch: 3/10, step: 54999, training_loss: 1.45909
accuracy: 0.48, validation_loss: 1.4772911071777344, num_samples: 100
Epoch: 3/10, step: 55019, training_loss: 1.82186
Epoch: 3/10, step: 55039, training_loss: 1.96751
Epoch: 3/10, step: 55059, training_loss: 0.87085
Epoch: 3/10, step: 55079, training_loss: 1.22939
Epoch: 3/10, step: 55099, training_loss: 1.13205
Epoch: 3/10, step: 55119, training_loss: 0.79304
Epoch: 3/10, step: 55139, training_loss: 1.45115
Epoch: 3/10, step: 55159, training_loss: 2.35182
Epoch: 3/10, step: 55179, training_loss: 1.57377
Epoch: 3/10, step: 55199, training_loss: 0.84636
Epoch: 3/10, step: 55219, training_loss: 1.42369
Epoch: 3/10, step: 55239, training_loss: 1.28671
Epoch: 3/10, step: 55259, training_loss: 1.40455
Epoch: 3/10, step: 55279, training_loss: 1.63742
Epoch: 3/10, step: 55299, training_loss: 1.12500
Epoch: 3/10, step: 55319, training_loss: 1.48382
Epoch: 3/10, step: 55339, training_loss: 1.91159
Epoch: 3/10, step: 55359, training_loss: 1.14667
Epoch: 3/10, step: 55379, training_loss: 1.61620
Epoch: 3/10, step: 55399, training_loss: 1.58463
Epoch: 3/10, step: 55419, training_loss: 1.10969
Epoch: 3/10, step: 55439, training_loss: 1.45049
Epoch: 3/10, step: 55459, training_loss: 1.21469
Epoch: 3/10, step: 55479, training_loss: 1.23958
Epoch: 3/10, step: 55499, training_loss: 0.75376
Epoch: 3/10, step: 55519, training_loss: 1.22298
Epoch: 3/10, step: 55539, training_loss: 1.41266
Epoch: 3/10, step: 55559, training_loss: 1.59889
Epoch: 3/10, step: 55579, training_loss: 1.40407
Epoch: 3/10, step: 55599, training_loss: 1.08768
Epoch: 3/10, step: 55619, training_loss: 1.47159
Epoch: 3/10, step: 55639, training_loss: 1.53561
Epoch: 3/10, step: 55659, training_loss: 1.46567
Epoch: 3/10, step: 55679, training_loss: 1.19441
Epoch: 3/10, step: 55699, training_loss: 0.93828
Epoch: 3/10, step: 55719, training_loss: 0.79960
Epoch: 3/10, step: 55739, training_loss: 1.38414
Epoch: 3/10, step: 55759, training_loss: 1.99274
Epoch: 3/10, step: 55779, training_loss: 1.12280
Epoch: 3/10, step: 55799, training_loss: 1.29174
Epoch: 3/10, step: 55819, training_loss: 1.28316
Epoch: 3/10, step: 55839, training_loss: 1.25312
Epoch: 3/10, step: 55859, training_loss: 1.04876
Epoch: 3/10, step: 55879, training_loss: 2.15433
Epoch: 3/10, step: 55899, training_loss: 1.10900
Epoch: 3/10, step: 55919, training_loss: 1.36278
Epoch: 3/10, step: 55939, training_loss: 2.40370
Epoch: 3/10, step: 55959, training_loss: 1.73001
Epoch: 3/10, step: 55979, training_loss: 1.40171
Epoch: 3/10, step: 55999, training_loss: 1.20636
accuracy: 0.54, validation_loss: 1.1748509407043457, num_samples: 100
Epoch: 3/10, step: 56019, training_loss: 1.87800
Epoch: 3/10, step: 56039, training_loss: 1.65046
Epoch: 3/10, step: 56059, training_loss: 0.55304
Epoch: 3/10, step: 56079, training_loss: 1.19643
Epoch: 3/10, step: 56099, training_loss: 1.29337
Epoch: 3/10, step: 56119, training_loss: 1.48976